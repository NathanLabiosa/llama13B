{"question": "Which one of the following is the most appropriate definition of a 99% confidence interval?", "choices": [{"label": "A", "text": "99% of the time in repeated samples, the interval would contain the true value of the parameter"}, {"label": "B", "text": "99% of the time in repeated samples, the interval would contain the estimated value of the parameter"}, {"label": "C", "text": "99% of the time in repeated samples, the null hypothesis will be rejected"}, {"label": "D", "text": "99% of the time in repeated samples, the null hypothesis will not be rejected when it was false"}], "answerKey": "A", "model_answer": ""}
{"question": "What is the main difference between the Dickey Fuller (DF) and Phillips-Perron (PP) approaches to unit root testing?", "choices": [{"label": "A", "text": "ADF is a single equation approach to unit root testing while PP is a systems approach"}, {"label": "B", "text": "PP tests reverse the DF null and alternative hypotheses so that there is stationarity under the null hypothesis of the PP test"}, {"label": "C", "text": "The PP test incorporates an automatic correction for autocorrelated residuals in the test regression"}, {"label": "D", "text": "PP tests have good power in small samples whereas DF tests do not."}], "answerKey": "C", "model_answer": ""}
{"question": "If there were a leverage effect in practice, what would be the shape of the news impact curve for as model that accounted for that leverage?", "choices": [{"label": "A", "text": "It would rise more quickly for negative disturbances than for positive ones of the same magnitude"}, {"label": "B", "text": "It would be symmetrical about zero"}, {"label": "C", "text": "It would rise less quickly for negative disturbances than for positive ones of the same magnitude"}, {"label": "D", "text": "It would be zero for all positive disturbances"}], "answerKey": "A", "model_answer": "LECTURE: One of the implications of the theory is that there is a leverage effect: for small positive shocks, the news impact curve may be rising, but for small negative shocks, the news impact curve may be falling. This means that the pattern of news affecting consumer sentiment differs depending on whether the news is good or bad.\nThe news impact curve measures the relationship between consumer sentiment and the amount of news. If there is a leverage effect, the news impact curve will change shape. For smaller amounts of news, the effect of good news will be higher than the effect of bad news.\nSOLUTION: If there were a leverage effect in practice, the news impact curve would rise less quickly for negative disturbances than for positive ones of the same magnitude. For smaller amounts of news, the effect of good news would be higher than the effect of bad news."}
{"question": "Which of the following statements is false concerning the linear probability model?", "choices": [{"label": "A", "text": "There is nothing in the model to ensure that the estimated probabilities lie between zero and one"}, {"label": "B", "text": "Even if the probabilities are truncated at zero and one, there will probably be many observations for which the probability is either exactly zero or exactly one"}, {"label": "C", "text": "The error terms will be heteroscedastic and not normally distributed"}, {"label": "D", "text": "The model is much harder to estimate than a standard regression model with a continuous dependent variable"}], "answerKey": "D", "model_answer": "LECTURE: A linear probability model is a model of the form:\nP(X = x) = f(x; \u03b2) = \u03b20 + \u03b21x + \u03b22x2 ... + \u03b2nxn\nwhere X is a binary response (at the upper end, a continuous response), and \u03b2 is a vector of coefficients. The vector \u03b2 is estimated using maximum likelihood methods, and the error term is \u03b5.\nThe linear probability model is a special case of a general probability model, which is of the form:\nP(X = x) = g(x; \u03b8) = \u03b80 + \u03b81x + \u03b82x2 ... + \u03b8nxn\nwhere \u03b8 is a vector of coefficients. The vector \u03b8 is estimated using maximum likelihood methods, and the error term is \u03b5.\nFor the general probability model, the estimated probabilities will be between zero and one. For the linear probability model, there is nothing in the model to ensure that the estimated probabilities lie between zero and one.\nEven if the probabilities are truncated at zero and one, there will probably be many observations for which the probability is either exactly zero or exactly one.\nThe error terms will be heteroscedastic and not normally distributed.\nThis is not necessarily true. Heteroscedasticity refers to an error term with a variable variance. A normal error term is one that follows a normal distribution. If the error term is heteroscedastic and normal, then the error terms will be normally distributed.\nThe model is much harder to estimate than a standard regression model with a continuous dependent variable.\nThis is not necessarily true. The estimations for the linear probability model are simpler than those for a general probability model."}
{"question": "Which of the following statements concerning the regression population and sample is FALSE?", "choices": [{"label": "A", "text": "The population is the total collection of all items of interest"}, {"label": "B", "text": "The population can be infinite"}, {"label": "C", "text": "In theory, the sample could be larger than the population"}, {"label": "D", "text": "A random sample is one where each individual item from the population is equally likely to be drawn."}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following statements is INCORRECT concerning a comparison of the Box-Pierce Q and the Ljung-Box Q* statistics for linear dependence in time series?", "choices": [{"label": "A", "text": "Asymptotically, the values of the two test statistics will be equal"}, {"label": "B", "text": "The Q test has better small-sample properties than the Q*"}, {"label": "C", "text": "The Q test is sometimes over-sized for small samples"}, {"label": "D", "text": "As the sample size tends towards infinity, both tests will show a tendency to always reject the null hypothesis of zero autocorrelation coefficients."}], "answerKey": "B", "model_answer": "LECTURE: In a time series, the value of each observation depends on the value of the previous observation. This dependence can be described by the autocorrelation function (ACF).\nThe ACF can be calculated for any lags (intervals between observations). The lag is denoted by \u03b4. For example, the ACF at lag \u03b4 is the correlation between the time series observation and the time series transformed by waiting \u03b4 periods.\nThe Box-Pierce Q test and the Ljung-Box Q* test are statistical tests for the null hypothesis that there is no autocorrelation in the time series. These tests calculate the Q test statistic.\nThe Q test has better small-sample properties than the Q* test. This means that when the sample size is small, the Q test is a better test for detecting autocorrelation.\nAs the sample size tends towards infinity, both tests will show a tendency to always reject the null hypothesis of zero autocorrelation coefficients. This means that as the sample size increases, both tests will detect autocorrelation.\nSOLUTION: The Q test statistic is calculated as the sum of the squares of the autocorrelation coefficients. The Q* test statistic is calculated as the sum of the autocorrelation coefficients squared. For a series with no autocorrelation, the autocorrelation coefficients are zero. So, the values of the two test statistics will be equal.\nHowever, the Q test statistic is calculated using all of the autocorrelation coefficients. The Q* test statistic is calculated using only the first 5 or 6 autocorrelation coefficients. For small samples, the Q test statistic is sometimes over-sized for small samples. This means that the Q test statistic may be too large."}
{"question": "A parsimonious model is one that", "choices": [{"label": "A", "text": "Includes too many variables"}, {"label": "B", "text": "Includes as few variables as possible to explain the data"}, {"label": "C", "text": "Is a well-specified model"}, {"label": "D", "text": "Is a mis-specified model"}], "answerKey": "A", "model_answer": "LECTURE: A parsimonious model is one that includes as few variables as possible to explain the data.\nFor example, consider two linear models:\nY1 = A1X1 + A2X2 + B1X1 + B2X2\nY2 = C1X1 + C2X2 + D1X1 + D2X2\nThe two models are equally good at predicting Y. So, the more parsimonious model is Y1."}
{"question": "Which of the following is NOT a feature of continuously compounded returns (i.e. log-returns)?", "choices": [{"label": "A", "text": "They can be interpreted as continuously compounded changes in the prices"}, {"label": "B", "text": "They can be added over time to give returns for longer time periods"}, {"label": "C", "text": "They can be added across a portfolio of assets to give portfolio returns"}, {"label": "D", "text": "They are usually fat-tailed"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following features of financial asset return time-series could be captured using a standard GARCH(1,1) model?\n\ni) Fat tails in the return distribution\n\n\nii) Leverage effects\n\n\niii) Volatility clustering\n\n\niv) Volatility affecting returns", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: Financial asset return time-series are often characterized by the following features:\nFat tails in the return distribution. The return distribution may have a tail that decays slowly, suggesting that the tails are fat.\nLeverage effects. Asset returns may be affected by the leverage of the asset's issuer.\nVolatility clustering. Volatility may be clustered, with periods of high volatility being followed by periods of low volatility.\nVolatility affecting returns. Asset returns may be affected by the volatility of the asset's returns.\nA GARCH(1,1) model can capture the following features:\nVolatility clustering. The GARCH(1,1) model includes a variable that measures the squared difference between the return and the mean return. This variable is calculated over a one-period lag. It can capture the clustering of volatility, as the variable measures the squared difference over a lag.\nVolatility affecting returns. The GARCH(1,1) model includes a variable that measures the volatility of the return. This variable is calculated as the standard deviation of the return over a one-period lag. It can capture the fact that the volatility of the return affects the return.\nA GARCH(1,1) model cannot capture the following features:\nFat tails in the return distribution. The GARCH(1,1) model does not include variables that measure the tail of the return distribution. So, it cannot capture the fact that the tails of the return distribution are fat.\nLeverage effects. The GARCH(1,1) model does not include variables that measure the leverage of the asset's issuer. So, it cannot capture the effect of leverage on asset returns."}
{"question": "Consider the estimation of a GARCH-M model. If the data employed were a time-series of daily corporate bond percentage returns, which of the following would you expect the value of the GARCH-in-mean parameter estimate to be?", "choices": [{"label": "A", "text": "Less than -1"}, {"label": "B", "text": "Between -1 and 0"}, {"label": "C", "text": "Between 0 and 1"}, {"label": "D", "text": "Bigger than 1"}], "answerKey": "C", "model_answer": ""}
{"question": "Under which of the following situations would bootstrapping be preferred to pure simulation?\n\ni) If it is desired that the distributional properties of the data in the experiment\n\nare the same as those of some actual data\n\n\nii) If it is desired that the distributional properties of the data in the experiment\n\nare known exactly\n\n\niii) If the distributional properties of the actual data are unknown\n\n\niv) If the sample of actual data available is very small", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: Bootstrapping and pure simulation are two methods for conducting a statistical analysis.\nBootstrapping is a technique for creating multiple random samples from a single sample. It is a method for assessing the sampling distribution of a statistic.\nPure simulation is a method for conducting a statistical analysis that uses a computer to build models of complex systems. It is a method for assessing the probability of a outcome.\nSOLUTION: Bootstrapping is preferred to pure simulation when it is desired to assess the sampling distribution of a statistic.\nBootstrapping can also be used to estimate the probability of a outcome, but pure simulation is generally more effective for this purpose.\nPure simulation can be used when it is desired to assess the probability of a outcome, and when the distributional properties of the data in the experiment are known exactly.\nThis leaves cases where the distributional properties of the actual data are unknown and where the sample of actual data available is very small. In these cases, pure simulation is preferred to bootstrapping."}
{"question": "Which of the following may be consequences of one or more of the CLRM assumptions being violated?\n\ni) The coefficient estimates are not optimal\n\n\nii) The standard error estimates are not optimal\n\n\niii) The distributions assumed for the test statistics are inappropriate\n\n\niv) Conclusions regarding the strength of relationships between the dependent\n\nand independent variables may be invalid.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "LECTURE: Common assumptions of CLRM include the normality of the sampling distribution, the homoscedasticity of the sampling distribution, and the absence of multicollinearity. Violations of these assumptions can have serious consequences for the validity of the CLRM conclusions.\nThe normality assumption implies that the coefficients in the model are normally distributed with the specified population. This assumption can be violated if the sample size is very large, producing a unimodal distribution.\nThe homoscedasticity assumption implies that the variance of the sampling distribution is constant across the range of the independent variable. This assumption can be violated if the variance increases as the independent variable reaches higher values.\nThe absence of multicollinearity assumption implies that the independent variables are not highly correlated with each other. This assumption can be violated if two or more independent variables are highly correlated.\nIf one or more of these assumptions are violated, the coefficient estimates may be unreliable, and the standard error estimates may be unreliable. As a result, conclusions regarding the strength of relationships between the dependent and independent variables may be invalid.\nSOLUTION: All four consequences may be consequences of one or more of the CLRM assumptions being violated.\nThe violation of the normality assumption may result in the coefficient estimates being not optimal and the standard error estimates being not optimal.\nThe violation of the homoscedasticity assumption may result in the standard error estimates being not optimal.\nThe violation of the absence of multicollinearity assumption may result in the coefficient estimates being not optimal and the conclusions regarding the strength of relationships between the dependent and independent variables may be invalid."}
{"question": "Which of the following statements is true concerning forecasting in econometrics?", "choices": [{"label": "A", "text": "Forecasts can only be made for time-series data"}, {"label": "B", "text": "Mis-specified models are certain to produce inaccurate forecasts"}, {"label": "C", "text": "Structural forecasts are simpler to produce than those from time series models"}, {"label": "D", "text": "In-sample forecasting ability is a poor test of model adequacy"}], "answerKey": "D", "model_answer": "LECTURE: In econometrics, a model is said to be correctly specified if it uses all relevant economic variables and estimates them with sufficient precision. If a model is correctly specified, it is likely to have good in-sample forecasting ability.\nHowever, a correctly specified model does not necessarily have good out-of-sample forecasting ability. For example, a model that includes too many variables or estimates them with too much precision may be deemed incorrectly specified. Such a model may have good in-sample forecasting ability, but it is likely to have poor out-of-sample forecasting ability.\nThere are three common methods for making forecasts with econometric models:\nIn-sample forecasting: These are forecasts that are based on the part of the time series that occurs before a particular point in time. In-sample forecasts are often used to assess the accuracy of a model's forecasts.\nOut-of-sample forecasting: These are forecasts that are based on the part of the time series that occurs after a particular point in time. Out-of-sample forecasts are important because they indicate how well the model can forecast into the future.\nStructural forecasting: These are forecasts that are based on the underlying structure of a time series rather than on the specific values of the variables used in the model.\nTime-series forecasting: These are forecasts that are based on the specific values of the variables used in the model. Time-series forecasts are often made using methods such as exponential smoothing or moving averages.\nSOLUTION: A statement is true concerning forecasting in econometrics if it is consistent with the above discussion.\nForecasts can only be made for time-series data. In-sample and out-of-sample forecasts are made with time-series data.\nMis-specified models are certain to produce inaccurate forecasts. A mis-specified model is one that is not correctly specified. Inaccurate forecasts are produced by mis-specified models.\nStructural forecasts are simpler to produce than those from time series models. It is not necessarily the case that structural forecasts are simpler to produce than time-series foreccasts.\nIn-sample forecasting ability is a poor test of model adequacy. In-sample forecasting ability is a good test of a model's in-sample forecasting ability. However, in-sample forecasting ability is not a good test of a model's out-of-sample forecasting ability."}
{"question": "The pacf is necessary for distinguishing between", "choices": [{"label": "A", "text": "An AR and an MA model"}, {"label": "B", "text": "An AR and an ARMA model"}, {"label": "C", "text": "An MA and an ARMA model"}, {"label": "D", "text": "Different models from within the ARMA family"}], "answerKey": "B", "model_answer": ""}
{"question": "Negative residual autocorrelation is indicated by which one of the following?", "choices": [{"label": "A", "text": "A cyclical pattern in the residuals"}, {"label": "B", "text": "An alternating pattern in the residuals"}, {"label": "C", "text": "A complete randomness in the residuals"}, {"label": "D", "text": "Residuals that are all close to zero"}], "answerKey": "B", "model_answer": "LECTURE: In an autoregressive model, the residuals have a pattern of repeating every n periods, where n is the order of the model. This pattern is known as autocorrelation.\nResiduals that are autocorrelated have a pattern of repeating after a certain number of periods. For example, if the order of the model is 2, then residuals that are autocorrelated have a pattern of repeating every 2 periods.\nThe degree of autocorrelation is called the correlation coefficient. The correlation coefficient can be between -1 and 1.\nA correlation coefficient of 1 indicates a strong positive correlation. The residuals repeat exactly every period.\nA correlation coefficient of -1 indicates a strong negative correlation. The residuals reverse exactly every period.\nA correlation coefficient of 0 indicates no correlation. The residuals do not repeat or reverse.\nSOLUTION: Negative residual autocorrelation is indicated by a complete randomness in the residuals. No residuals are close to zero."}
{"question": "Which of the following statements are true concerning a comparison between ARCH(q) and GARCH(1,1) models?\n\ni) The ARCH(q) model is likely to be the more parsimonious\n\n\nii) The ARCH(q) model is the more likely to violate non-negativity constraints\n\n\niii) The ARCH(q) model can allow for an infinite number of previous lags of squared\n\nreturns to affect the current conditional variance\n\n\niv) The GARCH(1,1) model will usually be sufficient to capture all of the dependence\n\nin the conditional variance", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following statements are true concerning a triangular or recursive system?\n\ni) The parameters can be validly estimated using separate applications of OLS to\n\neach equation\n\n\nii) The independent variables may be correlated with the error terms in other\n\nequations\n\n\niii) An application of 2SLS would lead to unbiased but inefficient parameter estimates\n\n\niv) The independent variables may be correlated with the error terms in the equations\n\nin which they appear as independent variables", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
{"question": "Which one of the following statements best describes the algebraic representation of the fitted regression line?", "choices": [{"label": "A", "text": "\\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t + \\hat{u}_t"}, {"label": "B", "text": "\\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t"}, {"label": "C", "text": "\\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t + u_t"}, {"label": "D", "text": "y_t = \\hat{\\alpha} + \\hat{\\beta}x_t + \\hat{u}_t"}], "answerKey": "B", "model_answer": ""}
{"question": "What are the dimensions of $\\hat{u}^t \\hat{u}?", "choices": [{"label": "A", "text": "T x k"}, {"label": "B", "text": "T x 1"}, {"label": "C", "text": "k x 1"}, {"label": "D", "text": "1 x 1"}], "answerKey": "D", "model_answer": ""}
{"question": "The characteristic roots of the MA process\n\n$y_t = -3u_{t-1} + u_{t-2} + u_t$\n\nare", "choices": [{"label": "A", "text": "1 and 2"}, {"label": "B", "text": "1 and 0.5"}, {"label": "C", "text": "2 and -0.5"}, {"label": "D", "text": "1 and -3"}], "answerKey": "B", "model_answer": "LECTURE: The characteristic roots of a linear difference equation help you understand the behavior of the equation.\nIf a linear difference equation has a characteristic root of 0, the general solution will have a term that is proportional to the independent variable.\nIf a linear difference equation has a characteristic root of -1, the general solution will have a term that is proportional to the independent variable raised to an odd power.\nIf a linear difference equation has a characteristic root of 1, the general solution will have a term that is proportional to the independent variable raised to an even power.\nIf a linear difference equation has a characteristic root of 2, the general solution will have a term that is proportional to the independent variable raised to an even power.\nIf a linear difference equation has a characteristic root of -2, the general solution will have a term that is proportional to the independent variable raised to an odd power.\nIf a linear difference equation has a characteristic root of -0.5, the general solution will have a term that is proportional to the independent variable raised to a power between 1 and 2.\nIf a linear difference equation has a characteristic root of 3, the general solution will have a term that is proportional to the independent variable raised to a power of 3.\nIf a linear difference equation has a characteristic root of 0.5, the general solution will have a term that is proportional to the independent variable raised to a power between 2 and 3.\nSOLUTION: The characteristic roots of the MA process\n$y\\_t = -3u_{t-1} + u_{t-2} + u\\_t$\nare 1 and 2.\nThese roots are not equal to 0 or -1, so the general solution will have a term that is proportional to the independent variable.\nThe general solution is\n$y\\_t = -3u\\_t + 2u\\_{t-1}$"}
{"question": "Which of the following is an equivalent expression for saying that the explanatory variable is \"non-stochastic\"?", "choices": [{"label": "A", "text": "The explanatory variable is partly random"}, {"label": "B", "text": "The explanatory variable is fixed in repeated samples"}, {"label": "C", "text": "The explanatory variable is correlated with the errors"}, {"label": "D", "text": "The explanatory variable always has a value of one"}], "answerKey": "B", "model_answer": ""}
{"question": "Suppose that the Durbin Watson test is applied to a regression containing two explanatory variables plus a constant with 50 data points. The test statistic takes a value of 1.53. What is the appropriate conclusion?", "choices": [{"label": "A", "text": "Residuals appear to be positively autocorrelated"}, {"label": "B", "text": "Residuals appear to be negatively autocorrelated"}, {"label": "C", "text": "Residuals appear not to be autocorrelated"}, {"label": "D", "text": "The test result is inconclusive"}], "answerKey": "D", "model_answer": ""}
{"question": "If OLS is used in the presence of autocorrelation, which of the following will be likely consequences?\n\ni) Coefficient estimates may be misleading\n\n\nii) Hypothesis tests could reach the wrong conclusions\n\n\niii) Forecasts made from the model could be biased\n\n\niv) Standard errors may inappropriate", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "LECTURE: If an OLS (ordinary least squares) model is used in the presence of autocorrelation, the following will be likely consequences:\n\ni) Coefficient estimates may be misleading. Because autocorrelation leads to false correlations, the actual variables in the model may not be as closely related as the estimates suggest.\n\nii) Hypothesis tests could reach the wrong conclusions. The false correlations can lead to false conclusions about the significance of the variables in the model.\n\niii) Forecasts made from the model could be biased. Because the false correlations are only apparent, they will not hold in the future, and the model's forecasts may be too optimistic.\n\niv) Standard errors may be inappropriate. The inflated standard errors in the autocorrelated errors do not match up with the actual variability in the model.\n\nSOLUTION: All four consequences are likely when an OLS model is used in the presence of autocorrelation."}
{"question": "What will be the properties of the OLS estimator in the presence of multicollinearity?", "choices": [{"label": "A", "text": "It will be consistent, unbiased and efficient"}, {"label": "B", "text": "It will be consistent and unbiased but not efficient"}, {"label": "C", "text": "It will be consistent but not unbiased"}, {"label": "D", "text": "It will not be consistent"}], "answerKey": "A", "model_answer": ""}
{"question": "Which one of the following would NOT be a consequence of using non-stationary data in levels form?", "choices": [{"label": "A", "text": "The regression $R^2$ may be spuriously high"}, {"label": "B", "text": "Test statistics may not follow standard distributions"}, {"label": "C", "text": "Statistical inferences may be invalid"}, {"label": "D", "text": "Parameter estimates may be biased"}], "answerKey": "D", "model_answer": ""}
{"question": "If a series, y, follows a random walk, what is the optimal one-step ahead forecast of y?", "choices": [{"label": "A", "text": "The current value of y"}, {"label": "B", "text": "Zero"}, {"label": "C", "text": "One"}, {"label": "D", "text": "The average value of y over the in-sample period"}], "answerKey": "A", "model_answer": ""}
{"question": "The order condition is", "choices": [{"label": "A", "text": "A necessary and sufficient condition for identification"}, {"label": "B", "text": "A necessary but not sufficient condition for identification"}, {"label": "C", "text": "A sufficient but not necessary condition for identification"}, {"label": "D", "text": "A condition that is nether necessary nor sufficient for identification"}], "answerKey": "B", "model_answer": "LECTURE: A necessary condition is not a guarantee that something will happen. It is a condition that must be met for something to happen.\nA sufficient condition is a condition that is not only a must-have, but also a go-ahead. It is a condition that guarantees something will happen.\nA condition is nether necessary nor sufficient if it is not a necessary condition and not a sufficient condition.\nSOLUTION: The order condition is a necessary but not a sufficient condition for identification.\nA necessary condition is not a guarantee that something will happen. It is a condition that must be met for something to happen.\nThe order condition is a necessary condition for identification. This means that if the order condition is met, identification will occur. But the order condition alone does not guarantee that identification will occur.\nA sufficient condition is a condition that is not only a must-have, but also a go-ahead. It is a condition that guarantees something will happen.\nThe order condition is not a sufficient condition for identification. This means that the order condition alone does not guarantee that identification will occur."}
{"question": "If an estimator is said to have minimum variance, which of the following statements is NOT implied?", "choices": [{"label": "A", "text": "The probability that the estimate is a long way away from its true value is minimised"}, {"label": "B", "text": "The estimator is efficient"}, {"label": "C", "text": "Such an estimator would be termed \"best\""}, {"label": "D", "text": "Such an estimator will always be unbiased"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following are disadvantages of the Dickey-Fuller / Engle-Granger approach to testing for cointegration and modelling cointegrating relationships?\n\ni) Only one cointegrating relationship can be estimated\n\nii) Particularly for small samples. There is a high chance of the tests suggestingthat variables are not cointegrated when they are\n\niii) It is not possible to make inferences on the cointegrating regression\n\niv) The procedure forces the researcher to specify which is the dependent variable and which are the independent variables.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "LECTURE: The Dickey-Fuller / Engle-Granger approach to testing for cointegration and modelling cointegrating relationships involves testing whether two or more time series are cointegrated. This involves testing whether the series have a long-term equilibrium relationship.\nIf the test suggests that the variables are not cointegrated, the researcher can conclude that the variables do not have a long-term equilibrium relationship. If the test suggests that the variables are cointegrated, the researcher can use OLS to estimate the cointegrating relationship.\nHowever, there are several disadvantages to this approach. One disadvantage is that it is not possible to make inferences on the cointegrating regression. Another disadvantage is that the procedure forces the researcher to specify which is the dependent variable and which are the independent variables. In addition, only one cointegrating relationship can be estimated, and for small samples, there is a high chance of the tests suggesting that variables are not cointegrated when they are.\nSOLUTION: The correct answer is D."}
{"question": "Which of the following statements is true concerning the population regression function (PRF) and sample regression function (SRF)?", "choices": [{"label": "A", "text": "The PRF is the estimated model"}, {"label": "B", "text": "The PRF is used to infer likely values of the SRF"}, {"label": "C", "text": "Whether the model is good can be determined by comparing the SRF and the PRF"}, {"label": "D", "text": "The PRF is a description of the process thought to be generating the data."}], "answerKey": "D", "model_answer": "LECTURE: The population regression function (PRF) is the model that the researcher believes describes the process that generated the data. It is not possible to observe the population, so the PRF is not known with certainty. It is only known from the data.\nThe sample regression function (SRF) is the estimated model. It is estimated from the data.\nBoth the PRF and the SRF have a line with a negative slope. This tells you that, in general, as the independent variable increases, the dependent variable decreases. However, the PRF and the SRF are estimated from different data. So, they may be different.\nSOLUTION: The PRF is a description of the process thought to be generating the data. It is not possible to observe the population, so the PRF is not known with certainty. It is only known from the data.\nThe SRF is the estimated model. It is estimated from the data.\nSo, the PRF is a description of the process thought to be generating the data, and the SRF is the estimated model."}
{"question": "Which one of the following is a disadvantage of the general to specific or \"LSE\" (\"Hendry\") approach to building econometric models, relative to the specific to general approach?", "choices": [{"label": "A", "text": "Some variables may be excluded at the first stage leading to coefficient biases"}, {"label": "B", "text": "The final model may lack theoretical interpretation"}, {"label": "C", "text": "The final model may be statistically inadequate"}, {"label": "D", "text": "If the initial model is mis-specified, all subsequent steps will be invalid."}], "answerKey": "B", "model_answer": "LECTURE: When building an econometric model, you need to decide whether to start with a general model and then add specific variables (the \"LSE\" or \"Hendry\" approach) or start with a specific model and then generalize (the \"SE\" or \"Granger\" approach).\nOne disadvantage of the LSE approach is that it may be difficult to interpret the final model, because it is started from a general model. In contrast, the final model from the SE approach is more likely to have a clear interpretation, because it is started from a specific model.\nAnother disadvantage of the LSE approach is that the final model may not be statistically inferior to the SE approach. However, the LSE approach is generally more flexible, so it is usually the better approach when you are not sure about the functional form of the relationship between the variables.\nSOLUTION: The LSE approach excludes variables at the first stage, which may lead to biased coefficients. This is a disadvantage of the LSE approach."}
{"question": "Which of the following statements are true concerning maximum likelihood (ML) estimation in the context of GARCH models?\n\ni) Maximum likelihood estimation selects the parameter values that maximise the\n\nprobability that we would have actually observed the values of the series y that we\n\nactually did.\n\n\nii) GARCH models can only be estimated by ML and not by OLS\n\n\niii) For estimation of a standard linear model (with no GARCH), the OLS and ML\n\nestimates for the slope and intercept parameters will be identical but the estimator\n\nfor the variance of the disturbances is slightly different\n\n\niv) Most computer packages use numerical procedures to estimate GARCH models\n\nrather than a set of analytical formulae", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": ""}
{"question": "Including relevant lagged values of the dependent variable on the right hand side of a regression equation could lead to which one of the following?", "choices": [{"label": "A", "text": "Biased but consistent coefficient estimates"}, {"label": "B", "text": "Biased and inconsistent coefficient estimates"}, {"label": "C", "text": "Unbiased but inconsistent coefficient estimates"}, {"label": "D", "text": "Unbiased and consistent but inefficient coefficient estimates."}], "answerKey": "A", "model_answer": ""}
{"question": "Which one of the following factors is likely to lead to a relatively high degree of out-of-sample forecast accuracy?", "choices": [{"label": "A", "text": "A model that is based on financial theory"}, {"label": "B", "text": "A model that contains many variables"}, {"label": "C", "text": "A model whose dependent variable has recently exhibited a structural change"}, {"label": "D", "text": "A model that is entirely statistical in nature with no room for judgmental modification of forecasts"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following are plausible approaches to dealing with residual autocorrelation?\n\ni) Take logarithms of each of the variables\n\nii) Add lagged values of the variables to the regression equation\n\niii) Use dummy variables to remove outlying observations\n\niv) Try a model in first differenced form rather than in levels.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "LECTURE: Residual autocorrelation is the correlation between a variable and its own lags. Autocorrelation can be caused by deviations from the assumption that the observations are independent.\nOne way to deal with autocorrelation is to use a model with lags or lead lags. If there is autocorrelation after taking the first differences of a variable, you can try taking the second differences. If there is autocorrelation after taking the second differences, you can try taking the third differences, and so on.\nSOLUTION: To deal with residual autocorrelation, you can try adding lagged values of the variables to the regression equation (ii). You can also try a model in first differenced form rather than in levels (iv).\nTaking logarithms of each of the variables (i) may help with heteroscedasticity, but it does not address autocorrelation.\nRemoving outlying observations with dummy variables (iii) may help with autocorrelation, but it is not a definitive solution."}
{"question": "For an autoregressive process to be considered stationary", "choices": [{"label": "A", "text": "The roots of the characteristic equation must all lie inside the unit circle"}, {"label": "B", "text": "The roots of the characteristic equation must all lie on the unit circle"}, {"label": "C", "text": "The roots of the characteristic equation must all lie outside the unit circle"}, {"label": "D", "text": "The roots of the characteristic equation must all be less than one in absolute value"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following statements are true concerning information criteria?\n\n(i) Adjusted R-squared is an information criterion\n\n(ii) If the residual sum of squares falls when an additional term is added, the value of the information criterion will fall\n\n(iii) Akaike's information criterion always leads to model orders that are at least as large as those of Schwarz's information criterion\n\n(iv) Akaike's information criterion is consistent", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": ""}
{"question": "The \"within transform\" involves", "choices": [{"label": "A", "text": "Taking the average values of the variables"}, {"label": "B", "text": "Subtracting the mean of each entity away from each observation on that entity"}, {"label": "C", "text": "Estimating a panel data model using least squares dummy variables"}, {"label": "D", "text": "Using both time dummies and cross-sectional dummies in a fixed effects panel model"}], "answerKey": "B", "model_answer": ""}
{"question": "The purpose of \"augmenting\" the Dickey-Fuller test regression is to", "choices": [{"label": "A", "text": "Ensure that there is no heteroscedasticity in the test regression residuals."}, {"label": "B", "text": "Ensure that the test regression residuals are normally distributed"}, {"label": "C", "text": "Ensure that there is no autocorrelation in the test regression residuals"}, {"label": "D", "text": "Ensure that all of the non-stationarity is taken into account."}], "answerKey": "C", "model_answer": "LECTURE: In a regression model, the residuals are the differences between the observed values of the dependent variable and the values predicted by the model. The residuals can be checked for heteroscedasticity, which is a decrease in the variance of the residuals as the magnitude of the independent variable increases. Heteroscedasticity can be caused by non-constant variance of the errors.\nOne way to check for heteroscedasticity is to examine the residuals for a constant variance. One diagnostic is to look at the independence of the residuals. If the residuals are independent, then the variance of the residuals is constant.\nAnother way to check for heteroscedasticity is to examine the residuals for a constant pattern. If the residuals follow a constant pattern, such as a straight line, then the variance of the residuals is constant.\nThe Augmented Dickey-Fuller (ADF) test is a diagnostic for non-stationary time series. When the ADF test indicates that a time series is non-stationary, the test regression residuals may also be non-stationary. In this case, the residuals may also be heteroscedastic.\nTo augment the ADF test regression is to modify the test by adding terms to the regression. Augmenting the ADF test regression can ensure that all of the non-stationarity is taken into account. This can be important if the non-stationarity is caused by a pattern in the residuals.\nSOLUTION: The ADF test regression is a regression of the time series on its own lagged values. To augment the ADF test regression is to modify it by adding terms. For example, the augmented ADF test regression is a regression of the time series on its own lagged values and the square of its own lagged values.\nTo ensure that there is no autocorrelation in the test regression residuals, the ADF test regression needs to include terms for the squared lagged values of the time series. These terms can help to remove any autocorrelation in the residuals.\nTo ensure that all of the non-stationarity is taken into account, the ADF test regression needs to include terms for the lagged values of the time series. These terms can help to remove any non-stationarity that is not caused by a pattern in the residuals."}
{"question": "If a series, y, follows a random walk with drift b, what is the optimal one-step ahead forecast of the change in y?", "choices": [{"label": "A", "text": "The current value of y"}, {"label": "B", "text": "Zero"}, {"label": "C", "text": "One"}, {"label": "D", "text": "The average value of the change in y over the in-sample period"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following are plausible approaches to dealing with a model that exhibits heteroscedasticity?\n\ni) Take logarithms of each of the variables\n\nii) Use suitably modified standard errors\n\niii) Use a generalised least squares procedure\n\niv) Add lagged values of the variables to the regression equation.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: Heteroscedasticity occurs when the uncertainty of a model is constant. This means that the variance of the residuals is constant during the interval of the data. When this happens, the model is said to have constant uncertainty.\nThere are several possible reasons for heteroscedasticity:\nA source variable is missing.\nThe source variables are measured with error.\nThe source variables are correlated.\nThe model is incorrect.\nWhen there is heteroscedasticity, the standard errors of the model are not correct. This means that the t-tests and p-values of the model are not correct.\nThe general effect of heteroscedasticity is to make the t-tests and p-values of the model too optimistic. This means that the model is more likely to appear to be statistically significant than it really is.\nSOLUTION: To deal with heteroscedasticity, you can try the following approaches:\nTake logarithms of each of the variables.\nThis will often reduce heteroscedasticity. However, be careful if the variables are measured with error, as logarithming counts that are outside of the natural numbers as zeros. This can increase the variance of the residuals.\nUse suitably modified standard errors.\nStandard errors that are modified to account for heteroscedasticity can be used. For example, the White standard errors are modified to account for heteroscedasticity.\nWhite, E. W. (1980). A critical look at the assumptions of ordinary least squares. Journal of the Royal Statistical Society. Series B (Methodological), 42(2), 130-143.\nUse a generalised least squares procedure.\nGeneralised least squares procedures are designed to deal with heteroscedasticity. These procedures regress the standard error of the model on the model.\nCox, D. R., & Snell, E. J. (1980). Generalized least squares. Journal of the Royal Statistical Society. Series B (Methodological), 42(2), 144-162.\nAdd lagged values of the variables to the regression equation.\nAdding lagged values of the variables to the regression equation can help to reduce heteroscedasticity. This is because lagged values of the variables can help to stabilize the variance of the residuals."}
{"question": "Which of the following statements are true concerning the standardised residuals (residuals divided by their respective conditional standard deviations) from an estimated GARCH model?\n\ni) They are assumed to be normally distributed\n\n\nii) Their squares will be related to their lagged squared values if the GARCH model is\n\nappropriate\n\n\niii) In practice, they are likely to have fat tails\n\n\niv) If the GARCH model is adequate, the standardised residuals and the raw residuals\n\nwill be identical", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: In a GARCH model, the standardized residuals are the residuals divided by their respective conditional standard deviations.\nThe standardized residuals from a GARCH model are commonly used to calculate confidence intervals and conduct statistical tests.\nThe standardized residuals have a standard normal distribution under the assumption that the GARCH model is appropriate. This means that their values are not unlikely for a normal distribution.\nThe standardized residuals have fat tails. This means that there is a small probability of observing very large or very small values.\nThe lagged squared standardized residuals will be related to the lagged squared standardized residuals. This means that the standardized residuals have autocorrelation.\nThe raw residuals will be identical to the standardized residuals. This means that the standardized residuals have the same mean and autocovariance as the raw residuals.\nSOLUTION: They are assumed to be normally distributed. This means that the standardized residuals have a normal distribution.\nTheir squares will be related to their lagged squared values if the GARCH model is appropriate. This means that the standardized residuals have autocorrelation.\nIn practice, they are likely to have fat tails. This means that there is a small probability of observing very large or very small values.\nIf the GARCH model is adequate, the standardized residuals and the raw residuals will be identical. This means that the standardized residuals have the same mean and autocovariance as the raw residuals."}
{"question": "Which one of the following statements is true concerning VARs?", "choices": [{"label": "A", "text": "The coefficient estimates have intuitive theoretical interpretations"}, {"label": "B", "text": "The coefficient estimates usually have the same sign for all of the lags of a given variable in a given equation"}, {"label": "C", "text": "VARs often produce better forecasts than simultaneous equation structural models"}, {"label": "D", "text": "All of the components of a VAR must be stationary before it can be used for forecasting"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following statements is INCORRECT concerning the classical hypothesis testing framework?", "choices": [{"label": "A", "text": "If the null hypothesis is rejected, the alternative is accepted"}, {"label": "B", "text": "The null hypothesis is the statement being tested while the alternative encompasses the remaining outcomes of interest"}, {"label": "C", "text": "The test of significance and confidence interval approaches will always give the same conclusions"}, {"label": "D", "text": "Hypothesis tests are used to make inferences about the population parameters."}], "answerKey": "A", "model_answer": ""}
{"question": "An ARMA(p,q) (p, q are integers bigger than zero) model will have", "choices": [{"label": "A", "text": "An acf and pacf that both decline geometrically"}, {"label": "B", "text": "An acf that declines geometrically and a pacf that is zero after p lags"}, {"label": "C", "text": "An acf that declines geometrically and a pacf that is zero after q lags"}, {"label": "D", "text": "An acf that is zero after p lags and a pacf that is zero after q lags"}], "answerKey": "A", "model_answer": "LECTURE: In an ARMA(p,q) model, the acf declines geometrically as the lag increases. That is, for each unit increase in the lag, the absolute value of the acf decreases by a factor of 2.\nThe pacf is defined as the acf of the residuals. So, the pacf also declines geometrically.\nIf p < q, the pacf is zero after q lags. This is because the residuals are not affected by the random error terms that are further back in time than the q-th lag.\nIf q > p, the acf is zero after p lags. This is because the past values of the random error terms are not further back in time than the p-th lag.\nIf p = q, both the acf and pacf are zero after q lags.\nSOLUTION: An ARMA(p,q) model will have an acf and pacf that both decline geometrically, or an acf that is zero after p lags and a pacf that is zero after q lags."}
{"question": "Suppose that the following regression is estimated using 27 quarterly observations:\n\n$y_t = \\beta_1 + \\beta_2 x_2 + \\beta_3 x_{3t} + u_t$\n\nWhat is the appropriate critical value for a 2-sided 5% size of test of $H_0: \\beta_3 = 1$?", "choices": [{"label": "A", "text": "1.64"}, {"label": "B", "text": "1.71"}, {"label": "C", "text": "2.06"}, {"label": "D", "text": "1.96"}], "answerKey": "C", "model_answer": ""}
{"question": "Suppose that two researchers, using the same 3 variables and the same 250 observations on each variable, estimate a VAR. One estimates a VAR(6), while the other estimates a VAR(4). The determinants of the variance-covariance matrices of the residuals for each VAR are 0.0036 and 0.0049 respectively. What is the values of the test statistic for performing a test of whether the VAR(6) can be restricted to a VAR(4)?", "choices": [{"label": "A", "text": "77.07"}, {"label": "B", "text": "0.31"}, {"label": "C", "text": "0.33"}, {"label": "D", "text": "4.87"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following is a DISADVANTAGE of using pure time-series models (relative to structural models)?", "choices": [{"label": "A", "text": "They are not theoretically motivated"}, {"label": "B", "text": "They cannot produce forecasts easily"}, {"label": "C", "text": "They cannot be used for very high frequency data"}, {"label": "D", "text": "It is difficult to determine the appropriate explanatory variables for use in pure time-series models"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following are alternative names for the dependent variable (usually denoted by y) in linear regression analysis?\n\n(i) The regressand\n\n(ii) The regressor\n\n(iii) The explained variable\n\n(iv) The explanatory variable", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following are advantages of the VAR approach to modelling the relationship between variables relative to the estimation of full structural models?\n\ni) VARs receive strong motivation from financial and economic theory\n\n\nii) VARs in their reduced forms can be used easily to produce time-series forecasts\n\n\niii) VAR models are typically highly parsimonious\n\n\niv) OLS can be applied separately to each equation in a reduced form VAR", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "LECTURE: One way to model the relationship between variables is with a structural model. A structural model represents the underlying mechanisms that drive the data. A vector auto-regressive (VAR) model is a type of structural model.\nVARs are defined by a set of equations that describe the relationships between the variables. The equations contain both short-term and long-term coefficients. The short-term coefficients describe how the variables change over time. The long-term coefficients represent how the variables are affected by their own values over time.\nThe long-term coefficients in a VAR model are not directly estimable. However, they can be estimated indirectly by using the short-term coefficients.\nThere are several advantages to using a VAR approach relative to a full structural model. One advantage is that a VAR model is typically highly parsimonious. This means that a VAR model with only a few variables can fit a wide variety of time-series data.\nAnother advantage is that VAR models can be used easily to produce time-series forecasts. Forecasting is the process of using historical data to make predictions about future data."}
{"question": "Which of the following statements is TRUE concerning the standard regression model?", "choices": [{"label": "A", "text": "y has a probability distribution"}, {"label": "B", "text": "x has a probability distribution"}, {"label": "C", "text": "The disturbance term is assumed to be correlated with x"}, {"label": "D", "text": "For an adequate model, the residual (u-hat) will be zero for all sample data points"}], "answerKey": "A", "model_answer": ""}
{"question": "Consider the following model for $y_t$:\n\n$y_t = \\mu + \\lambda t + u_t$\n\nWhich one of the following most accurately describes the process for $y_t$?", "choices": [{"label": "A", "text": "A unit root process"}, {"label": "B", "text": "A stationary process"}, {"label": "C", "text": "A deterministic trend process"}, {"label": "D", "text": "A random walk with drift"}], "answerKey": "C", "model_answer": "LECTURE: A process is stationary if its statistical properties do not change over time. A unit root process is one whose statistical properties change over time. A random walk is a type of unit root process.\nA deterministic trend process is a process whose value is systematically changing over time."}
{"question": "Which of the following is correct concerning logit and probit models?", "choices": [{"label": "A", "text": "They use a different method of transforming the model so that the probabilities lie between zero and one"}, {"label": "B", "text": "The logit model can result in too many observations falling at exactly zero or exactly one"}, {"label": "C", "text": "For the logit model, the marginal effect of a change in one of the explanatory variables is simply the estimate of the parameter attached to that variable, whereas this is not the case for the probit model"}, {"label": "D", "text": "The probit model is based on a cumulative logistic function"}], "answerKey": "A", "model_answer": ""}
{"question": "What is the most important disadvantage of the diagonal VECH approach to building multivariate GARCH models that is overcome by the BEKK formulation?", "choices": [{"label": "A", "text": "The diagonal VECH model is hard to interpret intuitively"}, {"label": "B", "text": "The diagonal VECH model contains too many parameters"}, {"label": "C", "text": "The diagonal VECH model does not ensure a positive-definite variance-covariance matrix"}, {"label": "D", "text": "The BEKK model reduces the dimensionality problem that arises when a number of series are modelled together."}], "answerKey": "C", "model_answer": ""}
{"question": "If a relevant variable is omitted from a regression equation, the consequences would be that:\n\ni) The standard errors would be biased\n\n\nii) If the excluded variable is uncorrelated with all of the included variables, all of\n\nthe slope coefficients will be inconsistent.\n\n\niii) If the excluded variable is uncorrelated with all of the included variables, the\n\nintercept coefficient will be inconsistent.\n\n\niv) If the excluded variable is uncorrelated with all of the included variables, all of\n\nthe slope and intercept coefficients will be consistent and unbiased but inefficient.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following are alternative names for the independent variable (usually denoted by x) in linear regression analysis?\n\n(i) The regressor\n\n(ii) The regressand\n\n(iii) The causal variable\n\n(iv) The effect variable", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: In linear regression analysis, the independent variable is usually denoted by x. It is important to choose a name for the independent variable that makes it clear what the variable represents.\nThe dependent variable is usually denoted by y.\nThe alternative names for the independent variable are regressor, regressand, and causal variable.\nA regressor is a variable that regresses, or gets bigger, when the dependent variable gets bigger. The independent variable x is a regressor because x gets bigger when y gets bigger.\nA regressand is a variable that regresses, or gets bigger, when the independent variable gets bigger. The dependent variable y is a regressand because y gets bigger when x gets bigger.\nA causal variable is a variable that causes another variable to change. The independent variable x is a causal variable because x causes y to change.\nThe effect variable is another name for the dependent variable. It is called the effect variable because it is the variable that is affected by the independent variable.\nSOLUTION: The alternative names for the independent variable are the regressor and the causal variable.\nThe independent variable x is a regressor because x gets bigger when y gets bigger.\nThe independent variable x is a causal variable because x causes y to change."}
{"question": "Consider the OLS estimator for the standard error of the slope coefficient. Which of the following statement(s) is (are) true?\n\n(i) The standard error will be positively related to the residual variance\n\n(ii) The standard error will be negatively related to the dispersion of the observations on the explanatory variable about their mean value\n\n(iii) The standard error will be negatively related to the sample size\n\n(iv) The standard error gives a measure of the precision of the coefficient estimate.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": ""}
{"question": "What is the meaning of the term \"heteroscedasticity\"?", "choices": [{"label": "A", "text": "The variance of the errors is not constant"}, {"label": "B", "text": "The variance of the dependent variable is not constant"}, {"label": "C", "text": "The errors are not linearly independent of one another"}, {"label": "D", "text": "The errors have non-zero mean"}], "answerKey": "A", "model_answer": ""}
{"question": "If a Durbin Watson statistic takes a value close to zero, what will be the value of the first order autocorrelation coefficient?", "choices": [{"label": "A", "text": "Close to zero"}, {"label": "B", "text": "Close to plus one"}, {"label": "C", "text": "Close to minus one"}, {"label": "D", "text": "Close to either minus one or plus one"}], "answerKey": "C", "model_answer": ""}
{"question": "Under the null hypothesis of a Bera-Jarque test, the distribution has", "choices": [{"label": "A", "text": "Zero skewness and zero kurtosis"}, {"label": "B", "text": "Zero skewness and a kurtosis of three"}, {"label": "C", "text": "Skewness of one and zero kurtosis"}, {"label": "D", "text": "Skewness of one and kurtosis of three."}], "answerKey": "B", "model_answer": ""}
{"question": "If an estimator is said to be consistent, it is implied that", "choices": [{"label": "A", "text": "On average, the estimated coefficient values will equal the true values"}, {"label": "B", "text": "The OLS estimator is unbiased and no other unbiased estimator has a smaller variance"}, {"label": "C", "text": "The estimates will converge upon the true values as the sample size increases"}, {"label": "D", "text": "The coefficient estimates will be as close to their true values as possible for small and large samples."}], "answerKey": "C", "model_answer": "LECTURE: When an estimator is consistent, it is implied that, on average, the estimated coefficient values will equal the true values. Consistency is a necessary condition for a useful estimator.\nThe OLS estimator is unbiased, and no other unbiased estimator has a smaller variance.\nThis tells you that the OLS estimator is the best possible estimator for the coefficients of the linear model. No other estimator can do better in terms of both bias and variance.\nThe estimates will converge upon the true values as the sample size increases.\nAs the sample size increases, the estimator becomes closer to the true value. This is a necessary condition for a good estimator.\nThe coefficient estimates will be as close to their true values as possible for small and large samples.\nFor both small and large samples, the OLS estimator is as close to the true value as possible."}
{"question": "Which of the following is a typical characteristic of financial asset return time-series?", "choices": [{"label": "A", "text": "Their distributions are thin-tailed"}, {"label": "B", "text": "They are not weakly stationary"}, {"label": "C", "text": "They are highly autocorrelated"}, {"label": "D", "text": "They have no trend"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following assumptions are required to show the consistency, unbiasedness and efficiency of the OLS estimator?\n\ni) $E(u_t) = 0$\n\n\nii) $\\text{Var}(u_t) = \\sigma^2$\n\n\niii) $\\text{Cov}(u_t, u_{t-j}) = 0 \\forall j$\n\n\niv) $u_t \\sim N(0, \\sigma^2)$", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following is a disadvantage of the fixed effects approach to estimating a panel model?", "choices": [{"label": "A", "text": "The model is likely to be technical to estimate"}, {"label": "B", "text": "The approach may not be valid if the composite error term is correlated with one or more of the explanatory variables"}, {"label": "C", "text": "The number of parameters to estimate may be large, resulting in a loss of degrees of freedom"}, {"label": "D", "text": "The fixed effects approach can only capture cross-sectional heterogeneity and not temporal variation in the dependent variable."}], "answerKey": "C", "model_answer": ""}
{"question": "Consider an identical situation to that of question 21, except that now a 2-sided alternative is used. What would now be the appropriate conclusion?", "choices": [{"label": "A", "text": "H0 is rejected"}, {"label": "B", "text": "H0 is not rejected"}, {"label": "C", "text": "H1 is rejected"}, {"label": "D", "text": "There is insufficient information given in the question to reach a conclusion"}], "answerKey": "A", "model_answer": ""}
{"question": "The price of a house is best described as what type of number?", "choices": [{"label": "A", "text": "Discrete"}, {"label": "B", "text": "Cardinal"}, {"label": "C", "text": "Ordinal"}, {"label": "D", "text": "Nominal"}], "answerKey": "B", "model_answer": "LECTURE: Numbers are usually described by their properties.\nThere are four common ways to describe numbers.\nA number is discrete if it can be put into a specific order. The numbers on a number line are discrete.\nA number is finite if it has a end. The set of natural numbers is finite.\nA number is infinite if it has no end. The set of even numbers is infinite.\nA number is nominal if it refers to a name. The number 5 refers to the number of times something is happening.\nThe price of a house is best described as nominal. The price of a house does not depend on the house's specific characteristics.\nSOLUTION: Price is nominal."}
{"question": "If a Johansen \"trace\" test for a null hypothesis of 2 cointegrating vectors is applied to a system containing 4 variables is conducted, which eigenvalues would be used in the test?", "choices": [{"label": "A", "text": "All of them"}, {"label": "B", "text": "The largest 2"}, {"label": "C", "text": "The smallest 2"}, {"label": "D", "text": "The second largest"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following statements is true concerning variance decomposition analysis of VARs?\n\ni) Variance decompositions measure the impact of a unit shock to each of the variables on the VAR\n\nii) Variance decompositions can be thought of as measuring the proportion of the forecast error variance that is attributable to each variable\n\niii) The ordering of the variables is important for calculating impulse responses but not variance decompositions\n\niv) It is usual that most of the forecast error variance for a given variable is attributable to shocks to that variable", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": ""}
{"question": "Suppose that we have estimated a GARCH model for daily equity returns, and we are interested in producing a 10-day forecast of the volatility (measured by the standard deviation of returns) for use in a value at risk model. How could such a forecast most validly be calculated?", "choices": [{"label": "A", "text": "Produce 1, 2, 3, ..., 10 step ahead conditional variance forecasts and add them up"}, {"label": "B", "text": "Produce 1, 2, 3, ..., 10 step ahead conditional variance forecasts and add them up and take the square root"}, {"label": "C", "text": "Produce 1, 2, 3, ..., 10 step ahead conditional variance forecasts, take the square roots of each one and add them up"}, {"label": "D", "text": "Produce a 1-step ahead conditional variance forecast, take its square root and multiply it by the square root of 10"}], "answerKey": "B", "model_answer": ""}
{"question": "Suppose that the value of $R^2$ for an estimated regression model is exactly zero. Which of the following are true?\n\ni) All coefficient estimates on the slopes will be zero\n\nii) The fitted line will be horizontal with respect to all of the explanatory variables\n\niii) The regression line has not explained any of the variability of y about its mean value\n\niv) The intercept coefficient estimate must be zero.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: The value of $R^2$ for an estimated regression model is exactly zero. This indicates that the regression line has not used any of the information in the explanatory variable(s). In other words, the intercept coefficient estimate is zero, and the slope coefficients are all zero.\nSOLUTION: The value of $R^2$ is zero. This means that the regression line has not used any of the information in the explanatory variable(s). So, the intercept coefficient estimate must be zero, and the slope coefficients are all zero.\nSo, the only true statements are i and ii."}
{"question": "A white noise process will have\n\n(i) A zero mean\n\n(ii) A constant variance\n\n(iii) Autocovariances that are constant\n\n(iv) Autocovariances that are zero except at lag zero", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following statements are true concerning the Box-Jenkins approach to diagnostic testing for ARMA models?\n\n(i) The tests will show whether the identified model is either too large or too small\n\n(ii) The tests involve checking the model residuals for autocorrelation, heteroscedasticity, and non-normality\n\n(iii) If the model suggested at the identification stage is appropriate, the acf and pacf for the residuals should show no additional structure\n\n(iv) If the model suggested at the identification stage is appropriate, the coefficients on the additional variables under the overfitting approach will be statistically insignificant", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": ""}
{"question": "Which one of the following would be a plausible response to a finding of residual non-normality?", "choices": [{"label": "A", "text": "Use a logarithmic functional form instead of a linear one"}, {"label": "B", "text": "Add lags of the variables on the right hand side of the regression model"}, {"label": "C", "text": "Estimate the model in first differenced form"}, {"label": "D", "text": "Remove any large outliers from the data."}], "answerKey": "D", "model_answer": ""}
{"question": "The fixed effects panel model is also sometimes known as", "choices": [{"label": "A", "text": "A seemingly unrelated regression model"}, {"label": "B", "text": "The least squares dummy variables approach"}, {"label": "C", "text": "The random effects model"}, {"label": "D", "text": "Heteroscedasticity and autocorrelation consistent"}], "answerKey": "B", "model_answer": "LECTURE: In a fixed effects model, the unit of observation is the unit itself. The model estimates the fixed effects of being in a particular unit, such as a school or a classroom, on outcomes, such as test scores.\nFor example, consider a study of schools in different states. In this study, each school is its own unit. The model estimates the fixed effects of being in a particular school on test scores.\nThe key assumption of the fixed effects model is that each unit is different from other units in observable ways. In the example of the study of schools in different states, each school is different from other schools in the state in which it is located.\nThe fixed effects model can also include other variables, such as student characteristics, in the model. These variables are estimated separately for each unit.\nSOLUTION: The fixed effects panel model is also sometimes known as the random effects model. In this model, the unit of observation is the panel unit. The model estimates the fixed effects of being in a particular panel unit, such as a class or a school, on outcomes, such as test scores.\nThe key assumption of the random effects model is that each panel unit is different from other panel units in observable ways.\nThe random effects model can also include other variables, such as student characteristics, in the model. These variables are estimated separately for each panel unit."}
{"question": "Which of the following statements is TRUE concerning OLS estimation?", "choices": [{"label": "A", "text": "OLS minimises the sum of the vertical distances from the points to the line"}, {"label": "B", "text": "OLS minimises the sum of the squares of the vertical distances from the points to the line"}, {"label": "C", "text": "OLS minimises the sum of the horizontal distances from the points to the line"}, {"label": "D", "text": "OLS minimises the sum of the squares of the horizontal distances from the points to the line."}], "answerKey": "B", "model_answer": ""}
{"question": "If the standard tools for time-series analysis, such as estimation of the acf, pacf and spectral analysis, find no evidence of structure in the data, this implies that the data are which of the following?", "choices": [{"label": "A", "text": "Normally distributed"}, {"label": "B", "text": "Uncorrelated"}, {"label": "C", "text": "Independent"}, {"label": "D", "text": "Fat-tailed"}], "answerKey": "B", "model_answer": "LECTURE: Time-series data are observations taken at different points in time. Their structure includes autocorrelation, which is the correlation of a time series with itself at a later time, and heteroscedasticity, which is a change in the variance of the time series over time.\nAutocorrelation is the correlation of a time series with itself at a later time. This correlation can be used to determine if a time series is normally distributed.\nIf the acf and pacf are not significant, the data are normally distributed.\nThe pacf is the partial autocorrelation function. It measures the correlation of a time series with itself after removing the effects of earlier values.\nThe acf is the autocorrelation function. It measures the correlation of a time series with itself at a later time.\nSOLUTION: If the standard tools for time-series analysis, such as estimation of the acf, pacf and spectral analysis, find no evidence of structure in the data, this implies that the data are uncorrelated.\nUncorrelated data are not related to each other. They do not have a pattern of changing together.\nFat-tailed data are related to each other, but have a pattern of changing that is not normal. This pattern can be either positive or negative.\nIndependent data are not related to each other. They do not have a pattern of changing together.\nNormally distributed data are not related to each other. They do not have a pattern of changing together."}
{"question": "If two variables, $x_t$ and $y_t$ are said to be cointegrated, which of the following statements are true?\n\ni) $x_t$ and $y_t$ must both be stationary\n\n\nii) Only one linear combination of $x_t$ and $y_t$ will be stationary\n\n\niii) The cointegrating equation for $x_t$ and $y_t$ describes the short-run relationship\n\nbetween the two series\n\n\niv) The residuals of a regression of $y_t$ on $x_t$ must be stationary", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": ""}
{"question": "A dependent variable whose values are not observable outside a certain range but where the corresponding values of the independent variables are still available would be most accurately described as what kind of variable?", "choices": [{"label": "A", "text": "Censored"}, {"label": "B", "text": "Truncated"}, {"label": "C", "text": "Multinomial variable"}, {"label": "D", "text": "Discrete choice"}], "answerKey": "A", "model_answer": "LECTURE: In statistics, there are many different types of variables. Here are some ways variables can be described:\nA continuous variable is a variable that can take on any value within a certain range.\nA discrete variable is a variable that can only take on certain values.\nA multinomial variable is a variable that can take on values from more than one group.\nA categorical variable is a variable that can take on values from a certain group.\nA count variable is a variable that represents the number of events or items.\nFor example, the number of cookies in a batch is a count variable.\nA percentage is a special type of number that is less than 1. Percentages are often used to describe large quantities by comparing them with smaller quantities.\nFor example, the percentage of red cars in a company's fleet is a percentage that describes the red cars as a proportion of the total number of cars.\nA variable with a truncated distribution is a variable whose values are not observed above a certain point.\nFor example, the times in a statistics class might be truncated if students have difficulty measuring times longer than 1 hour.\nA variable with a censored distribution is a variable whose values are not observed when the values of other variables are certain.\nFor example, the temperature in a statistics class might be censored if students have difficulty measuring temperatures when the humidity is 100%.\nSOLUTION: The dependent variable whose values are not observable outside a certain range but where the corresponding values of the independent variables are still available would be most accurately described as censored."}
{"question": "A Hausman test would be used for", "choices": [{"label": "A", "text": "Determining whether an equation that is part of a simultaneous system is identified"}, {"label": "B", "text": "Determining whether a simultaneous framework is needed for a particular variable"}, {"label": "C", "text": "Determining whether 2SLS or ILS is optimal"}, {"label": "D", "text": "Determining whether the structural form equations can be obtained via substitution from the reduced forms"}], "answerKey": "B", "model_answer": ""}
{"question": "Under the matrix notation for the classical linear regression model, $y = X \\beta + u$, what are the dimensions of $u$?", "choices": [{"label": "A", "text": "T x k"}, {"label": "B", "text": "T x 1"}, {"label": "C", "text": "k x 1"}, {"label": "D", "text": "1 x 1"}], "answerKey": "B", "model_answer": ""}
{"question": "How many parameters will be required to be estimated in total for all equations of a standard form, unrestricted, tri-variate VAR(4), ignoring the intercepts?", "choices": [{"label": "A", "text": "12"}, {"label": "B", "text": "4"}, {"label": "C", "text": "3"}, {"label": "D", "text": "36"}], "answerKey": "D", "model_answer": "LECTURE: A vector autoregression (VAR) is a model that shows how several variables change over time.\nThe standard form of a VAR is:\nYt=\u2211i=1p\u03b2iYt\u2212i+\u03f5tYt=\u03b20Yt\u22121+\u03b21Yt\u22122+\u2026+\u03b2p\u22121Yt\u2212p+\u03f5tYt is a vector of endogenous variables.\n\u03f5t is a vector of error terms.\np is the number of variables in the vector.\nThe parameter \u03b2i is estimated using a subset of the data. The smallest subset that can be used for parameter estimation is called a minimum order VAR.\nThe number of parameters that must be estimated in a VAR with order p is p+1. In a standard form VAR, all p variables are specified to be I(1).\nThe intercept, \u03b20, is estimated using Yt and all of the other variables.\nThe parameters \u03b21 to \u03b2p\u22121 are estimated using Yt and Yt\u22121 to Yt\u2212p+1.\nThe VAR is identified by the order of the model. Identifying parameters are the values of the \u03b2i that make the model match the data.\nWithout intercepts, there are p \u2212 1 parameters to be estimated.\nFor the special case of a tri-variate VAR(2), there are 3 parameters to be estimated.\nFor a unrestricted, tri-variate VAR(4), there are 12 parameters to be estimated.\nThe number of parameters may seem intimidating, but most are estimated to be zero. In fact, in a VAR(2) with only 3 coefficients to be estimated, over 99% of the coefficients are typically estimated to be zero.\nSOLUTION: An unrestricted, tri-variate VAR(4) has 12 parameters to be estimated. Of these, 5 are estimated constants.\nThe other 7 parameters are estimated using 4 variables.\nSo, in total, 7 parameters will be required to be estimated for these 7 equations."}
{"question": "A researcher tests for structural stability in the following regression model:\n\n$y_t = \\beta_1 + \\beta_2 x_{2t} + \\beta_3 x_{3t} + u_t$\n\nThe total sample of 200 observations is split exactly in half for the sub-sample regressions. Which would be the unrestricted residual sum of squares?", "choices": [{"label": "A", "text": "The RSS for the whole sample"}, {"label": "B", "text": "The RSS for the first sub-sample"}, {"label": "C", "text": "The RSS for the second sub-sample"}, {"label": "D", "text": "The sum of the RSS for the first and second sub-samples"}], "answerKey": "D", "model_answer": "LECTURE: In a regression study, the residual sum of squares (RSS) measures the total distance between the observed values of the dependent variable and the values predicted by the regression model. The RSS can be calculated by summing the squared differences between the predicted and observed values.\nThe RSS for a sample is the sum of the squared differences for the observations in the sample.\nThe unrestricted residual sum of squares is the RSS for the whole sample. It can be calculated by dividing the RSS for the first sub-sample by 2.\nThe restricted residual sum of squares is the RSS for the second sub-sample. It can be calculated by subtracting the RSS for the first sub-sample from the RSS for the whole sample.\nSOLUTION: The total sample is split exactly in half for the sub-sample regressions. So, the second sub-sample contains 100 observations.\nThe RSS for the first sub-sample is 200. The RSS for the second sub-sample is 100. So, the sum of the RSS for the first and second sub-samples is 300.\nThe unrestricted residual sum of squares is the RSS for the whole sample. So, the unrestricted RSS is 200."}
{"question": "Suppose that we are interested in testing the null hypothesis that a GARCH(2,2) model can be restricted to a process with a constant conditional variance using the likelihood ratio test approach. Which of the following statements are true?", "choices": [{"label": "A", "text": "The test statistic will follow a chi-squared distribution with 2 degrees of freedom under the null hypothesis"}, {"label": "B", "text": "The value of the log-likelihood function will almost always be bigger for the restricted model than for the unrestricted model"}, {"label": "C", "text": "If the relevant values of the log-likelihood functions are -112.3 and -118.4, the value of the test statistic is 12.2"}, {"label": "D", "text": "The likelihood ratio test compares the slopes of the log-likelihood function at the maximum and at the restricted parameter value."}], "answerKey": "C", "model_answer": ""}
{"question": "Which one of the following is NOT a plausible remedy for near multicollinearity?", "choices": [{"label": "A", "text": "Use principal components analysis"}, {"label": "B", "text": "Drop one of the collinear variables"}, {"label": "C", "text": "Use a longer run of data"}, {"label": "D", "text": "Take logarithms of each of the variables"}], "answerKey": "D", "model_answer": ""}
{"question": "Consider the following AR(2) process:\n\nyt = 1.5 yt-1 - 0.5 yt-2 + ut\n\nThis is a", "choices": [{"label": "A", "text": "Stationary process"}, {"label": "B", "text": "Unit root process"}, {"label": "C", "text": "Explosive process"}, {"label": "D", "text": "Stationary and unit root process"}], "answerKey": "B", "model_answer": "LECTURE: A statistical process is a function that describes the evolution of a random variable over time.\nA stationary process is a statistical process where the statistical properties do not change over time.\nA unit root process is a statistical process where the statistical properties change suddenly at the beginning of the time series.\nAn explosive process is a statistical process where the statistical properties change suddenly at an unknown point in time.\nA mixing process is a statistical process where the statistical properties are influenced by both past and future values.\nA stationary and mixing process is a statistical process where the statistical properties do not change over time and are influenced by both past and future values.\nA stationary process is a mixing process.\nAn explosive process is a mixing process.\nA unit root process is a nonstationary process.\nA nonstationary process is a mixing process."}
{"question": "Which of the following could be used as a test for autocorrelation up to third order?", "choices": [{"label": "A", "text": "The Durbin Watson test"}, {"label": "B", "text": "White's test"}, {"label": "C", "text": "The RESET test"}, {"label": "D", "text": "The Breusch-Godfrey test"}], "answerKey": "D", "model_answer": ""}
{"question": "The residual from a standard regression model is defined as", "choices": [{"label": "A", "text": "The difference between the actual value, y, and the mean, y-bar"}, {"label": "B", "text": "The difference between the fitted value, y-hat, and the mean, y-bar"}, {"label": "C", "text": "The difference between the actual value, y, and the fitted value, y-hat"}, {"label": "D", "text": "The square of the difference between the fitted value, y-hat, and the mean, y-bar"}], "answerKey": "C", "model_answer": ""}
{"question": "If OLS is applied separately to each equation that is part of a simultaneous system, the resulting estimates will be", "choices": [{"label": "A", "text": "Unbiased and consistent"}, {"label": "B", "text": "Biased but consistent"}, {"label": "C", "text": "Biased and inconsistent"}, {"label": "D", "text": "It is impossible to apply OLS to equations that are part of a simultaneous system"}], "answerKey": "C", "model_answer": ""}
{"question": "Which one of the following is NOT an example of mis-specification of functional form?", "choices": [{"label": "A", "text": "Using a linear specification when y scales as a function of the squares of x"}, {"label": "B", "text": "Using a linear specification when a double-logarithmic model would be more appropriate"}, {"label": "C", "text": "Modelling y as a function of x when in fact it scales as a function of 1/x"}, {"label": "D", "text": "Excluding a relevant variable from a linear regression model"}], "answerKey": "D", "model_answer": ""}
{"question": "Suppose that we wished to evaluate the factors that affected the probability that an investor would choose an equity fund rather than a bond fund or a cash investment. Which class of model would be most appropriate?", "choices": [{"label": "A", "text": "A logit model"}, {"label": "B", "text": "A multinomial logit"}, {"label": "C", "text": "A tobit model"}, {"label": "D", "text": "An ordered logit model"}], "answerKey": "B", "model_answer": "LECTURE: Authors have developed various classes of models to address situations in which the dependent variable is categorical. One class of models is used when there are three or more outcomes. In these models, the dependent variable is modeled as a function of one or more predictor variables.\nThe ordered logit model is used when the outcomes are ordered, or ranked, in a way that makes sense for the problem at hand. The dependent variable is modeled as a function of the predictor variables using the logistic function.\nThe multinomial logit model is used when there are three or more outcomes, and the outcomes are not all ordered. The dependent variable is modeled as a function of the predictor variables using the logistic function.\nThe tobit model is used when the dependent variable is a binary decision about whether to participate in a program or not. The dependent variable is modeled as a function of the predictor variables using the logistic function.\nThe logit model is used when the dependent variable is a binary decision with three or more possible outcomes. The dependent variable is modeled as a function of the predictor variables using the logistic function.\nSOLUTION: An equity fund, a bond fund, and a cash investment are not all ranked, and the decision to invest in each is not a binary decision. So, a logit model, a multinomial logit model, or an ordered logit model would not be appropriate.\nA tobit model could be used. It is appropriate when the dependent variable is a binary decision about whether to participate in a program or not. In this case, the question is whether to invest in an equity fund, a bond fund, or a cash investment."}
{"question": "Which of the following statements will be true if the number of replications used in a Monte Carlo study is small?\n\ni) The statistic of interest may be estimated imprecisely\n\n\nii) The results may be affected by unrepresentative combinations of random draws\n\n\niii) The standard errors on the estimated quantities may be unacceptably large\n\n\niv) Variance reduction techniques can be used to reduce the standard errors", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "LECTURE: Monte Carlo studies use random sampling to simulate real-world processes.\nSuppose you want to estimate the probability that it will rain tomorrow. You can use a Monte Carlo study to do this. For example, you could simulate tomorrow's weather 100 times by running the following code:\nprob = 0;\ndry = 0;\nfor i from 1 to 100:\nif weather is dry:\ndry = dry + 1;\nprob = prob + dry/100;"}
{"question": "Which of the following is a disadvantage of the random effects approach to estimating a panel model?", "choices": [{"label": "A", "text": "The approach may not be valid if the composite error term is correlated with one or more of the explanatory variables"}, {"label": "B", "text": "The number of parameters to estimate may be large, resulting in a loss of degrees of freedom"}, {"label": "C", "text": "The random effects approach can only capture cross-sectional heterogeneity and not temporal variation in the dependent variable."}, {"label": "D", "text": "All of (a) to (c) are potential disadvantages of the random effects approach."}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following could result in autocorrelated residuals?\n\ni) Slowness of response of the dependent variable to changes in the values of the independent variables\n\nii) Over-reactions of the dependent variable to changes in the independent variables\n\niii) Omission of relevant explanatory variables that are autocorrelated\n\niv) Outliers in the data", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: Residuals are the differences between the dependent variable and the predicted value. Residuals can be used to check how well the model fits the data.\nAutocorrelated residuals occur when the residuals show a pattern as you move through the data. This can occur when you omits relevant variables or when there is a slow response or overreaction of the dependent variable to changes in the independent variables.\nSOLUTION: Omitting relevant explanatory variables that are autocorrelated can result in autocorrelated residuals.\nOver-reactions of the dependent variable to changes in the independent variables can also result in autocorrelated residuals.\nA slowness of response of the dependent variable to changes in the values of the independent variables does not necessarily result in autocorrelated residuals.\nOutliers in the data do not necessarily result in autocorrelated residuals."}
{"question": "Which of the following statements are true concerning the acf and pacf?\n\n(i) The acf and pacf are often hard to interpret in practice\n\n(ii) The acf and pacf can be difficult to calculate for some data sets\n\n(iii) Information criteria represent an alternative approach to model order determination\n\n(iv) If applied correctly, the acf and pacf will always deliver unique model selections", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: One of the challenges of data analysis is to select the best model for your data. One approach is to examine the autocorrelation function (ACF) and partial autocorrelation function (PACF).\nThe ACF measures the linear relationship between a time series and its past values. For example, the ACF at lag 1 measures the relationship between the time series and its past value 1 period ago.\nThe PACF measures the linear relationship between a time series and its past values, holding the past values constant from index 1 on. For example, the PACF at lag 1 measures the relationship between the time series and its past value 1 period ago, holding the past value 1 period ago constant.\nThe ACF and PACF are functions of the lag. You can choose to plot the ACF and PACF for a number of lags, or you can use information criteria to determine the optimal number of lags.\nThere are many information criteria that can be used to determine the optimal number of lags. Some of the most popular criteria are the AIC (Akaike information criterion) and the BIC (Bayesian information criterion). These criteria rank models based on the number of lags and the quality of the fit to the data.\nFor example, consider the following models:\nModel 1: AR(2)\nModel 2: MA(2)\nBoth models have two lags. The AIC and BIC criteria can be used to determine which model is a better fit for the data.\nThe AIC and BIC criteria are based on the number of lags and the quality of the fit to the data. The quality of the fit to the data is measured using a goodness-of-fit measure, such as the sum of the squared residuals.\nThe residuals are the differences between the observed values and the values predicted by the model. The sum of the squared residuals is a measure of the overall fit of the model to the data.\nA lower value of AIC and BIC indicates a better fit of the model to the data.\nSOLUTION: The ACF and PACF can be difficult to calculate for some data sets. However, information criteria can be used as an alternative approach to model order determination.\nIf applied correctly, the ACF and PACF will always deliver unique model selections. However, information criteria can be used as a substitute for the ACF and PACF."}
{"question": "Which of the following conditions are necessary for a series to be classifiable as a weakly stationary process?\n\n(i) It must have a constant mean\n\n(ii) It must have a constant variance\n\n(iii) It must have constant autocovariances for given lags\n\n(iv) It must have a constant probability distribution", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
{"question": "Consider the following equation and determine the class of model that it best represents\n\n$y_{it} = \\alpha + \\beta_{it} + \\mu_i + \\nu_{it}$", "choices": [{"label": "A", "text": "An entity fixed effects model"}, {"label": "B", "text": "A time fixed effects model"}, {"label": "C", "text": "A random effects model"}, {"label": "D", "text": "A pure time series model"}], "answerKey": "A", "model_answer": "LECTURE: In a linear regression model, the dependent variable is a function of the independent variables plus some errors. The two types of errors are the random errors and the fixed errors.\nFor example, consider the model:\ny = \u03b20 + \u03b21x + u\nThe random errors are the ones that have mean zero and a constant variance. These errors are caused by the uncertainty in the measurement of the independent variables. For example, consider measuring a person's height in centimeters. The measurement may have a constant variance, but the mean height is not zero.\nThe fixed errors are the ones that do not change within groups. In the model above, the fixed errors are represented by \u03b20. The uncertainty in \u03b20 is due to the variation in the independent variable that is not measured, such as income or education.\nThere are two types of models for analyzing the data with random or fixed errors: the entity fixed effects model and the random effects model.\nIn an entity fixed effects model, the fixed effects are represented by a set of constants. The constants are represented by the term \u03b20 in the model. The model below represents an entity fixed effects model:\ny = \u03b20 + \u03b21x + u\nThe random effects model is similar to the entity fixed effects model. The main difference is that the constants are not represented by a term in the model. The model below represents a random effects model:\ny = \u03b20 + \u03b21x + u\nThe time fixed effects model is a type of random effects model. In a time fixed effects model, the constants are represented by a term in the model. The model below represents a time fixed effects model:\ny = \u03b20i + \u03b21i x + u\nThe pure time series model is a type of model that does not have a constant variance. In a pure time series model, the errors have a constant mean and a constant variance. The model below represents a pure time series model:\ny = \u03b1 + \u03b2t + ut\nSOLUTION: The equation\nyit = \u03b1 + \u03b2it + \u03bci + \u03bdit\nrepresents a random effects model. In this model, the constants are not represented by a term in the model."}
{"question": "Note that statistical tables are not necessary to answer this question. For a sample of 1000 observations, the Dickey-Fuller test statistic values are", "choices": [{"label": "A", "text": "More negative than (i.e. bigger in absolute value than) those in the left hand tail of a normal distribution"}, {"label": "B", "text": "Less negative than (i.e. smaller in absolute value than) those in the left hand tail of a normal distribution"}, {"label": "C", "text": "Obtained from an analytical formula for the density of the Dickey-Fuller distribution"}, {"label": "D", "text": "More negative (i.e. bigger in absolute value) for a 10% size of test than a 5% test."}], "answerKey": "A", "model_answer": ""}
{"question": "Suppose that a hypothesis test is conducted using a 5% significance level. Which of the following statements are correct?\n\n(i) The significance level is equal to the size of the test\n\n(ii) The significance level is equal to the power of the test\n\n(iii) 2.5% of the total distribution will be in each tail rejection region for a 2-sided test\n\n(iv) 5% of the total distribution will be in each tail rejection region for a 2-sided test.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": ""}
{"question": "Which one of the following criticisms of the Dickey-Fuller/Engle-Granger approach to dealing with cointegrated variables is overcome by the Engle-Yoo (EY) procedure?", "choices": [{"label": "A", "text": "In the context of small samples, Dickey Fuller tests are prone to conclude that there is a unit root in a series when there is not"}, {"label": "B", "text": "The Engle-Granger (EG) approach can only detect up to one cointegrating relationship even though there could be more than one"}, {"label": "C", "text": "The variables are treated asymmetrically in the cointegrating tests"}, {"label": "D", "text": "It is not possible to perform tests about the cointegrating relationship"}], "answerKey": "D", "model_answer": ""}
{"question": "Consider a series that follows an MA(1) with zero mean and a moving average coefficient of 0.4. What is the value of the autocovariance at lag 1?", "choices": [{"label": "A", "text": "0.4"}, {"label": "B", "text": "1"}, {"label": "C", "text": "0.34"}, {"label": "D", "text": "It is not possible to determine the value of the autocovariances without knowing the disturbance variance."}], "answerKey": "D", "model_answer": "LECTURE: The autocovariance function is a measure of how closely the innovations in a series resemble the innovations from a different time period. The autocovariance at lag 1 is the autocovariance between the innovations at time 1 and the innovations at time 0.\nThe autocovariance at lag 1 is given by:\nC[1] = E[(X[0] - \u03bc[0])(X[1] - \u03bc[1])]\nwhere X is the innovation process, \u03bc is the mean process, and E is the expected value operator.\nThe mean and variance of the innovations are given by:\n\u03bc[0] = 0\n\u03bc[1] = 0\n\u03c3[1] = \u03c3/0.4 = 0.8\u03c3\nThe autocovariance at lag 1 is 0.4."}
{"question": "Which of the following estimation techniques are available for the estimation of over-identified systems of simultaneous equations?\n\ni) OLS\n\nii) ILS\n\niii) 2SLS\n\niv) IV", "choices": [{"label": "A", "text": "(iii) only"}, {"label": "B", "text": "(iii) and (iv) only"}, {"label": "C", "text": "(ii), (iii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii) and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: Estimation techniques are methods for calculating the coefficients in a regression model. Different techniques can be used for different types of models.\nNormal estimates are calculated using maximum likelihood estimates. These are used for simple linear regression and regular linear regression.\nDeviation estimates are used for multiple linear regression. These are more resistant to outliers.\nOLS (ordinary least squares) is a technique for finding the estimates of the coefficients in a linear regression model. It is based on the normal estimates.\nProportional sums estimates are used when there are different Xs for each Y. These are used for fixed effects regression.\n2SLS (two-stage least squares) is a technique for addressing heteroscedasticity and autocorrelation in the errors. It involves regressing the dependent variable on the predictors, and then regressing the predictors on the dependent variable.\nIV (instrumental variables) is a technique for addressing endogenous predictors. It involves using a predictor that is correlated with the dependent variable but not directly with the predictors.\nILS (instrumental variables least squares) is a technique for finding the estimates of the coefficients in a multiple regression model when there is heteroscedasticity and autocorrelation in the errors. It involves regressing the dependent variable on the predictors, and then regressing the predictors on the dependent variable."}
{"question": "Which one of the following statements best describes a Type II error?", "choices": [{"label": "A", "text": "It is the probability of incorrectly rejecting the null hypothesis"}, {"label": "B", "text": "It is equivalent to the power of the test"}, {"label": "C", "text": "It is equivalent to the size of the test"}, {"label": "D", "text": "It is the probability of failing to reject a null hypothesis that was wrong"}], "answerKey": "D", "model_answer": "A Type II error is the probability of failing to reject a null hypothesis that was wrong. It is a type of error people make when they assume that a test has failed when it actually has not.\nThe size of a test is the probability of rejecting the null hypothesis when it is false. A test's size is always less than or equal to the level of significance. In other words, the larger the level of significance, the higher the size of the test.\nThe power of a test is the probability of rejecting the null hypothesis when it is false. A test's power is always less than or equal to its size. In other words, the larger the size of the test, the higher the power of the test.\nThe probability of incorrectly rejecting the null hypothesis is a type of error that can happen when the null hypothesis is true. This error is called a Type I error."}
{"question": "Which one of the following would be the most appropriate as a 95% (two-sided) confidence interval for the intercept term of the model given in question 21?", "choices": [{"label": "A", "text": "(-4.79,2.19)"}, {"label": "B", "text": "(-4.16,4.16)"}, {"label": "C", "text": "(-1.98,1.98)"}, {"label": "D", "text": "(-5.46,2.86)"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following are characteristics of a stationary process?\n\ni) It crosses its mean value frequently\n\n\nii) It has constant mean and variance\n\n\niii) It contains no trend component\n\n\niv) It will be stationary in first difference form", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": ""}
{"question": "Consider again the VAR model of equation 16. Which of the following conditions must hold for it to be said that there is bi-directional feedback?", "choices": [{"label": "A", "text": "The b and d coefficients significant and the a and c coefficients insignificant"}, {"label": "B", "text": "The a and c coefficients significant and the b and d coefficients insignificant"}, {"label": "C", "text": "The a and c coefficients significant"}, {"label": "D", "text": "The b and d coefficients significant"}], "answerKey": "D", "model_answer": "LECTURE: Feedback is the term used to describe the effect of one variable on its own value. If a variable changes in response to its own current value, it is said to have a feedback effect.\nWhen testing for the presence of feedback in a VAR model, you need to examine the a, b, c, and d coefficients. Feedback exists if at least one of the b coefficients is significant.\nBecause the d coefficient is just the reciprocal of the b coefficient, the d coefficient will also be significant if the b coefficient is significant. So, the a and c coefficients can be insignificant, and the b and d coefficients can be significant if there is bi-directional feedback."}
{"question": "Consider the following sample autocorrelation estimates obtained using 250 data points:\n\n1) Lag 1 2 3\n\n2) Coefficient 0.2 -0.15 -0.1\n\n3) Assuming that the coefficients are approximately normally distributed, which of the coefficients are statistically significant at the 5% level?", "choices": [{"label": "A", "text": "1 only"}, {"label": "B", "text": "1 and 2 only"}, {"label": "C", "text": "1, 2 and 3 only"}, {"label": "D", "text": "It is not possible to determine the statistical significance since no standard errors have been given"}], "answerKey": "B", "model_answer": "LECTURE: Autocorrelation is a statistical phenomenon that occurs when a variable is correlated with its own past values.\nFor example, consider the simple linear regression of y on x. The regression function is y = a + bx. If we observe a pattern in the cross-products of the data, such as bx, we have identified the autocorrelation in the data.\nAutocorrelation coefficients can be helpful in identifying the degree to which the model is a function of its own past values.\nIf the autocorrelation coefficient is close to zero, then the model is not a function of its own past values.\nIf the autocorrelation coefficient is greater than zero, then a small part of the model is a function of its own past values.\nIf the autocorrelation coefficient is greater than one, then a large part of the model is a function of its own past values.\nSOLUTION: The model is a function of its own past values if the autocorrelation coefficient is greater than zero. An autocorrelation coefficient of 0.2 and -0.15 is greater than zero, so these coefficients are statistically significant at the 5% level. An autocorrelation coefficient of -0.1 is less than zero, so it is not statistically significant at the 5% level."}
{"question": "Which one of the following is examined by looking at a goodness of fit statistic?", "choices": [{"label": "A", "text": "How well the population regression function fits the data"}, {"label": "B", "text": "How well the sample regression function fits the population regression function"}, {"label": "C", "text": "How well the sample regression function fits the data"}, {"label": "D", "text": "How well the population regression function fits the sample regression function."}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following statements are correct concerning the use of antithetic variates as part of a Monte Carlo experiment?\n\ni) Antithetic variates work by reducing the number of replications required to cover the whole probability space\n\nii) Antithetic variates involve employing a similar variable to that used in the simulation, but whose properties are known analytically\n\niii) Antithetic variates involve using the negative of each of the random draws and repeating the experiment using those values as the draws\n\niv) Antithetic variates involve taking one over each of the random draws and repeating the experiment using those values as the draws", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": ""}
{"question": "Which one of the following statements is true concerning alternative forecast accuracy measures?", "choices": [{"label": "A", "text": "Mean squared error is usually highly correlated with trading rule profitability"}, {"label": "B", "text": "Mean absolute error provides a quadratic loss function"}, {"label": "C", "text": "Mean absolute percentage error is a useful measure for evaluating asset return forecasts"}, {"label": "D", "text": "Mean squared error penalises large forecast errors disproportionately more than small forecast errors"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following criticisms of standard (\"plain vanilla\") GARCH models can be overcome by EGARCH models?\n\ni) Estimated coefficient values from GARCH models may be negative\n\nii) GARCH models cannot account for leverage effects\n\niii) The responsiveness of future volatility to positive and negative shocks is symmetric under a GARCH formulation\n\niv) GARCH models cannot allow for a feedback from the volatility to the returns", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
{"question": "Suppose that 100 separate firms were tested to determine how many of them \"beat the market\" using a Jensen-type regression, and it is found that 3 fund managers significantly do so. Does this suggest prima facie evidence for stock market inefficiency?", "choices": [{"label": "A", "text": "Yes"}, {"label": "B", "text": "No"}, {"label": "C", "text": "In order to answer this question, you would need to test every fund manager trading in that market"}, {"label": "D", "text": "There is insufficient information given in the question to draw a conclusion about market efficiency."}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following are advantages of the use of panel data over pure cross-sectional or pure time-series modelling?\n\n(i) The use of panel data can increase the number of degrees of freedom and therefore the power of tests\n\n(ii) The use of panel data allows the average value of the dependent variable to vary either cross-sectionally or over time or both\n\n(iii) The use of panel data enables the researcher allows the estimated relationship between the independent and dependent variables to vary either cross-sectionally or over time or both", "choices": [{"label": "A", "text": "(i) only"}, {"label": "B", "text": "(i) and (ii) only"}, {"label": "C", "text": "(ii) only"}, {"label": "D", "text": "(i), (ii), and (iii)"}], "answerKey": "B", "model_answer": "LECTURE: Panel data are observations on multiple units (individuals, companies, countries, etc.) over multiple time periods. Panel data can be used to estimate dynamics, which are patterns of change over time. Panel data also can be used to estimate static patterns, which are the relationships between variables.\nThere are several advantages to using panel data instead of cross-sectional or time-series data.\nFirst, panel data can increase the number of degrees of freedom and the power of tests. More observations can make estimates more precise.\nSecond, panel data allow the average value of the dependent variable to vary either cross-sectionally or over time or both. This means that changes in the dependent variable can be studied as if they were experiments.\nThird, panel data enable the researcher to estimate the relationship between the independent and dependent variables to vary either cross-sectionally or over time or both. This means that the researcher can examine whether the nature of the relationship between the variables depends on the units or the time period.\nSOLUTION: All of the above."}
{"question": "If the Engle-Granger test is applied to the residuals of a potentially cointegrating regression, what would be the interpretation of the null hypothesis?", "choices": [{"label": "A", "text": "The variables are cointegrated"}, {"label": "B", "text": "The variables are not cointegrated"}, {"label": "C", "text": "Both variables are stationary"}, {"label": "D", "text": "Both variables are non-stationary"}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following statements are true concerning the autocorrelation function (acf) and partial autocorrelation function (pacf)?\n\ni) The acf and pacf will always be identical at lag one whatever the model\n\nii) The pacf for an MA(q) model will in general be non-zero beyond lag q\n\niii) The pacf for an AR(p) model will be zero beyond lag p\n\niv) The acf and pacf will be the same at lag two for an MA(1) model", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
