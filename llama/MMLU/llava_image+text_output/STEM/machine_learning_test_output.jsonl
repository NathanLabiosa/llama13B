{"question": "Statement 1| Linear regression estimator has the smallest variance among all unbiased estimators. Statement 2| The coefficients \u03b1 assigned to the classifiers assembled by AdaBoost are always non-negative.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "LECTURE: A random sample of 30 values was collected from a population. The sample mean was found to be 15. The population standard deviation was calculated to be 5.\nThe variance of a sample is always calculated as the average of the squared differences from the mean.\nSo, the variance of the sample is:\nvar(x) = \u2211(x - 15)2 / 30\nvar(x) = (130 - 15) / 30\nvar(x) = 10 / 30\nvar(x) = 0.526\nThe standard deviation of a population is defined as the square root of the population variance.\nSo, the standard deviation of the population is:\n\u03c3 = \u221a0.526\n\u03c3 = 0.771\nThe best estimate of the population mean is the sample mean. The linear regression estimator has the smallest variance among all unbiased estimators. So, the sample mean is the least biased estimator of the population mean.\nThe AdaBoost classifier is assembled by picking a class and setting its weight to 1, and then iteratively picking a class whose error is largest and setting its weight to 1. So, the coefficients \u03b1 assigned to the classifiers assembled by AdaBoost are always non-negative."}
{"question": "Statement 1| RoBERTa pretrains on a corpus that is approximate 10x larger than the corpus BERT pretrained on. Statement 2| ResNeXts in 2018 usually used tanh activation functions.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: Statements 1 and 2 are true.\nStatement 1 is true. RoBERTa is a language model that is based on BERT. It is trained on a corpus that is 10 times as large as the corpus that BERT was trained on. This means that RoBERTa has 10 times as much data to use during training.\nStatement 2 is false. ResNeXt models do not always use tanh activation functions."}
{"question": "Statement 1| Support vector machines, like logistic regression models, give a probability distribution over the possible labels given an input example. Statement 2| We would expect the support vectors to remain the same in general as we move from a linear kernel to higher order polynomial kernels.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: Statement 1 is false.\nA support vector machine (SVM) uses a linear kernel by default. If you change the kernel to a polynomial kernel of degree 2, the SVM becomes an ordinary least squares model.\nStatement 2 is true.\nThe support vectors remain the same in a polynomial kernel of degree 2 as in a linear kernel."}
{"question": "A machine learning problem involves four attributes plus a class. The attributes have 3, 2, 2, and 2 possible values each. The class has 3 possible values. How many maximum possible different examples are there?", "choices": [{"label": "A", "text": "12"}, {"label": "B", "text": "24"}, {"label": "C", "text": "48"}, {"label": "D", "text": "72"}], "answerKey": "D", "model_answer": "LECTURE: For a machine learning problem, the examples are the data. Each example is a row in the training dataset. The maximum number of different examples is equal to the maximum number of possible values for each attribute multiplied by the maximum number of possible values for the class.\nThis total number is 3 multiplied by 3 multiplied by 2 multiplied by 2 multiplied by 2 multiplied by 2. This product is known as the multiplication principle of counting.\nYou can use this principle to count the maximum number of different examples for machines learning problems with more attributes and a class.\nSOLUTION: Apply the multiplication principle of counting.\nThe maximum number of different examples is 3 multiplied by 3 multiplied by 2 multiplied by 2 multiplied by 2 multiplied by 2.\nThis number is 72."}
{"question": "As of 2020, which architecture is best for classifying high-resolution images?", "choices": [{"label": "A", "text": "convolutional networks"}, {"label": "B", "text": "graph networks"}, {"label": "C", "text": "fully connected networks"}, {"label": "D", "text": "RBF networks"}], "answerKey": "A", "model_answer": "LECTURE: Network architecture is a critical aspect of designing an image classifier. Each type of network architecture has its own advantages and disadvantages.\nA convolutional network is a type of network architecture that is well suited to processing grids of data, such as images. Convolutional networks have been the most successful architecture for classifying high-resolution images.\nA graph network is a type of network architecture that is well suited to modeling complex connections between data points. Graph networks can be effective for classifying images with subtle patterns.\nA fully connected network is a type of network architecture in which each layer is connected to every other layer. Fully connected networks can be effective for classifying images, but they can be computationally inefficient.\nA RBF network is a type of network architecture in which nodes can represent items from a small number of classes. RBF networks can be effective for classifying images, but they can be computationally inefficient."}
{"question": "Statement 1| The log-likelihood of the data will always increase through successive iterations of the expectation maximation algorithm. Statement 2| One disadvantage of Q-learning is that it can only be used when the learner has prior knowledge of how its actions affect its environment.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: Statement 1 is false.\nThe log-likelihood of the data can increase or decrease depending on the data and the algorithm being used.\nStatement 2 is false.\nQ-learning does not require that the learner have prior knowledge of how its actions affect the environment."}
{"question": "Let us say that we have computed the gradient of our cost function and stored it in a vector g. What is the cost of one gradient descent update given the gradient?", "choices": [{"label": "A", "text": "O(D)"}, {"label": "B", "text": "O(N)"}, {"label": "C", "text": "O(ND)"}, {"label": "D", "text": "O(ND^2)"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| For a continuous random variable x and its probability distribution function p(x), it holds that 0 \u2264 p(x) \u2264 1 for all x. Statement 2| Decision tree is learned by minimizing information gain.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": ""}
{"question": "Consider the Bayesian network given below. How many independent parameters are needed for this Bayesian Network H -> U <- P <- W?", "choices": [{"label": "A", "text": "2"}, {"label": "B", "text": "4"}, {"label": "C", "text": "8"}, {"label": "D", "text": "16"}], "answerKey": "C", "model_answer": "LECTURE: A Bayesian network is a directed acyclic graph (DAG) that represents a set of random variables and their dependencies.\nThe nodes in the graph represent random variables, and the edges represent the dependencies between them. An arrow points from one random variable to another to indicate that the second random variable is dependent on the first.\nThe probability of a random variable is represented as a function of its parents in the graph. For example, the probability of a random variable U is represented as a function of the parents P and W.\nIn this graph, H is not a parent of U. So, U is not dependent on H.\nP is a parent of U. So, U is dependent on P.\nW is a parent of P. So, P is dependent on W.\nSo, there are two independent parameters in this Bayesian network: P and W.\nH is not independent because it is a parent of U."}
{"question": "As the number of training examples goes to infinity, your model trained on that data will have:", "choices": [{"label": "A", "text": "Lower variance"}, {"label": "B", "text": "Higher variance"}, {"label": "C", "text": "Same variance"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": "LECTURE: The variance of a model is a measure of how much the model's predictions vary.\nHigh variance indicates that the model's predictions are all over the place. This means that the model is flexible, but it may not be learning the right pattern.\nLow variance indicates that the model's predictions are consistent, but they may be too simple. This means that the model is not flexible enough.\nSOLUTION: As the number of training examples goes to infinity, the model trained on that data will have lower variance. This is because the model will be able to find the right pattern by looking at more data."}
{"question": "Statement 1| The set of all rectangles in the 2D plane (which includes non axisaligned rectangles) can shatter a set of 5 points. Statement 2| The VC-dimension of k-Nearest Neighbour classifier when k = 1 is infinite.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "_ refers to a model that can neither model the training data nor generalize to new data.", "choices": [{"label": "A", "text": "good fitting"}, {"label": "B", "text": "overfitting"}, {"label": "C", "text": "underfitting"}, {"label": "D", "text": "all of the above"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| The F1 score can be especially useful for datasets with class high imbalance. Statement 2| The area under the ROC curve is one of the main metrics used to assess anomaly detectors.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| The back-propagation algorithm learns a globally optimal neural network with hidden layers. Statement 2| The VC dimension of a line should be at most 2, since I can find at least one case of 3 points that cannot be shattered by any line.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: A graph is a collection of vertices and edges. A simple graph is a graph with no edges.\nThe degree of a vertex is the number of edges incident to the vertex.\nThe minimum degree of a graph is the minimum degree of any vertex in the graph.\nThe VC dimension of a graph is the number of vertices required to make the graph shatter a set.\nA graph shatters a set if the set is covered by some subset of vertices in the graph.\nA subset of vertices in a graph is a shattered set if it is not a shattered set.\nSOLUTION: The back-propagation algorithm learns a globally optimal neural network with hidden layers.\nThis statement is false. A single training example may not be sufficient to learn a globally optimal neural network with hidden layers.\nThe VC dimension of a line should be at most 2, since I can find at least one case of 3 points that cannot be shattered by any line.\nThis statement is false. The VC dimension of a line is 2."}
{"question": "High entropy means that the partitions in classification are", "choices": [{"label": "A", "text": "pure"}, {"label": "B", "text": "not pure"}, {"label": "C", "text": "useful"}, {"label": "D", "text": "useless"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| Layer Normalization is used in the original ResNet paper, not Batch Normalization. Statement 2| DCGANs use self-attention to stabilize training.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": ""}
{"question": "In building a linear regression model for a particular data set, you observe the coefficient of one of the features having a relatively high negative value. This suggests that", "choices": [{"label": "A", "text": "This feature has a strong effect on the model (should be retained)"}, {"label": "B", "text": "This feature does not have a strong effect on the model (should be ignored)"}, {"label": "C", "text": "It is not possible to comment on the importance of this feature without additional information"}, {"label": "D", "text": "Nothing can be determined."}], "answerKey": "C", "model_answer": "LECTURE: When building a linear regression model, you can calculate the coefficient (or value) for each feature. A coefficient can be positive or negative.\nA positive coefficient indicates that the value of the feature is increasing as the target variable increases. So, the effect of the feature is positive.\nA negative coefficient indicates that the value of the feature is decreasing as the target variable increases. So, the effect of the feature is negative.\nThe magnitude (or size) of the coefficient shows how much the feature affects the model. A larger magnitude coefficient has a stronger effect on the model.\nSOLUTION: A relatively high negative value for the coefficient of a feature suggests that the effect of the feature is negative. In other words, as the target variable increases, the value of the feature decreases. This indicates that the feature has a strong effect on the model. So, it should be retained."}
{"question": "For a neural network, which one of these structural assumptions is the one that most affects the trade-off between underfitting (i.e. a high bias model) and overfitting (i.e. a high variance model):", "choices": [{"label": "A", "text": "The number of hidden nodes"}, {"label": "B", "text": "The learning rate"}, {"label": "C", "text": "The initial choice of weights"}, {"label": "D", "text": "The use of a constant-term unit input"}], "answerKey": "A", "model_answer": ""}
{"question": "For polynomial regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "The polynomial degree"}, {"label": "B", "text": "Whether we learn the weights by matrix inversion or gradient descent"}, {"label": "C", "text": "The assumed variance of the Gaussian noise"}, {"label": "D", "text": "The use of a constant-term unit input"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| As of 2020, some models attain greater than 98% accuracy on CIFAR-10. Statement 2| The original ResNets were not optimized with the Adam optimizer.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: Statements 1 and 2 are true.\nIn the past, some models have achieved 98% accuracy on CIFAR-10.\nHowever, the original ResNets were not optimized with the Adam optimizer."}
{"question": "The K-means algorithm:", "choices": [{"label": "A", "text": "Requires the dimension of the feature space to be no bigger than the number of samples"}, {"label": "B", "text": "Has the smallest value of the objective function when K = 1"}, {"label": "C", "text": "Minimizes the within class variance for a given number of clusters"}, {"label": "D", "text": "Converges to the global optimum if and only if the initial means are chosen as some of the samples themselves"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| VGGNets have convolutional kernels of smaller width and height than AlexNet's first-layer kernels. Statement 2| Data-dependent weight initialization procedures were introduced before Batch Normalization.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: Statements of limitations are often qualitative. They may describe a limitation in terms of time, convenience, or practicality.\nA statement of a limitation may include a sentence or a phrase that indicates a restriction or a constraint.\nSOLUTION: The first statement is true. VGG net architectures have smaller convolutional kernels than AlexNet in their first layers.\nThe second statement is false. Data-dependent weight initialization procedures were introduced after Batch Normalization."}
{"question": "What is the rank of the following matrix? A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]", "choices": [{"label": "A", "text": "0"}, {"label": "B", "text": "1"}, {"label": "C", "text": "2"}, {"label": "D", "text": "3"}], "answerKey": "B", "model_answer": "LECTURE: A matrix is a grid of numbers.\nThe rank of a matrix is the number of rows or columns in the matrix that are not dependent.\nFor example, consider the matrix:\nA = | 1 | 0 |\n| 0 | 1 |\n| 1 | 0 |\nThis matrix has a rank of 1. The first row is dependent on the second row, so the rank is less than 2.\nSOLUTION: To find the rank of matrix A, look at the matrix.\nSince there are three different elements in the matrix, the rank is 3."}
{"question": "Statement 1| Density estimation (using say, the kernel density estimator) can be used to perform classification. Statement 2| The correspondence between logistic regression and Gaussian Naive Bayes (with identity class covariances) means that there is a one-to-one correspondence between the parameters of the two classifiers.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: Statement 1 is true. Density estimation can be used to perform classification by plotting a cloud of data points and classification is based on the classification of the unlabeled data points that have values closest to the classification boundary.\nGaussian Naive Bayes is a probabilistic classifier. It calculates the probability that a data point belongs to each class and then assigns the data point to the class with the highest probability.\nLogistic regression is a probabilistic classifier. It calculates the probability that a data point belongs to each class and then assigns the data point to the class with the highest probability.\nThe correspondence between logistic regression and Gaussian Naive Bayes (with identity class covariances) shows that there is a one-to-one correspondence between the parameters of the two classifiers.\nStatement 2 is false. The correspondence between logistic regression and Gaussian Naive Bayes (with identity class covariances) shows that there is a one-to-one correspondence between the parameters of the two classifiers. However, density estimation is not a classification algorithm."}
{"question": "Suppose we would like to perform clustering on spatial data such as the geometrical locations of houses. We wish to produce clusters of many different sizes and shapes. Which of the following methods is the most appropriate?", "choices": [{"label": "A", "text": "Decision Trees"}, {"label": "B", "text": "Density-based clustering"}, {"label": "C", "text": "Model-based clustering"}, {"label": "D", "text": "K-means clustering"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| In AdaBoost weights of the misclassified examples go up by the same multiplicative factor. Statement 2| In AdaBoost, weighted training error e_t of the tth weak classifier on training data with weights D_t tends to increase as a function of t.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "MLE estimates are often undesirable because", "choices": [{"label": "A", "text": "they are biased"}, {"label": "B", "text": "they have high variance"}, {"label": "C", "text": "they are not consistent estimators"}, {"label": "D", "text": "None of the above"}], "answerKey": "B", "model_answer": "LECTURE: Estimators have different properties that affect their value. Here are some common properties of estimators:\nConsistency: A consistent estimator is one whose value gets closer to the true value as the sample size increases.\nUnbiased: A unbiased estimator is one that has a mean of zero when the true value is equal to the hypothesized value.\nNormal: A normal estimator is one whose values follow a normal distribution as the sample size increases.\nBounded: A bounded estimator has a range of values that is within a bounded distance from the true value.\nVariance: The variance of an estimator is a measure of how far the estimator is, on average, from the true value. A estimator with a low variance is better than a estimator with a high variance.\nSOLUTION: MLE estimates are often undesirable because they are biased. A biased estimator is one whose mean is not equal to the true value."}
{"question": "Computational complexity of Gradient descent is,", "choices": [{"label": "A", "text": "linear in D"}, {"label": "B", "text": "linear in N"}, {"label": "C", "text": "polynomial in D"}, {"label": "D", "text": "dependent on the number of iterations"}], "answerKey": "C", "model_answer": "LECTURE: In machine learning, you often need to optimize a model. For example, you might want to find the values of the parameters that make the model's predictions as accurate as possible.\nFor a pure function of n parameters, there are only n ways to assign values to those parameters. To find the optimal values, you can try each possible set of values and evaluate each set.\nThe number of operations needed to evaluate one set of parameters is constant, so the total number of operations is linear in the number of parameters. In other words, the computational complexity of finding the optimal parameters is linear in n."}
{"question": "Averaging the output of multiple decision trees helps _.", "choices": [{"label": "A", "text": "Increase bias"}, {"label": "B", "text": "Decrease bias"}, {"label": "C", "text": "Increase variance"}, {"label": "D", "text": "Decrease variance"}], "answerKey": "D", "model_answer": "LECTURE: The average of multiple decision trees is less risky than a single decision tree. This is because the average takes the best decision from each tree. For example, if the trees predict that A, B, and C are the best choices, the average decision will be A.\nSo, the average of multiple decision trees helps decrease bias and decrease variance."}
{"question": "The model obtained by applying linear regression on the identified subset of features may differ from the model obtained at the end of the process of identifying the subset during", "choices": [{"label": "A", "text": "Best-subset selection"}, {"label": "B", "text": "Forward stepwise selection"}, {"label": "C", "text": "Forward stage wise selection"}, {"label": "D", "text": "All of the above"}], "answerKey": "C", "model_answer": ""}
{"question": "Neural networks:", "choices": [{"label": "A", "text": "Optimize a convex objective function"}, {"label": "B", "text": "Can only be trained with stochastic gradient descent"}, {"label": "C", "text": "Can use a mix of different activation functions"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": ""}
{"question": "Say the incidence of a disease D is about 5 cases per 100 people (i.e., P(D) = 0.05). Let Boolean random variable D mean a patient \u201chas disease D\u201d and let Boolean random variable TP stand for \"tests positive.\" Tests for disease D are known to be very accurate in the sense that the probability of testing positive when you have the disease is 0.99, and the probability of testing negative when you do not have the disease is 0.97. What is P(TP), the prior probability of testing positive.", "choices": [{"label": "A", "text": "0.0368"}, {"label": "B", "text": "0.473"}, {"label": "C", "text": "0.078"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": "LECTURE: The probability of a disease is called the incidence of the disease.\nThe probability of testing positive for a disease is called the sensitivity of the test, or the true positive rate.\nThe probability of testing negative for a disease is called the specificity of the test, or the true negative rate.\nGiven the incidence of a disease D, the prior probability of testing positive is given by the sensitivity of the test times the incidence of the disease:\nP(TP) = specificity x incidence\nTo check whether this probability is between 0.0368 and 0.473, included in 0.078, or none of the above, consider the following table:\nSOLUTION: The only value in the table that is between 0.0368 and 0.473 is 0.078. So, P(TP) is between 0.0368 and 0.473."}
{"question": "Statement 1| After mapped into feature space Q through a radial basis kernel function, 1-NN using unweighted Euclidean distance may be able to achieve better classification performance than in original space (though we can\u2019t guarantee this). Statement 2| The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SVM.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: A high-dimensional space does not necessarily make a classification problem more difficult. The VC dimension of a model is a measure of its ability to classify a set of points.\nFor example, consider a linear boundary that separates two regions. The regions are not necessarily aligned with the coordinate axis. This linear boundary can separate the regions with different slopes and positions.\nNow consider a higher-dimensional space. A linear boundary can still separate the regions by defining a hyperplane within the higher-dimensional space. The number of possible positions and slopes of this hyperplane is equal to the VC dimension of a simple linear SVM.\nSo, a simple linear SVM has a smaller VC dimension than a Perceptron.\nSOLUTION: The first statement is true. The second statement is false.\nAfter mapped into feature space Q through a radial basis kernel function, 1-NN using unweighted Euclidean distance may be able to achieve better classification performance than in original space (though we can\u2019t guarantee this).\nThe VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SVM.\nA simple linear SVM has a smaller VC dimension than a Perceptron."}
{"question": "The disadvantage of Grid search is", "choices": [{"label": "A", "text": "It can not be applied to non-differentiable functions."}, {"label": "B", "text": "It can not be applied to non-continuous functions."}, {"label": "C", "text": "It is hard to implement."}, {"label": "D", "text": "It runs reasonably slow for multiple linear regression."}], "answerKey": "D", "model_answer": "LECTURE: Some machine learning algorithms can be applied only to specific types of functions.\nA non-differentiable function is a function that is not differentiable at certain points. A non-continuous function is a function that is not continuous at certain points.\nA non-differentiable function cannot be used with gradient-based optimization algorithms.\nA non-continuous function cannot be used with optimization algorithms that rely on discrete steps.\nSome machine learning algorithms require a significant amount of data to be effective.\nGrid search is a brute-force search over a parameter space. It is hard to implement and runs reasonably slow for multiple linear regression."}
{"question": "Predicting the amount of rainfall in a region based on various cues is a ______ problem.", "choices": [{"label": "A", "text": "Supervised learning"}, {"label": "B", "text": "Unsupervised learning"}, {"label": "C", "text": "Clustering"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": "LECTURE: In machine learning, you can divide the types of learning problems into three categories: supervised learning, unsupervised learning, and reinforcement learning.\nIn supervised learning, the algorithm is trained using labeled data. The data consists of inputs and outputs, and the algorithm learns to map inputs to outputs.\nSOLUTION: To predict the amount of rainfall in a region based on various cues, you need to learn what information (inputs) can be used to make the prediction. This is a supervised learning problem."}
{"question": "Which of the following sentence is FALSE regarding regression?", "choices": [{"label": "A", "text": "It relates inputs to outputs."}, {"label": "B", "text": "It is used for prediction."}, {"label": "C", "text": "It may be used for interpretation."}, {"label": "D", "text": "It discovers causal relationships"}], "answerKey": "D", "model_answer": "LECTURE: A graph shows the relationship between two things. A graph can help you see how one thing changes with another.\nA scatter plot is a type of graph. It shows the relationship between two things. In a scatter plot, each point represents the input and output for a single object.\nSOLUTION: Regression is a method of prediction. It uses observations of one variable to predict observations of another variable.\nSo, regression relates inputs to outputs. It is used for prediction.\nInterpretation can be made from the coefficients in the regression equation. But the regression equation may be used for prediction.\nAs a method of prediction, regression may be used to estimate the outcome of a single object. But it may not be used to interpret the meaning of the inputs.\nIt is not true that regression discovers causal relationships. Regression can uncover patterns of change. But it does not tell you what is causing the change."}
{"question": "Which one of the following is the main reason for pruning a Decision Tree?", "choices": [{"label": "A", "text": "To save computing time during testing"}, {"label": "B", "text": "To save space for storing the Decision Tree"}, {"label": "C", "text": "To make the training set error smaller"}, {"label": "D", "text": "To avoid overfitting the training set"}], "answerKey": "D", "model_answer": ""}
{"question": "Statement 1| The kernel density estimator is equivalent to performing kernel regression with the value Yi = 1/n at each point Xi in the original data set. Statement 2| The depth of a learned decision tree can be larger than the number of training examples used to create the tree.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": ""}
{"question": "Suppose your model is overfitting. Which of the following is NOT a valid way to try and reduce the overfitting?", "choices": [{"label": "A", "text": "Increase the amount of training data."}, {"label": "B", "text": "Improve the optimisation algorithm being used for error minimisation."}, {"label": "C", "text": "Decrease the model complexity."}, {"label": "D", "text": "Reduce the noise in the training data."}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| The softmax function is commonly used in mutliclass logistic regression. Statement 2| The temperature of a nonuniform softmax distribution affects its entropy.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following is/are true regarding an SVM?", "choices": [{"label": "A", "text": "For two dimensional data points, the separating hyperplane learnt by a linear SVM will be a straight line."}, {"label": "B", "text": "In theory, a Gaussian kernel SVM cannot model any complex separating hyperplane."}, {"label": "C", "text": "For every kernel function used in a SVM, one can obtain an equivalent closed form basis expansion."}, {"label": "D", "text": "Overfitting in an SVM is not a function of number of support vectors."}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following is the joint probability of H, U, P, and W described by the given Bayesian Network H -> U <- P <- W? [note: as the product of the conditional probabilities]", "choices": [{"label": "A", "text": "P(H, U, P, W) = P(H) * P(W) * P(P) * P(U)"}, {"label": "B", "text": "P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(W | H, P)"}, {"label": "C", "text": "P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(U | H, P)"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| Since the VC dimension for an SVM with a Radial Base Kernel is infinite, such an SVM must be worse than an SVM with polynomial kernel which has a finite VC dimension. Statement 2| A two layer neural network with linear activation functions is essentially a weighted combination of linear separators, trained on a given dataset; the boosting algorithm built on linear separators also finds a combination of linear separators, therefore these two algorithms will give the same result.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| The ID3 algorithm is guaranteed to find the optimal decision tree. Statement 2| Consider a continuous probability distribution with density f() that is nonzero everywhere. The probability of a value x is equal to f(x).", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": ""}
{"question": "Given a Neural Net with N input nodes, no hidden layers, one output node, with Entropy Loss and Sigmoid Activation Functions, which of the following algorithms (with the proper hyper-parameters and initialization) can be used to find the global optimum?", "choices": [{"label": "A", "text": "Stochastic Gradient Descent"}, {"label": "B", "text": "Mini-Batch Gradient Descent"}, {"label": "C", "text": "Batch Gradient Descent"}, {"label": "D", "text": "All of the above"}], "answerKey": "D", "model_answer": "LECTURE: Algorithms are designed to find minimum values of functions. A local optimum is a minimum value of a function inside a neighborhood of the function. A global optimum is the minimum value of the function over all of the function's values.\nSOLUTION: To find the global optimum of a function, you can use an optimization algorithm. An optimization algorithm takes the current function value and information about the function's behavior to choose the next value to try.\nThe sigmoid activation function is used in neural networks. The sigmoid function is a function that maps an input to a value between 0 and 1. The entropy loss function is a measure of the information in the output of the neural network.\nTo find the global optimum of a function, you can use an optimization algorithm that is designed to find the global optimum. Batch Gradient Descent, Mini-Batch Gradient Descent, and Stochastic Gradient Descent are algorithms that can be used to find the global optimum.\nThese algorithms have different names, but they are all gradient descent algorithms. They use the gradient of the function to determine how to find the next value to try. The gradient tells you how much the function changes as you change the function value.\nEach of these algorithms has hyper-parameters that you can tune to find the best possible function value. Hyper-parameters are values that are not function arguments. You may need to try multiple algorithms and different hyper-parameter settings to find the global optimum."}
{"question": "Adding more basis functions in a linear model, pick the most probably option:", "choices": [{"label": "A", "text": "Decreases model bias"}, {"label": "B", "text": "Decreases estimation bias"}, {"label": "C", "text": "Decreases variance"}, {"label": "D", "text": "Doesn\u2019t affect bias and variance"}], "answerKey": "A", "model_answer": ""}
{"question": "Consider the Bayesian network given below. How many independent parameters would we need if we made no assumptions about independence or conditional independence H -> U <- P <- W?", "choices": [{"label": "A", "text": "3"}, {"label": "B", "text": "4"}, {"label": "C", "text": "7"}, {"label": "D", "text": "15"}], "answerKey": "D", "model_answer": "LECTURE: A Bayesian network is a directed acyclic graph (DAG) in which each node represents a random variable. The edges from a node to its children represent dependencies between the variables.\nThe probability of a random variable in a Bayesian network is not merely a function of the probability of its parents, but also of the probability of the network conditions. The network conditions are the values of the random variables in the network that are not parents of the variable in question.\nFor example, in the following network, the probability of N is not merely a function of the probability of N3 and N4, but also of the probability of N1 and N2.\nN1 -- N2 -- N3 -- N4 -- N\nThe probability of N1 is a function of the probability of N1 and the probability of N3 and N4.\nThe probability of N2 is a function of the probability of N2 and the probability of N3 and N4.\nThe probability of N3 is a function of the probability of N3 and the probability of N4.\nThe probability of N4 is a function of the probability of N4.\nIn a Bayesian network, the probability of a variable is not just a function of the probability of its parents, but also of the probability of the network conditions.\nThe probability of a variable is not a function of the probability of its grandparents, or great-grandparents, and so on.\nA variable in a Bayesian network does not have a parental relationship with variables that are not its parents in the network.\nSOLUTION: To determine the number of independent parameters, consider the Bayesian network structure:\nH <- P <- W\nU <- P <- W\nThe icons inside the nodes represent independent parameters. Parameters that have no parents are independent.\nIn the given network, H and U have no parents. So, they are independent.\nSo, we need 2 independent parameters."}
{"question": "Another term for out-of-distribution detection is?", "choices": [{"label": "A", "text": "anomaly detection"}, {"label": "B", "text": "one-class detection"}, {"label": "C", "text": "train-test mismatch robustness"}, {"label": "D", "text": "background detection"}], "answerKey": "A", "model_answer": "LECTURE: A graph is a set of nodes (points) and a set of edges (lines).\nThe nodes of a graph are typically marked with symbols such as A, B, C, and so on.\nThe edges of a graph are typically marked with symbols such as E1, E2, E3, and so on.\nSome graphs have a self-edge, which is an edge that connects a node to itself. The self-edge is marked with a symbol such as E.\nA simple graph is a graph with no self-edges.\nAn edge connects two nodes. An edge does not connect a node to itself.\nAn undirected graph is a graph without any directed edges.\nA directed graph is a graph with at least one directed edge. A directed edge points from one node to another.\nA cyclic graph is a directed graph with a self-edge.\nThe direction of an edge is usually denoted by the endpoints of the edge. For example, the edge E1 connects nodes A and B. The direction of E1 is denoted by A and B.\nSOLUTION: Another term for out-of-distribution detection is anomaly detection."}
{"question": "Statement 1| We learn a classifier f by boosting weak learners h. The functional form of f\u2019s decision boundary is the same as h\u2019s, but with different parameters. (e.g., if h was a linear classifier, then f is also a linear classifier). Statement 2| Cross validation can be used to select the number of iterations in boosting; this procedure may help reduce overfitting.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": ""}
{"question": "Statement 1| Highway networks were introduced after ResNets and eschew max pooling in favor of convolutions. Statement 2| DenseNets usually cost more memory than ResNets.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": ""}
{"question": "If N is the number of instances in the training dataset, nearest neighbors has a classification run time of", "choices": [{"label": "A", "text": "O(1)"}, {"label": "B", "text": "O( N )"}, {"label": "C", "text": "O(log N )"}, {"label": "D", "text": "O( N^2 )"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| The original ResNets and Transformers are feedforward neural networks. Statement 2| The original Transformers use self-attention, but the original ResNet does not.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| RELUs are not monotonic, but sigmoids are monotonic. Statement 2| Neural networks trained with gradient descent with high probability converge to the global optimum.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": ""}
{"question": "The numerical output of a sigmoid node in a neural network:", "choices": [{"label": "A", "text": "Is unbounded, encompassing all real numbers."}, {"label": "B", "text": "Is unbounded, encompassing all integers."}, {"label": "C", "text": "Is bounded between 0 and 1."}, {"label": "D", "text": "Is bounded between -1 and 1."}], "answerKey": "C", "model_answer": "LECTURE: Neural networks are made up of nodes, or processing units. Each node in a neural network performs a mathematical operation on its input.\nA sigmoid node is a type of node that performs a specific mathematical operation. The output of a sigmoid node is a value between 0 and 1.\nSOLUTION: The output of a sigmoid node is unbounded, but it is always between 0 and 1."}
{"question": "Which of the following can only be used when training data are linearly separable?", "choices": [{"label": "A", "text": "Linear hard-margin SVM."}, {"label": "B", "text": "Linear Logistic Regression."}, {"label": "C", "text": "Linear Soft margin SVM."}, {"label": "D", "text": "The centroid method."}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following are the spatial clustering algorithms?", "choices": [{"label": "A", "text": "Partitioning based clustering"}, {"label": "B", "text": "K-means clustering"}, {"label": "C", "text": "Grid based clustering"}, {"label": "D", "text": "All of the above"}], "answerKey": "D", "model_answer": "LECTURE: Spatial clustering is a type of data clustering that is used to group data points that are located near one another. There are several algorithms that can be used for spatial clustering, including partitioning-based clustering, k-means clustering, and grid-based clustering.\nPartitioning-based clustering is a method of clustering in which the data is divided into pieces, or partitions, based on the intercluster distance.\nK-means clustering is a method of clustering in which the data is divided into k clusters, based on the distance between the data points.\nGrid-based clustering is a method of clustering in which the data is divided into subspaces, or grids, based on the intercluster distance.\nSOLUTION: K-means clustering is a method of clustering in which the data is divided into k clusters, based on the distance between the data points.\nGrid-based clustering is a method of clustering in which the data is divided into subspaces, or grids, based on the intercluster distance."}
{"question": "Statement 1| The maximum margin decision boundaries that support vector machines construct have the lowest generalization error among all linear classifiers. Statement 2| Any decision boundary that we get from a generative model with classconditional Gaussian distributions could in principle be reproduced with an SVM and a polynomial kernel of degree less than or equal to three.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "LECTURE: Linear classifiers are a family of classifiers that make their classification decisions based on a linear decision boundary. They cannot capture nonlinear relationships between the features and the target.\nA linear classifier's decision boundary is a straight line or a hyperplane in input space. The position of the decision boundary determines which observations are classified as belonging to a particular class.\nSOLUTION: Statement 1 is true.\nMaximum margin decision boundaries have the lowest generalization error among all linear classifiers. This means that if you are using a linear classifier and you want to have the lowest error on new, unseen data, you should use a maximum margin decision boundary.\nStatement 2 is false.\nIt is not true that any decision boundary that we get from a generative model with class-conditional Gaussian distributions could in principle be reproduced with an SVM and a polynomial kernel of degree less than or equal to three. In fact, the converse is true: for many generative models with class-conditional Gaussian distributions, the decision boundaries can be reproduced with an SVM and a polynomial kernel of degree less than or equal to three. However, this is not true in general."}
{"question": "Statement 1| L2 regularization of linear models tends to make models more sparse than L1 regularization. Statement 2| Residual connections can be found in ResNets and Transformers.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": ""}
{"question": "Suppose we like to calculate P(H|E, F) and we have no conditional independence information. Which of the following sets of numbers are sufficient for the calculation?", "choices": [{"label": "A", "text": "P(E, F), P(H), P(E|H), P(F|H)"}, {"label": "B", "text": "P(E, F), P(H), P(E, F|H)"}, {"label": "C", "text": "P(H), P(E|H), P(F|H)"}, {"label": "D", "text": "P(E, F), P(E|H), P(F|H)"}], "answerKey": "B", "model_answer": ""}
{"question": "Which among the following prevents overfitting when we perform bagging?", "choices": [{"label": "A", "text": "The use of sampling with replacement as the sampling technique"}, {"label": "B", "text": "The use of weak classifiers"}, {"label": "C", "text": "The use of classification algorithms which are not prone to overfitting"}, {"label": "D", "text": "The practice of validation performed on every classifier trained"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| PCA and Spectral Clustering (such as Andrew Ng\u2019s) perform eigendecomposition on two different matrices. However, the size of these two matrices are the same. Statement 2| Since classification is a special case of regression, logistic regression is a special case of linear regression.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: Eigendecomposition is the process of factoring a matrix into its eigenvalues and eigenvectors.\nPCA and spectral clustering are two techniques that use eigendecomposition.\nPCA stands for Principal Component Analysis. It is a technique for reducing the dimensionality of a dataset.\nSpectral clustering is a technique for clustering data.\nBoth PCA and spectral clustering use eigendecomposition. But they apply it to different matrices.\nPCA applies eigendecomposition to a matrix of coefficients. The matrix of coefficients is created by applying a transformation to the data.\nSpectral clustering applies eigendecomposition to a matrix of distances. The matrix of distances is created by taking the distances between the data points.\nSince classification is a special case of regression, logistic regression is a special case of linear regression.\nThis statement is false. Logistic regression is not a special case of linear regression.\nInstead, linear regression is a generalization of logistic regression. Logistic regression is a type of linear regression."}
{"question": "Statement 1| The Stanford Sentiment Treebank contained movie reviews, not book reviews. Statement 2| The Penn Treebank has been used for language modeling.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: Statements of fact make claims that are either true or false.\nThe truth of a statement of fact can be determined by consulting outside information.\nOutside information is new information that is not stated in the text.\nYou can use outside information to decide if a statement of fact is true or false.\nBe careful! Some statements of fact may at first appear to be true, but they can be false.\nFor example, George Washington became president of the United States. This statement is true.\nHowever, George Washington became president of the United States in 1789. This statement is false.\nStatements of opinion make claims that are either true or false.\nThe truth of a statement of opinion cannot be determined by outside information.\nInstead, you can evaluate a statement of opinion by determining whether it is based on a valid argument.\nFor example, George Washington was a better president than Thomas Jefferson. This statement of opinion cannot be determined to be true or false. It is based on a valid argument.\nHowever, George Washington was never president. This statement of opinion is false. It is not based on a valid argument.\nSOLUTION: Statement 1 is true and Statement 2 is false.\nThe Penn Treebank has been used for language modeling. This statement is false. The Stanford Sentiment Treebank contained movie reviews, not book reviews. This statement is true."}
{"question": "What is the dimensionality of the null space of the following matrix? A = [[3, 2, \u22129], [\u22126, \u22124, 18], [12, 8, \u221236]]", "choices": [{"label": "A", "text": "0"}, {"label": "B", "text": "1"}, {"label": "C", "text": "2"}, {"label": "D", "text": "3"}], "answerKey": "C", "model_answer": ""}
{"question": "What are support vectors?", "choices": [{"label": "A", "text": "The examples farthest from the decision boundary."}, {"label": "B", "text": "The only examples necessary to compute f(x) in an SVM."}, {"label": "C", "text": "The data centroid."}, {"label": "D", "text": "All the examples that have a non-zero weight \u03b1k in a SVM."}], "answerKey": "B", "model_answer": "LECTURE: In a linear support vector machine, the decision boundary is a line. The position of the line is chosen so as to maximize the margin, which is the distance between the line and the closest examples in the training data. The margin is represented by \u03b5.\nThe line is parallel to the weighted sum of the training data. The weights are the coefficients of the features in the equation of the line.\nThe decision boundary is the line that maximizes the margin.\nAll the examples that have a non-zero weight \u03b1k in a SVM.\nSupport vectors are the examples that have a non-zero weight \u03b1k in a SVM. These examples are closest to the decision boundary.\nThe data centroid is not necessarily a support vector.\nThe centroid is the average of all the examples. It may not be on the decision boundary, and it may not have a non-zero weight.\nThe other examples are not support vectors.\nThese examples are not closest to the decision boundary, and they may not have a non-zero weight.\nThe examples farthest from the decision boundary.\nThese examples are not closest to the decision boundary, and they may not have a non-zero weight."}
{"question": "Statement 1| Word2Vec parameters were not initialized using a Restricted Boltzman Machine. Statement 2| The tanh function is a nonlinear activation function.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: In a graph, the weight of an edge is called the distance between two nodes. The distance between two nodes in a graph is not necessarily the same as the length of a shortest path between them.\nFor example, consider the graph shown below.\nThe distance between nodes A and B is 1.\nThe distance between nodes A and C is 2.\nThe distance between nodes B and C is 1.\nSOLUTION: The tanh function is a nonlinear activation function. It is a restriction Boltzmann machine.\nThe parameter updates are performed in the following order:\ndW1 = \u03b7(dL1dt)\ndL1 = dW1dt\ndW2 = \u03b7(dL2dt)\ndL2 = dW2dt\ndW1 is the amount by which the weights connecting nodes v1 and v2 need to be updated. It is calculated as the product of the learning rate \u03b7 and the partial derivative of the loss function with respect to dL1dt.\ndL1 is the amount by which the weights connecting nodes v1 and v2 need to be updated. It is calculated as the product of the learning rate \u03b7 and dW1dt.\ndW2 is the amount by which the weights connecting nodes v2 and v3 need to be updated. It is calculated as the product of the learning rate \u03b7 and the partial derivative of the loss function with respect to dL2dt.\ndL2 is the amount by which the weights connecting nodes v2 and v3 need to be updated. It is calculated as the product of the learning rate \u03b7 and dW2dt."}
{"question": "If your training loss increases with number of epochs, which of the following could be a possible issue with the learning process?", "choices": [{"label": "A", "text": "Regularization is too low and model is overfitting"}, {"label": "B", "text": "Regularization is too high and model is underfitting"}, {"label": "C", "text": "Step size is too large"}, {"label": "D", "text": "Step size is too small"}], "answerKey": "C", "model_answer": "LECTURE: In the context of machine learning, a model is said to overfit when it is too complex and has learned the noise in the training data. This can be caused by a high level of regularization, a small amount of training data, or a complex model.\nOverfitting can be fixed by using a simpler model, using more training data, or reducing regularization.\nA model is said to underfit when it is too simple and has not learned the underlying pattern in the data. This can be caused by a low level of regularization, a large amount of training data, or a simple model.\nUnderfitting can be fixed by using a more complex model, increasing regularization, or using more training data.\nSOLUTION: If the training loss increases with the number of epochs, the model is taking longer to converge. This can be caused by a large step size or a high level of regularization.\nA large step size can be fixed by using a smaller step size.\nA high level of regularization can be fixed by using a lower level of regularization."}
{"question": "Say the incidence of a disease D is about 5 cases per 100 people (i.e., P(D) = 0.05). Let Boolean random variable D mean a patient \u201chas disease D\u201d and let Boolean random variable TP stand for \"tests positive.\" Tests for disease D are known to be very accurate in the sense that the probability of testing positive when you have the disease is 0.99, and the probability of testing negative when you do not have the disease is 0.97. What is P(D | TP), the posterior probability that you have disease D when the test is positive?", "choices": [{"label": "A", "text": "0.0495"}, {"label": "B", "text": "0.078"}, {"label": "C", "text": "0.635"}, {"label": "D", "text": "0.97"}], "answerKey": "C", "model_answer": "LECTURE: Conditional probability is the probability that an event occurs given that another event has occurred.\nP(A | B) = P(A and B) / P(B)\nSo, P(D | TP) is the probability that you have disease D given that the test is positive. This is equal to the probability that the test is positive when you have the disease, which is 0.99, multiplied by the probability that you have the disease, which is 0.05.\nP(D | TP) = 0.99 \u00d7 0.05 = 0.0495"}
{"question": "Statement 1| Traditional machine learning results assume that the train and test sets are independent and identically distributed. Statement 2| In 2017, COCO models were usually pretrained on ImageNet.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| The values of the margins obtained by two different kernels K1(x, x0) and K2(x, x0) on the same training set do not tell us which classifier will perform better on the test set. Statement 2| The activation function of BERT is the GELU.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following is a clustering algorithm in machine learning?", "choices": [{"label": "A", "text": "Expectation Maximization"}, {"label": "B", "text": "CART"}, {"label": "C", "text": "Gaussian Na\u00efve Bayes"}, {"label": "D", "text": "Apriori"}], "answerKey": "A", "model_answer": ""}
{"question": "You've just finished training a decision tree for spam classification, and it is getting abnormally bad performance on both your training and test sets. You know that your implementation has no bugs, so what could be causing the problem?", "choices": [{"label": "A", "text": "Your decision trees are too shallow."}, {"label": "B", "text": "You need to increase the learning rate."}, {"label": "C", "text": "You are overfitting."}, {"label": "D", "text": "None of the above."}], "answerKey": "A", "model_answer": "LECTURE: In supervised learning, you are given a set of labeled data points. A supervised learning model uses these data points to learn the relationship between the input data and the labels.\nFor example, consider a simple linear regression model. In this model, the input data consists of a single data point with two features, and the label is a single number. The model learns a linear equation that maps the features to the label.\nThe following are the steps to train a supervised learning model:\n1. Load the data: You will need to load the data that you will use to train your model.\n2. Preprocess the data: You will need to preprocess the data to prepare it for use with a machine learning model.\n3. Choose a model: You will need to choose a model to train on your data.\n4. Train the model: You will need to fit the model to your data.\n5. Evaluate the model: You will need to evaluate the model to ensure that it is learning an accurate relationship between the input data and the labels.\n6. Use the model: You can use the model to make predictions on new, unlabeled data.\nSOLUTION: You have already completed the steps to train a decision tree for spam classification. So, the problem is not with the steps you have taken.\nThe problem is that the decision tree is too shallow. A decision tree is a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is a supervised learning model.\nA decision tree is too shallow if it only has a few levels. Each level in the decision tree represents a feature. A decision tree with a few levels will not be able to capture the relationships between the input data and the labels.\nYou can try to increase the size of the decision tree by adding more levels.\nYou can also try to increase the number of trees in your ensemble. An ensemble is a group of models that work together to make predictions."}
{"question": "K-fold cross-validation is", "choices": [{"label": "A", "text": "linear in K"}, {"label": "B", "text": "quadratic in K"}, {"label": "C", "text": "cubic in K"}, {"label": "D", "text": "exponential in K"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| Industrial-scale neural networks are normally trained on CPUs, not GPUs. Statement 2| The ResNet-50 model has over 1 billion parameters.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: Statements 1 and 2 are not necessarily true.\nIndustrial-scale neural networks are normally trained on GPUs, not CPUs.\nThe ResNet-50 model has over 1 billion parameters."}
{"question": "Given two Boolean random variables, A and B, where P(A) = 1/2, P(B) = 1/3, and P(A | \u00acB) = 1/4, what is P(A | B)?", "choices": [{"label": "A", "text": "1/6"}, {"label": "B", "text": "1/4"}, {"label": "C", "text": "3/4"}, {"label": "D", "text": "1"}], "answerKey": "D", "model_answer": "LECTURE: Conditional probability is the probability that an event will happen, given that another event has happened.\nIf A and B are two events, then the conditional probability of A given B is written as P(A | B).\nP(A | B) = P(A and B) / P(B)\nIf A and B are random variables, then the conditional probability of A given B is written as P(A | B).\nP(A | B) = P(A and B) / P(B)\nThe random variable B is called the condition.\nWhen you calculate the conditional probability of a random variable, you are interested in what happens to the value of the random variable when another random variable takes on a particular value.\nFor example, if the random variable B is 1, then the conditional probability of the random variable A being 1 or 2 is given by P(A = 1 | B = 1) and P(A = 2 | B = 1).\nSOLUTION: First, calculate the probabilities.\nP(A | \u00acB) = P(A and \u00acB) / P(\u00acB)\nP(A | \u00acB) = P(A) / P(\u00acB)\nP(A | \u00acB) = 1/2 / 1/3\nP(A | \u00acB) = 2/3\nThen, calculate the probability that B happens given that A happens.\nP(B | A) = P(A and B) / P(A)\nP(B | A) = P(B) / (P(A) / \u00acP(B | \u00acA))\nP(B | A) = P(B) / (2/3 / 1/4)\nP(B | A) = 3/4"}
{"question": "Existential risks posed by AI are most commonly associated with which of the following professors?", "choices": [{"label": "A", "text": "Nando de Frietas"}, {"label": "B", "text": "Yann LeCun"}, {"label": "C", "text": "Stuart Russell"}, {"label": "D", "text": "Jitendra Malik"}], "answerKey": "C", "model_answer": "LECTURE: Philosophers and artificial intelligence researchers have identified several types of risks that might arise as AI systems become more capable. Some of the risks are accidents that could happen suddenly, such as an AI attacking a human out of ignorance of the value of safety. Other risks are due to the long-term impact of AI systems, such as autonomous vehicles causing changes to the infrastructure of a city and the long-term unemployment of drivers.\nExistential risks are the risks that threaten the entire future of humanity. They are generally associated with severe long-term impacts that are hard to predict."}
{"question": "Statement 1| Maximizing the likelihood of logistic regression model yields multiple local optimums. Statement 2| No classifier can do better than a naive Bayes classifier if the distribution of the data is known.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: A strong argument uses specific evidence.\nWhen you are evaluating a claim, look for evidence that is directly related to the claim.\nSome evidence is not directly related to the claim.\nWhen you are evaluating a claim, look for evidence that is directly related to the claim.\nAn argument may have evidence that is not directly related to the claim.\nIn this case, the evidence is not directly related to the claim.\nAn argument may make a claim that is not supported by the evidence.\nIn this case, the claim is not supported by the evidence.\nSOLUTION: The first statement is true.\nThe second statement is false.\nA naive Bayes classifier is a probabilistic classifier that assumes the features are independent.\nIf the distribution of the data is known, then a naive Bayes classifier is not a good model.\nA logistic regression model is a probabilistic model that assumes the features are connected.\nIf the distribution of the data is known, then a logistic regression model can still have multiple local optima."}
{"question": "For Kernel Regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether kernel function is Gaussian versus triangular versus box-shaped"}, {"label": "B", "text": "Whether we use Euclidian versus L1 versus L\u221e metrics"}, {"label": "C", "text": "The kernel width"}, {"label": "D", "text": "The maximum height of the kernel function"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| The SVM learning algorithm is guaranteed to find the globally optimal hypothesis with respect to its object function. Statement 2| After being mapped into feature space Q through a radial basis kernel function, a Perceptron may be able to achieve better classification performance than in its original space (though we can\u2019t guarantee this).", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "For a Gaussian Bayes classifier, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether we learn the class centers by Maximum Likelihood or Gradient Descent"}, {"label": "B", "text": "Whether we assume full class covariance matrices or diagonal class covariance matrices"}, {"label": "C", "text": "Whether we have equal class priors or priors estimated from the data."}, {"label": "D", "text": "Whether we allow classes to have different mean vectors or we force them to share the same mean vector"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| Overfitting is more likely when the set of training data is small. Statement 2| Overfitting is more likely when the hypothesis space is small.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": ""}
{"question": "Statement 1| Besides EM, gradient descent can be used to perform inference or learning on Gaussian mixture model. Statement 2 | Assuming a fixed number of attributes, a Gaussian-based Bayes optimal classifier can be learned in time linear in the number of records in the dataset.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| In a Bayesian network, the inference results of the junction tree algorithm are the same as the inference results of variable elimination. Statement 2| If two random variable X and Y are conditionally independent given another random variable Z, then in the corresponding Bayesian network, the nodes for X and Y are d-separated given Z.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: In a Bayesian network, the structure is defined by the dependencies among random variables. Two random variables are directly connected in the network if they are directly related. They are indirectly connected if they are related through other random variables.\nThe junction tree algorithm is a method for constructing a Bayesian network. It represents the dependencies among random variables by building a tree structure.\nThe variable elimination algorithm is another method for constructing a Bayesian network. It represents the dependencies among random variables by using conditional independence.\nIf the junction tree algorithm and the variable elimination algorithm represent the same dependencies, then the inference results will be the same.\nThis means that Statement 1 is true.\nd-separation is a property of dependencies among random variables. If two nodes in a Bayesian network are d-separated, they are not connected in the direct connections of the network.\nIf two random variables are conditionally independent given another random variable Z, then in the corresponding Bayesian network, the nodes for X and Y are d-separated given Z. This means that X and Y are not directly connected in the network.\nThis means that Statement 2 is true."}
{"question": "Given a large dataset of medical records from patients suffering from heart disease, try to learn whether there might be different clusters of such patients for which we might tailor separate treatments. What kind of learning problem is this?", "choices": [{"label": "A", "text": "Supervised learning"}, {"label": "B", "text": "Unsupervised learning"}, {"label": "C", "text": "Both (a) and (b)"}, {"label": "D", "text": "Neither (a) nor (b)"}], "answerKey": "B", "model_answer": ""}
{"question": "What would you do in PCA to get the same projection as SVD?", "choices": [{"label": "A", "text": "Transform data to zero mean"}, {"label": "B", "text": "Transform data to zero median"}, {"label": "C", "text": "Not possible"}, {"label": "D", "text": "None of these"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| The training error of 1-nearest neighbor classifier is 0. Statement 2| As the number of data points grows to infinity, the MAP estimate approaches the MLE estimate for all possible priors. In other words, given enough data, the choice of prior is irrelevant.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": ""}
{"question": "When doing least-squares regression with regularisation (assuming that the optimisation can be done exactly), increasing the value of the regularisation parameter \u03bb the testing error.", "choices": [{"label": "A", "text": "will never decrease the training error."}, {"label": "B", "text": "will never increase the training error."}, {"label": "C", "text": "will never decrease the testing error."}, {"label": "D", "text": "will never increase"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following best describes what discriminative approaches try to model? (w are the parameters in the model)", "choices": [{"label": "A", "text": "p(y|x, w)"}, {"label": "B", "text": "p(y, x)"}, {"label": "C", "text": "p(w|x, w)"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| CIFAR-10 classification performance for convolution neural networks can exceed 95%. Statement 2| Ensembles of neural networks do not improve classification accuracy since the representations they learn are highly correlated.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: Statements 1 and 2 are false.\nThe correct answer is D.\nWhen trained on CIFAR-10, convolutional neural networks (CNNs) can achieve classification accuracy that exceeds 95%. This is because the dataset is designed for visual recognition problems and includes images that are difficult to distinguish.\nEnsembles of neural networks do not improve classification accuracy since the representations they learn are highly correlated. This statement is false.\nEnsemble methods can improve classification accuracy, even when the models in the ensemble are highly correlated. The correlation between models can be reduced by applying regularization techniques or by using different model architectures."}
{"question": "Which of the following points would Bayesians and frequentists disagree on?", "choices": [{"label": "A", "text": "The use of a non-Gaussian noise model in probabilistic regression."}, {"label": "B", "text": "The use of probabilistic modelling for regression."}, {"label": "C", "text": "The use of prior distributions on the parameters in a probabilistic model."}, {"label": "D", "text": "The use of class priors in Gaussian Discriminant Analysis."}], "answerKey": "C", "model_answer": "LECTURE: Frequentist and Bayesian approaches to statistical modeling differ in their philosophical assumptions and in their methods for inference.\nFrequentist methods base their results on the behavior of an infinite number of similar models. Frequentist methods use concepts such as probability and significance to describe the uncertainty in the conclusions of an analysis. They assume that the observed data is a random sample from a large population.\nIn contrast, Bayesian methods base their results on the behavior of a particular model. Bayesian methods use concepts such as prior knowledge and posterior uncertainty to describe the uncertainty in the conclusions of an analysis. They assume that the observed data is a random realization of a population.\nBayesian and frequentist methods can be used to perform a wide variety of statistical analyses.\nThe use of a non-Gaussian noise model in probabilistic regression is not necessarily something that Bayesians and frequentists would disagree on. It depends on the specific models being compared.\nThe use of prior distributions on the parameters in a probabilistic model is something that Bayesians and frequentists would disagree on. Frequentist methods do not allow for the use of prior distributions.\nThe use of class priors in Gaussian Discriminant Analysis is something that Bayesians and frequentists would disagree on. Frequentist methods do not allow for the use of class priors.\nThe use of probabilistic modeling for regression is something that Bayesians and frequentists would disagree on. Frequentist methods base their results on the behavior of an infinite number of similar models. Bayesian methods base their results on the behavior of a particular model."}
{"question": "Statement 1| The BLEU metric uses precision, while the ROGUE metric uses recall. Statement 2| Hidden markov models were frequently used to model English sentences.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| ImageNet has images of various resolutions. Statement 2| Caltech-101 has more images than ImageNet.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: Statements like these can be tested by looking at the relative sizes of the sets.\nFor example, if 50% of the sets are true and 50% are false, then the statement is false.\nIf 100% of the sets are true or false, then the statement is true.\nSOLUTION: You can test both statements by looking at the relative sizes of the sets.\nThere are many more ImageNet datasets than Caltech-101 datasets. So, ImageNet has more images than Caltech-101.\nImageNet has images of various resolutions. So, ImageNet has images of different sizes.\nSo, both statements are true."}
{"question": "Which of the following is more appropriate to do feature selection?", "choices": [{"label": "A", "text": "Ridge"}, {"label": "B", "text": "Lasso"}, {"label": "C", "text": "both (a) and (b)"}, {"label": "D", "text": "neither (a) nor (b)"}], "answerKey": "B", "model_answer": "LECTURE: Feature selection is the process of selecting a subset of the variables in a dataset."}
{"question": "Suppose you are given an EM algorithm that finds maximum likelihood estimates for a model with latent variables. You are asked to modify the algorithm so that it finds MAP estimates instead. Which step or steps do you need to modify?", "choices": [{"label": "A", "text": "Expectation"}, {"label": "B", "text": "Maximization"}, {"label": "C", "text": "No modification necessary"}, {"label": "D", "text": "Both"}], "answerKey": "B", "model_answer": "LECTURE: The Expectation-Maximation (EM) algorithm is a method for finding maximum likelihood estimates of parameters in models with latent variables. The EM algorithm performs the following steps:\nExpectation step: Compute the expected value of the logarithm of the likelihood function, given the observed data and the current estimated values of the latent variables and parameters.\nMaximization step: Maximize the expected value function with respect to the latent variables and the parameters.\nBoth of these steps are necessary for the EM algorithm to find maximum likelihood estimates.\nTo find minimum average probability (MAP) estimates, you need to modify the EM algorithm so that it finds the values of the latent variables and parameters that maximize the joint probability of the observed data and the latent variables. These values are the MAP estimates.\nNo modification is necessary to the Expectation step, and you need to modify only the Maximization step. In the Maximization step, instead of maximizing the expected value function with respect to the latent variables and parameters, you need to modify the EM algorithm to find the values of the latent variables and parameters that maximize the joint probability of the observed data and the latent variables."}
{"question": "For a Gaussian Bayes classifier, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether we learn the class centers by Maximum Likelihood or Gradient Descent"}, {"label": "B", "text": "Whether we assume full class covariance matrices or diagonal class covariance matrices"}, {"label": "C", "text": "Whether we have equal class priors or priors estimated from the data"}, {"label": "D", "text": "Whether we allow classes to have different mean vectors or we force them to share the same mean vector"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| For any two variables x and y having joint distribution p(x, y), we always have H[x, y] \u2265 H[x] + H[y] where H is entropy function. Statement 2| For some directed graphs, moralization decreases the number of edges present in the graph.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: A graph is a set of vertices and a set of edges that connect vertices. The edges in a graph have a direction, and each direction is associated with a numerical value, called the weight of the edge. A directed graph is a graph with at least one edge that has a direction.\nA moralized graph is a directed graph in which every edge has the same weight.\nThe entropy function H is a measure of the randomness or unpredictability of a variable. For a discrete variable x, H[x] is the number of bits needed to specify x.\nSOLUTION: Statement 1 is true. For any two discrete variables x and y, H[x, y] \u2265 H[x] + H[y].\nMoralization does not necessarily decrease the number of edges present in a graph. For example, consider a graph with one edge weighing 1 and one edge weighing 2. The moralized graph has edges weighing 1.\nStatement 2 is false. Consider a graph with one edge weighing 2. In its moralized version, the weight of each edge is 1. But the number of edges present in the graph decreased from 1 to 0."}
{"question": "Which of the following is NOT supervised learning?", "choices": [{"label": "A", "text": "PCA"}, {"label": "B", "text": "Decision Tree"}, {"label": "C", "text": "Linear Regression"}, {"label": "D", "text": "Naive Bayesian"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| A neural network's convergence depends on the learning rate. Statement 2| Dropout multiplies randomly chosen activation values by zero.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Which one of the following is equal to P(A, B, C) given Boolean random variables A, B and C, and no independence or conditional independence assumptions between any of them?", "choices": [{"label": "A", "text": "P(A | B) * P(B | C) * P(C | A)"}, {"label": "B", "text": "P(C | A, B) * P(A) * P(B)"}, {"label": "C", "text": "P(A, B | C) * P(C)"}, {"label": "D", "text": "P(A | B, C) * P(B | A, C) * P(C | A, B)"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following tasks can be best solved using Clustering.", "choices": [{"label": "A", "text": "Predicting the amount of rainfall based on various cues"}, {"label": "B", "text": "Detecting fraudulent credit card transactions"}, {"label": "C", "text": "Training a robot to solve a maze"}, {"label": "D", "text": "All of the above"}], "answerKey": "B", "model_answer": "LECTURE: In the past, data processing often involved moving data to a central location for processing. For example, in a bank, transactions might be recorded in a central location, and periodically, a clerk would go through the transactions and perform any necessary processing.\nWith the rise of computing, processing can be done automatically. For example, a program can be designed to sort transactions by category. This can be done by setting up a program that uses clustering to group transactions by category. Clustering is a type of machine learning that involves grouping data into clusters based on how they compare to each other.\nSOLUTION: To predict the amount of rainfall based on various cues, you can use clustering to group data from various cues together. For example, you can use clustering to group data from rainfall, humidity, and wind together.\nTo detect fraudulent credit card transactions, you can use clustering to group transactions into those that are legitimate and those that are fraudulent. For example, a transaction might be deemed fraudulent if it is much higher than other transactions made around the same time to the same merchant.\nTraining a robot to solve a maze involves using clustering to group data from the robot's movements into those that are effective at solving the maze and those that are not. For example, the robot's movements might be effective at solving the maze if they lead to the robot reaching the goal more quickly."}
{"question": "After applying a regularization penalty in linear regression, you find that some of the coefficients of w are zeroed out. Which of the following penalties might have been used?", "choices": [{"label": "A", "text": "L0 norm"}, {"label": "B", "text": "L1 norm"}, {"label": "C", "text": "L2 norm"}, {"label": "D", "text": "either (a) or (b)"}], "answerKey": "D", "model_answer": ""}
{"question": "A and B are two events. If P(A, B) decreases while P(A) increases, which of the following is true?", "choices": [{"label": "A", "text": "P(A|B) decreases"}, {"label": "B", "text": "P(B|A) decreases"}, {"label": "C", "text": "P(B) decreases"}, {"label": "D", "text": "All of above"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| When learning an HMM for a fixed set of observations, assume we do not know the true number of hidden states (which is often the case), we can always increase the training data likelihood by permitting more hidden states. Statement 2| Collaborative filtering is often a useful model for modeling users' movie preference.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "You are training a linear regression model for a simple estimation task, and notice that the model is overfitting to the data. You decide to add in $\\ell_2$ regularization to penalize the weights. As you increase the $\\ell_2$ regularization coefficient, what will happen to the bias and variance of the model?", "choices": [{"label": "A", "text": "Bias increase ; Variance increase"}, {"label": "B", "text": "Bias increase ; Variance decrease"}, {"label": "C", "text": "Bias decrease ; Variance increase"}, {"label": "D", "text": "Bias decrease ; Variance decrease"}], "answerKey": "B", "model_answer": "LECTURE: When you have a model with multiple variables, each variable's bias and variance are important.\nBias is a measure of how well the model fits the training data. A highly biased model fits the training data perfectly. However, a highly biased model may not have a low variance, which means that the model may not be able to fit new data well.\nVariance is a measure of how well the model fits the training data relative to the residuals. A highly variable model fits the training data a lot relative to the residuals. However, a highly variable model may not have a low bias, which means that the model may not be able to fit new data well.\nWhen you have a model with regularization, the trade-off between bias and variance is different. Regularization can decrease the model's bias and decrease the model's variance.\nSOLUTION: As you increase the L2 regularization coefficient, the model's weights will decrease. This decrease in weights will decrease the bias of the model. At the same time, the decrease in weights will increase the variance of the model."}
{"question": "Which PyTorch 1.8 command(s) produce $10\\times 5$ Gaussian matrix with each entry i.i.d. sampled from $\\mathcal{N}(\\mu=5,\\sigma^2=16)$ and a $10\\times 10$ uniform matrix with each entry i.i.d. sampled from $U[-1,1)$?", "choices": [{"label": "A", "text": "\\texttt{5 + torch.randn(10,5) * 16} ; \\texttt{torch.rand(10,10,low=-1,high=1)}"}, {"label": "B", "text": "\\texttt{5 + torch.randn(10,5) * 16} ; \\texttt{(torch.rand(10,10) - 0.5) / 0.5}"}, {"label": "C", "text": "\\texttt{5 + torch.randn(10,5) * 4} ; \\texttt{2 * torch.rand(10,10) - 1}"}, {"label": "D", "text": "\\texttt{torch.normal(torch.ones(10,5)*5,torch.ones(5,5)*16)} ; \\texttt{2 * torch.rand(10,10) - 1}"}], "answerKey": "C", "model_answer": "LECTURE: Matrices are represented in PyTorch as tables of data. A matrix can be created by specifying its height (number of rows) and width (number of columns). Each element of the matrix can be specified explicitly.\nFor example, the matrix below has height 3 and width 4.\n|  | 1 | 2 | 3 |\n|  | 4 | 5 | 6 |\n|  | 7 | 8 | 9 |\n|  |10|11|12|\nThe matrix below has height 4 and width 2.\n|   |0 |2 |4 |\n|   |6 |8 |10|\n|   |12|14|16|\n|   |18|20|22|\nMatrices can be created with a specific type, such as a float matrix or a complex matrix.\n5 + torch.randn(10,5) * 16\n creates a 10 by 5 matrix with entries that are floating-point numbers drawn from a normal distribution with a mean of 5 and a standard deviation of 16.\nThe command torch.randn(10,5) * 16 draws a sample from a normal distribution with a mean of 5 and a standard deviation of 16, and multiplies it by a 10 by 5 matrix.\nThe resulting matrix has the following values:\n |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n2 * torch.rand(10,10) - 1\n creates a 10 by 10 matrix with entries that are floating-point numbers drawn from a normal distribution with a mean of 0 and a standard deviation of 1.\nThe command 2 * torch.rand(10,10) - 1 draws two samples from a normal distribution with a mean of 0 and a standard deviation of 1, and subtracts 1 from each sample.\nThe resulting matrix has the following values:\n |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n |  |  |  |  |"}
{"question": "Statement 1| The ReLU's gradient is zero for $x<0$, and the sigmoid gradient $\\sigma(x)(1-\\sigma(x))\\le \\frac{1}{4}$ for all $x$. Statement 2| The sigmoid has a continuous gradient and the ReLU has a discontinuous gradient.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Which is true about Batch Normalization?", "choices": [{"label": "A", "text": "After applying batch normalization, the layer\u2019s activations will follow a standard Gaussian distribution."}, {"label": "B", "text": "The bias parameter of affine layers becomes redundant if a batch normalization layer follows immediately afterward."}, {"label": "C", "text": "The standard weight initialization must be changed when using Batch Normalization."}, {"label": "D", "text": "Batch Normalization is equivalent to Layer Normalization for convolutional neural networks."}], "answerKey": "B", "model_answer": "LECTURE: During training, the weight of each parameter in a layer is adjusted to reduce the difference between the layer\u2019s output and the expected output. Different layers have different types of parameters, and these parameters are initialized with different sets of values.\nThere are several ways to initialize the parameters of a layer. Some common methods are used for all types of layers, while others are specific to convolutional layers, recurrent layers, or layers with batch normalization.\nWhen you use batch normalization on a layer, the layer\u2019s activations are normalized to have a standard deviation of 1 and a mean of 0. This is similar to the normalization of tensors that is performed during the training process.\nAfter applying batch normalization, the layer\u2019s activations will follow a standard Gaussian distribution.\nThe bias parameter of an affine layer becomes redundant if a batch normalization layer follows immediately afterward. This is because the batch normalization layer will apply its own learning rate to the activations, and the bias parameter of the affine layer will not be used.\nThe standard weight initialization is used for the parameters of a layer when you do not provide another initialization method. Often, the standard weight initialization is used when you initialize the parameters of a layer without adding any offsets.\nWhen using batch normalization, the standard weight initialization must be changed. The mean and variance of the normalized input must be adjusted to use the correct values for the learning rate.\nSOLUTION: After applying batch normalization, the layer\u2019s activations will follow a standard Gaussian distribution.\nThe bias parameter of an affine layer becomes redundant if a batch normalization layer follows immediately afterward.\nThe standard weight initialization must be changed when using Batch Normalization.\nBatch Normalization is equivalent to Layer Normalization for convolutional neural networks. During training, the layer normalization function is applied to the activations of a convolutional layer."}
{"question": "Suppose we have the following objective function: $\\argmin_{w} \\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\gamma \\norm{w}^2_2$ What is the gradient of $\\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\lambda \\norm{w}^2_2$ with respect to $w$?", "choices": [{"label": "A", "text": "$\\nabla_w f(w) = (X^\\top X + \\lambda I)w - X^\\top y + \\lambda w$"}, {"label": "B", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + \\lambda$"}, {"label": "C", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + \\lambda w$"}, {"label": "D", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + (\\lambda+1) w$"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following is true of a convolution kernel?", "choices": [{"label": "A", "text": "Convolving an image with $\\begin{bmatrix}1 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$ would not change the image"}, {"label": "B", "text": "Convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ would not change the image"}, {"label": "C", "text": "Convolving an image with $\\begin{bmatrix}1 & 1 & 1\\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}$ would not change the image"}, {"label": "D", "text": "Convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ would not change the image"}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following is false?", "choices": [{"label": "A", "text": "Semantic segmentation models predict the class of each pixel, while multiclass image classifiers predict the class of entire image."}, {"label": "B", "text": "A bounding box with an IoU (intersection over union) equal to $96\\%$ would likely be considered at true positive."}, {"label": "C", "text": "When a predicted bounding box does not correspond to any object in the scene, it is considered a false positive."}, {"label": "D", "text": "A bounding box with an IoU (intersection over union) equal to $3\\%$ would likely be considered at false negative."}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following is false?", "choices": [{"label": "A", "text": "The following fully connected network without activation functions is linear: $g_3(g_2(g_1(x)))$, where $g_i(x) = W_i x$ and $W_i$ are matrices."}, {"label": "B", "text": "Leaky ReLU $\\max\\{0.01x,x\\}$ is convex."}, {"label": "C", "text": "A combination of ReLUs such as $ReLU(x) - ReLU(x-1)$ is convex."}, {"label": "D", "text": "The loss $\\log \\sigma(x)= -\\log(1+e^{-x})$ is concave"}], "answerKey": "C", "model_answer": ""}
{"question": "We are training fully connected network with two hidden layers to predict housing prices. Inputs are $100$-dimensional, and have several features such as the number of square feet, the median family income, etc. The first hidden layer has $1000$ activations. The second hidden layer has $10$ activations. The output is a scalar representing the house price. Assuming a vanilla network with affine transformations and with no batch normalization and no learnable parameters in the activation function, how many parameters does this network have?", "choices": [{"label": "A", "text": "111021"}, {"label": "B", "text": "110010"}, {"label": "C", "text": "111110"}, {"label": "D", "text": "110011"}], "answerKey": "A", "model_answer": "LECTURE: To calculate the number of parameters in a neural network, you need to count the number of parameters in the activations, the output, and the biases.\nThe activations have a total of 1000 + 10 + 1 = 1011 parameters.\nThe output has 1 parameter.\nThe biases have 1000 + 10 + 1 = 1010 parameters.\nSo, the network has a total of 1011 + 1 + 1010 = 111021 parameters."}
{"question": "Statement 1| The derivative of the sigmoid $\\sigma(x)=(1+e^{-x})^{-1}$ with respect to $x$ is equal to $\\text{Var}(B)$ where $B\\sim \\text{Bern}(\\sigma(x))$ is a Bernoulli random variable. Statement 2| Setting the bias parameters in each layer of neural network to 0 changes the bias-variance trade-off such that the model's variance increases and the model's bias decreases", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": ""}
