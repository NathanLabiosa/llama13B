{"question": "Which one of the following is the most appropriate definition of a 99% confidence interval?", "choices": [{"label": "A", "text": "99% of the time in repeated samples, the interval would contain the true value of the parameter"}, {"label": "B", "text": "99% of the time in repeated samples, the interval would contain the estimated value of the parameter"}, {"label": "C", "text": "99% of the time in repeated samples, the null hypothesis will be rejected"}, {"label": "D", "text": "99% of the time in repeated samples, the null hypothesis will not be rejected when it was false"}], "answerKey": "A", "model_answer": ""}
{"question": "What is the main difference between the Dickey Fuller (DF) and Phillips-Perron (PP) approaches to unit root testing?", "choices": [{"label": "A", "text": "ADF is a single equation approach to unit root testing while PP is a systems approach"}, {"label": "B", "text": "PP tests reverse the DF null and alternative hypotheses so that there is stationarity under the null hypothesis of the PP test"}, {"label": "C", "text": "The PP test incorporates an automatic correction for autocorrelated residuals in the test regression"}, {"label": "D", "text": "PP tests have good power in small samples whereas DF tests do not."}], "answerKey": "C", "model_answer": "LECTURE: In the context of statistical hypothesis testing, a null hypothesis is a statement of no effect or no difference. A alternative hypothesis is the opposite of the null hypothesis.\nFor example, in the context of a unit root test, the null hypothesis is that the time series is nonstationary, and the alternative hypothesis is that the time series is stationary.\nSOLUTION: The main difference between the Dickey-Fuller (DF) and Phillips-Perron (PP) approaches to unit root testing is that the PP test incorporates an automatic correction for autocorrelated residuals in the test regression, while the DF test does not.\nThis means that the PP test is more powerful than the DF test when the sample size is small, and the test is run on a time series with autocorrelated errors. The PP test \"sees\" a larger fraction of the underlying signal because the correction removes the bias introduced by the autocorrelated errors."}
{"question": "If there were a leverage effect in practice, what would be the shape of the news impact curve for as model that accounted for that leverage?", "choices": [{"label": "A", "text": "It would rise more quickly for negative disturbances than for positive ones of the same magnitude"}, {"label": "B", "text": "It would be symmetrical about zero"}, {"label": "C", "text": "It would rise less quickly for negative disturbances than for positive ones of the same magnitude"}, {"label": "D", "text": "It would be zero for all positive disturbances"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following statements is false concerning the linear probability model?", "choices": [{"label": "A", "text": "There is nothing in the model to ensure that the estimated probabilities lie between zero and one"}, {"label": "B", "text": "Even if the probabilities are truncated at zero and one, there will probably be many observations for which the probability is either exactly zero or exactly one"}, {"label": "C", "text": "The error terms will be heteroscedastic and not normally distributed"}, {"label": "D", "text": "The model is much harder to estimate than a standard regression model with a continuous dependent variable"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following statements concerning the regression population and sample is FALSE?", "choices": [{"label": "A", "text": "The population is the total collection of all items of interest"}, {"label": "B", "text": "The population can be infinite"}, {"label": "C", "text": "In theory, the sample could be larger than the population"}, {"label": "D", "text": "A random sample is one where each individual item from the population is equally likely to be drawn."}], "answerKey": "C", "model_answer": "LECTURE: A population is a group of things, such as people or animals, that you want to learn about.\nA sample is a group of things that you take from a population. A sample is not as large as a population.\nSOLUTION: The following statement is false:\nIn theory, the sample could be larger than the population.\nA sample must be smaller than the population."}
{"question": "Which of the following statements is INCORRECT concerning a comparison of the Box-Pierce Q and the Ljung-Box Q* statistics for linear dependence in time series?", "choices": [{"label": "A", "text": "Asymptotically, the values of the two test statistics will be equal"}, {"label": "B", "text": "The Q test has better small-sample properties than the Q*"}, {"label": "C", "text": "The Q test is sometimes over-sized for small samples"}, {"label": "D", "text": "As the sample size tends towards infinity, both tests will show a tendency to always reject the null hypothesis of zero autocorrelation coefficients."}], "answerKey": "B", "model_answer": "LECTURE: When testing for linear dependence in a time series, the Box-Pierce Q test and the Ljung-Box Q* test are two commonly used statistical tests. The null hypothesis of these tests is that the autocorrelation function is zero, which means that there is no linear dependence in the data.\nThe Box-Pierce Q test is based on the partial autocorrelation function (PACF). The Q test has good small-sample properties, but it may be over-sized for small samples, which means that it may have a hightype I error rate.\nThe Ljung-Box Q* test is based on the generalized autocorrelation function (GACF). The Q* test is similar to the Box-Pierce Q test, but it is moderately conservative, which means that it has a slightly higher level of significance. As the sample size tends towards infinity, both tests will show a tendency to always reject the null hypothesis of zero autocorrelation coefficients.\nSOLUTION: The statement that the Q test has better small-sample properties than the Q* test is incorrect. Small-sample properties are similar for the two tests.\nThe statement that asymptotically, the values of the two test statistics will be equal is incorrect. As the sample size tends towards infinity, the Q test will have a tendency to always reject the null hypothesis, while the Q* test will be conservative.\nThe statement that the Q test is sometimes over-sized for small samples is correct. As the sample size gets smaller, the test becomes more conservative. This means that it has a higher type I error rate."}
{"question": "A parsimonious model is one that", "choices": [{"label": "A", "text": "Includes too many variables"}, {"label": "B", "text": "Includes as few variables as possible to explain the data"}, {"label": "C", "text": "Is a well-specified model"}, {"label": "D", "text": "Is a mis-specified model"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following is NOT a feature of continuously compounded returns (i.e. log-returns)?", "choices": [{"label": "A", "text": "They can be interpreted as continuously compounded changes in the prices"}, {"label": "B", "text": "They can be added over time to give returns for longer time periods"}, {"label": "C", "text": "They can be added across a portfolio of assets to give portfolio returns"}, {"label": "D", "text": "They are usually fat-tailed"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following features of financial asset return time-series could be captured using a standard GARCH(1,1) model?\n\ni) Fat tails in the return distribution\n\n\nii) Leverage effects\n\n\niii) Volatility clustering\n\n\niv) Volatility affecting returns", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: Financial asset return time-series are often characterized by the following features:\nFat tails in the return distribution: The return distribution has a higher kurtosis (a higher peak than a normal distribution) than a normal distribution.\nLeverage effects: As-yet-unrealized returns have a significant effect on the current asset price.\nVolatility clustering: Volatility is clustered, or correlated, over time.\nVolatility affecting returns: Large changes in volatility have a larger effect on the asset's returns than would be expected from the change in volatility alone.\nA standard GARCH(1,1) model can capture the following features:\nVolatility affecting returns: The model's volatility terms can capture the effect of volatility on returns.\nHowever, the model cannot capture the following features:\nLeverage effects: The model does not have leCTURE: A financial asset's leverage effects occur when as-yet-unrealized returns have a significant effect on the current asset price. A GARCH(1,1) model does not have terms that capture the effect of as-yet-unrealized returns on the current asset price.\nFat tails in the return distribution: The model assumes that the return distribution is a normal distribution, which has a lower kurtosis than a fat-tailed distribution.\nVolatility clustering: The model does not have terms that capture the correlation of volatility over time."}
{"question": "Consider the estimation of a GARCH-M model. If the data employed were a time-series of daily corporate bond percentage returns, which of the following would you expect the value of the GARCH-in-mean parameter estimate to be?", "choices": [{"label": "A", "text": "Less than -1"}, {"label": "B", "text": "Between -1 and 0"}, {"label": "C", "text": "Between 0 and 1"}, {"label": "D", "text": "Bigger than 1"}], "answerKey": "C", "model_answer": "LECTURE: For a GARCH-M model, the GARCH-in-mean parameter estimate is the value of the long-term mean of the GARCH model. This parameter estimate is usually denoted by \u03bc.\nIf the GARCH model is correctly specified, then \u03bc is given by the following equation:\n\u03bc = \u03c9 + \u03b4\u03bc + \u03b5,\nwhere \u03c9 is the long-term mean of the standardized residuals from a GARCH model with a constant parameter, \u03b4 is the GARCH-in-mean parameter, and \u03b5 is the error term.\nThe standardized residuals from a GARCH model with a constant parameter have a mean of 0 and a standard deviation of 1. So, \u03c9 is the long-term mean of the standardized residuals.\nFor a GARCH-M model, the GARCH-in-mean parameter \u03b4 is usually estimated along with the other parameters of the model. The value of \u03b4 is not known in advance.\nIf the GARCH-M model is correctly specified, then the value of \u03b4 is the estimated long-term mean of the standardized residuals from a GARCH model with a constant parameter and a moving average term.\nThe moving average term in the GARCH-M model is denoted by \u0639. It has a mean of 0 and a standard deviation of \u03c3MA.\nSo, the GARCH-in-mean parameter \u03b4 is equal to the long-term mean of the standardized residuals from a GARCH model with a constant parameter and a moving average term. This long-term mean is given by \u03c9 + \u03c3MA.\nTherefore, the value of the GARCH-in-mean parameter estimate \u03bc is equal to \u03c9 + \u03c3MA."}
{"question": "Under which of the following situations would bootstrapping be preferred to pure simulation?\n\ni) If it is desired that the distributional properties of the data in the experiment\n\nare the same as those of some actual data\n\n\nii) If it is desired that the distributional properties of the data in the experiment\n\nare known exactly\n\n\niii) If the distributional properties of the actual data are unknown\n\n\niv) If the sample of actual data available is very small", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following may be consequences of one or more of the CLRM assumptions being violated?\n\ni) The coefficient estimates are not optimal\n\n\nii) The standard error estimates are not optimal\n\n\niii) The distributions assumed for the test statistics are inappropriate\n\n\niv) Conclusions regarding the strength of relationships between the dependent\n\nand independent variables may be invalid.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "LECTURE: The Central Limit Theorem (CLRM) assumes that the sample is large. If the sample size is too small, the CLRM may not apply. The CLRM states that the sum of a large number of random variables, each of which is of a fixed size, is approximately normally distributed with a mean equal to the mean of the original variables and a variance equal to the variance of the original variables.\nIf the CLRM is violated, the assumptions for many statistical tests can be compromised. For example, if the sample size is too small, the results of a hypothesis test may not be reliable.\nSOLUTION: To determine whether the CLRM assumptions are violated, consider the following:\nThe coefficient estimates are not optimal: This assumption applies to the variables that are used in a regression analysis. If the CLRM is violated, the estimates of the regression coefficients may be not optimal.\nThe standard error estimates are not optimal: This assumption applies to the standard errors of the estimates of the regression coefficients. If the CLRM is violated, the standard error estimates may be not optimal.\nThe distributions assumed for the test statistics are inappropriate: This assumption applies to the distributions of the test statistics. If the CLRM is violated, the distributions assumed for the test statistics may be inappropriate.\nConclusions regarding the strength of relationships between the dependent and independent variables may be invalid: This assumption applies to the conclusions that are drawn from the regression analysis. If the CLRM is violated, the conclusions may be invalid.\nNow, look at each answer choice.\nChoice: A.\nThis choice is incorrect. The coefficient estimates are not optimal, and the standard error estimates are not optimal are the only assumptions that are violated. The distributions assumed for the test statistics are not inappropriate, and the conclusions are not invalid.\nChoice: B.\nThis choice is incorrect. The coefficient estimates are not optimal and the standard error estimates are not optimal are the only assumptions that are violated. The distributions assumed for the test statistics are not inappropriate, and the conclusions are not invalid.\nChoice: C.\nThis choice is correct. The coefficient estimates are not optimal, and the standard error estimates are not optimal are the only assumptions that are violated. The distributions assumed for the test statistics are not inappropriate, and the conclusions are not invalid.\nChoice: D.\nThis choice is incorrect. The coefficient estimates are not optimal, and the standard error estimates are not optimal are the only assumptions that are violated. The distributions assumed for the test statistics are not inappropriate, and the conclusions are not invalid."}
{"question": "Which of the following statements is true concerning forecasting in econometrics?", "choices": [{"label": "A", "text": "Forecasts can only be made for time-series data"}, {"label": "B", "text": "Mis-specified models are certain to produce inaccurate forecasts"}, {"label": "C", "text": "Structural forecasts are simpler to produce than those from time series models"}, {"label": "D", "text": "In-sample forecasting ability is a poor test of model adequacy"}], "answerKey": "D", "model_answer": ""}
{"question": "The pacf is necessary for distinguishing between", "choices": [{"label": "A", "text": "An AR and an MA model"}, {"label": "B", "text": "An AR and an ARMA model"}, {"label": "C", "text": "An MA and an ARMA model"}, {"label": "D", "text": "Different models from within the ARMA family"}], "answerKey": "B", "model_answer": "LECTURE: When you are trying to determine which model to use for a time series, you need to decide which model is best for distinguishing between the patterns in the series. You can use both an AR and an MA model to do this.\nAn AR model looks at the own past values of the series to make its forecast.\nAn MA model looks at the own past errors of the series to make its forecast.\nWhen a model looks at its own past values or errors, it is called an autoregressive (AR) or moving average (MA) model, respectively.\nYou can also use an ARMA model, which is a combination of an AR and an MA model. An ARMA model looks at the own past values and errors of the series to make its forecast.\nA model from within the ARMA family is any ARMA model.\nSOLUTION: To distinguish between a particular set of values and the forecast from each model, you need to evaluate the models using a statistic called the sum of squared errors.\nThe sum of squared errors is the average of the squared differences between the observed values and the forecasted values.\nIn this case, the observed values are the given values, and the forecasted values are the values that would be produced by each model.\nTo calculate the sum of squared errors for a model, you need to specify the values of the model.\nFor example, the sum of squared errors for an AR model with p values is given by the formula:\n\u2211[forecasted value - observed value]^2 / \u2211[observed value - average observed value]^2\nand the sum of squared errors for an ARMA model with p values and q errors is given by the formula:\n\u2211[forecasted value - observed value]^2 / \u2211[observed value - average observed value]^2\nYou can use these formulas to calculate the sum of squared errors for each model. The model with the lower sum of squared errors is the best model for distinguishing between the given values.\nAn AR and an MA model are not within the ARMA family. So, a model from within the ARMA family is not either of these models.\nA model from within the ARMA family is any ARMA model. So, a model from within the ARMA family is a model with both AR and MA terms.\nA comparison of the sums of squared errors tells you that an ARMA model is a better model for distinguishing between the given values than an AR or an MA model."}
{"question": "Negative residual autocorrelation is indicated by which one of the following?", "choices": [{"label": "A", "text": "A cyclical pattern in the residuals"}, {"label": "B", "text": "An alternating pattern in the residuals"}, {"label": "C", "text": "A complete randomness in the residuals"}, {"label": "D", "text": "Residuals that are all close to zero"}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following statements are true concerning a comparison between ARCH(q) and GARCH(1,1) models?\n\ni) The ARCH(q) model is likely to be the more parsimonious\n\n\nii) The ARCH(q) model is the more likely to violate non-negativity constraints\n\n\niii) The ARCH(q) model can allow for an infinite number of previous lags of squared\n\nreturns to affect the current conditional variance\n\n\niv) The GARCH(1,1) model will usually be sufficient to capture all of the dependence\n\nin the conditional variance", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "LECTURE: When comparing two models, such as ARCH(q) and GARCH(1,1), it is often useful to consider the following:\n1. Parsimony: A more parsimonious model is simpler and has fewer parameters to estimate. In the case of ARCH and GARCH models, the number q in the ARCH(q) model is a parameter. So, the ARCH(q) model is less parsimonious than the GARCH(1,1) model.\n2. Non-negativity constraints: The GARCH(1,1) model will not violate non-negativity constraints, but the ARCH(q) model may.\n3. Number of previous lags of squared returns: The ARCH(q) model can allow for an infinite number of previous lags of squared returns to affect the current conditional variance. The GARCH(1,1) model has only one previous lag of squared returns.\n4. Capturing dependence: The GARCH(1,1) model will usually be sufficient to capture all the dependence in the conditional variance. This means that a GARCH(1,1) model is as good as, or better than, an ARCH(q) model.\nSOLUTION: Look at each statement:\nARCH(q) is more parsimonious than GARCH(1,1).\nARCH(q) can allow for an infinite number of previous lags of squared returns to affect the current conditional variance.\nGARCH(1,1) will usually be sufficient to capture all the dependence in the conditional variance.\nSo, the choices:\nLECTURE: A model is sufficient for a task if it is good enough to answer the question you want to ask. For example, if you want to know the effect of a change in the interest rate on the stock market, a GARCH(1,1) model is sufficient. It will answer most questions you might have about the data.\nA model is more parsimonious than another model if it has fewer parameters to estimate. For example, an ARCH(1) model has one parameter less than an ARCH(2) model.\nGiven these definitions, you can see that the GARCH(1,1) model is sufficient for the task of comparing the two models. The GARCH(1,1) model will answer most questions you might have about the data. The ARCH(q) model is more parsimonious than the GARCH(1,1) model. It has one parameter less."}
{"question": "Which of the following statements are true concerning a triangular or recursive system?\n\ni) The parameters can be validly estimated using separate applications of OLS to\n\neach equation\n\n\nii) The independent variables may be correlated with the error terms in other\n\nequations\n\n\niii) An application of 2SLS would lead to unbiased but inefficient parameter estimates\n\n\niv) The independent variables may be correlated with the error terms in the equations\n\nin which they appear as independent variables", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: In a triangular or recursive system, the independent variables may be correlated with the error terms in other equations. This means that ordinary least squares (OLS) may not produce unbiased estimates.\nTo address this problem, you can use two-stage least squares (2SLS) to estimate the parameters. In the first stage, you estimate the error terms in one equation using the other equations as predictors. In the second stage, you estimate the parameters of the original equation using the estimated error terms.\nThe parameters can be validly estimated using separate applications of OLS to each equation.\nThis statement is true for a triangular system, where independent variables may be correlated with the error terms in other equations. But it is not true for a recursive system, where the independent variables are correlated with the error terms in the same equation.\nAn application of 2SLS would lead to unbiased but inefficient parameter estimates.\nThis statement is true for a triangular or recursive system. Because the independent variables are correlated with the error terms in other equations, OLS may not produce unbiased estimates. But 2SLS can help reduce bias.\nThe independent variables may be correlated with the error terms in the equations in which they appear as independent variables.\nThis statement is true for a recursive system, where the independent variables are correlated with the error terms in the same equation. But it is not true for a triangular system, where the independent variables are not correlated with the error terms in other equations."}
{"question": "Which one of the following statements best describes the algebraic representation of the fitted regression line?", "choices": [{"label": "A", "text": "\\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t + \\hat{u}_t"}, {"label": "B", "text": "\\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t"}, {"label": "C", "text": "\\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t + u_t"}, {"label": "D", "text": "y_t = \\hat{\\alpha} + \\hat{\\beta}x_t + \\hat{u}_t"}], "answerKey": "B", "model_answer": "LECTURE: The algebraic representation of the fitted regression line is y = \\alpha + \\beta x.\nThe model is written as y = \\hat{y} when discussing the estimated line.\nThe model is written as y = \\tilde{y} when discussing the residuals from the estimated line.\nSOLUTION: The algebraic representation of the fitted regression line is given by \\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t.\nThe other three answers are all equivalent to this answer."}
{"question": "What are the dimensions of $\\hat{u}^t \\hat{u}?", "choices": [{"label": "A", "text": "T x k"}, {"label": "B", "text": "T x 1"}, {"label": "C", "text": "k x 1"}, {"label": "D", "text": "1 x 1"}], "answerKey": "D", "model_answer": "LECTURE: The general dimension of a matrix is the number of rows and the number of columns.\nIf either the number of rows or the number of columns is 1, the matrix is a vector.\nIf a matrix has more than one row and more than one column, it is a matrix.\nSOLUTION: The matrix \ufe0fu^t \ufe0fu has more than one row and more than one column, so it is a matrix.\nEach element of the matrix \ufe0fu^t \ufe0fu is a scalar. So, the matrix has the same number of rows as \ufe0fu and the same number of columns as \ufe0fu.\nThere are two cases to consider:\nCase 1: \ufe0fu is a vector. In this case, \ufe0fu^t \ufe0fu is a vector with the same number of elements as \ufe0fu. So, the dimension of \ufe0fu^t \ufe0fu is 1 x 1.\nCase 2: \ufe0fu is not a vector. In this case, \ufe0fu is a matrix. The dimension of \ufe0fu is the number of rows in \ufe0fu. So, the dimension of \ufe0fu^t \ufe0fu is the number of rows in \ufe0fu x the number of columns in \ufe0fu."}
{"question": "The characteristic roots of the MA process\n\n$y_t = -3u_{t-1} + u_{t-2} + u_t$\n\nare", "choices": [{"label": "A", "text": "1 and 2"}, {"label": "B", "text": "1 and 0.5"}, {"label": "C", "text": "2 and -0.5"}, {"label": "D", "text": "1 and -3"}], "answerKey": "B", "model_answer": "LECTURE: The characteristic roots of a MA process are the values of the roots of its characteristic equation. The characteristic equation is the equation obtained by replacing the variable in the characteristic roots of the MA process with zero.\nThe characteristic equation of a MA process is of the form:\n$b^n - ab^(n-1) + a^2b^(n-2) - \\cdots + a^(n-1) = 0$\nIf $a = 1$ and $b = -3$, then the characteristic equation is:\n$1 - 3(-3)^(n-1) + 3^2(-3)^(n-2) - \\cdots + 3^(n-1) = 0$\nIf $a = 1$ and $b = -0.5$, then the characteristic equation is:\n$1 - 0.5(-0.5)^(n-1) + 0.5^2(-0.5)^(n-2) - \\cdots + 0.5^(n-1) = 0$\nIf $a = 2$ and $b = -0.5$, then the characteristic equation is:\n$2 - 0.5(-0.5)^(n-1) + 0.5^2(-0.5)^(n-2) - \\cdots + 0.5^(n-1) = 0$\nIf $a = 1$ and $b = -3$, then the characteristic roots are:\n$1, -3, 1-3, -3(1-3), 1-3(-3), -3(1-3)(-3), \\ldots$\nIf $a = 1$ and $b = -0.5$, then the characteristic roots are:\n$1, -0.5, 1-0.5, -0.5(1-0.5), 1-0.5(-0.5), -0.5(1-0.5)(-0.5), \\ldots$\nIf $a = 2$ and $b = -0.5$, then the characteristic roots are:\n$2, -0.5, 2-0.5, -0.5(2-0.5), 2-0.5(-0.5), -0.5(2-0.5)(-0.5), \\ldots$"}
{"question": "Which of the following is an equivalent expression for saying that the explanatory variable is \"non-stochastic\"?", "choices": [{"label": "A", "text": "The explanatory variable is partly random"}, {"label": "B", "text": "The explanatory variable is fixed in repeated samples"}, {"label": "C", "text": "The explanatory variable is correlated with the errors"}, {"label": "D", "text": "The explanatory variable always has a value of one"}], "answerKey": "B", "model_answer": "LECTURE: Some variables are counted on one or two separate pieces of observation.\nA constant, or fixed, variable is the same every time you measure it. It is not random.\nA random variable is different each time you measure it. It is random."}
{"question": "Suppose that the Durbin Watson test is applied to a regression containing two explanatory variables plus a constant with 50 data points. The test statistic takes a value of 1.53. What is the appropriate conclusion?", "choices": [{"label": "A", "text": "Residuals appear to be positively autocorrelated"}, {"label": "B", "text": "Residuals appear to be negatively autocorrelated"}, {"label": "C", "text": "Residuals appear not to be autocorrelated"}, {"label": "D", "text": "The test result is inconclusive"}], "answerKey": "D", "model_answer": ""}
{"question": "If OLS is used in the presence of autocorrelation, which of the following will be likely consequences?\n\ni) Coefficient estimates may be misleading\n\n\nii) Hypothesis tests could reach the wrong conclusions\n\n\niii) Forecasts made from the model could be biased\n\n\niv) Standard errors may inappropriate", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "LECTURE: When an ordinary least squares (OLS) model is used to estimate coefficients in the presence of autocorrelation, the following consequences may occur:\ni. Coefficient estimates may be misleading. Because the model includes autocorrelated errors, the usual 95% confidence intervals and hypothesis tests may be incorrect.\nii. Hypothesis tests could reach the wrong conclusions. If the autocorrelated errors affect the model's coefficients, the usual hypothesis tests may reach incorrect conclusions.\niii. Forecasts made from the model could be biased. The model's forecasts may be too optimistic or too pessimistic.\niv. Standard errors may be inappropriate. The model's standard errors may not be accurate, which could lead to incorrect hypothesis tests."}
{"question": "What will be the properties of the OLS estimator in the presence of multicollinearity?", "choices": [{"label": "A", "text": "It will be consistent, unbiased and efficient"}, {"label": "B", "text": "It will be consistent and unbiased but not efficient"}, {"label": "C", "text": "It will be consistent but not unbiased"}, {"label": "D", "text": "It will not be consistent"}], "answerKey": "A", "model_answer": "LECTURE: The ordinary least squares (OLS) estimator is consistent, unbiased, and efficient when the multicollinearity is not too severe.\nConsistent: The OLS estimator is still well-defined when multicollinearity is present.\nUnbiased: The OLS estimator still provides an unbiased estimate of the true population parameter when multicollinearity is present.\nEfficient: The OLS estimator still provides the smallest possible variance for an estimator when multicollinearity is not too severe.\nWhen multicollinearity is too severe, the OLS estimator is no longer efficient. This means that there is another estimator that has a smaller variance. Different authors have defined thresholds for what is considered \"too severe\" for multicollinearity. Below is one possible definition.\nIf the correlations between pairs of predictors are all equal and greater than 0.75, the multicollinearity is too severe.\nSOLUTION: The OLS estimator will be consistent and unbiased but not efficient.\nWhen multicollinearity is present, the estimator will still provide a consistent and unbiased estimate of the true population parameter. But it will not be the most efficient estimate."}
{"question": "Which one of the following would NOT be a consequence of using non-stationary data in levels form?", "choices": [{"label": "A", "text": "The regression $R^2$ may be spuriously high"}, {"label": "B", "text": "Test statistics may not follow standard distributions"}, {"label": "C", "text": "Statistical inferences may be invalid"}, {"label": "D", "text": "Parameter estimates may be biased"}], "answerKey": "D", "model_answer": "LECTURE: When you use non-stationary time series data in levels form, the following consequences may occur:\nThe regression $R^2$ may be spuriously high.\nTest statistics may not follow standard distributions.\nStatistical inferences may be invalid.\nParameter estimates may be biased.\nSOLUTION: In levels form, non-stationary time series data have a trend or a seasonal pattern that is not constant over time. This can affect the reliability of statistical inferences.\nThe other factors listed above can also be affected by non-stationary data. For example, a trend or a seasonal pattern that is not constant can cause the regression $R^2$ to be spuriously high or bias parameter estimates.\nHowever, at least one of the factors listed above is not affected by non-stationary data in levels form: test statistics may not follow standard distributions."}
{"question": "If a series, y, follows a random walk, what is the optimal one-step ahead forecast of y?", "choices": [{"label": "A", "text": "The current value of y"}, {"label": "B", "text": "Zero"}, {"label": "C", "text": "One"}, {"label": "D", "text": "The average value of y over the in-sample period"}], "answerKey": "A", "model_answer": ""}
{"question": "The order condition is", "choices": [{"label": "A", "text": "A necessary and sufficient condition for identification"}, {"label": "B", "text": "A necessary but not sufficient condition for identification"}, {"label": "C", "text": "A sufficient but not necessary condition for identification"}, {"label": "D", "text": "A condition that is nether necessary nor sufficient for identification"}], "answerKey": "B", "model_answer": "LECTURE: A necessary condition is a condition that must be true for something to be true. If a condition is necessary, it is also sufficient.\nA sufficient condition is a condition that is true whenever something is true. If a condition is sufficient, it is also necessary.\nSOLUTION: The order condition is a necessary condition for identification.\nYou must order 10 or more items to qualify for identification. This means that ordering 10 or more items is a necessary condition for identification. But it is not a sufficient condition.\nThere are many ways to identify 10 or more items. The order condition is one way to do this. So, the order condition is a necessary but not sufficient condition for identification."}
{"question": "If an estimator is said to have minimum variance, which of the following statements is NOT implied?", "choices": [{"label": "A", "text": "The probability that the estimate is a long way away from its true value is minimised"}, {"label": "B", "text": "The estimator is efficient"}, {"label": "C", "text": "Such an estimator would be termed \"best\""}, {"label": "D", "text": "Such an estimator will always be unbiased"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following are disadvantages of the Dickey-Fuller / Engle-Granger approach to testing for cointegration and modelling cointegrating relationships?\n\ni) Only one cointegrating relationship can be estimated\n\nii) Particularly for small samples. There is a high chance of the tests suggestingthat variables are not cointegrated when they are\n\niii) It is not possible to make inferences on the cointegrating regression\n\niv) The procedure forces the researcher to specify which is the dependent variable and which are the independent variables.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "LECTURE: In order to test for cointegration, you must first test whether two or more time series are integrated. The unit root test can be used to test the integration of a time series. A unit root is evidence of integration, but not vice versa.\nA time series is integrated if the difference between its observed values grows without bound. This means that the ratio of the observed values of two instances of the time series tends to a finite limit as the instances get closer.\nThe difference between the observed values of a time series and its lag tend to a finite limit as the lag tends to zero. This limit is called the trend. If the trend is negative, the time series is said to have a unit root. If the trend is positive, the time series is said to be stationary.\nA time series is stationary if it does not have a trend. It is observed only at the instant in time. Stationary time series are more convenient to work with, because they do not change over time.\nHow to test for cointegration\nAfter you have tested whether two or more time series are integrated, you can use the procedures of the Engle-Granger or the Johansen test to detect cointegration.\nThe Engle-Granger test involves testing whether two or more time series have a common trend. If they do, then the time series are cointegrated.\nThe Johansen test involves testing whether two or more time series have a common structure. If they do, then the time series are cointegrated.\nBoth the Engle-Granger and the Johansen test have their own assumptions. Be sure to satisfy these assumptions before conducting either test.\nHow to estimate cointegrating relationships\nAfter you have detected cointegration, you can use the cointegrating regression to estimate relationships between the time series. The cointegrating regression is a usual least-squares regression in which the dependent variable is detrended.\nThe regression includes the following equations:\ny = \u03b1 + \u03b2x + \u03b5\nx = \u2211i=1p \u03b3i xi + \u03b4\nIn this regression, y is the detrended dependent variable, x is the independent variable, and \u03b5 is the error term. The \u03b3i and \u03b4 are the parameters to be estimated.\nThe \u03b3i are the coefficients in the equation x = \u2211i=1p \u03b3i xi, which is the trend part of the independent variable. This equation represents the independent variable as a linear combination of its own lags.\nThe \u03b4 is the coefficient in the equation x = \u2211i=1p \u03b3i xi + \u03b4, which is the error correction term. This term represents the estimated effect of the independent variable on the dependent variable.\nThe cointegrating regression can be estimated using ordinary least-squares. However, the ordinary least-squares estimates of the \u03b3i and \u03b4 may be poor if there are many lags in the trend equation. In this case, you can use the least squares method that is based on the minimum of the sum of the absolute values of the \u03b3i."}
{"question": "Which of the following statements is true concerning the population regression function (PRF) and sample regression function (SRF)?", "choices": [{"label": "A", "text": "The PRF is the estimated model"}, {"label": "B", "text": "The PRF is used to infer likely values of the SRF"}, {"label": "C", "text": "Whether the model is good can be determined by comparing the SRF and the PRF"}, {"label": "D", "text": "The PRF is a description of the process thought to be generating the data."}], "answerKey": "D", "model_answer": "LECTURE: The population regression function (PRF) is a description of the process thought to be generating the data. It is the function that describes the relationship between the independent variable and the dependent variable in the population. The sample regression function (SRF) is an estimate of the PRF. It is calculated from the snapshot of data that is available in the population.\nThe population regression function is not known. It is estimated from the sample data using a method called ordinary least squares. The sample regression function is a good estimate of the population regression function.\nThe choice of the best model for a given situation depends on the specific data and the questions being asked.\nSOLUTION: The PRF is a description of the process thought to be generating the data.\nThe SRF is an estimate of the PRF.\nThe PRF and the SRF are the same."}
{"question": "Which one of the following is a disadvantage of the general to specific or \"LSE\" (\"Hendry\") approach to building econometric models, relative to the specific to general approach?", "choices": [{"label": "A", "text": "Some variables may be excluded at the first stage leading to coefficient biases"}, {"label": "B", "text": "The final model may lack theoretical interpretation"}, {"label": "C", "text": "The final model may be statistically inadequate"}, {"label": "D", "text": "If the initial model is mis-specified, all subsequent steps will be invalid."}], "answerKey": "B", "model_answer": "LECTURE: When building an econometric model, you must decide how to order the variables. You can start with the most general variables and work down to the most specific variables, or you can start with the most specific variables and work up to the most general variables.\nThe general to specific approach is also known as the \"LSE\" (Last Step First) approach. It begins with the most specific variables and works up to the most general variables.\nThe specific to general approach is also known as the \"Hendry\" approach. It begins with the most general variables and works down to the most specific variables.\nSOLUTION: The specific to general approach is less likely to produce coefficient biases when using the LSE approach to build a model. This is because the LSE approach begins by estimating the most specific variables, which are estimated with the most flexible set of instruments.\nThe final model may lack theoretical interpretation.\nThe specific to general approach may produce a model that is more interpretable, because it begins with the most general variables and works down to the most specific variables.\nThe final model may be statistically inadequate.\nThe LSE approach may produce a model that is statistically inadequate if the initial model is mis-specified. This is because the LSE approach relies on the instruments in the last step to identify the coefficients of the other variables. If the initial variable specification is incorrect, the instruments in the last step will also be incorrect.\nSome variables may be excluded at the first stage leading to coefficient biases.\nThe specific to general approach may exclude some variables at the first stage, leading to coefficient biases in the final model. This is because the specific to general approach begins by estimating the most specific variables, which may have incomplete instruments."}
{"question": "Which of the following statements are true concerning maximum likelihood (ML) estimation in the context of GARCH models?\n\ni) Maximum likelihood estimation selects the parameter values that maximise the\n\nprobability that we would have actually observed the values of the series y that we\n\nactually did.\n\n\nii) GARCH models can only be estimated by ML and not by OLS\n\n\niii) For estimation of a standard linear model (with no GARCH), the OLS and ML\n\nestimates for the slope and intercept parameters will be identical but the estimator\n\nfor the variance of the disturbances is slightly different\n\n\niv) Most computer packages use numerical procedures to estimate GARCH models\n\nrather than a set of analytical formulae", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "LECTURE: Maximum likelihood estimation is a method of estimating the parameters of a statistical model. The method assumes that the data were generated by the model, and it uses the data to estimate the parameters that maximize the probability of the data.\nFor a Gaussian linear model, the maximum likelihood estimates of the parameters are the OLS estimates. But for nonlinear models, including GARCH models, the asymptotic covariance matrix of the estimated parameters is not invertible, so the OLS estimates do not exist. In such cases, the maximum likelihood estimate of a parameter is the value that maximizes the probability of the data.\nGiven the observed data, y, and a GARCH model, we can calculate the expected value of y, E[y]. The estimated parameter values that maximize the probability of the observed data, E[y], are the maximum likelihood estimates.\nThe maximum likelihood estimates of the parameters in a GARCH model can be calculated by using numerical optimization methods. Many computer packages use these methods to estimate the parameters of a GARCH model.\nThere are analytical formulae for the maximum likelihood estimates of the parameters in a GARCH model, but these formulae are not practical to use for estimation. The analytical formulae involve the likelihood function, which is the probability of the observed data, written as a function of the parameter values. The likelihood function is usually not available in a form that is simple to evaluate.\nChoice: D."}
{"question": "Including relevant lagged values of the dependent variable on the right hand side of a regression equation could lead to which one of the following?", "choices": [{"label": "A", "text": "Biased but consistent coefficient estimates"}, {"label": "B", "text": "Biased and inconsistent coefficient estimates"}, {"label": "C", "text": "Unbiased but inconsistent coefficient estimates"}, {"label": "D", "text": "Unbiased and consistent but inefficient coefficient estimates."}], "answerKey": "A", "model_answer": "LECTURE: Regression models are used to predict a continuous dependent variable. A regression equation is written as:\nY = a + bX1 + cX2 + ... + kXk\na. The intercept a is the value of the dependent variable when the independent variable X1 is zero.\nb. The slope b is the change in the dependent variable for a one-unit increase in the independent variable X1.\nc. The slope c is the change in the dependent variable for a one-unit increase in the independent variable X2.\n...\nk. The slope k is the change in the dependent variable for a one-unit increase in the independent variable Xk."}
{"question": "Which one of the following factors is likely to lead to a relatively high degree of out-of-sample forecast accuracy?", "choices": [{"label": "A", "text": "A model that is based on financial theory"}, {"label": "B", "text": "A model that contains many variables"}, {"label": "C", "text": "A model whose dependent variable has recently exhibited a structural change"}, {"label": "D", "text": "A model that is entirely statistical in nature with no room for judgmental modification of forecasts"}], "answerKey": "A", "model_answer": "LECTURE: Out-of-sample forecast accuracy is the ability of a model to make accurate predictions on data that were not used to build the model.\nSOLUTION: A model that is based on financial theory is likely to lead to a relatively high degree of out-of-sample forecast accuracy. Financial theory provides a framework for understanding how economic entities interact. A model based on financial theory will be able to capture these relationships and make accurate predictions.\nA model that contains many variables is not necessarily a better forecaster. A model with many variables may fit the data well without having a good understanding of the underlying relationships.\nA model whose dependent variable has recently exhibited a structural change is likely to have a lower degree of out-of-sample forecast accuracy. A structural change in the dependent variable can change the nature of the relationship between the independent and dependent variables. A model that is based on an earlier era will not be able to capture these changes and may have a lower degree of out-of-sample forecast accuracy.\nA model that is entirely statistical in nature with no room for judgmental modification of forecasts is likely to have a lower degree of out-of-sample forecast accuracy. Judgment can be especially important when dealing with exogenous, or outside, variables that may affect the dependent variable. A model that has no room for judgment may not be able to capture these effects and may have a lower degree of out-of-sample forecast accuracy."}
{"question": "Which of the following are plausible approaches to dealing with residual autocorrelation?\n\ni) Take logarithms of each of the variables\n\nii) Add lagged values of the variables to the regression equation\n\niii) Use dummy variables to remove outlying observations\n\niv) Try a model in first differenced form rather than in levels.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "LECTURE: When you have a time series with autocorrelation, or correlation between observations that is not due to a common cause, you can use one of the following approaches to deal with the autocorrelation:\n1. Use a non-stationary model: If the autocorrelation is due to a non-stationary component, using a non-stationary model, such as an ARIMA model, can help. An ARIMA model is a combination of an autoregressive model, an integrated model, and a moving average model.\n2. Use a stationary model: If the autocorrelation is due to a stationary component, using a stationary model, such as an ARIMA model with a constant mean, can help. A constant mean is a model with only random variables and no fixed values.\n3. Use a differenced model: If the autocorrelation is due to a trend component, using a differenced model can help. Taking the first difference of a time series removes the trend from the series.\n4. Use a transform: If the autocorrelation is due to a seasonal component, using a transform of the time series, such as a logarithmic transform, can help."}
{"question": "For an autoregressive process to be considered stationary", "choices": [{"label": "A", "text": "The roots of the characteristic equation must all lie inside the unit circle"}, {"label": "B", "text": "The roots of the characteristic equation must all lie on the unit circle"}, {"label": "C", "text": "The roots of the characteristic equation must all lie outside the unit circle"}, {"label": "D", "text": "The roots of the characteristic equation must all be less than one in absolute value"}], "answerKey": "C", "model_answer": "LECTURE: A process is said to be stationary if its statistical properties do not change over time. An autoregressive process is a type of statistical model that describes the relationships between a dependent variable and its own past values, as well as any other exogenous variables.\nAn autoregressive process is stationary if its statistical properties are unchanged when viewed over time. One way to tell if an autoregressive process is stationary is to examine the roots of its characteristic equation.\nThe roots of a characteristic equation are said to be inside the unit circle if they are all less than one in absolute value. A process is stationary if and only if the roots of its characteristic equation are inside the unit circle.\nThe roots of a characteristic equation are said to be on the unit circle if they are equal to one in magnitude and opposite in sign. A process is stationary if and only if the roots of its characteristic equation are on the unit circle.\nThe roots of a characteristic equation are said to be outside the unit circle if they are greater than one in absolute value. A process is stationary if and only if the roots of its characteristic equation are outside the unit circle.\nSOLUTION: To tell if the roots of a characteristic equation are less than one in absolute value, look at the magnitude of each root. If the absolute value of each root is less than one, then the roots are less than one in absolute value.\nIf the roots are less than one in absolute value, then the process is stationary."}
{"question": "Which of the following statements are true concerning information criteria?\n\n(i) Adjusted R-squared is an information criterion\n\n(ii) If the residual sum of squares falls when an additional term is added, the value of the information criterion will fall\n\n(iii) Akaike's information criterion always leads to model orders that are at least as large as those of Schwarz's information criterion\n\n(iv) Akaike's information criterion is consistent", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: One of the most important tasks in the modeling of a statistical problem is selecting the best model to fit the data. This is because a model that is too simple may not capture the complexity of the data, but a model that is too complex may be unable to fit the data well.\nInformation criteria are used to evaluate the fit of a statistical model. An information criterion is a measure of the goodness of fit of a statistical model. It takes into account the balance between the fit of the model and the complexity of the model.\nThere are several information criteria that are commonly used. Some of the most popular ones are described below.\nAdjusted R-squared. This criterion is like R-squared, but it has been adjusted for the number of predictors in the model. A higher adjusted R-squared indicates a better fit.\nAkaike's information criterion (AIC). This criterion balances the fit of the model with the complexity of the model. A smaller AIC indicates a better model fit.\nBayesian information criterion (BIC). This criterion is like AIC, but it penalizes models that have more parameters. A smaller BIC indicates a better model fit.\nSchwarz's information criterion (SIC). This criterion is like AIC, but it gives a higher penalty for larger models. A smaller SIC indicates a better model fit."}
{"question": "The \"within transform\" involves", "choices": [{"label": "A", "text": "Taking the average values of the variables"}, {"label": "B", "text": "Subtracting the mean of each entity away from each observation on that entity"}, {"label": "C", "text": "Estimating a panel data model using least squares dummy variables"}, {"label": "D", "text": "Using both time dummies and cross-sectional dummies in a fixed effects panel model"}], "answerKey": "B", "model_answer": ""}
{"question": "The purpose of \"augmenting\" the Dickey-Fuller test regression is to", "choices": [{"label": "A", "text": "Ensure that there is no heteroscedasticity in the test regression residuals."}, {"label": "B", "text": "Ensure that the test regression residuals are normally distributed"}, {"label": "C", "text": "Ensure that there is no autocorrelation in the test regression residuals"}, {"label": "D", "text": "Ensure that all of the non-stationarity is taken into account."}], "answerKey": "C", "model_answer": "LECTURE: One way to check for stationarity is to use a statistic such as the Augmented Dickey-Fuller (ADF) test statistic. The ADF test checks whether a time series is stationary.\nIf the ADF test statistic is less than the critical value, then the alternative hypothesis is rejected, and you can conclude that the series is stationary.\nIf the ADF test statistic is greater than the critical value, then the null hypothesis is rejected, and you can conclude that the series is nonstationary.\nThe ADF test can also be used to test for nonstationarity. In this case, the null hypothesis is that the series is stationary, and the alternative hypothesis is that the series is nonstationary."}
{"question": "If a series, y, follows a random walk with drift b, what is the optimal one-step ahead forecast of the change in y?", "choices": [{"label": "A", "text": "The current value of y"}, {"label": "B", "text": "Zero"}, {"label": "C", "text": "One"}, {"label": "D", "text": "The average value of the change in y over the in-sample period"}], "answerKey": "D", "model_answer": "LECTURE: A random walk is a series of steps that are perform-ed at random. In a random walk, each step is performed independently of the steps before it.\nA random walk with drift is a random walk in which each step is performed at a slightly different height than the previous step. This slight difference is called the drift.\nIf a random walk with drift has a positive drift, the sequence of steps moves upward as it goes. If a random walk with drift has a negative drift, the sequence of steps moves downward as it goes.\nIf a random walk has no drift, the sequence of steps is neither upward nor downward biased.\nSOLUTION: To forecast the change in a series y that follows a random walk with drift b, you can use the value of the drift b as your forecast.\nIn other words, the optimal one-step ahead forecast of the change in y is b."}
{"question": "Which of the following are plausible approaches to dealing with a model that exhibits heteroscedasticity?\n\ni) Take logarithms of each of the variables\n\nii) Use suitably modified standard errors\n\niii) Use a generalised least squares procedure\n\niv) Add lagged values of the variables to the regression equation.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: Heteroscedasticity occurs when the variability of the residuals is not constant. This means that the error terms have a different variance when predicting each part of the dependent variable.\nHeteroscedasticity can be a problem for two reasons:\n1. The standard errors of the coefficients are not equal. This means that the confidence intervals for the coefficients are not equal. So, you can't be sure that the coefficients are equal across the entire range of the dependent variable.\n2. The model's goodness of fit is not equal. Heteroscedasticity can produce a model that is misspecified, and the model's goodness of fit is not as good as it should be.\nIf your model exhibits heteroscedasticity, you can use one of the following approaches to deal with it:\n1. Use suitably modified standard errors: This involves using flexible and robust standard errors that are not affected as much by heteroscedasticity.\n2. Use a generalised least squares procedure: This involves re-estimating the model using a different weighting approach that is not affected as much by heteroscedasticity.\n3. Take logarithms of each of the variables: This involves transforming the variables so that they have a constant variability.\n4. Add lagged values of the variables to the regression equation: This involves using values of the variables from previous time periods as predictors in the regression equation.\nSOLUTION: The first approach is to use suitably modified standard errors. This involves using flexible and robust standard errors that are not affected as much by heteroscedasticity.\nThe third approach is to take logarithms of each of the variables. This involves transforming the variables so that they have a constant variability.\nThe fourth approach is to add lagged values of the variables to the regression equation. This involves using values of the variables from previous time periods as predictors in the regression equation."}
{"question": "Which of the following statements are true concerning the standardised residuals (residuals divided by their respective conditional standard deviations) from an estimated GARCH model?\n\ni) They are assumed to be normally distributed\n\n\nii) Their squares will be related to their lagged squared values if the GARCH model is\n\nappropriate\n\n\niii) In practice, they are likely to have fat tails\n\n\niv) If the GARCH model is adequate, the standardised residuals and the raw residuals\n\nwill be identical", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: In a GARCH model, the standardized residuals are the residuals divided by their respective conditional standard deviations.\nThe standardized residuals and the raw residuals are uncorrelated. This means that as the number of standardized residuals increase, the variance of the average of those standardized residuals will approach the variance of the raw residuals.\nThe standardized residuals have a mean of zero and a constant variance. This means that the mean of the standardized residuals is zero, and the variability of the standardized residuals is constant.\nIf the standardized residuals have fat tails, the raw residuals will have fat tails. This means that the variability of the raw residuals is greater than the variability of the standardized residuals.\nSOLUTION: The GARCH model is appropriate when the conditions for a GARCH model are met. One of the conditions is that the standardized residuals have a mean of zero and a constant variance. So, the first statement is true.\nThe second statement is true. If the GARCH model is appropriate, the standardized residuals and the raw residuals will be identical.\nThe third statement is true. In practice, the standardized residuals are likely to have a constant variance.\nThe fourth statement is false. The standardized residuals and the raw residuals are uncorrelated. This means that the standardized residuals are not identical to the raw residuals."}
{"question": "Which one of the following statements is true concerning VARs?", "choices": [{"label": "A", "text": "The coefficient estimates have intuitive theoretical interpretations"}, {"label": "B", "text": "The coefficient estimates usually have the same sign for all of the lags of a given variable in a given equation"}, {"label": "C", "text": "VARs often produce better forecasts than simultaneous equation structural models"}, {"label": "D", "text": "All of the components of a VAR must be stationary before it can be used for forecasting"}], "answerKey": "C", "model_answer": "LECTURE: A vector auto regression (VAR) is a model that shows how several variables change over time. It is a type of multivariate model.\nA vector auto regression (VAR) has several variables and several coefficients. Each coefficient shows how much one variable changes for a one-unit change in another variable. The coefficients are estimated using the observations.\nThe VAR model is used to forecast future values of the variables. To do this, you use the coefficients to calculate the expected future values of each variable. You then sum these expected future values to get a forecast for the future of the VAR.\nSOLUTION: The coefficient estimates usually have the same sign for all of the lags of a given variable in a given equation.\nThis statement is true for many VARs. It is usually not possible for a VAR to have negative coefficients for all of the lags of a given variable.\nThe coefficient estimates have intuitive theoretical interpretations.\nThis statement is true for a VAR. The coefficients show how much one variable changes for a one-unit change in another variable. These changes are predicted by the theory.\nVARs often produce better forecasts than simultaneous equation structural models.\nThis statement is false. There is no direct evidence that VARs often produce better forecasts than simultaneous equation structural models.\nAll of the components of a VAR must be stationary before it can be used for forecasting.\nThis statement is false. A VAR with non-stationary components can be used to forecast future values. But, the forecasts may not be accurate."}
{"question": "Which of the following statements is INCORRECT concerning the classical hypothesis testing framework?", "choices": [{"label": "A", "text": "If the null hypothesis is rejected, the alternative is accepted"}, {"label": "B", "text": "The null hypothesis is the statement being tested while the alternative encompasses the remaining outcomes of interest"}, {"label": "C", "text": "The test of significance and confidence interval approaches will always give the same conclusions"}, {"label": "D", "text": "Hypothesis tests are used to make inferences about the population parameters."}], "answerKey": "A", "model_answer": "LECTURE: Classical hypothesis testing is a procedure used to make decisions about the population parameters based on sample data. The classical hypothesis testing framework has the following steps:\n1. State the null hypothesis and the alternative hypothesis.\nThe null hypothesis is the statement being tested. It is usually written as H0. The alternative hypothesis is the statement that is considered in the event that the null hypothesis is rejected. It is usually written as Ha.\nFor example, if you want to know if a coin is fair, you could test the null hypothesis that the coin is fair (H0) against the alternative hypothesis that the coin is biased (Ha).\n2. Calculate the test statistic.\nThe test statistic is a value that is calculated from the sample data. The test statistic is used to determine whether the evidence from the sample differs from the evidence that would be expected if the null hypothesis were true.\nThere are many different test statistics. The choice of test statistic depends on the type of data and the nature of the problem.\nFor example, if you were testing the hypothesis that the average height of birds in a certain forest is 12 inches, and you collected a sample of 50 birds and found that the average height was 12 inches, then the test statistic would be 0. The sample data and the null hypothesis are in agreement!\n3. Determine the degrees of freedom.\nThe degrees of freedom is the number of values in the sample that are used to estimate a parameter.\nThe degrees of freedom is important because it is used to calculate the value of the test statistic.\nFor example, if you were testing the hypothesis that the mean weight of a certain type of apple is 1 pound, and you took a sample of 5 apples and obtained a sample mean of 12 ounces, then the degrees of freedom is 1.\nThe sample mean is used to estimate the population mean.\n4. Compare the test statistic to the critical value.\nThe critical value is a value that is based on the significance level. The critical value is used to determine whether to reject the null hypothesis.\nIf the test statistic is greater than the critical value, the null hypothesis is rejected. This means that there is evidence to support the alternative hypothesis.\nIf the test statistic is less than the critical value, the null hypothesis is not rejected. This means that there is not enough evidence to support the alternative hypothesis.\nThe significance level is the probability of rejecting the null hypothesis when it is actually true. The significance level is usually set at 0.05. This means that 5% of the null hypotheses that are tested will be rejected when they are actually true.\n5. Make a decision.\nIf the null hypothesis is rejected, the alternative hypothesis is accepted. This means that there is evidence to support the alternative hypothesis.\nIf the null hypothesis is not rejected, the alternative hypothesis is not accepted. This means that there is not enough evidence to support the alternative hypothesis."}
{"question": "An ARMA(p,q) (p, q are integers bigger than zero) model will have", "choices": [{"label": "A", "text": "An acf and pacf that both decline geometrically"}, {"label": "B", "text": "An acf that declines geometrically and a pacf that is zero after p lags"}, {"label": "C", "text": "An acf that declines geometrically and a pacf that is zero after q lags"}, {"label": "D", "text": "An acf that is zero after p lags and a pacf that is zero after q lags"}], "answerKey": "A", "model_answer": "LECTURE: A time series is a sequence of observations about a variable that is measured at different points in time. Many time series are not stationary, which means that the statistical properties of the time series change over time. A common way to analyze a non-stationary time series is to transform it into a stationary time series.\nOne way to do this is by using a differencing operator, which is a mathematical operation that moves a variable to the left. The differencing operator can be used to transform a time series into a stationary time series.\nIf a time series is differenced by q lags, then the first difference is the original time series differenced by 1 lag. The second difference is the first difference differenced by 1 lag, and so on.\nThe autocorrelation function (acf) and partial autocorrelation function (pacf) are measurements that can be used to understand the correlation between a time series and its lagged versions. These functions are defined for a stationary time series.\nIf a time series is not stationary, its acf and pacf will change when the time series is differenced. The acf and pacf will change until the time series becomes stationary.\nFor an ARMA(p,q) time series, the acf will decline geometrically after q lags. The pacf will be zero after q lags.\nFor an ARIMA(p,d,q) time series, the acf will decline geometrically after p lags. The pacf will be zero after p lags. The differencing operator is applied p times to the time series to make it stationary.\nSOLUTION: The model will have an acf that declines geometrically and a pacf that is zero after q lags. This is shown in the pacf by the fact that the pacf is zero after q lags. The acf declines geometrically, which means that for small values of k, the acf will be equal to 1. For larger values of k, the acf will be much smaller than 1."}
{"question": "Suppose that the following regression is estimated using 27 quarterly observations:\n\n$y_t = \\beta_1 + \\beta_2 x_2 + \\beta_3 x_{3t} + u_t$\n\nWhat is the appropriate critical value for a 2-sided 5% size of test of $H_0: \\beta_3 = 1$?", "choices": [{"label": "A", "text": "1.64"}, {"label": "B", "text": "1.71"}, {"label": "C", "text": "2.06"}, {"label": "D", "text": "1.96"}], "answerKey": "C", "model_answer": "LECTURE: For a 2-sided test, the critical values are determined by the null and alternative hypotheses.\nIf the null hypothesis is one-sided, the critical values are determined by the significance level and the alternative hypothesis.\nIf the null hypothesis is two-sided, the critical values are determined by the significance level and the size of the test.\nThe critical values are written with an apostrophe on either side: '2.06' for a 2-sided test with a size of 2% and a significance level of 5%.\nSOLUTION: The test is for a 2-sided 5% size test of the hypothesis:\n$H_0: \\beta_3 = 1$.\nThe critical value is 1.96."}
{"question": "Suppose that two researchers, using the same 3 variables and the same 250 observations on each variable, estimate a VAR. One estimates a VAR(6), while the other estimates a VAR(4). The determinants of the variance-covariance matrices of the residuals for each VAR are 0.0036 and 0.0049 respectively. What is the values of the test statistic for performing a test of whether the VAR(6) can be restricted to a VAR(4)?", "choices": [{"label": "A", "text": "77.07"}, {"label": "B", "text": "0.31"}, {"label": "C", "text": "0.33"}, {"label": "D", "text": "4.87"}], "answerKey": "A", "model_answer": "LECTURE: When estimating a vector autoregression (VAR) with N exogenous variables, there are N(N-1)/2 unknown parameters in the VAR, so an unrestricted VAR has N(N-1)/2 free parameters. The covariance matrix of the residuals has (N-1) free parameters, so an unrestricted VAR has (N-1) + N(N-1)/2 = N(N-1) + N(N-1)/2 = N(2N-1)/2 free parameters.\nIf one estimates a VAR(p) with exogenous variables, the model has N(2N-1)/2 free parameters. So, the determinant of the covariance matrix of the residuals for the VAR(p) is non-zero. This means that the VAR(p) is overparameterized.\nFor p < 2N-2, the model is underidentified, since there are more free parameters in the model than there are restrictions. In this case, it is not possible to determine the coefficients of the model.\nFor p \u2265 2N-2, the model is identifiable, since there are more restrictions than free parameters. In this case, the coefficients of the model are unique.\nSOLUTION: The VAR(6) is overparameterized, since it has 6 free parameters. The VAR(4) is underparameterized, since it has 4 free parameters. So, the VAR(6) can be restricted to a VAR(4). The test statistic for this hypothesis test is 0.33, which is the value of the test statistic."}
{"question": "Which of the following is a DISADVANTAGE of using pure time-series models (relative to structural models)?", "choices": [{"label": "A", "text": "They are not theoretically motivated"}, {"label": "B", "text": "They cannot produce forecasts easily"}, {"label": "C", "text": "They cannot be used for very high frequency data"}, {"label": "D", "text": "It is difficult to determine the appropriate explanatory variables for use in pure time-series models"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following are alternative names for the dependent variable (usually denoted by y) in linear regression analysis?\n\n(i) The regressand\n\n(ii) The regressor\n\n(iii) The explained variable\n\n(iv) The explanatory variable", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: In linear regression analysis, the relationship between the dependent variable and the independent variable is described by a linear equation. The independent variable is called the explanatory variable, and the dependent variable is called the response variable.\nWhen you are trying to find the relationship between two variables, it can be helpful to graph the variables. This is called a scatter plot.\nSOLUTION: The dependent variable is usually denoted by y, and the independent variable is usually denoted by x.\nThe explanatory variable is a synonym for the independent variable.\nThe explained variable is a synonym for the dependent variable.\nBoth explanatory and explained vary by context. In some problems, one of the variables may be the independent variable and the other may be the dependent variable."}
{"question": "Which of the following are advantages of the VAR approach to modelling the relationship between variables relative to the estimation of full structural models?\n\ni) VARs receive strong motivation from financial and economic theory\n\n\nii) VARs in their reduced forms can be used easily to produce time-series forecasts\n\n\niii) VAR models are typically highly parsimonious\n\n\niv) OLS can be applied separately to each equation in a reduced form VAR", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "LECTURE: One of the key advantages of the VAR approach to modelling the relationship between variables relative to the estimation of full structural models is that VARs in their reduced forms can be used easily to produce time-series forecasts.\nTo produce time-series forecasts, you can use the future values of the variables in the VAR in their reduced forms. The future values are found by plugging in the values of the other variables in the VAR in their reduced forms.\nThe other choices are incorrect because they do not identify key advantages of the VAR approach."}
{"question": "Which of the following statements is TRUE concerning the standard regression model?", "choices": [{"label": "A", "text": "y has a probability distribution"}, {"label": "B", "text": "x has a probability distribution"}, {"label": "C", "text": "The disturbance term is assumed to be correlated with x"}, {"label": "D", "text": "For an adequate model, the residual (u-hat) will be zero for all sample data points"}], "answerKey": "A", "model_answer": ""}
{"question": "Consider the following model for $y_t$:\n\n$y_t = \\mu + \\lambda t + u_t$\n\nWhich one of the following most accurately describes the process for $y_t$?", "choices": [{"label": "A", "text": "A unit root process"}, {"label": "B", "text": "A stationary process"}, {"label": "C", "text": "A deterministic trend process"}, {"label": "D", "text": "A random walk with drift"}], "answerKey": "C", "model_answer": "LECTURE: A stationary process is a statistical process that has no trend or no obvious pattern. It is a process that is described by a statistical distribution that is constant over time.\nA unit root process is a statistical process that has a trend, but the trend is not necessarily constant. The trend may increase or decrease over time.\nA random walk is a mathematical concept that describes a process that has a random trend. In a random walk, the trend is not predictable.\nA deterministic trend process is a statistical process that has a trend, and the trend is predictable. The trend may increase or decrease over time."}
{"question": "Which of the following is correct concerning logit and probit models?", "choices": [{"label": "A", "text": "They use a different method of transforming the model so that the probabilities lie between zero and one"}, {"label": "B", "text": "The logit model can result in too many observations falling at exactly zero or exactly one"}, {"label": "C", "text": "For the logit model, the marginal effect of a change in one of the explanatory variables is simply the estimate of the parameter attached to that variable, whereas this is not the case for the probit model"}, {"label": "D", "text": "The probit model is based on a cumulative logistic function"}], "answerKey": "A", "model_answer": ""}
{"question": "What is the most important disadvantage of the diagonal VECH approach to building multivariate GARCH models that is overcome by the BEKK formulation?", "choices": [{"label": "A", "text": "The diagonal VECH model is hard to interpret intuitively"}, {"label": "B", "text": "The diagonal VECH model contains too many parameters"}, {"label": "C", "text": "The diagonal VECH model does not ensure a positive-definite variance-covariance matrix"}, {"label": "D", "text": "The BEKK model reduces the dimensionality problem that arises when a number of series are modelled together."}], "answerKey": "C", "model_answer": "LECTURE: One way to build a multivariate GARCH model is to use the diagonal VECH approach. In this approach, each univariate GARCH model has a variant that uses vectorized variable estimates and has diagonal covariance matrices. The main disadvantage of the diagonal VECH approach is that it does not ensure a positive-definite variance-covariance matrix.\nThe BEKK formulation overcomes this disadvantage. It is a generalization of the VECH approach that uses a block-diagonal matrix to separate the variables. The BEKK model reduces the dimensionality problem that arises when a number of series are modelled together."}
{"question": "If a relevant variable is omitted from a regression equation, the consequences would be that:\n\ni) The standard errors would be biased\n\n\nii) If the excluded variable is uncorrelated with all of the included variables, all of\n\nthe slope coefficients will be inconsistent.\n\n\niii) If the excluded variable is uncorrelated with all of the included variables, the\n\nintercept coefficient will be inconsistent.\n\n\niv) If the excluded variable is uncorrelated with all of the included variables, all of\n\nthe slope and intercept coefficients will be consistent and unbiased but inefficient.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: Omitting a relevant variable from a regression equation can have several consequences.\nIf a variable that is predictive of the dependent variable is excluded from the regression, the slope coefficient for that variable will be inconsistent. This means that the estimated value of the slope coefficient will be too high or too low.\nIf an excluded variable is correlated with any of the included variables, the standard errors of the slope coefficients will be biased. This means that the estimated values of the slope coefficients will be too high.\nIf an excluded variable is uncorrelated with all of the included variables, the intercept coefficient will be inconsistent. This means that the estimated value of the intercept coefficient will be too high or too low.\nIf an excluded variable is uncorrelated with all of the included variables, the slope and intercept coefficients will be consistent and unbiased but inefficient. This means that the estimated values of the slope and intercept coefficients will be correct, but the standard errors will be too large.\nSOLUTION: Omitting a relevant variable from a regression equation will cause the standard errors to be biased. This means that the estimated values of the slope coefficients will be too high.\nThe excluded variable is uncorrelated with the included variables.\nSo, the slope and intercept coefficients will be consistent and unbiased but inefficient."}
{"question": "Which of the following are alternative names for the independent variable (usually denoted by x) in linear regression analysis?\n\n(i) The regressor\n\n(ii) The regressand\n\n(iii) The causal variable\n\n(iv) The effect variable", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: In linear regression, the independent variable is usually denoted by x. The dependent variable is usually denoted by y.\nWhen you have a regression problem, you want to figure out how x affects y. This is called the relationship between x and y.\nThe relationship between x and y can be described with statistics. The slope of the line represents the change in y for a one-unit change in x. The y-intercept represents the value of y when x is zero.\nThese statistics can be used to predict how y will change for a given value of x.\nSOLUTION: The independent variable is usually denoted by x. So, the effect variable is y.\nThe regressionand is another name for the dependent variable.\nThe regressor is another name for the independent variable.\nThe causal variable is not a term that is used in linear regression."}
{"question": "Consider the OLS estimator for the standard error of the slope coefficient. Which of the following statement(s) is (are) true?\n\n(i) The standard error will be positively related to the residual variance\n\n(ii) The standard error will be negatively related to the dispersion of the observations on the explanatory variable about their mean value\n\n(iii) The standard error will be negatively related to the sample size\n\n(iv) The standard error gives a measure of the precision of the coefficient estimate.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "LECTURE: The standard error of the slope coefficient is an estimate of the precision of the coefficient estimate. The standard error can be used to calculate a confidence interval for the slope coefficient.\nThe standard error can also be used to test if the slope coefficient is significantly different from zero.\nSOLUTION: The OLS estimator for the standard error of the slope coefficient is:\nStandard error = sqrt(Cov(Y, Y)/n)\nwhere Cov(Y, Y) is the covariance of the dependent variable Y with itself, and n is the sample size.\nSo, the standard error is negatively related to the dispersion of the observations on the explanatory variable about their mean value. This is statement (ii).\nThe standard error is also negatively related to the sample size. This is statement (iii).\nThe standard error will be positively related to the residual variance. This is false. It is possible to have a small standard error without a small residual variance.\nThe standard error gives a measure of the precision of the coefficient estimate. This is true."}
{"question": "What is the meaning of the term \"heteroscedasticity\"?", "choices": [{"label": "A", "text": "The variance of the errors is not constant"}, {"label": "B", "text": "The variance of the dependent variable is not constant"}, {"label": "C", "text": "The errors are not linearly independent of one another"}, {"label": "D", "text": "The errors have non-zero mean"}], "answerKey": "A", "model_answer": ""}
{"question": "If a Durbin Watson statistic takes a value close to zero, what will be the value of the first order autocorrelation coefficient?", "choices": [{"label": "A", "text": "Close to zero"}, {"label": "B", "text": "Close to plus one"}, {"label": "C", "text": "Close to minus one"}, {"label": "D", "text": "Close to either minus one or plus one"}], "answerKey": "C", "model_answer": ""}
{"question": "Under the null hypothesis of a Bera-Jarque test, the distribution has", "choices": [{"label": "A", "text": "Zero skewness and zero kurtosis"}, {"label": "B", "text": "Zero skewness and a kurtosis of three"}, {"label": "C", "text": "Skewness of one and zero kurtosis"}, {"label": "D", "text": "Skewness of one and kurtosis of three."}], "answerKey": "B", "model_answer": "LECTURE: The Bera-Jarque test is a test for normality. It tests the null hypothesis that the data are normally distributed against the alternative hypothesis that the data are not normally distributed.\nThe Bera-Jarque test is based on the skewness and kurtosis of the data. Skewness is a measure of the asymmetry of the distribution. A skewed distribution has a long tail in one direction. Kurtosis is a measure of the peakiness of the distribution. A distribution with high kurtosis has a more peaked distribution than a distribution with low kurtosis.\nIf the Bera-Jarque test is performed using the five-step procedure, the test statistic is compared to the critical value. The null hypothesis is rejected if the test statistic is greater than the critical value.\nThe Bera-Jarque test is similar to the Shapiro-Wilk test. The Shapiro-Wilk test is also a test for normality. The Shapiro-Wilk test uses only the skewness of the data.\nSOLUTION: The Bera-Jarque test has four possible outcomes.\nZero skewness and zero kurtosis.\nZero skewness and a kurtosis of three.\nSkewness of one and zero kurtosis.\nSkewness of one and kurtosis of three.\nFor each outcome, decide whether the data are normally distributed.\nIf the data are normally distributed, the null hypothesis is not rejected.\nIf the data are not normally distributed, the null hypothesis is rejected.\nSince the null hypothesis of a Bera-Jarque test has a kurtosis of three and a skewness of one, that outcome is not possible. So, the other three outcomes are possible."}
{"question": "If an estimator is said to be consistent, it is implied that", "choices": [{"label": "A", "text": "On average, the estimated coefficient values will equal the true values"}, {"label": "B", "text": "The OLS estimator is unbiased and no other unbiased estimator has a smaller variance"}, {"label": "C", "text": "The estimates will converge upon the true values as the sample size increases"}, {"label": "D", "text": "The coefficient estimates will be as close to their true values as possible for small and large samples."}], "answerKey": "C", "model_answer": "LECTURE: A consistent estimator is one whose estimates converge upon the true parameter values as the sample size increases.\nIf an estimator is consistent, it is implied that:\nOn average, the estimated coefficient values will equal the true values.\nThe OLS estimator is unbiased and no other unbiased estimator has a smaller variance.\nThe estimates will converge upon the true values as the sample size increases.\nThe coefficient estimates will be as close to their true values as possible for small and large samples."}
{"question": "Which of the following is a typical characteristic of financial asset return time-series?", "choices": [{"label": "A", "text": "Their distributions are thin-tailed"}, {"label": "B", "text": "They are not weakly stationary"}, {"label": "C", "text": "They are highly autocorrelated"}, {"label": "D", "text": "They have no trend"}], "answerKey": "D", "model_answer": "LECTURE: A financial asset is a type of investment. Financial assets are assets that have a value that can be traded, such as stocks and bonds.\nA financial asset's value at any point in time is determined by the interactions of many different people: investors, corporations, and governments. These interactions can change the asset's value. For example, a corporation's financial performance is often reported in the news. If the news reports that a corporation is doing well, the value of its stock is likely to go up. If the news reports that a corporation is doing poorly, the value of its stock is likely to go down.\nAn asset's value can also be changed by economic conditions. For example, interest rates and foreign exchange rates affect the value of many financial assets.\nSOLUTION: A financial asset's return time-series is a record of the asset's returns (profits or losses) over time. A financial asset's return can change over time for many different reasons, including the asset's performance and changes in the economy.\nA financial asset's return time-series may have the following typical characteristics:\nIt is not weakly stationary. This means that the mean (average) return and the standard deviation (a measure of the variability of the returns) are not constant over time.\nIt is highly autocorrelated. This means that the returns from one time period are related to the returns from previous time periods.\nIt has a trend. This means that the returns are increasing or decreasing over time.\nIt has a thin-tailed distribution. This means that the returns are not uniformly distributed. Instead, the returns are clustered around a central value."}
{"question": "Which of the following assumptions are required to show the consistency, unbiasedness and efficiency of the OLS estimator?\n\ni) $E(u_t) = 0$\n\n\nii) $\\text{Var}(u_t) = \\sigma^2$\n\n\niii) $\\text{Cov}(u_t, u_{t-j}) = 0 \\forall j$\n\n\niv) $u_t \\sim N(0, \\sigma^2)$", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following is a disadvantage of the fixed effects approach to estimating a panel model?", "choices": [{"label": "A", "text": "The model is likely to be technical to estimate"}, {"label": "B", "text": "The approach may not be valid if the composite error term is correlated with one or more of the explanatory variables"}, {"label": "C", "text": "The number of parameters to estimate may be large, resulting in a loss of degrees of freedom"}, {"label": "D", "text": "The fixed effects approach can only capture cross-sectional heterogeneity and not temporal variation in the dependent variable."}], "answerKey": "C", "model_answer": "LECTURE: Panel data are collected for multiple units over time. Panel data can be used to estimate models that include both cross-sectional and time-series variables.\nA panel model is a type of econometric model that is estimated using data from a panel dataset. A panel model includes variables that are measured at the group or panel level, as well as variables that are measured at the individual or time-series level. Panel data may be used to examine cross-sectional patterns, time-series patterns, or both.\nThe following graph shows the pattern of a time-series variable and a cross-sectional variable. The solid line shows the time-series pattern of the variable y. The different symbols show the cross-sectional pattern of the variable y.\nThe panel model is estimated using the data in the graph. The model includes fixed effects for the groups (or panel members). The fixed effects are represented by the small grey cells. The other variables in the model are estimated using the method of least squares."}
{"question": "Consider an identical situation to that of question 21, except that now a 2-sided alternative is used. What would now be the appropriate conclusion?", "choices": [{"label": "A", "text": "H0 is rejected"}, {"label": "B", "text": "H0 is not rejected"}, {"label": "C", "text": "H1 is rejected"}, {"label": "D", "text": "There is insufficient information given in the question to reach a conclusion"}], "answerKey": "A", "model_answer": "LECTURE: A hypothesis test is a way of formulating and answering a question about a population parameter using a sample from the population. To conduct a hypothesis test, you need to define the null hypothesis and the alternative hypothesis.\nThe null hypothesis, H0, is usually a statement of no change or no difference.\nThe alternative hypothesis, H1, is usually a statement of change or difference.\nTo determine if the evidence supports the alternative hypothesis, you must test the null hypothesis against the alternative hypothesis. This is done using a significance level, which is the probability of rejecting the null hypothesis when it is, in fact, true. Common significance levels are 0.01, 0.05, and 0.10.\nIf the calculated value of the test statistic is less than the critical value of the test statistic at the chosen significance level, then the null hypothesis is rejected. This means that there is evidence to support the alternative hypothesis.\nIf the calculated value of the test statistic is greater than or equal to the critical value of the test statistic at the chosen significance level, then the null hypothesis is not rejected. This means that there is not enough evidence to support the alternative hypothesis.\nSOLUTION: The problem presents a 2-sided alternative hypothesis. For a 2-sided hypothesis, the null hypothesis must be one of the following: H0 is true, or H0 is false.\nThe given null hypothesis is H0: \u03bc = 60.\nThere are two possible alternatives: H1: \u03bc > 60 or H1: \u03bc < 60.\nThe problem asks you to determine if there is sufficient information to reach a conclusion. You can do this by testing the null hypothesis against each alternative hypothesis.\nSince the null hypothesis is H0: \u03bc = 60, and both alternatives are H1: \u03bc > 60 or H1: \u03bc < 60, there is sufficient information to reach a conclusion."}
{"question": "The price of a house is best described as what type of number?", "choices": [{"label": "A", "text": "Discrete"}, {"label": "B", "text": "Cardinal"}, {"label": "C", "text": "Ordinal"}, {"label": "D", "text": "Nominal"}], "answerKey": "B", "model_answer": "LECTURE: Numbers can be described by the terms cardinal, ordinal, and nominal.\nCardinal numbers describe size. Cardinal numbers can be written with or without the word \"of.\"\nThe cardinal number 8 is larger than the cardinal number 2.\nThe cardinal number 8 is written with the word \"of.\"\nThere are 8 plants in the container.\nOrdinal numbers describe order. Ordinal numbers are written with the word \"th.\"\nThe ordinal number 1st is larger than the ordinal number 2nd.\nThere is only 1 student in the class who has a 1st in the spelling bee.\nThe other students have 2nds or 3rds.\nNominal numbers describe groupings. The nominal number 7 is the largest number in the group.\nThe nominal number 7 is marked with an arrow.\nSOLUTION: The price of a house is best described as nominal.\nNominal numbers describe groupings. The nominal number 7 is the largest number in the group.\nThe nominal number 7 is marked with an arrow."}
{"question": "If a Johansen \"trace\" test for a null hypothesis of 2 cointegrating vectors is applied to a system containing 4 variables is conducted, which eigenvalues would be used in the test?", "choices": [{"label": "A", "text": "All of them"}, {"label": "B", "text": "The largest 2"}, {"label": "C", "text": "The smallest 2"}, {"label": "D", "text": "The second largest"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following statements is true concerning variance decomposition analysis of VARs?\n\ni) Variance decompositions measure the impact of a unit shock to each of the variables on the VAR\n\nii) Variance decompositions can be thought of as measuring the proportion of the forecast error variance that is attributable to each variable\n\niii) The ordering of the variables is important for calculating impulse responses but not variance decompositions\n\niv) It is usual that most of the forecast error variance for a given variable is attributable to shocks to that variable", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "LECTURE: Variance decomposition analysis of a VAR is a way of analyzing the sources of variation in a set of time series. It uses impulse response functions and forecast error variance to break down the variance of the time series into separate components.\nImpulse response functions show how each variable in the VAR would respond to a shock, or impulse, applied to that variable. A shock is a temporary change to a variable. For example, a tax increase is a shock to the tax variable.\nForecast error variance is the portion of the variance of a time series that is not predicted by the VAR. It is the difference between the actual variance of the time series and the variance predicted by the impulse response functions.\nVariance decompositions measure the impact of a unit shock to each variable on the VAR. A unit shock is a temporary change to a variable in which the shock has a magnitude of 1.\nVariance decompositions can be thought of as measuring the proportion of the forecast error variance that is attributable to each variable. This means that each variable's impulse response functions show how the variable would respond to a shock that has a magnitude of 1.\nThe ordering of the variables is important for calculating impulse responses but not variance decompositions. This means that the order in which the variables are placed in the VAR does affect the impulse response functions, but it does not affect the variance decompositions.\nIt is usual that most of the forecast error variance for a given variable is attributable to shocks to that variable. This means that most of the variance of a time series is caused by variations in that time series.\nSOLUTION: Look at each choice:"}
{"question": "Suppose that we have estimated a GARCH model for daily equity returns, and we are interested in producing a 10-day forecast of the volatility (measured by the standard deviation of returns) for use in a value at risk model. How could such a forecast most validly be calculated?", "choices": [{"label": "A", "text": "Produce 1, 2, 3, ..., 10 step ahead conditional variance forecasts and add them up"}, {"label": "B", "text": "Produce 1, 2, 3, ..., 10 step ahead conditional variance forecasts and add them up and take the square root"}, {"label": "C", "text": "Produce 1, 2, 3, ..., 10 step ahead conditional variance forecasts, take the square roots of each one and add them up"}, {"label": "D", "text": "Produce a 1-step ahead conditional variance forecast, take its square root and multiply it by the square root of 10"}], "answerKey": "B", "model_answer": ""}
{"question": "Suppose that the value of $R^2$ for an estimated regression model is exactly zero. Which of the following are true?\n\ni) All coefficient estimates on the slopes will be zero\n\nii) The fitted line will be horizontal with respect to all of the explanatory variables\n\niii) The regression line has not explained any of the variability of y about its mean value\n\niv) The intercept coefficient estimate must be zero.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: The estimated regression line is the line that minimizes the residuals. Residuals are the differences between the dependent variable and the estimated dependent variable.\nThe residual for a point is the difference between the dependent variable and the estimated dependent variable for that point.\nThe sum of the residuals is the sum of the differences between the dependent variable and the estimated dependent variable.\nSOLUTION: The estimated regression line is a line. A line has both a slope and an intercept.\nSo, there are two coefficient estimates for the regression line to minimize the residuals: the intercept coefficient estimate and the slope coefficient estimate.\nIf the value of $R^2$ for an estimated regression model is exactly zero, then the intercept coefficient estimate is zero. So, the slope coefficient estimate is the only coefficient estimate that the regression line can minimize the residuals with.\nSo, the slope coefficient estimate must be zero. This means that the fitted line is horizontal with respect to all of the explanatory variables.\nThe intercept coefficient estimate cannot be zero. This means that the intercept of the fitted line is not zero.\nSo, the value of y when all of the explanatory variables are zero must be zero. This means that the regression line has not explained any of the variability of y about its mean value."}
{"question": "A white noise process will have\n\n(i) A zero mean\n\n(ii) A constant variance\n\n(iii) Autocovariances that are constant\n\n(iv) Autocovariances that are zero except at lag zero", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "LECTURE: Autocovariance is a measure of how two values change together. The autocovariance of a process at two points in time is given by:\nC(h) = Cov(X(t), X(t \u2212 h))\nwhere Cov is the covariance between two random variables, and X(t) and X(t \u2212 h) are the values of two processes at times t and t \u2212 h.\nThe autocovariance at lag 0 is the variance of the process, and the autocovariance at other lags is zero.\nSo, the statement that the autocovariance is zero except at lag zero means that the variance of the process is constant.\nThe statement that the autocovariance is constant means that the process has a constant variance.\nSo, the only ways to have a zero mean and a constant variance is to have a white noise process.\nSOLUTION: A white noise process has the properties described in the question. To see why, note that the autocovariance of a white noise process is zero except at lag 0, which means that the variance of the process is constant. Also, the mean of a white noise process is zero."}
{"question": "Which of the following statements are true concerning the Box-Jenkins approach to diagnostic testing for ARMA models?\n\n(i) The tests will show whether the identified model is either too large or too small\n\n(ii) The tests involve checking the model residuals for autocorrelation, heteroscedasticity, and non-normality\n\n(iii) If the model suggested at the identification stage is appropriate, the acf and pacf for the residuals should show no additional structure\n\n(iv) If the model suggested at the identification stage is appropriate, the coefficients on the additional variables under the overfitting approach will be statistically insignificant", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "LECTURE: One of the most powerful features of the ARMA model is the Box-Jenkins approach to model identification. This approach involves a set of diagnostic tests based on the autocorrelation function (ACF) and partial autocorrelation function (PACF) of the residuals. The Box-Jenkins approach helps you determine the order of the ARMA model.\nThe Box-Jenkins approach has several important components:\nThe ACF and PACF of the residuals can help you determine if there is autocorrelation in the residuals. As a residual is a difference, it is not autocorrelated.\nThe ACF and PACF of the residuals can help you determine if there is heteroscedasticity in the residuals. Heteroscedasticity occurs when the variance of the residuals is not constant.\nThe ACF and PACF of the residuals can help you determine if there is non-normality in the residuals. Normality refers to the distribution of the residuals.\nIf the ACF and PACF of the residuals show autocorrelation, heteroscedasticity, or non-normality, you can take steps to correct these problems. For example, you can use a different order for the ARMA model.\nThe Box-Jenkins approach has two stages: the identification stage and the estimation stage.\nDuring the identification stage, you use the ACF and PACF to determine the order of the ARMA model. The identified model is then used to make predictions.\nDuring the estimation stage, you estimate the parameters of the identified model.\nSOLUTION: The Box-Jenkins approach has four main diagnostic tests for determining if the identified model is appropriate.\nThe tests involve checking the model residuals for autocorrelation, heteroscedasticity, and non-normality.\nIf the model suggested at the identification stage is appropriate, the acf and pacf for the residuals should show no additional structure.\nThe coefficients on the additional variables under the overfitting approach will be statistically insignificant."}
{"question": "Which one of the following would be a plausible response to a finding of residual non-normality?", "choices": [{"label": "A", "text": "Use a logarithmic functional form instead of a linear one"}, {"label": "B", "text": "Add lags of the variables on the right hand side of the regression model"}, {"label": "C", "text": "Estimate the model in first differenced form"}, {"label": "D", "text": "Remove any large outliers from the data."}], "answerKey": "D", "model_answer": "LECTURE: One of the key assumptions of a normal linear regression model is that the dependent variable is normally distributed. If the dependent variable is not normally distributed, the model's assumptions are violated. This is called non-normality.\nA normal linear regression model has a normal distribution of residuals. This means that the residuals are normally distributed, and that the regression line is a good fit to the data.\nIf the dependent variable is not normally distributed, the residuals may also not be normally distributed. This is called residual non-normality.\nSOLUTION: One plausible response to a finding of residual non-normality is to estimate the model in first differenced form.\nIf the dependent variable is not normally distributed, taking the first difference of the dependent variable may make it normally distributed. This is because taking the first difference of a non-normal distribution may change it into a normal distribution.\nFirst difference: The difference between an observable and its predecessor.\nFor example, the first difference of a stock's price is the difference between the stock's price today and its price yesterday.\nEstimating a regression model in first differenced form means to estimate a new model using the first differences of the original data."}
{"question": "The fixed effects panel model is also sometimes known as", "choices": [{"label": "A", "text": "A seemingly unrelated regression model"}, {"label": "B", "text": "The least squares dummy variables approach"}, {"label": "C", "text": "The random effects model"}, {"label": "D", "text": "Heteroscedasticity and autocorrelation consistent"}], "answerKey": "B", "model_answer": "LECTURE: In a fixed effects model, the fixed effects are the variables that do not change over the period of time being studied. A fixed effects model is a type of empirical model.\nIn a fixed effects model, the model includes a term for each fixed effect. The term for each fixed effect contains a one and a coefficient that shows the effect of that fixed effect on the dependent variable.\nThe coefficient for each fixed effect represents the average effect of that fixed effect. The average effect does not necessarily represent the effect at a specific point in time for a specific unit.\nFor example, if a country is included as a fixed effect in a model that analyses crime rates, the model estimates the average crime rate for that country. The average crime rate does not tell you the actual crime rate at a specific point in time for that country.\nA seemingly unrelated regression model is a type of fixed effects model. It is used when there are many independent variables but only a few independent observations. This type of model is also called a fixed effects panel data model.\nThe least squares dummy variables approach is a type of fixed effects model. It is used when there are many independent variables, but there are many independent observations for each independent variable. In this type of model, each independent variable has a separate dummy variable.\nThe random effects model is a type of fixed effects model. It is used when the fixed effects include a random component, such as a random component that represents the residual variation of the dependent variable.\nHeteroscedasticity and autocorrelation consistent is a type of fixed effects model. It is used when the fixed effects include variables that are correlated with the random component of the fixed effects.\nSOLUTION: The fixed effects panel model is also sometimes known as the least squares dummy variables approach. The least squares dummy variables approach is a type of fixed effects model. It is used when there are many independent variables, but there are many independent observations for each independent variable. In this type of model, each independent variable has a separate dummy variable."}
{"question": "Which of the following statements is TRUE concerning OLS estimation?", "choices": [{"label": "A", "text": "OLS minimises the sum of the vertical distances from the points to the line"}, {"label": "B", "text": "OLS minimises the sum of the squares of the vertical distances from the points to the line"}, {"label": "C", "text": "OLS minimises the sum of the horizontal distances from the points to the line"}, {"label": "D", "text": "OLS minimises the sum of the squares of the horizontal distances from the points to the line."}], "answerKey": "B", "model_answer": "LECTURE: One of the key features of linear regression is that it allows you to make predictions about the score on a dependent variable for new values of an independent variable. To do this, you can use the line that represents the regression of the independent variable on the dependent variable. This line is called the best fit line.\nThe best fit line is the line that minimizes the sum of the squares of the vertical distances from the points to the line. This idea is shown in the figure below.\nThe distance from a point to a line is called a vertical distance. The sum of the vertical distances from the points to the line is called the sum of the vertical distances.\nTo find the line that minimizes the sum of the vertical distances, you need to solve for the line that fits the points best. This is done by finding the line that has a minimum sum of the vertical distances.\nOne way to find this line is to choose a new line that is parallel to the original line and finds the line that has a minimum sum of the vertical distances. This new line is called the best fit line.\nSOLUTION: The best fit line is the line that minimizes the sum of the squares of the vertical distances from the points to the line. This is shown by the blue line in the figure above."}
{"question": "If the standard tools for time-series analysis, such as estimation of the acf, pacf and spectral analysis, find no evidence of structure in the data, this implies that the data are which of the following?", "choices": [{"label": "A", "text": "Normally distributed"}, {"label": "B", "text": "Uncorrelated"}, {"label": "C", "text": "Independent"}, {"label": "D", "text": "Fat-tailed"}], "answerKey": "B", "model_answer": "LECTURE: Time-series data are data that are collected at different points in time. Many economic and financial data sets are time-series data.\nTime-series data may be affected by trends, which are changes that occur in the data over time. A time-series data set with a trend will show a change in the slope of the line that is fitted to the data.\nTime-series data may also be affected by seasonal patterns, which are repeated changes that occur at the same time each year. A time-series data set with seasonal patterns will have a line that is fitted to the data change its slope and intercept each year.\nTime-series data may also be affected by random events, or shocks. A time-series data set with random events will have a line that is fitted to the data change its slope and/or intercept over time.\nSOLUTION: To determine if the data are normally distributed, uncorrelated, independent, or fat-tailed, look at the values of the acf, pacf, and spectral analysis.\nThe acf shows the autocorrelation of the data. The autocorrelation of a set of data is the correlation between the data and its own lags. The acf has values between -1 and 1.\nIf the acf is equal to 0, then the data are uncorrelated.\nIf the acf is equal to 1, then the data are perfectly correlated.\nIf the acf is equal to -1, then the data are perfectly negatively correlated.\nThe pacf shows the partial autocorrelation of the data. The partial autocorrelation of a set of data is the correlation between the data and its own lags after accounting for the correlation between the data and its own lagged values. The pacf has values between -1 and 1.\nIf the pacf is equal to 0, then the data are uncorrelated.\nIf the pacf is equal to 1, then the data are perfectly correlated.\nIf the pacf is equal to -1, then the data are perfectly negatively correlated.\nThe spectral analysis shows the power of the data at different frequencies. A frequency is a cycle per observation. If the data have a frequency of 1, then each observation is a year.\nIf the spectral analysis shows that the data have no power at high frequencies, then the data are fat-tailed.\nIf the spectral analysis shows that the data have power at high frequencies, then the data are normally distributed.\nIf the spectral analysis shows that the data have power at low frequencies, then the data are uncorrelated."}
{"question": "If two variables, $x_t$ and $y_t$ are said to be cointegrated, which of the following statements are true?\n\ni) $x_t$ and $y_t$ must both be stationary\n\n\nii) Only one linear combination of $x_t$ and $y_t$ will be stationary\n\n\niii) The cointegrating equation for $x_t$ and $y_t$ describes the short-run relationship\n\nbetween the two series\n\n\niv) The residuals of a regression of $y_t$ on $x_t$ must be stationary", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "LECTURE: Two variables are said to be cointegrated if they can be expressed as the ratio of two deterministic variables. That is,"}
{"question": "A dependent variable whose values are not observable outside a certain range but where the corresponding values of the independent variables are still available would be most accurately described as what kind of variable?", "choices": [{"label": "A", "text": "Censored"}, {"label": "B", "text": "Truncated"}, {"label": "C", "text": "Multinomial variable"}, {"label": "D", "text": "Discrete choice"}], "answerKey": "A", "model_answer": "LECTURE: Variables are values that contain data. An independent variable is a value that affects or determines the value of another value, called a dependent variable.\nIndependent variables are often called inputs or drivers, and dependent variables are often called outputs or recipients.\nA variable is called observable if it is possible to measure or observe its values.\nA variable is called identified if it is possible to identify its value, even though it may not be directly observable.\nA variable is called nonobservable if it is not possible to observe or identify its value.\nSOLUTION: The dependent variable is truncated, or cut off, at a certain value. This value is called a threshold. The dependent variable is not observable beyond this threshold.\nThink about a dependent variable that represents a person's age. An independent variable that represents a person's driving experience is truncated at a certain value, say, 100. This means that a person's driving experience is not observable beyond 100."}
{"question": "A Hausman test would be used for", "choices": [{"label": "A", "text": "Determining whether an equation that is part of a simultaneous system is identified"}, {"label": "B", "text": "Determining whether a simultaneous framework is needed for a particular variable"}, {"label": "C", "text": "Determining whether 2SLS or ILS is optimal"}, {"label": "D", "text": "Determining whether the structural form equations can be obtained via substitution from the reduced forms"}], "answerKey": "B", "model_answer": ""}
{"question": "Under the matrix notation for the classical linear regression model, $y = X \\beta + u$, what are the dimensions of $u$?", "choices": [{"label": "A", "text": "T x k"}, {"label": "B", "text": "T x 1"}, {"label": "C", "text": "k x 1"}, {"label": "D", "text": "1 x 1"}], "answerKey": "B", "model_answer": "LECTURE: The matrix notation for the classical linear regression model is:\ny = X\u03b2 + u\nwhere y is a k x 1 column vector of actual values for the dependent variable, X is an m x n column vector of actual values for the independent variables, \u03b2 is a k x 1 column vector of the regression parameters, and u is a k x 1 column vector of error terms.\nThe dimensions of the error term u are k x 1."}
{"question": "How many parameters will be required to be estimated in total for all equations of a standard form, unrestricted, tri-variate VAR(4), ignoring the intercepts?", "choices": [{"label": "A", "text": "12"}, {"label": "B", "text": "4"}, {"label": "C", "text": "3"}, {"label": "D", "text": "36"}], "answerKey": "D", "model_answer": "LECTURE: A variable is a set of values. A parameter is a number that goes into the set of values for a variable.\nThink about a variable, y, with values y1, y2, y3, ..., yn. There are n parameters associated with the variable y.\nThe intercept is a special parameter that is associated with all variables. It is not linked to a specific value of the variable.\nThe other parameters are linked to specific values of the variable. For each value of the variable, there is a corresponding parameter.\nFor example, for the variable y = 2x + 1, there are two parameters: the parameter 2, which is associated with the value y = 2x + 1, and the parameter 1, which is associated with the value y = 1.\nSOLUTION: An unrestricted, tri-variate VAR(4) has 4 parameters that are associated with each variable. It has a total of 4 \u00d7 4 = 16 parameters.\nHowever, the intercepts do not have to be estimated. So, the number of parameters that must be estimated is 16 - 4 = 12."}
{"question": "A researcher tests for structural stability in the following regression model:\n\n$y_t = \\beta_1 + \\beta_2 x_{2t} + \\beta_3 x_{3t} + u_t$\n\nThe total sample of 200 observations is split exactly in half for the sub-sample regressions. Which would be the unrestricted residual sum of squares?", "choices": [{"label": "A", "text": "The RSS for the whole sample"}, {"label": "B", "text": "The RSS for the first sub-sample"}, {"label": "C", "text": "The RSS for the second sub-sample"}, {"label": "D", "text": "The sum of the RSS for the first and second sub-samples"}], "answerKey": "D", "model_answer": ""}
{"question": "Suppose that we are interested in testing the null hypothesis that a GARCH(2,2) model can be restricted to a process with a constant conditional variance using the likelihood ratio test approach. Which of the following statements are true?", "choices": [{"label": "A", "text": "The test statistic will follow a chi-squared distribution with 2 degrees of freedom under the null hypothesis"}, {"label": "B", "text": "The value of the log-likelihood function will almost always be bigger for the restricted model than for the unrestricted model"}, {"label": "C", "text": "If the relevant values of the log-likelihood functions are -112.3 and -118.4, the value of the test statistic is 12.2"}, {"label": "D", "text": "The likelihood ratio test compares the slopes of the log-likelihood function at the maximum and at the restricted parameter value."}], "answerKey": "C", "model_answer": "LECTURE: The GARCH model is a generalization of the ARCH model. Both models are used to specify the relationship between the variance of an asset's return and its past squared differences.\nA GARCH(p, q) model has the following form:\nVAR(y) = \u03c3^2(\u0394y) / \u03c3^2(y) = \u0394y^T \u03a3\u03b4(y) \u0394y + \u03b5^T \u03b5\nwhere y is a vector of asset returns, \u0394y is a vector of their past squared differences, \u03a3\u03b4(y) is a diagonal matrix of the GARCH model's parameters \u03b4, \u03b5 is a vector of the model's errors, and \u03c3^2(y) is the variance of y.\nThe GARCH(2, 2) model is a GARCH model with p = 2 and q = 2. It has the following form:\n\u0394y^T \u03a3\u03b4(y) \u0394y = \u03b21\u0394y^T \u0394y + \u03b22(\u0394y^T \u0394y)^2"}
{"question": "Which one of the following is NOT a plausible remedy for near multicollinearity?", "choices": [{"label": "A", "text": "Use principal components analysis"}, {"label": "B", "text": "Drop one of the collinear variables"}, {"label": "C", "text": "Use a longer run of data"}, {"label": "D", "text": "Take logarithms of each of the variables"}], "answerKey": "D", "model_answer": ""}
{"question": "Consider the following AR(2) process:\n\nyt = 1.5 yt-1 - 0.5 yt-2 + ut\n\nThis is a", "choices": [{"label": "A", "text": "Stationary process"}, {"label": "B", "text": "Unit root process"}, {"label": "C", "text": "Explosive process"}, {"label": "D", "text": "Stationary and unit root process"}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following could be used as a test for autocorrelation up to third order?", "choices": [{"label": "A", "text": "The Durbin Watson test"}, {"label": "B", "text": "White's test"}, {"label": "C", "text": "The RESET test"}, {"label": "D", "text": "The Breusch-Godfrey test"}], "answerKey": "D", "model_answer": "LECTURE: A series of numbers is said to be autocorrelated up to order q if the correlation between the numbers at time t and time t + r is the same as the correlation between the numbers at time t and time t + s for 0 <= s <= r. In other words, the correlation between the numbers at different times is not changing much as the time difference increases from r to s.\nOne measure of autocorrelation is the correlation between a series and a lagged version of the series. The lag is the time difference between the numbers. For example, the correlation between numbers at time t and time t + 1 is a measure of autocorrelation up to order 1.\nSOLUTION: The Durbin Watson test and White's test are tests for the presence of autocorrelated errors in the regression. The RESET test and the Breusch-Godfrey test are tests for the presence of autocorrelation in the data.\nThe Durbin Watson test and White's test do not test for autocorrelation in the data.\nThe Breusch-Godfrey test is a test for autocorrelation in the data up to first order. That is, the test checks if the correlation between numbers at time t and time t + 1 is significant.\nThe RESET test is a test for autocorrelation in the data up to third order. That is, the test checks if the correlation between numbers at time t and time t + 1, 2, or 3 is significant."}
{"question": "The residual from a standard regression model is defined as", "choices": [{"label": "A", "text": "The difference between the actual value, y, and the mean, y-bar"}, {"label": "B", "text": "The difference between the fitted value, y-hat, and the mean, y-bar"}, {"label": "C", "text": "The difference between the actual value, y, and the fitted value, y-hat"}, {"label": "D", "text": "The square of the difference between the fitted value, y-hat, and the mean, y-bar"}], "answerKey": "C", "model_answer": ""}
{"question": "If OLS is applied separately to each equation that is part of a simultaneous system, the resulting estimates will be", "choices": [{"label": "A", "text": "Unbiased and consistent"}, {"label": "B", "text": "Biased but consistent"}, {"label": "C", "text": "Biased and inconsistent"}, {"label": "D", "text": "It is impossible to apply OLS to equations that are part of a simultaneous system"}], "answerKey": "C", "model_answer": ""}
{"question": "Which one of the following is NOT an example of mis-specification of functional form?", "choices": [{"label": "A", "text": "Using a linear specification when y scales as a function of the squares of x"}, {"label": "B", "text": "Using a linear specification when a double-logarithmic model would be more appropriate"}, {"label": "C", "text": "Modelling y as a function of x when in fact it scales as a function of 1/x"}, {"label": "D", "text": "Excluding a relevant variable from a linear regression model"}], "answerKey": "D", "model_answer": ""}
{"question": "Suppose that we wished to evaluate the factors that affected the probability that an investor would choose an equity fund rather than a bond fund or a cash investment. Which class of model would be most appropriate?", "choices": [{"label": "A", "text": "A logit model"}, {"label": "B", "text": "A multinomial logit"}, {"label": "C", "text": "A tobit model"}, {"label": "D", "text": "An ordered logit model"}], "answerKey": "B", "model_answer": "LECTURE: Many statistical models are used to analyze observational data. When the dependent variable is categorical, with more than two possible outcomes, logit models are commonly used.\nA logit model is a logistic model used to analyze the probability of a binary outcome. The dependent variable is a probability, which means that the sum of the values for the dependent variable is equal to 1.\nA multinomial logit model is a variation of the logit model. It is used when the dependent variable has more than two possible outcomes. The multinomial logit model is a set of logit models, one for each category.\nAn ordered logit model is a special case of the logit model. It is used when the categories in the dependent variable are ordered. For example, categories of consumer spending on a product are ordered: customers spend either zero, some, or all of their money.\nA tobit model is a model used to analyze a dependent variable that is the outcome of a discrete decision-making process. The tobit model is used when the decision being made is binary, and the outcome is observed. For example, whether a customer renews a lease is a decision that is observed. But whether a customer takes out a lease is a decision that is not observed. A tobit model is not appropriate for the latter decision."}
{"question": "Which of the following statements will be true if the number of replications used in a Monte Carlo study is small?\n\ni) The statistic of interest may be estimated imprecisely\n\n\nii) The results may be affected by unrepresentative combinations of random draws\n\n\niii) The standard errors on the estimated quantities may be unacceptably large\n\n\niv) Variance reduction techniques can be used to reduce the standard errors", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "LECTURE: Monte Carlo methods use random numbers to simulate a situation and estimate the desired quantity. This can be done by assigning a value to the quantity for each random draw. The average of the assigned values is an estimate of the desired quantity. The standard deviation of the assigned values is an estimate of the uncertainty in the estimate.\nA Monte Carlo study uses random numbers to generate many possible estimates of a quantity. It then analyzes the random values to calculate the standard error and the variance of the estimate.\nThe standard error is the estimated uncertainty in an estimate. The standard error is calculated by dividing the standard deviation by the square root of the number of random draws.\nThe variance is the estimated uncertainty in an estimate. The variance is calculated by subtracting the mean from each value, square each resulting value, and then average the squared values.\nSOLUTION: A small number of replications will produce an estimate that is too uncertain. This happens because the estimate is based on a small number of random draws.\nThe standard errors on the estimated quantities may be unacceptably large.\nThe results may be affected by unrepresentative combinations of random draws.\nThis happens because the estimate is based on a small number of random draws.\nVariance reduction techniques can be used to reduce the standard errors.\nThis happens by using a different estimation technique that has a smaller variance."}
{"question": "Which of the following is a disadvantage of the random effects approach to estimating a panel model?", "choices": [{"label": "A", "text": "The approach may not be valid if the composite error term is correlated with one or more of the explanatory variables"}, {"label": "B", "text": "The number of parameters to estimate may be large, resulting in a loss of degrees of freedom"}, {"label": "C", "text": "The random effects approach can only capture cross-sectional heterogeneity and not temporal variation in the dependent variable."}, {"label": "D", "text": "All of (a) to (c) are potential disadvantages of the random effects approach."}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following could result in autocorrelated residuals?\n\ni) Slowness of response of the dependent variable to changes in the values of the independent variables\n\nii) Over-reactions of the dependent variable to changes in the independent variables\n\niii) Omission of relevant explanatory variables that are autocorrelated\n\niv) Outliers in the data", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: A model is a set of assumptions that are used to relate a dependent variable to one or more independent variables. Many real-world relationships are curvilinear or are subject to other complications, but most statistical models use straight lines or classical statistical methods to approximate these relationships. This approximation can be fine for analyzing some types of data, but it can lead to incorrect results when the relationships are highly curved or when there are other complicating factors.\nAutocorrelated residuals are a type of problem that can occur when using a statistical model. Autocorrelated residuals happen when the residuals (the difference between the observed values and the predicted values) have a pattern of being either too high or too low for nearby observed values. This pattern is called autocorrelation.\nTo determine if you have autocorrelated residuals, look for a pattern in the residuals. This pattern should be assessed using the independent variable. If the pattern stays the same or changes in a regular way as the independent variable changes, then you have autocorrelated residuals.\nSOLUTION: Look for a pattern in the residuals that is related to the independent variable. If the pattern stays the same or changes in a regular way as the independent variable changes, then you have autocorrelated residuals.\nThe omission of relevant explanatory variables that are autocorrelated can cause autocorrelated residuals.\nOver-reactions of the dependent variable to changes in the independent variables can cause autocorrelated residuals.\nSlowness of response of the dependent variable to changes in the values of the independent variables does not necessarily cause autocorrelated residuals.\nOutliers in the data can cause autocorrelated residuals, but they are not the only possible cause."}
{"question": "Which of the following statements are true concerning the acf and pacf?\n\n(i) The acf and pacf are often hard to interpret in practice\n\n(ii) The acf and pacf can be difficult to calculate for some data sets\n\n(iii) Information criteria represent an alternative approach to model order determination\n\n(iv) If applied correctly, the acf and pacf will always deliver unique model selections", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: The autocorrelation function (acf) and partial autocorrelation function (pacf) are tools used to understand the correlation of a variable with itself over time or after controlling for other variables.\nThe acf measures the linear relationship between a variable and its lags. For example, the acf at lag 1 measures the relationship between the variable and its past value.\nThe pacf measures the relationship between a variable and its lags after controlling for the effects of other variables. For example, the pacf at lag 1, partialled by the other variables, measures the relationship between the variable and its past value after controlling for the effects of the other variables.\nThe concepts of the acf and pacf are introduced in many standard texts on statistical methods.\nSOLUTION: The following statements are true concerning the acf and pacf:\n\u2022 The acf and pacf can be difficult to calculate for some data sets.\n\u2022 Information criteria represent an alternative approach to model order determination.\n\u2022 If applied correctly, the acf and pacf will always deliver unique model selections.\nThe following statement is not true:\n\u2022 The acf and pacf are often hard to interpret in practice.\nInterpretation of the acf and pacf can be difficult, but they are never hard to interpret."}
{"question": "Which of the following conditions are necessary for a series to be classifiable as a weakly stationary process?\n\n(i) It must have a constant mean\n\n(ii) It must have a constant variance\n\n(iii) It must have constant autocovariances for given lags\n\n(iv) It must have a constant probability distribution", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: A stationary process is one in which the statistical properties do not change over time. A weakly stationary process is one in which the mean, variance, and autocovariance remain constant over time.\nA strongly stationary process is one in which the mean, variance, autocovariance, and cross-covariance with respect to another process all remain constant over time.\nA process that is not stationary is one in which the mean, variance, autocovariance, and cross-covariance with respect to another process all change over time.\nSOLUTION: A process is weakly stationary if it has a constant mean, constant variance, and constant autocovariances.\nSo, the conditions in (ii) and (iv) are necessary for a series to be classifiable as a weakly stationary process."}
{"question": "Consider the following equation and determine the class of model that it best represents\n\n$y_{it} = \\alpha + \\beta_{it} + \\mu_i + \\nu_{it}$", "choices": [{"label": "A", "text": "An entity fixed effects model"}, {"label": "B", "text": "A time fixed effects model"}, {"label": "C", "text": "A random effects model"}, {"label": "D", "text": "A pure time series model"}], "answerKey": "A", "model_answer": "LECTURE: For a model to represent a pure time series, the part of the model that involves the explanatory variables must include only variables that are constant over time.\nThe variable in the equation that is not constant over time is the error term, which is represented by \u03b5it. This term is called the disturbance term. It has mean zero and constant variance, which is why it appears in the form of the error term in the model.\nThe other types of models have at least one explanatory variable that is not constant over time.\nAn entity fixed effects model includes at least one entity fixed effect, which is an arbitrary constant that is added to the error term. Entity fixed effects are used to account for differences between observing the same entity at different times.\nA time fixed effects model includes at least one time fixed effect, which is an arbitrary constant that is added to the error term. Time fixed effects are used to account for differences between observing the same entity at the same time.\nA random effects model includes at least one random effect, which is an arbitrary constant that is added to the error term. Random effects are used to account for differences between observing the same entity and time.\nSOLUTION: The model includes one time fixed effect, which is added to the error term. This represents the class of a time fixed effects model."}
{"question": "Note that statistical tables are not necessary to answer this question. For a sample of 1000 observations, the Dickey-Fuller test statistic values are", "choices": [{"label": "A", "text": "More negative than (i.e. bigger in absolute value than) those in the left hand tail of a normal distribution"}, {"label": "B", "text": "Less negative than (i.e. smaller in absolute value than) those in the left hand tail of a normal distribution"}, {"label": "C", "text": "Obtained from an analytical formula for the density of the Dickey-Fuller distribution"}, {"label": "D", "text": "More negative (i.e. bigger in absolute value) for a 10% size of test than a 5% test."}], "answerKey": "A", "model_answer": ""}
{"question": "Suppose that a hypothesis test is conducted using a 5% significance level. Which of the following statements are correct?\n\n(i) The significance level is equal to the size of the test\n\n(ii) The significance level is equal to the power of the test\n\n(iii) 2.5% of the total distribution will be in each tail rejection region for a 2-sided test\n\n(iv) 5% of the total distribution will be in each tail rejection region for a 2-sided test.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": ""}
{"question": "Which one of the following criticisms of the Dickey-Fuller/Engle-Granger approach to dealing with cointegrated variables is overcome by the Engle-Yoo (EY) procedure?", "choices": [{"label": "A", "text": "In the context of small samples, Dickey Fuller tests are prone to conclude that there is a unit root in a series when there is not"}, {"label": "B", "text": "The Engle-Granger (EG) approach can only detect up to one cointegrating relationship even though there could be more than one"}, {"label": "C", "text": "The variables are treated asymmetrically in the cointegrating tests"}, {"label": "D", "text": "It is not possible to perform tests about the cointegrating relationship"}], "answerKey": "D", "model_answer": ""}
{"question": "Consider a series that follows an MA(1) with zero mean and a moving average coefficient of 0.4. What is the value of the autocovariance at lag 1?", "choices": [{"label": "A", "text": "0.4"}, {"label": "B", "text": "1"}, {"label": "C", "text": "0.34"}, {"label": "D", "text": "It is not possible to determine the value of the autocovariances without knowing the disturbance variance."}], "answerKey": "D", "model_answer": "LECTURE: The autocovariance function is defined for lags 0, 1, and 2. It is not defined for other lags.\nThe autocovariance at lag 1 is the correlation between the time series at periods 0 and 1.\nIf the time series has a constant mean, the autocovariance at lag 1 is equal to the moving average coefficient.\nFor a MA(q) time series, the autocovariance at lag q is equal to the moving average coefficient.\nFor a MAR(q) time series, the autocovariance at lag q is equal to zero.\nSOLUTION: The time series is an MA(1) with a moving average coefficient of 0.4. So, the autocovariance at lag 1 is equal to the moving average coefficient: 0.4."}
{"question": "Which of the following estimation techniques are available for the estimation of over-identified systems of simultaneous equations?\n\ni) OLS\n\nii) ILS\n\niii) 2SLS\n\niv) IV", "choices": [{"label": "A", "text": "(iii) only"}, {"label": "B", "text": "(iii) and (iv) only"}, {"label": "C", "text": "(ii), (iii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii) and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: In an over-identified system of simultaneous equations, there are more equations than unknowns. This situation arises when there are more independent variables than necessary to estimate the parameters of the model. In such cases, the least-squares estimates are still consistent and normally hypothesis testable.\nThere are two techniques that can be used to estimate the parameters of an over-identified system:\n* Instrumental variables (IV) can be used to manipulate the independent variables in such a way that the instrument becomes a valid proxy for the original independent variable. This allows you to substitute the instrument for the original independent variable in the equations, reducing the number of unknowns to estimate.\n* Two-stage least squares (2SLS) is a method of using instrumental variables in the estimation of a system of simultaneous equations. The first stage involves using the ordinary least squares method to estimate the parameters of the equations using the instruments as independent variables. The second stage involves using the estimated parameters from the first stage to solve for the parameters of the original system of equations.\nThe following technique is not useful for over-identified systems:\n* Instrumental variables cannot be used to make an over-identified system under-identified. If there are more equations than unknowns, adding more independent variables will not help to estimate the parameters."}
{"question": "Which one of the following statements best describes a Type II error?", "choices": [{"label": "A", "text": "It is the probability of incorrectly rejecting the null hypothesis"}, {"label": "B", "text": "It is equivalent to the power of the test"}, {"label": "C", "text": "It is equivalent to the size of the test"}, {"label": "D", "text": "It is the probability of failing to reject a null hypothesis that was wrong"}], "answerKey": "D", "model_answer": "LECTURE: A Type II error is the probability of failing to reject a null hypothesis that was wrong. It is common to use a Type I error and a Type II error to assess the errors that can be made in a hypothesis test.\nA Type I error is the probability of incorrectly rejecting a null hypothesis. The null hypothesis is wrongly rejected when the sample evidence is strong enough to justify rejection. The Type I error is controlled by the level of significance chosen for the test.\nA Type II error is the probability of failing to reject a null hypothesis that was wrong. The null hypothesis is wrongly accepted when the sample evidence is not strong enough to justify rejection. The Type II error is a function of the level of significance chosen for the test.\nSOLUTION: A Type II error is the probability of failing to reject a null hypothesis that was wrong. The correct answer is D."}
{"question": "Which one of the following would be the most appropriate as a 95% (two-sided) confidence interval for the intercept term of the model given in question 21?", "choices": [{"label": "A", "text": "(-4.79,2.19)"}, {"label": "B", "text": "(-4.16,4.16)"}, {"label": "C", "text": "(-1.98,1.98)"}, {"label": "D", "text": "(-5.46,2.86)"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following are characteristics of a stationary process?\n\ni) It crosses its mean value frequently\n\n\nii) It has constant mean and variance\n\n\niii) It contains no trend component\n\n\niv) It will be stationary in first difference form", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "LECTURE: A process is stationary if its statistical properties do not change over time. This means that the mean, variance, and other statistical measures are constant.\nA nonstationary process is one in which the statistical properties change over time. This means that the mean, variance, and other statistical measures are not constant.\nSOLUTION: A process is stationary in first difference form if it has a trend component. To remove the trend component, take the first difference of the process. A first difference is the difference between a process's current value and its previous value.\nA process is stationary if it is stationary in first difference form. This means that the mean, variance, and other statistical measures are constant.\nThis graph shows two stationary processes. The blue line is a simple random walk. The red line is a process with a trend of 2."}
{"question": "Consider again the VAR model of equation 16. Which of the following conditions must hold for it to be said that there is bi-directional feedback?", "choices": [{"label": "A", "text": "The b and d coefficients significant and the a and c coefficients insignificant"}, {"label": "B", "text": "The a and c coefficients significant and the b and d coefficients insignificant"}, {"label": "C", "text": "The a and c coefficients significant"}, {"label": "D", "text": "The b and d coefficients significant"}], "answerKey": "D", "model_answer": "LECTURE: A variable is a formal symbol that represents a quantity in the econometric model. A variable can be an independent variable, a dependent variable, or a disturbance.\nAn independent variable is a variable that is plotted on the x-axis of a graph. An independent variable can be thought of as the value of the variable that is chosen for a particular observation.\nA dependent variable is a variable that is plotted on the y-axis of a graph. A dependent variable can be thought of as the value of the variable that is observed for a particular value of the independent variable.\nA disturbance is a variable that is not plotted on the graph. A disturbance is an independent variable if it affects the dependent variable, or a dependent variable if it is affected by the independent variable.\nSOLUTION: To determine whether there is bidirectional feedback, look at the b and d coefficients. The b and d coefficients represent the effects of the independent variable on the dependent variable when the disturbance is held constant, and when the dependent variable is held constant, respectively.\nThe a and c coefficients represent the effects of the independent variable on the dependent variable when the disturbance is not held constant, and when the dependent variable is not held constant, respectively.\nIf both the b and d coefficients are significant, and the a and c coefficients are insignificant, then there is bidirectional feedback.\nThe a and c coefficients are significant if their standard errors are not equal to zero. The b and d coefficients are significant if their standard errors are not equal to zero."}
{"question": "Consider the following sample autocorrelation estimates obtained using 250 data points:\n\n1) Lag 1 2 3\n\n2) Coefficient 0.2 -0.15 -0.1\n\n3) Assuming that the coefficients are approximately normally distributed, which of the coefficients are statistically significant at the 5% level?", "choices": [{"label": "A", "text": "1 only"}, {"label": "B", "text": "1 and 2 only"}, {"label": "C", "text": "1, 2 and 3 only"}, {"label": "D", "text": "It is not possible to determine the statistical significance since no standard errors have been given"}], "answerKey": "B", "model_answer": ""}
{"question": "Which one of the following is examined by looking at a goodness of fit statistic?", "choices": [{"label": "A", "text": "How well the population regression function fits the data"}, {"label": "B", "text": "How well the sample regression function fits the population regression function"}, {"label": "C", "text": "How well the sample regression function fits the data"}, {"label": "D", "text": "How well the population regression function fits the sample regression function."}], "answerKey": "C", "model_answer": "LECTURE: A goodness of fit statistic is a value that indicates how well a regression function fits the data. Two important goodness of fit statistics are the mean squared error and the mean absolute error.\nThe mean squared error is the average of the squared differences between the predicted and actual values.\nThe mean absolute error is the average of the absolute differences between the predicted and actual values.\nSOLUTION: The correct answer is A.\nTo determine how well the population regression function fits the data, you look at the mean squared error. This statistic is calculated using the predicted values from the population regression function and the actual values."}
{"question": "Which of the following statements are correct concerning the use of antithetic variates as part of a Monte Carlo experiment?\n\ni) Antithetic variates work by reducing the number of replications required to cover the whole probability space\n\nii) Antithetic variates involve employing a similar variable to that used in the simulation, but whose properties are known analytically\n\niii) Antithetic variates involve using the negative of each of the random draws and repeating the experiment using those values as the draws\n\niv) Antithetic variates involve taking one over each of the random draws and repeating the experiment using those values as the draws", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": ""}
{"question": "Which one of the following statements is true concerning alternative forecast accuracy measures?", "choices": [{"label": "A", "text": "Mean squared error is usually highly correlated with trading rule profitability"}, {"label": "B", "text": "Mean absolute error provides a quadratic loss function"}, {"label": "C", "text": "Mean absolute percentage error is a useful measure for evaluating asset return forecasts"}, {"label": "D", "text": "Mean squared error penalises large forecast errors disproportionately more than small forecast errors"}], "answerKey": "D", "model_answer": "LECTURE: Forecast accuracy measures are used to evaluate the performance of forecasts. For any forecast, these measures determine the error between the forecast and the actual outcome.\nMean absolute error (MAE) is the average absolute difference between the forecast and the actual outcome.\nMean absolute percentage error (MAPE) is the average absolute difference between the forecast and the actual outcome, expressed as a percentage of the actual outcome.\nMean squared error (MSE) is the average of the squared differences between the forecast and the actual outcome.\nMean absolute percentage error is a useful measure for evaluating asset return forecasts.\nMean squared error penalises large forecast errors disproportionately more than small forecast errors."}
{"question": "Which of the following criticisms of standard (\"plain vanilla\") GARCH models can be overcome by EGARCH models?\n\ni) Estimated coefficient values from GARCH models may be negative\n\nii) GARCH models cannot account for leverage effects\n\niii) The responsiveness of future volatility to positive and negative shocks is symmetric under a GARCH formulation\n\niv) GARCH models cannot allow for a feedback from the volatility to the returns", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
{"question": "Suppose that 100 separate firms were tested to determine how many of them \"beat the market\" using a Jensen-type regression, and it is found that 3 fund managers significantly do so. Does this suggest prima facie evidence for stock market inefficiency?", "choices": [{"label": "A", "text": "Yes"}, {"label": "B", "text": "No"}, {"label": "C", "text": "In order to answer this question, you would need to test every fund manager trading in that market"}, {"label": "D", "text": "There is insufficient information given in the question to draw a conclusion about market efficiency."}], "answerKey": "B", "model_answer": "LECTURE: Many people believe that the stock market is an efficient market. An efficient market is one in which the prices of securities accurately reflect their true value. In an efficient market, it is not possible to consistently beat the market.\nThere are two main parts to the efficient market hypothesis:\nFirst, market prices reflect all available information. If one person has inside information about a security, that person could use that information to buy or sell securities at a price that does not reflect that information. However, if the inside information is not secret, and the information becomes public, the price of the security will change to reflect that information.\nSecond, to earn a higher return than the market, one must take on higher risk. If the prices of securities accurately reflect their true value, then it is not possible to earn a higher return without taking on higher risk. This idea is known as the risk return tradeoff.\nSOLUTION: The fact that three fund managers significantly beat the market does not prove that the market is inefficient. It is possible that these fund managers have found a way to accurately predict market trends. But it is also possible that they are taking on more risk."}
{"question": "Which of the following are advantages of the use of panel data over pure cross-sectional or pure time-series modelling?\n\n(i) The use of panel data can increase the number of degrees of freedom and therefore the power of tests\n\n(ii) The use of panel data allows the average value of the dependent variable to vary either cross-sectionally or over time or both\n\n(iii) The use of panel data enables the researcher allows the estimated relationship between the independent and dependent variables to vary either cross-sectionally or over time or both", "choices": [{"label": "A", "text": "(i) only"}, {"label": "B", "text": "(i) and (ii) only"}, {"label": "C", "text": "(ii) only"}, {"label": "D", "text": "(i), (ii), and (iii)"}], "answerKey": "B", "model_answer": "LECTURE: Panel data are observations on multiple units over time. Panel data have become increasingly important in the social sciences because they allow the researcher to study the behavior of individuals, households, or firms over time.\nConsider a panel data set with N units and T time periods. The panel data set has observations on each unit for each of the T time periods.\nThe first observation in the panel data set is the initial value of the variable of interest. This observation is called the initial value of the panel.\nThe other T-1 observations in the panel data set are the subsequent values of the variable of interest. These observations are called the subsequent values of the panel.\nA cross-sectional design has observations on the same units at a single point in time.\nA time-series design has observations on the same unit over multiple time periods.\nTo use panel data, you need to use models that take into account the panel structure.\nTwo types of models can be used with panel data:\nFixed effects models. In a fixed effects model, each unit is assigned a fixed effect. The fixed effect does not change over time.\nRandom effects models. In a random effects model, each unit is assigned a random effect. The random effect may change over time.\nSOLUTION: The use of panel data allows the average value of the dependent variable to vary either cross-sectionally or over time or both. It also increases the number of degrees of freedom and therefore the power of tests.\nSo, the use of panel data has advantages over pure cross-sectional or pure time-series modelling."}
{"question": "If the Engle-Granger test is applied to the residuals of a potentially cointegrating regression, what would be the interpretation of the null hypothesis?", "choices": [{"label": "A", "text": "The variables are cointegrated"}, {"label": "B", "text": "The variables are not cointegrated"}, {"label": "C", "text": "Both variables are stationary"}, {"label": "D", "text": "Both variables are non-stationary"}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following statements are true concerning the autocorrelation function (acf) and partial autocorrelation function (pacf)?\n\ni) The acf and pacf will always be identical at lag one whatever the model\n\nii) The pacf for an MA(q) model will in general be non-zero beyond lag q\n\niii) The pacf for an AR(p) model will be zero beyond lag p\n\niv) The acf and pacf will be the same at lag two for an MA(1) model", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: The autocorrelation function (acf) and partial autocorrelation function (pacf) are used to determine the autoregressive and moving average models of a time series. The acf and pacf are identical at lag one for any model. The pacf for an MA(q) model will be non-zero beyond lag q. The pacf for an AR(p) model will be zero beyond lag p. The acf and pacf will be the same at lag two for an MA(1) model.\nSOLUTION: Look at the choices:\nThe pacf for an MA(q) model will in general be non-zero beyond lag q.\nThe pacf for an AR(p) model will be zero beyond lag p.\nThe acf and pacf will be the same at lag two for an MA(1) model.\nThese statements are true."}
