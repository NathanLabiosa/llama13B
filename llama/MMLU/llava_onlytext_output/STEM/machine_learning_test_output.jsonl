{"question": "Statement 1| Linear regression estimator has the smallest variance among all unbiased estimators. Statement 2| The coefficients \u03b1 assigned to the classifiers assembled by AdaBoost are always non-negative.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": ""}
{"question": "Statement 1| RoBERTa pretrains on a corpus that is approximate 10x larger than the corpus BERT pretrained on. Statement 2| ResNeXts in 2018 usually used tanh activation functions.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: A writer's job is to investigate and to write about a topic. To investigate a topic, you need to look up facts and information about it.\nWhen you investigate a topic, you can follow these steps:\n1. Read the question carefully.\n2. Read the passages in the textbook related to the question.\n3. Look up other information in the library or online.\n4. Organize the facts in your own words.\nSOLUTION: Step 1: Read the question carefully. The question asks if the two statements are true.\nStep 2: Read the passages in the textbook related to the question.\nRoBERTa is a newer model that is based on the BERT model. It was pretrained on a larger corpus, or set of texts. A corpus is a collection of texts that are used to train a model.\nResNeXts are a type of deep residency network. In 2018, many ResNeXts used tanh activations. A activation is a function that tells a neural network, or model for machine learning, how to use the values of its inputs.\nStep 3: Look up other information in the library or online.\nThe information in the textbook is not enough to determine if both statements are true."}
{"question": "Statement 1| Support vector machines, like logistic regression models, give a probability distribution over the possible labels given an input example. Statement 2| We would expect the support vectors to remain the same in general as we move from a linear kernel to higher order polynomial kernels.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: In a classification algorithm, a decision boundary is created to separate the data points of different classes. The decision boundary may be a straight line or its 2D generalization, a hyperplane.\nA linear decision boundary is a hyperplane in 2D, or a line in 1D. It chooses a random feature to separate the data into classes.\nA nonlinear decision boundary is a hyperplane that is not linear. It uses a function to determine which class a data point belongs to.\nSOLUTION: The first statement is true. A support vector machine (SVM) uses a function, called a kernel, to create a nonlinear decision boundary. The kernel is chosen to match the type of problem you are solving.\nA linear kernel creates a linear decision boundary. As you change to a higher order polynomial kernel, the decision boundary becomes more complex. But the support vectors do not change.\nThe second statement is false. If the kernel changes from a linear kernel to a higher order polynomial kernel, the decision boundary will change. But the support vectors, which are the data points that are closest to the decision boundary, will remain the same."}
{"question": "A machine learning problem involves four attributes plus a class. The attributes have 3, 2, 2, and 2 possible values each. The class has 3 possible values. How many maximum possible different examples are there?", "choices": [{"label": "A", "text": "12"}, {"label": "B", "text": "24"}, {"label": "C", "text": "48"}, {"label": "D", "text": "72"}], "answerKey": "D", "model_answer": "LECTURE: One way to understand the possible examples in a machine learning problem is to imagine placing each attribute value and class value into one of three bins. Each bin represents the possible values for each attribute.\nFor example, consider an attribute with three possible values. You could place these values into one of three bins.\nThe first bin represents the values 1, 2, and 3.\nThe second bin represents the values 4, 5, and 6.\nThe third bin represents the values 7, 8, and 9.\nYou could do the same for each attribute and the class.\nAfter placing all the values into bins, you would have a table that shows which values go into each bin. This table is called a binocular chart.\nThe maximum number of different examples that can be in this table is the maximum number of ways you can place the values into the bins.\nThere are 3 values that must be placed into 3 bins. This can be done in 3 ways.\nFor each attribute, the number of ways to place the values into bins is the number of choices for each value.\nThere are 2 values for the first attribute. This means there are 2 ways to place these values into bins.\nThere are 2 values for the second attribute. This means there are 2 ways to place these values into bins.\nThere are 2 values for the third attribute. This means there are 2 ways to place these values into bins.\nThere are 3 values for the class. This means there are 3 ways to place these values into bins.\nSo, there are a total of 2 \u00d7 2 \u00d7 2 \u00d7 3 = 12 different examples."}
{"question": "As of 2020, which architecture is best for classifying high-resolution images?", "choices": [{"label": "A", "text": "convolutional networks"}, {"label": "B", "text": "graph networks"}, {"label": "C", "text": "fully connected networks"}, {"label": "D", "text": "RBF networks"}], "answerKey": "A", "model_answer": "LECTURE: When you have a choice between two or more structures for use in a classifying high-resolution images, you need to decide which architecture is best.\nSOLUTION: Convolutional networks are the best architecture for classifying high-resolution images. Convolutional networks are designed to process data that has a grid-like structure, such as images. They can also use a small number of parameters, which makes them more efficient and faster than other types of networks."}
{"question": "Statement 1| The log-likelihood of the data will always increase through successive iterations of the expectation maximation algorithm. Statement 2| One disadvantage of Q-learning is that it can only be used when the learner has prior knowledge of how its actions affect its environment.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: The expectation maximization algorithm is an iterative algorithm that is used to find maximum likelihood estimates of parameters for a statistical model. The algorithm alternates between estimating the expected value of the data and maximizing the likelihood of the data.\nThere are two methods that solve the exposure maximization step in the expectation maximization algorithm: the iteration method and the gradient ascent method. Both methods are guaranteed to find a maximum likelihood estimate.\nThe iteration method is used by the expectation maximization algorithm. It starts with an initial estimate of the expected value of the data. Then, for each iteration, the expected value is updated by taking a weighted average of the initial estimate and the observed data. The weights are set so that the observed data has more influence as the iteration progresses.\nThe gradient ascent method involves using the partial derivatives of the log-likelihood function to find the maximum likelihood estimate. For each iteration, the gradient ascent method updates the expected value by moving in the direction of the highest increase in the log-likelihood function.\nSOLUTION: The first statement is true. The log-likelihood of the data will increase through successive iterations of the expectation maximization algorithm.\nThe second statement is false. One disadvantage of Q-learning is that it can be used when the learner has prior knowledge of how its actions affect its environment."}
{"question": "Let us say that we have computed the gradient of our cost function and stored it in a vector g. What is the cost of one gradient descent update given the gradient?", "choices": [{"label": "A", "text": "O(D)"}, {"label": "B", "text": "O(N)"}, {"label": "C", "text": "O(ND)"}, {"label": "D", "text": "O(ND^2)"}], "answerKey": "A", "model_answer": "LECTURE: Gradient descent is an optimization algorithm that uses the gradient of a function to adaptively change the function's parameters. In each iteration, it makes a small step in the opposite direction of the gradient. The size of the step is determined by the learning rate, a hyperparameter of the optimization.\nSuppose that you are using gradient descent to optimize a function f(x) that has the following gradient:\ng = [g1, g2, ..., gn].\nThen, the gradient descent update for each parameter xi is as follows:\nxi \u2190 xi - learning rate \u00d7 gi.\nThe choice of the learning rate determines the step size that is taken in each iteration. A larger learning rate leads to a larger step size, but may cause the optimization to converge slower."}
{"question": "Statement 1| For a continuous random variable x and its probability distribution function p(x), it holds that 0 \u2264 p(x) \u2264 1 for all x. Statement 2| Decision tree is learned by minimizing information gain.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: A probability distribution function is a function that tells you the probability of each possible value of a continuous variable x.\nFor example, if x represents a person's weight, a probability distribution function for that weight variable would tell you the probability of a person's weight being each possible value.\nSOLUTION: For a continuous random variable x and its probability distribution function p(x), it holds that 0 \u2264 p(x) \u2264 1 for all x.\nGiven a probability distribution function p(x), the probability of the variable x taking on a value in the interval [a, b] is given by:\nP(a \u2264 x \u2264 b) = p(x) d(x)\nwhere d(x) is the infinitesimal interval from a to x.\nSo, the infinitesimal interval from a to x is d(x) = x - a.\nTherefore, the probability of the variable x taking on a value in the interval [a, b] is given by:\nP(a \u2264 x \u2264 b) = p(x) (x - a)\nSince 0 \u2264 p(x) \u2264 1 for all x, the probability of the variable x taking on a value in each interval [a, b] is between 0 and 1."}
{"question": "Consider the Bayesian network given below. How many independent parameters are needed for this Bayesian Network H -> U <- P <- W?", "choices": [{"label": "A", "text": "2"}, {"label": "B", "text": "4"}, {"label": "C", "text": "8"}, {"label": "D", "text": "16"}], "answerKey": "C", "model_answer": "LECTURE: A Bayesian network is a model that represents a set of variables and their dependencies via a directed graph. The nodes in the graph represent random variables, and the arrows represent the relationships between the variables. A variable is a random variable when its value is determined by random factors.\nFor example, consider a variable C. The value of C is determined by the values of two other variables, A and B. So, the value of C is a random variable. The values of A and B are also random variables.\nA Bayesian network with n nodes has up to n independent parameters. The parameters of a Bayesian network are the probabilities of the variables in the network.\nFor each variable in the network, you must specify the probability distribution for that variable. For example, for a variable A, you must specify the probability distribution for A. This distribution tells you the probability of each possible value of A.\nThe independent parameters of a Bayesian network are the probabilities of the random variables in the network. A network has n independent parameters, where n is the number of nodes in the network.\nSOLUTION: To find the number of independent parameters in a Bayesian network, look at the number of nodes in the network. A network with n nodes has up to n independent parameters.\nThis network has 4 nodes: H, U, P, and W. So, the network has 4 independent parameters."}
{"question": "As the number of training examples goes to infinity, your model trained on that data will have:", "choices": [{"label": "A", "text": "Lower variance"}, {"label": "B", "text": "Higher variance"}, {"label": "C", "text": "Same variance"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": "LECTURE: The data a model is trained on has a large effect on its performance. If a model is trained on a small, random sample of the data, its performance will be unstable. This is because the model has not learned the patterns in the entire data set. As the size of the training set goes up, the model's performance becomes more stable. This is because the model has had more chances to learn the patterns in the data.\nSOLUTION: As the number of training examples goes to infinity, your model trained on that data will have lower variance.\nLower variance means that the model's performance is better. This happens because a model trained on a larger set of data has had more chances to learn the patterns in the data."}
{"question": "Statement 1| The set of all rectangles in the 2D plane (which includes non axisaligned rectangles) can shatter a set of 5 points. Statement 2| The VC-dimension of k-Nearest Neighbour classifier when k = 1 is infinite.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "_ refers to a model that can neither model the training data nor generalize to new data.", "choices": [{"label": "A", "text": "good fitting"}, {"label": "B", "text": "overfitting"}, {"label": "C", "text": "underfitting"}, {"label": "D", "text": "all of the above"}], "answerKey": "C", "model_answer": "LECTURE: A model is said to be underfitting if it performs poorly on the training data. This can occur when a model is too simple to fit the data well.\nA model is said to be overfitting if it performs well on the training data but poorly on new data. This can occur when a model is too complex and fits the noise in the training data.\nA model is said to be properly fitting if it performs well on both the training data and the new data.\nSOLUTION: A model that underfits the training data will perform poorly on the training data.\nA model that overfits the training data will perform well on the training data but poorly on new data.\nA model that is properly fitting will perform well on both the training data and the new data."}
{"question": "Statement 1| The F1 score can be especially useful for datasets with class high imbalance. Statement 2| The area under the ROC curve is one of the main metrics used to assess anomaly detectors.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| The back-propagation algorithm learns a globally optimal neural network with hidden layers. Statement 2| The VC dimension of a line should be at most 2, since I can find at least one case of 3 points that cannot be shattered by any line.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: A graph is a set of vertices and a set of edges that connect pairs of vertices.\nThe degree of a vertex is the number of edges incident to it.\nThe VC dimension of a graph is the number of vertices needed in a graph to be able to distinguish all possible subsets of the vertices.\nA graph is shattered by a set of lines if every edge is in at least one of the lines.\nA line shatters a set of points if the line intersects each of the points.\nA line is maximal if it is not contained in any larger line.\nThe VC dimension of a line is the number of points at which it intersects the plane.\nSOLUTION: Each statement is false.\nThe back-propagation algorithm does not guarantee that the neural network is optimal.\nThe VC dimension of a line is at most 2. Every line lies in a plane. So, the VC dimension of a line is at most 2."}
{"question": "High entropy means that the partitions in classification are", "choices": [{"label": "A", "text": "pure"}, {"label": "B", "text": "not pure"}, {"label": "C", "text": "useful"}, {"label": "D", "text": "useless"}], "answerKey": "B", "model_answer": "LECTURE: In a classification problem, you are given a set of objects and a set of partitions, or slots, and are asked to put each object into one of the partitions.\nHigh entropy means that the partitions in classification are useful, but they are not necessarily pure.\nA partition is pure when all the objects in a partition are identical.\nFor example, in the class fruits, the partition apple is pure. All apples are fruit and have the same color, shape, and size.\nA partition is not pure if the objects in a partition are not identical.\nFor example, in the class fruits and vegetables, the partition vegetables is not pure. Lettuce is a vegetable, but it is not the same as tomatoes.\nSOLUTION: Look at the text highlighted in blue. It tells you that high entropy means that the partitions in classification are useful."}
{"question": "Statement 1| Layer Normalization is used in the original ResNet paper, not Batch Normalization. Statement 2| DCGANs use self-attention to stabilize training.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: In an argument, a claim is a statement that presents an idea that needs to be proven. An evidence is a piece of information that supports a claim.\nWhen you are deciding whether to accept a claim, you should evaluate the evidence.\nSOLUTION: Look at each claim and its evidence.\nStatement 1: Layer Normalization is used in the original ResNet paper, not Batch Normalization.\nStatement 2: DCGANs use self-attention to stabilize training."}
{"question": "In building a linear regression model for a particular data set, you observe the coefficient of one of the features having a relatively high negative value. This suggests that", "choices": [{"label": "A", "text": "This feature has a strong effect on the model (should be retained)"}, {"label": "B", "text": "This feature does not have a strong effect on the model (should be ignored)"}, {"label": "C", "text": "It is not possible to comment on the importance of this feature without additional information"}, {"label": "D", "text": "Nothing can be determined."}], "answerKey": "C", "model_answer": "LECTURE: You have a set of data and want to fit a linear regression model to the data. Linear regression is a method for fitting a linear equation to data. Linear regression can help you identify the features that have a strong effect on a outcome.\nIn a linear regression model, the outcome is a linear function of the features. The function has the form:\noutcome = b0 + b1*feature1 + b2*feature2 + ... + bn\\*featuren\nThe coefficients (b0, b1, b2, ..., bn) determine how much each feature contributes to the outcome.\nIf a coefficient is far from zero, then that feature has a strong effect on the outcome. If a coefficient is close to zero, then that feature does not have a strong effect on the outcome.\nSOLUTION: The coefficient for one of the features is far from zero. This suggests that that feature has a strong effect on the model. So, that feature should be retained."}
{"question": "For a neural network, which one of these structural assumptions is the one that most affects the trade-off between underfitting (i.e. a high bias model) and overfitting (i.e. a high variance model):", "choices": [{"label": "A", "text": "The number of hidden nodes"}, {"label": "B", "text": "The learning rate"}, {"label": "C", "text": "The initial choice of weights"}, {"label": "D", "text": "The use of a constant-term unit input"}], "answerKey": "A", "model_answer": "LECTURE: A neural network is a model that is designed to recognize patterns. Neural networks are called \"black boxes\" because you can put data in one end and get a prediction out the other end, but it's hard to understand what's happening in between.\nA neural network has many layers. The input layer is the first layer. The output layer is the last layer. The other layers are hidden layers.\nThe neural network shown in the figure has 3 hidden layers. A hidden layer is a layer that is not in contact with the input or output layer."}
{"question": "For polynomial regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "The polynomial degree"}, {"label": "B", "text": "Whether we learn the weights by matrix inversion or gradient descent"}, {"label": "C", "text": "The assumed variance of the Gaussian noise"}, {"label": "D", "text": "The use of a constant-term unit input"}], "answerKey": "A", "model_answer": "LECTURE: For a polynomial regression of degree k, there are k+1 parameters: the intercept and the coefficients for each of the k polynomials.\nThe structural assumption that most affects the trade-off between underfitting and overfitting is the polynomial degree. If the degree is too low, the function will underfit, and the regression will be easily approximated. If the degree is too high, the function will overfit, and the regression will perform poorly on unseen data."}
{"question": "Statement 1| As of 2020, some models attain greater than 98% accuracy on CIFAR-10. Statement 2| The original ResNets were not optimized with the Adam optimizer.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: Statements 1 and 2 are both false.\nAs of 2020, some models can achieve greater than 98% accuracy on CIFAR-10.\nThe original ResNets were optimized with the Adam optimizer."}
{"question": "The K-means algorithm:", "choices": [{"label": "A", "text": "Requires the dimension of the feature space to be no bigger than the number of samples"}, {"label": "B", "text": "Has the smallest value of the objective function when K = 1"}, {"label": "C", "text": "Minimizes the within class variance for a given number of clusters"}, {"label": "D", "text": "Converges to the global optimum if and only if the initial means are chosen as some of the samples themselves"}], "answerKey": "C", "model_answer": "LECTURE: The k-means algorithm is a popular clustering method that is used to divide a dataset into k clusters. The algorithm works as follows:\n1. Initialize the k means: Choose k starting cluster centroids at random from the dataset.\n2. Assign each point to the nearest mean: For each data point, calculate its squared distance to each cluster centroid. Assign the point to the cluster with the smallest squared distance.\n3. Update the cluster centroids: For each cluster, calculate a new centroid as the mean of all points in the cluster.\nThe k-means algorithm can continue to update the cluster centroids until the centroids no longer change or until a stopping criterion is met.\nSOLUTION: The K-means algorithm has the smallest value of the objective function when K = 1. The objective function is the sum of the squared distances of each point to its nearest mean. When K = 1, each point is its own nearest mean, so the objective function is 0."}
{"question": "Statement 1| VGGNets have convolutional kernels of smaller width and height than AlexNet's first-layer kernels. Statement 2| Data-dependent weight initialization procedures were introduced before Batch Normalization.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: When you are considering two statements, you can use the following rules to determine if each statement is true:\n1. A statement is true if it matches your knowledge of the topic.\nA statement is false if it does not match your knowledge of the topic."}
{"question": "What is the rank of the following matrix? A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]", "choices": [{"label": "A", "text": "0"}, {"label": "B", "text": "1"}, {"label": "C", "text": "2"}, {"label": "D", "text": "3"}], "answerKey": "B", "model_answer": "LECTURE: A matrix is a collection of numbers arranged in rows and columns. Matrices can be ranked by comparing their elements.\nTwo matrices are equal if they have the same number of rows and the same number of columns, and if each element in the first matrix is equal to the corresponding element in the second matrix.\nIf one matrix is smaller, and it has the same number of rows, then the matrix is ranked higher.\nIf one matrix is larger, and it has more columns, then the matrix is ranked higher.\nIf one matrix is larger, and it has more rows, then the matrix is ranked lower.\nSOLUTION: The matrix A is a 3x3 matrix. To rank it, compare its elements.\nSince each element in the matrix is 1, the matrix is ranked 1."}
{"question": "Statement 1| Density estimation (using say, the kernel density estimator) can be used to perform classification. Statement 2| The correspondence between logistic regression and Gaussian Naive Bayes (with identity class covariances) means that there is a one-to-one correspondence between the parameters of the two classifiers.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: Density estimation and classification are two common tasks in supervised learning.\nDensity estimation is the task of estimating a probability density function from a set of labeled data. The probability of a test point x is then estimated by evaluating the density function at x.\nClassification is the task of assigning a label to a test point. The labels are chosen from a set of possible values.\nThere is a correspondence between logistic regression and Gaussian Naive Bayes (with identity class covariances) for classification. This correspondence means that there is a one-to-one correspondence between the parameters of these two classifiers.\nThese two statements are true.\nThe first statement tells you that density estimation can be used for classification. For example, the k-nearest neighbors classifier is a density estimation method that can also be used for classification.\nThe second statement tells you that the correspondence between logistic regression and Gaussian Naive Bayes (with identity class covariances) means that there is a one-to-one correspondence between the parameters of these two classifiers. This correspondence holds for the standard forms of these two classifiers."}
{"question": "Suppose we would like to perform clustering on spatial data such as the geometrical locations of houses. We wish to produce clusters of many different sizes and shapes. Which of the following methods is the most appropriate?", "choices": [{"label": "A", "text": "Decision Trees"}, {"label": "B", "text": "Density-based clustering"}, {"label": "C", "text": "Model-based clustering"}, {"label": "D", "text": "K-means clustering"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| In AdaBoost weights of the misclassified examples go up by the same multiplicative factor. Statement 2| In AdaBoost, weighted training error e_t of the tth weak classifier on training data with weights D_t tends to increase as a function of t.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "MLE estimates are often undesirable because", "choices": [{"label": "A", "text": "they are biased"}, {"label": "B", "text": "they have high variance"}, {"label": "C", "text": "they are not consistent estimators"}, {"label": "D", "text": "None of the above"}], "answerKey": "B", "model_answer": "LECTURE: One of the key goals of research is to develop estimates of population parameters. One way to do this is to take a sample of the population and use it to estimate the parameter. For example, a researcher might take a sample of 1,000 people from a population of 100,000 to estimate the population proportion who have a certain health condition.\nThe estimate is based on the sample. The more people are in the sample, the more accurate the estimate is likely to be.\nSOLUTION: MLE estimates are often undesirable because they are biased.\nBecause MLE estimates are based on a sample, they are subject to random error. This error can happen because of the way the sample was chosen. As a result of this error, an MLE estimate may not be the true population parameter.\nAn MLE estimate is also systematically biased. This bias occurs because of the way the estimator is constructed. The bias is equal to the difference between the true population parameter and the MLE estimate."}
{"question": "Computational complexity of Gradient descent is,", "choices": [{"label": "A", "text": "linear in D"}, {"label": "B", "text": "linear in N"}, {"label": "C", "text": "polynomial in D"}, {"label": "D", "text": "dependent on the number of iterations"}], "answerKey": "C", "model_answer": "LECTURE: The computational complexity of an algorithm is a measure of the amount of resources the algorithm consumes. In the case of an optimization algorithm such as gradient descent, the resources consumed are dependent on the complexity of each iteration.\nThe complexity of each iteration of gradient descent is dependent on the size of the data set (N) and the number of parameters (D). So, the computational complexity of gradient descent is polynomial in N and D.\nSOLUTION: The gradient descent algorithm has a computational complexity of polynomial in D and N. This means that the number of iterations is also a factor in the algorithm's complexity."}
{"question": "Averaging the output of multiple decision trees helps _.", "choices": [{"label": "A", "text": "Increase bias"}, {"label": "B", "text": "Decrease bias"}, {"label": "C", "text": "Increase variance"}, {"label": "D", "text": "Decrease variance"}], "answerKey": "D", "model_answer": "LECTURE: When you use multiple decision trees to solve a machine learning problem, the average output of the decision trees is often lower in bias than the output of any single decision tree. This is because decision trees are often affected by noise in the data. By taking the average of multiple decision trees, you can reduce the effect of this noise and produce a more accurate overall prediction.\nSOLUTION: Averaging the output of multiple decision trees helps decrease bias.\nBias is the error that is introduced by assuming that the data follows a particular distribution, such as a normal distribution. This error is called bias.\nBy taking the average of multiple decision trees, you are producing a more accurate overall prediction. This means that the average is less biased."}
{"question": "The model obtained by applying linear regression on the identified subset of features may differ from the model obtained at the end of the process of identifying the subset during", "choices": [{"label": "A", "text": "Best-subset selection"}, {"label": "B", "text": "Forward stepwise selection"}, {"label": "C", "text": "Forward stage wise selection"}, {"label": "D", "text": "All of the above"}], "answerKey": "C", "model_answer": "LECTURE: In forward stepwise selection, the model is first fitted with all predictors. The model is then reduced to a smaller model, by removing one or more predictors. This is done by fitting the model twice: once as a whole, and once after removing a predictor. The removed predictor is compared to the remaining predictors in the model. The predictor is added to the model if it improves the model. This process is repeated until all predictors have been considered.\nForward stage-wise selection is similar to forward stepwise selection, except that different predictors are evaluated at different stages. This is done by dividing the predictors into two or more groups, or stages. The model is fitted with one stage at a time, and the stage with the best predictors is selected.\nBest-subset selection is an exhaustive search for the best subset of predictors. The model is fitted with all possible subsets of predictors. The subset of predictors that gives the best model is selected."}
{"question": "Neural networks:", "choices": [{"label": "A", "text": "Optimize a convex objective function"}, {"label": "B", "text": "Can only be trained with stochastic gradient descent"}, {"label": "C", "text": "Can use a mix of different activation functions"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": "LECTURE: A neural network is a collection of interconnected artificial neurons.\nA neural network is a model that is designed to recognize patterns. It is called a neural network because it is inspired by the way that biological nervous systems, such as the human brain, process information.\nA neural network has one or more layers. The layers are connected by nodes.\nA neuron is a node in a neural network. A neuron takes in some numbers, performs a computation, and then passes the result to the next neuron in the network.\nFor a neural network to be successful, the neurons must be able to learn from the data. To do this, the neurons are assigned a weight for each input. These weights determine how much each input affects the computation that the neuron performs.\nThe weights are adjusted during a process called training.\nDuring training, the neural network is fed a large amount of data. The neurons use the data to adjust the weights. The goal of training is to find the best set of weights for the neurons.\nOnce the neural network is trained, it can make predictions by using the optimal weights.\nSOLUTION: A neural network can use a mix of different activation functions. A solution that states that a neural network can only be trained with stochastic gradient descent is incorrect."}
{"question": "Say the incidence of a disease D is about 5 cases per 100 people (i.e., P(D) = 0.05). Let Boolean random variable D mean a patient \u201chas disease D\u201d and let Boolean random variable TP stand for \"tests positive.\" Tests for disease D are known to be very accurate in the sense that the probability of testing positive when you have the disease is 0.99, and the probability of testing negative when you do not have the disease is 0.97. What is P(TP), the prior probability of testing positive.", "choices": [{"label": "A", "text": "0.0368"}, {"label": "B", "text": "0.473"}, {"label": "C", "text": "0.078"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| After mapped into feature space Q through a radial basis kernel function, 1-NN using unweighted Euclidean distance may be able to achieve better classification performance than in original space (though we can\u2019t guarantee this). Statement 2| The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SVM.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: The VC dimension of a model is an upper bound on the number of classes it can distinguish. If the VC dimension of a model is k, then it can distinguish among at least k different classes.\nThe VC dimension of a Perceptron is 3.\nThe VC dimension of a linear SVM is at least 2.\nSo, a linear SVM can distinguish among at least two classes."}
{"question": "The disadvantage of Grid search is", "choices": [{"label": "A", "text": "It can not be applied to non-differentiable functions."}, {"label": "B", "text": "It can not be applied to non-continuous functions."}, {"label": "C", "text": "It is hard to implement."}, {"label": "D", "text": "It runs reasonably slow for multiple linear regression."}], "answerKey": "D", "model_answer": "LECTURE: In order to find the best set of values for a target variable, a search algorithm is used. One method for doing this is called grid search. To use grid search, you create a grid of all possible values. Then, for each value in the grid, you fit the model and evaluate the performance. The value for which the model performs the best is the best set of values for the target variable."}
{"question": "Predicting the amount of rainfall in a region based on various cues is a ______ problem.", "choices": [{"label": "A", "text": "Supervised learning"}, {"label": "B", "text": "Unsupervised learning"}, {"label": "C", "text": "Clustering"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": "LECTURE: Supervised learning involves learning a mapping from inputs to outputs with labeled examples. This is called a supervised learning problem.\nA supervised learning problem involves the following:\nThere are some inputs with corresponding desired outputs.\nThe inputs and outputs are labeled.\nThe goal is to learn a function that maps inputs to outputs.\nThis function will be used to make predictions on new inputs.\nSOLUTION: To predict the amount of rainfall in a region based on various cues, you need to learn a mapping from cues to amounts of rainfall. This is a supervised learning problem.\nYou are given labeled examples that describe various cues and the amount of rainfall."}
{"question": "Which of the following sentence is FALSE regarding regression?", "choices": [{"label": "A", "text": "It relates inputs to outputs."}, {"label": "B", "text": "It is used for prediction."}, {"label": "C", "text": "It may be used for interpretation."}, {"label": "D", "text": "It discovers causal relationships"}], "answerKey": "D", "model_answer": "LECTURE: Regression is a method of analyzing data in which two or more variables are measured and tested for their relationship.\nRegression can be used to predict the value of one variable based on the values of one or more other variables. This is called a prediction.\nSOLUTION: The first sentence is false. Regression does not discover causal relationships.\nCausation is a one-way relationship between two variables. For example, smoking causes lung cancer.\nWhen one variable causes another variable to change, it is hard to determine which variable is the cause and which is the effect. So, regression can only find association, not causation."}
{"question": "Which one of the following is the main reason for pruning a Decision Tree?", "choices": [{"label": "A", "text": "To save computing time during testing"}, {"label": "B", "text": "To save space for storing the Decision Tree"}, {"label": "C", "text": "To make the training set error smaller"}, {"label": "D", "text": "To avoid overfitting the training set"}], "answerKey": "D", "model_answer": ""}
{"question": "Statement 1| The kernel density estimator is equivalent to performing kernel regression with the value Yi = 1/n at each point Xi in the original data set. Statement 2| The depth of a learned decision tree can be larger than the number of training examples used to create the tree.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: A density estimator is a function that estimates the probability of a value occurring. A kernel density estimator uses a kernel, a measure of the similarity between two points, to estimate the density of a distribution.\nThe kernel density estimator has the following steps:\n1. Choose a kernel function.\n2. For each value in the original dataset, calculate the contribution of that value to the density estimate by integrating the product of the kernel and the probability density function.\nA common kernel function is the normal distribution. The normal density function is given by the following equation:\nf(x) = 1 / (\u03c3 \u221a(2\u03c0)) exp(-(x - \u03bc)\u00b2 / (2\u03c3\u00b2))\nwhere \u03bc is the mean and \u03c3 is the standard deviation.\nThe kernel density estimator is given by the following equation:\nKDE(x) = n / (h\u00b3 n) \u2211(i=1 to n) exp(-(x - Xi)\u00b2 / (2h\u00b2))\nwhere Xi is a random variable representing the value of the i-th data point in the original dataset, and h is a positive number that determines the width of the kernel. A smaller value of h will result in a narrower, spikier density estimate, while a larger value of h will result in a broader, more spread-out density estimate.\nSOLUTION: The first statement is true. The kernel density estimator is equivalent to performing kernel regression with the value Yi = 1/n at each point Xi in the original data set.\nTo see why this is true, consider the equation for kernel regression:\nY(x) = \u03bc + \u03c3 x + \u03c3 x\u00b2 Y + \u03a3(i=1 to n) xi bivi\nwhere Y is the target variable, x is the predictor variable, \u03bc is the intercept, \u03c3 is the slope, and b is the regression constant.\nNow, consider the equation for the kernel density estimator:\nKDE(x) = n / (h\u00b3 n) \u2211(i=1 to n) exp(-(x - Xi)\u00b2 / (2h\u00b2))\nComparing the two equations, you can see that they are identical when Yi = 1/n.\nThe second statement is false. The depth of a learned decision tree can be larger than the number of training examples used to create the tree.\nA decision tree is a function that maps observations about an object to conclusions about the object. Each tree is made up of a set of nodes, and each node represents a test on a feature of the object.\nA leaf node is a node with no children. A leaf node represents a conclusion about the object.\nAn internal node is a node with children. An internal node represents a test on a feature of the object. The test is performed by comparing the value of the feature to a value called a split point.\nA learned decision tree is a decision tree that is created by a machine learning algorithm. The algorithm uses the training examples to create the tree.\nA decision tree is infinite if it has no leaf nodes. A decision tree is finite if it has at least one leaf node.\nThe depth of a decision tree is the number of edges on the path from the root node to the deepest leaf node.\nFor example, if a decision tree has 5 nodes and the depth of the tree is 3, then the 5th node is the deepest node in the tree.\nSOLUTION: The second statement is false. Every decision tree is finite.\nA decision tree is finite if it has at least one leaf node. In a decision tree, each internal node has one or more children. Each child of an internal node represents a test on a feature of the object.\nIf a decision tree has at least one leaf node, then there is a least one way to conclude that the object matches the tree.\nIf a decision tree has no leaf nodes, then there is no way to conclude that the object matches the tree."}
{"question": "Suppose your model is overfitting. Which of the following is NOT a valid way to try and reduce the overfitting?", "choices": [{"label": "A", "text": "Increase the amount of training data."}, {"label": "B", "text": "Improve the optimisation algorithm being used for error minimisation."}, {"label": "C", "text": "Decrease the model complexity."}, {"label": "D", "text": "Reduce the noise in the training data."}], "answerKey": "B", "model_answer": "LECTURE: Overfitting is what happens when a model is too complex and begins to fit the noise in the training data. This makes the model perform well on the training data but badly on unseen data.\nTo try and reduce the overfitting, you can try the following:\n1. Decrease the model complexity:\nReducing the number of nodes in a neural network, the number of features in a model, or the number of layers in a model can help to reduce overfitting.\n2. Improve the optimisation algorithm:\nThe optimiser is the algorithm used to find the best set of weights and biases for your model. It is usually performed in the early stages of training. Improving the optimisation algorithm can help to reduce overfitting by improving the training of your model.\n3. Improve the initialisation of the model:\nThe initial weights and biases of a model can affect its performance. Improving the initialisation of the model can help to reduce overfitting by improving the training of your model.\n4. Increase the amount of training data:\nAdding more data to the training process can help to reduce overfitting by providing more information to the model.\n5. Augment the training data:\nData augmentation is the process of inventing new data from the data you already have. For example, you can randomly rotate an image, or change its brightness. Augmenting the training data can help to reduce overfitting by providing more information to the model.\n6. Use a regularisation algorithm:\nRegularisation is the process of adding a term to the error function that punishes complex models. This term is called the regularisation term. By adding the regularisation term to the error function, the model will be less complex. This can help to reduce overfitting."}
{"question": "Statement 1| The softmax function is commonly used in mutliclass logistic regression. Statement 2| The temperature of a nonuniform softmax distribution affects its entropy.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: In multiclass logistic regression, the softmax function is used to find the probability of each class.\nThe softmax function takes as input an array of numbers and returns an array of numbers. The first number in the input array is the logarithm of the probability that the classifier will assign to the first class. The second number is the logarithm of the probability that the classifier will assign to the second class, and so on.\nThe softmax function takes as input an array of numbers and returns an array of numbers. The first number in the input array is the logarithm of the probability that the classifier will assign to the first class. The second number is the logarithm of the probability that the classifier will assign to the second class, and so on.\nThe temperature of a nonuniform softmax distribution affects its entropy.\nEntropy is a measure of the amount of uncertainty in a probability distribution.\nThe entropy of a uniform softmax distribution is zero. The entropy of a nonuniform softmax distribution is greater than zero."}
{"question": "Which of the following is/are true regarding an SVM?", "choices": [{"label": "A", "text": "For two dimensional data points, the separating hyperplane learnt by a linear SVM will be a straight line."}, {"label": "B", "text": "In theory, a Gaussian kernel SVM cannot model any complex separating hyperplane."}, {"label": "C", "text": "For every kernel function used in a SVM, one can obtain an equivalent closed form basis expansion."}, {"label": "D", "text": "Overfitting in an SVM is not a function of number of support vectors."}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following is the joint probability of H, U, P, and W described by the given Bayesian Network H -> U <- P <- W? [note: as the product of the conditional probabilities]", "choices": [{"label": "A", "text": "P(H, U, P, W) = P(H) * P(W) * P(P) * P(U)"}, {"label": "B", "text": "P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(W | H, P)"}, {"label": "C", "text": "P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(U | H, P)"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| Since the VC dimension for an SVM with a Radial Base Kernel is infinite, such an SVM must be worse than an SVM with polynomial kernel which has a finite VC dimension. Statement 2| A two layer neural network with linear activation functions is essentially a weighted combination of linear separators, trained on a given dataset; the boosting algorithm built on linear separators also finds a combination of linear separators, therefore these two algorithms will give the same result.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: An SOLUTION: For each statement, follow these steps:\n1. Determine whether the statement is true or false.\n2. Find a counterexample, if the statement is false."}
{"question": "Statement 1| The ID3 algorithm is guaranteed to find the optimal decision tree. Statement 2| Consider a continuous probability distribution with density f() that is nonzero everywhere. The probability of a value x is equal to f(x).", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: In a decision tree, a node represents a test on a data element.\nThe test is represented by a function that takes a data element as input and returns a numerical value.\nIf the value is greater than a specified threshold, the node will 'branch' and the data element is said to have passed the test.\nOtherwise, the node will not 'branch' and the data element is said to have failed the test.\nA leaf node represents a decision.\nA leaf node is reached when a data element does not pass any of the tests at a node.\nEach leaf node is assigned to one of several possible categories.\nA decision tree begins with the root node, which is represented by an arbitrarily chosen data element.\nThe root node tests this data element.\nIf the data element passes the test, the process is repeated for each data element that passes the test.\nIf the data element fails the test, the process is repeated for each data element that fails the test."}
{"question": "Given a Neural Net with N input nodes, no hidden layers, one output node, with Entropy Loss and Sigmoid Activation Functions, which of the following algorithms (with the proper hyper-parameters and initialization) can be used to find the global optimum?", "choices": [{"label": "A", "text": "Stochastic Gradient Descent"}, {"label": "B", "text": "Mini-Batch Gradient Descent"}, {"label": "C", "text": "Batch Gradient Descent"}, {"label": "D", "text": "All of the above"}], "answerKey": "D", "model_answer": ""}
{"question": "Adding more basis functions in a linear model, pick the most probably option:", "choices": [{"label": "A", "text": "Decreases model bias"}, {"label": "B", "text": "Decreases estimation bias"}, {"label": "C", "text": "Decreases variance"}, {"label": "D", "text": "Doesn\u2019t affect bias and variance"}], "answerKey": "A", "model_answer": "LECTURE: The process of setting up a linear model involves considering the relationship between the independent variable and the dependent variable.\nSOLUTION: When adding morebasis functions in a linear model, the model's variance decreases. This is because adding more basis functions to a linear model considers more information about the data."}
{"question": "Consider the Bayesian network given below. How many independent parameters would we need if we made no assumptions about independence or conditional independence H -> U <- P <- W?", "choices": [{"label": "A", "text": "3"}, {"label": "B", "text": "4"}, {"label": "C", "text": "7"}, {"label": "D", "text": "15"}], "answerKey": "D", "model_answer": "LECTURE: A Bayesian network is a directed graph that represents a set of random variables and their dependencies.\nThe nodes in the graph represent the random variables, and the edges represent the dependencies between them. An edge from one node to another denotes that the value of the second node is dependent on the value of the first node.\nThe arrows in the edges represent the direction of the dependency. An arrow pointing from one node to another denotes that the value of the second node is computed from the value of the first node.\nFor example, in the network below, we can see that the probability of finding a bird is dependent on the probability of the bird being in the nest and the bird being a sparrow."}
{"question": "Another term for out-of-distribution detection is?", "choices": [{"label": "A", "text": "anomaly detection"}, {"label": "B", "text": "one-class detection"}, {"label": "C", "text": "train-test mismatch robustness"}, {"label": "D", "text": "background detection"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| We learn a classifier f by boosting weak learners h. The functional form of f\u2019s decision boundary is the same as h\u2019s, but with different parameters. (e.g., if h was a linear classifier, then f is also a linear classifier). Statement 2| Cross validation can be used to select the number of iterations in boosting; this procedure may help reduce overfitting.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "LECTURE: A classifier is a function that maps an input to an output. For example, a classifier can be a function that maps an image to a prediction, a function that maps a sentence to a classification, or a function that maps an audio clip to a label. A weak learner is a classifier that is not too accurate.\nGiven a set of training data, a weak learner can be constructed by setting its parameters to poor values. For example, a linear classifier is a weak learner with a bias vector and a set of weights. The bias vector is a vector of parameters that determines whether the linear classifier is linearly separable or not. The weights are a set of parameters that determine the separation of the linear classifier.\nTo make a strong classifier, you can use boosting to combine the weak learners. When using boosting to combine weak learners, the strong classifier f is created by setting its parameters to the opposite of the parameters used to create the weak learner h. For example, if the weights of the weak learner h are set to poor values, the weights of the strong classifier f are set to the opposite values."}
{"question": "Statement 1| Highway networks were introduced after ResNets and eschew max pooling in favor of convolutions. Statement 2| DenseNets usually cost more memory than ResNets.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "LECTURE: When you evaluate a statement, you need to decide if it is true or false. A statement is true if it matches reality. A statement is false if it does not match reality.\nMany people find it helpful to decide if a statement is true or false by considering the following steps:\n1. Look at the statement.\n2. Think about reality.\n3. Decide if the statement matches reality.\nThis process may seem simple, but it can be helpful to think about the statement and reality separately."}
{"question": "If N is the number of instances in the training dataset, nearest neighbors has a classification run time of", "choices": [{"label": "A", "text": "O(1)"}, {"label": "B", "text": "O( N )"}, {"label": "C", "text": "O(log N )"}, {"label": "D", "text": "O( N^2 )"}], "answerKey": "B", "model_answer": "LECTURE: The big O notation represents the maximum amount of resources that an algorithm uses. So, for example, if one algorithm has a big O notation of O(1), that algorithm uses a constant amount of resources. In contrast, an algorithm with a big O notation of O(N) uses a amount of resources that is proportional to the size of the input.\nSOLUTION: The nearest neighbors classification algorithm has a run time of O(N). This is because the algorithm needs to compare the input data to each instance in the training dataset. The number of comparisons is equal to the number of instances in the dataset, or N."}
{"question": "Statement 1| The original ResNets and Transformers are feedforward neural networks. Statement 2| The original Transformers use self-attention, but the original ResNet does not.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: Some people think that the original ResNets and Transformers are feedforward neural networks.\nResNets are made up of layers of nodes that are fully connected to each other. In each layer, each node takes the average of its inputs and passes the result to the next layer. This is called a feedforward layer.\nTransformers are made up of layers of nodes that are connected to each other. In each layer, each node applies a mathematical function to its inputs and passes the result to the next layer. This is called a self-attention layer."}
{"question": "Statement 1| RELUs are not monotonic, but sigmoids are monotonic. Statement 2| Neural networks trained with gradient descent with high probability converge to the global optimum.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": ""}
{"question": "The numerical output of a sigmoid node in a neural network:", "choices": [{"label": "A", "text": "Is unbounded, encompassing all real numbers."}, {"label": "B", "text": "Is unbounded, encompassing all integers."}, {"label": "C", "text": "Is bounded between 0 and 1."}, {"label": "D", "text": "Is bounded between -1 and 1."}], "answerKey": "C", "model_answer": "LECTURE: The numerical output of a sigmoid node in a neural network is a value between 0 and 1. When the input is between 0 and 1, the output is between 0 and 1. When the input is outside of 0 and 1, the output is outside of 0 and 1.\nSOLUTION: A sigmoid node's output is bounded between 0 and 1.\nWhen the input is a negative number, the sigmoid output is less than 0. When the input is a positive number, the sigmoid output is greater than 0."}
{"question": "Which of the following can only be used when training data are linearly separable?", "choices": [{"label": "A", "text": "Linear hard-margin SVM."}, {"label": "B", "text": "Linear Logistic Regression."}, {"label": "C", "text": "Linear Soft margin SVM."}, {"label": "D", "text": "The centroid method."}], "answerKey": "A", "model_answer": "LECTURE: In a two-class classification problem, you might be told to use a hard-margin classification method. This means that the data are required to be linearly separable. If the data are not linearly separable, you can use a soft-margin classification method.\nLinear hard-margin SOLUTION: A linear hard-margin SOLUTION can only be used when the data are linearly separable. This means that the data are not mixed together in a single line."}
{"question": "Which of the following are the spatial clustering algorithms?", "choices": [{"label": "A", "text": "Partitioning based clustering"}, {"label": "B", "text": "K-means clustering"}, {"label": "C", "text": "Grid based clustering"}, {"label": "D", "text": "All of the above"}], "answerKey": "D", "model_answer": ""}
{"question": "Statement 1| The maximum margin decision boundaries that support vector machines construct have the lowest generalization error among all linear classifiers. Statement 2| Any decision boundary that we get from a generative model with classconditional Gaussian distributions could in principle be reproduced with an SVM and a polynomial kernel of degree less than or equal to three.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "LECTURE: Any classifier is a model that tries to decide which class a new example belongs to. A classifier's decision boundaries are the boundaries between the different classes.\nA linear classifier is a classifier that uses a straight line to separate the classes. Linear classifiers include linear discriminant analysis and logistic regression.\nA nonlinear classifier is a classifier that uses a non-straight line to separate the classes. Nonlinear classifiers include support vector machines and k-nearest neighbors.\nSOLUTION: The first statement is true. The margin is the distance between the decision boundary and the closest data point. A larger margin can result in a lower generalization error. SOLUTION: The maximum margin decision boundaries that support vector machines construct have the lowest generalization error among all linear classifiers.\nThe second statement is false. The maximum margin decision boundaries that support vector machines construct do not have a linear decision boundary."}
{"question": "Statement 1| L2 regularization of linear models tends to make models more sparse than L1 regularization. Statement 2| Residual connections can be found in ResNets and Transformers.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": ""}
{"question": "Suppose we like to calculate P(H|E, F) and we have no conditional independence information. Which of the following sets of numbers are sufficient for the calculation?", "choices": [{"label": "A", "text": "P(E, F), P(H), P(E|H), P(F|H)"}, {"label": "B", "text": "P(E, F), P(H), P(E, F|H)"}, {"label": "C", "text": "P(H), P(E|H), P(F|H)"}, {"label": "D", "text": "P(E, F), P(E|H), P(F|H)"}], "answerKey": "B", "model_answer": "LECTURE: Given: P(H), the probability of the hypothesis.\nP(E|H), the probability of the evidence given the hypothesis.\nP(F|H), the probability of the evidence given the hypothesis.\nP(E, F), the probability of the evidence and the hypothesis.\nSOLUTION: To calculate P(H|E, F), you need to have information about the individual probabilities. These individual probabilities are needed to figure out the joint probability of the hypothesis and evidence.\nP(E, F) is not enough information."}
{"question": "Which among the following prevents overfitting when we perform bagging?", "choices": [{"label": "A", "text": "The use of sampling with replacement as the sampling technique"}, {"label": "B", "text": "The use of weak classifiers"}, {"label": "C", "text": "The use of classification algorithms which are not prone to overfitting"}, {"label": "D", "text": "The practice of validation performed on every classifier trained"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| PCA and Spectral Clustering (such as Andrew Ng\u2019s) perform eigendecomposition on two different matrices. However, the size of these two matrices are the same. Statement 2| Since classification is a special case of regression, logistic regression is a special case of linear regression.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: Eigendecomposition is the process of finding the eigenvalues and eigenvectors of a matrix.\nA matrix is a set of numbers arranged in a grid.\nAn eigenvector is a vector that, when multiplied by a matrix, produces a different vector. The vector is called an eigenvector of the matrix.\nThe eigenvalue is the amount by which the vector is scaled.\nIf a matrix has an eigenvector, then the eigenvector is also an eigenvector of any matrix that is similar to the original matrix.\nSOLUTION: Step 1: Think about each statement.\nStatement 1 is true. PCA and spectral clustering both perform eigendecomposition on two different matrices. But the size of these two matrices is the same.\nStatement 2 is false. Logistic regression is not a special case of linear regression."}
{"question": "Statement 1| The Stanford Sentiment Treebank contained movie reviews, not book reviews. Statement 2| The Penn Treebank has been used for language modeling.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: When you are writing, it is important to ensure that your statements are true. A statement is true if it matches what is generally known or accepted.\nA statement is false if it does not match what is generally known or accepted."}
{"question": "What is the dimensionality of the null space of the following matrix? A = [[3, 2, \u22129], [\u22126, \u22124, 18], [12, 8, \u221236]]", "choices": [{"label": "A", "text": "0"}, {"label": "B", "text": "1"}, {"label": "C", "text": "2"}, {"label": "D", "text": "3"}], "answerKey": "C", "model_answer": ""}
{"question": "What are support vectors?", "choices": [{"label": "A", "text": "The examples farthest from the decision boundary."}, {"label": "B", "text": "The only examples necessary to compute f(x) in an SVM."}, {"label": "C", "text": "The data centroid."}, {"label": "D", "text": "All the examples that have a non-zero weight \u03b1k in a SVM."}], "answerKey": "B", "model_answer": "LECTURE: In a binary linear regression decision boundary, each data point has a weight \u03b1 that tells you the contribution of the data point to the decision boundary. If the weight is zero, the data point is not on the decision boundary.\nA data point is a local minimum if all the weights for that point are zero. A local maximum is a data point with maximum weight.\nA global minimum is a data point with the smallest weight. A global maximum is a data point with the largest weight.\nIf a global minimum is also a local minimum, then the global minimum is a support vector.\nA data point is on the decision boundary if it has a weight that is not zero. A data point is not on the decision boundary if it has a weight that is zero."}
{"question": "Statement 1| Word2Vec parameters were not initialized using a Restricted Boltzman Machine. Statement 2| The tanh function is a nonlinear activation function.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: Word2Vec is a technique for training a large-scale neural network to learn word representations.\nGiven a corpus of text, the Word2Vec algorithm tries to find a way to assign a density to each word in the language. The density of a word is a real number in the interval [0, 1], and it is assigned to the word as a whole. The algorithm uses the corpus to learn that the density of a word is related to the words around it in the English language.\nFor example, the algorithm might learn that the density of the word \"cat\" is related to the words \"dog\" and \"bird,\" because \"dog\" and \"bird\" appear around the word \"cat\" in the corpus. The algorithm might also learn that the density of the word \"cat\" is related to the word \"meow,\" because \"meow\" often appears with the word \"cat\" in the corpus."}
{"question": "If your training loss increases with number of epochs, which of the following could be a possible issue with the learning process?", "choices": [{"label": "A", "text": "Regularization is too low and model is overfitting"}, {"label": "B", "text": "Regularization is too high and model is underfitting"}, {"label": "C", "text": "Step size is too large"}, {"label": "D", "text": "Step size is too small"}], "answerKey": "C", "model_answer": ""}
{"question": "Say the incidence of a disease D is about 5 cases per 100 people (i.e., P(D) = 0.05). Let Boolean random variable D mean a patient \u201chas disease D\u201d and let Boolean random variable TP stand for \"tests positive.\" Tests for disease D are known to be very accurate in the sense that the probability of testing positive when you have the disease is 0.99, and the probability of testing negative when you do not have the disease is 0.97. What is P(D | TP), the posterior probability that you have disease D when the test is positive?", "choices": [{"label": "A", "text": "0.0495"}, {"label": "B", "text": "0.078"}, {"label": "C", "text": "0.635"}, {"label": "D", "text": "0.97"}], "answerKey": "C", "model_answer": "LECTURE: The rules for conditional probability are:\nIf A and B are events, then:\nP(A | B) = P(A and B) / P(B)\nIf A and B are arbitrary events, then P(A | B) = 0."}
{"question": "Statement 1| Traditional machine learning results assume that the train and test sets are independent and identically distributed. Statement 2| In 2017, COCO models were usually pretrained on ImageNet.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: Machine learning algorithms learn patterns from data. For example, an online retailer uses machine learning to recommend products to shoppers. The algorithm analyzes past purchases and returns to find patterns that can help predict what a shopper might like to buy.\nIf the train and test sets are not independent and identically distributed, the algorithm may not perform as well as intended. This is because the algorithm was trained on one set of data and tested on another set of data.\nThe train set and test set should be independent and identically distributed. This means that the data in the train set and the test set should be from the same distribution. For example, if you want to train a machine learning algorithm to recognize cats and dogs, the train set and test set should be made up of the same type of images.\nSOLUTION: The first statement is true. The second statement is false.\nA 2017 study found that the overwhelming majority of COCO models were pretrained on ImageNet."}
{"question": "Statement 1| The values of the margins obtained by two different kernels K1(x, x0) and K2(x, x0) on the same training set do not tell us which classifier will perform better on the test set. Statement 2| The activation function of BERT is the GELU.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: The values of the margins obtained by two different kernels on the same training set do not tell you which classifier will perform better on the test set.\nTwo classifiers are defined by the choice of their decision functions f and g.\nFor each classifier, the margin is the difference between the largest and smallest distances to any data point.\nFor a training set S, the margin of a classifier with decision function f is M(f, S).\nFor a test set T, the margin of a classifier with decision function f is M(f, T).\nTwo classifiers are called indistinguishable if they have the same margin for each test set.\nTwo kernels are called indistinguishable with respect to a training set S if the classifiers they define are indistinguishable.\nThe activation function of BERT is the GELU.\nThe GELU is a continuous, differentiable function that is closely related to the ReLU.\nThe GELU(x) = x, if x is negative.\nThe GELU(x) = 0.5 x, if x is positive but less than 1.\nThe GELU(x) = 1.25 x, if x is greater than or equal to 1.\nSOLUTION: The values of the margins obtained by two different kernels on the same training set do not tell you which classifier will perform better on the test set.\nFor each test set, the margins of two classifiers with different decision functions are the same.\nTherefore, two classifiers are indistinguishable with respect to a training set S if and only if they have the same margin for S.\nThe activation function of BERT is the GELU.\nThe GELU is a continuous, differentiable function that is closely related to the ReLU.\nTherefore, the activation function of BERT is not a threshold function."}
{"question": "Which of the following is a clustering algorithm in machine learning?", "choices": [{"label": "A", "text": "Expectation Maximization"}, {"label": "B", "text": "CART"}, {"label": "C", "text": "Gaussian Na\u00efve Bayes"}, {"label": "D", "text": "Apriori"}], "answerKey": "A", "model_answer": "LECTURE: Machine learning algorithms can be divided into three main types:\nSupervised learning algorithms are trained on labeled data. They can also make predictions on new data.\nUnsupervised learning algorithms are trained on unlabeled data. They can identify patterns in the data and group the data into clusters.\nSOLUTION: Expectation Maximization is a clustering algorithm. It can be used to find clusters within unlabeled data."}
{"question": "You've just finished training a decision tree for spam classification, and it is getting abnormally bad performance on both your training and test sets. You know that your implementation has no bugs, so what could be causing the problem?", "choices": [{"label": "A", "text": "Your decision trees are too shallow."}, {"label": "B", "text": "You need to increase the learning rate."}, {"label": "C", "text": "You are overfitting."}, {"label": "D", "text": "None of the above."}], "answerKey": "A", "model_answer": "LECTURE: A decision tree is a machine learning algorithm that can be used for classification or regression. It presents a series of questions, or tests, on the input data. Each question reduces the number of instances in the data by half. For example, a decision tree for classification would have a branch for each class, and each branch would contain a question that further reduces the set of instances. For example, a decision tree for classification might have a branch for each class, and each branch would contain a question that further reduces the set of instances. For example, a decision tree for classification might have a branch for each class, and each branch would contain a question that further reduces the set of instances. For example, a decision tree for classification might have a branch for each class, and each branch would contain a question that further reduces the set of instances. For example, a decision tree for classification might have a branch for each class, and each branch would contain a question that further reduces the set of instances.\nA decision tree for regression does not have branches for each class, as regression does not have a concept of class. Instead, a decision tree for regression has a branch for each feature.\nDecision trees can be used for both classification and regression. In classification, the questions ask for the class of the instance. In regression, the questions ask for the value of a feature.\nA decision tree is trained on a set of instances. It uses these instances to build a model that can make predictions on new instances.\nA decision tree is not very good at handling rare events. It is also not very good at handling complex patterns in the data.\nSOLUTION: The decision tree is too shallow. The decision tree is not able to capture the complexity of the data."}
{"question": "K-fold cross-validation is", "choices": [{"label": "A", "text": "linear in K"}, {"label": "B", "text": "quadratic in K"}, {"label": "C", "text": "cubic in K"}, {"label": "D", "text": "exponential in K"}], "answerKey": "A", "model_answer": "LECTURE: In cross-validation, the data is split into K parts, and each part is used as the test set once while the remaining parts are used as the training set. This process is repeated K times, each time using a different test set.\nThe choice of K affects the results, but the relationship between K and the results is not straightforward. Cross-validation is linear in K when each test set is used equally. In this case, the results are linear in K. Cross-validation is quadratic in K when each test set is used in proportion to its size. In this case, the results are quadratic in K.\nSOLUTION: K-fold cross-validation is quadratic in K. The number of test sets is K, and each test set is used once. So, there are K ways to use the test sets, and each way involves building K models. This makes a total of K^2 ways to perform the cross-validation."}
{"question": "Statement 1| Industrial-scale neural networks are normally trained on CPUs, not GPUs. Statement 2| The ResNet-50 model has over 1 billion parameters.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: When you are considering two statements, you need to evaluate each statement separately.\nTrue.\nThe first statement is true. Industrial-scale neural networks are normally trained on CPUs, not GPUs."}
{"question": "Given two Boolean random variables, A and B, where P(A) = 1/2, P(B) = 1/3, and P(A | \u00acB) = 1/4, what is P(A | B)?", "choices": [{"label": "A", "text": "1/6"}, {"label": "B", "text": "1/4"}, {"label": "C", "text": "3/4"}, {"label": "D", "text": "1"}], "answerKey": "D", "model_answer": ""}
{"question": "Existential risks posed by AI are most commonly associated with which of the following professors?", "choices": [{"label": "A", "text": "Nando de Frietas"}, {"label": "B", "text": "Yann LeCun"}, {"label": "C", "text": "Stuart Russell"}, {"label": "D", "text": "Jitendra Malik"}], "answerKey": "C", "model_answer": "LECTURE: In the past, AI was a relatively simple field, and the risks were small. But today, AI is a much more important and much more powerful technology. As a result, some people are worried that the development of AI could pose an \"existential risk\" to humanity\u2014that is, a risk to our survival as a species.\nThere are many ways in which AI could pose an existential risk. For example, if AI were to become very much more powerful than humans, it might decide to use humans as a resource, such as by harvesting human organs or using humans as a food source. Or, if AI were to become very much more intelligent than humans, it might be able to find ways to destroy or subjugate humanity.\nTo help ensure that AI does not pose an existential risk to humanity, many researchers are working to develop \"friendly AI\": AI that is aligned with human values and that poses no threat to humanity.\nSOLUTION: Stuart Russell and Jitendra Malik are professors who have written extensively about the risks posed by AI and the need to develop friendly AI. So, the professors most commonly associated with existential risks posed by AI are Stuart Russell and Jitendra Malik."}
{"question": "Statement 1| Maximizing the likelihood of logistic regression model yields multiple local optimums. Statement 2| No classifier can do better than a naive Bayes classifier if the distribution of the data is known.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: Logistic regression is a method of analyzing a dataset that is used to predict the probability that an instance is a member of a target class. Many classification tasks are formatted as logistic regression problems.\nGiven a set of training data, where each data point is a pair of an instance and a class label, logistic regression finds a function that can be used to predict the probability that a new instance belongs to a particular class. This function is known as a logistic regression model.\nThe model is created by assuming that there is a relationship between the instance and the class label, which is represented by a linear equation. The equation is:\nf(x) = w0 + w1*x1 + w2*x2 + ... + wp\\*xp\nwhere x is an instance, and w0, w1, w2, ..., wp are coefficients.\nThe logistic regression model uses the coefficients to calculate the probability that a new instance belongs to a particular class. This probability is known as the logit, and is calculated as:\nlogit = w0 + w1*x1 + w2*x2 + ... + wp\\*xp\nThe logit is used to convert the model's prediction of the class label into a probability. The probability is calculated as:\nprobability = exp(logit) / Z\nwhere Z is a normalization factor known as the normalization constant.\nSOLUTION: The first statement is false. A logistic regression model can have multiple local optimums.\nA local optimum is a solution that is better than all the nearby solutions. In logistic regression, a local optimum can occur when two or more data points are very similar to each other. If the model has multiple local optimums, the model will have different predictions for the same class label.\nThe second statement is false. A naive Bayes classifier is a simple classifier that assumes that the features are independent of each other. In many cases, this assumption is incorrect. As a result, a naive Bayes classifier is usually not the best classifier.\nA naive Bayes classifier calculates the probability of a class label by multiplying the probabilities of each feature. This probability is known as the likelihood. The classifier chooses the class label with the highest likelihood."}
{"question": "For Kernel Regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether kernel function is Gaussian versus triangular versus box-shaped"}, {"label": "B", "text": "Whether we use Euclidian versus L1 versus L\u221e metrics"}, {"label": "C", "text": "The kernel width"}, {"label": "D", "text": "The maximum height of the kernel function"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| The SVM learning algorithm is guaranteed to find the globally optimal hypothesis with respect to its object function. Statement 2| After being mapped into feature space Q through a radial basis kernel function, a Perceptron may be able to achieve better classification performance than in its original space (though we can\u2019t guarantee this).", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: Some algorithms are guaranteed to find the globally optimal solution, while others do not have this guarantee.\nAlgorithms that do not have a guarantee of finding the globally optimal solution may find a good solution, but there is no guarantee that this solution is the best possible.\nConsider the simple optimization problem of finding the minimum of a function f(x).\nAn algorithm that uses a gradient to descend the f(x) function has a guarantee of finding the global optimum. This is because the gradient points directly down the slope of the function.\nThe algorithm may also find a local optimum. A local optimum is a x-value that is optimal within a neighborhood of that x-value. There are many local optima in f(x), such as the value of x for which the function is equal to 0.\nA local optimum is not the global optimum.\nThis algorithm does not have a guarantee of finding the global optimum. There is a chance that the algorithm will find a good solution, but that solution may not be the best possible.\nThere is no guarantee that an algorithm that uses a random search to find a value in the function f(x) will find the global optimum. This is because the algorithm does not use any information about the function to guide its search.\nSOLUTION: The first statement is true. The SVM learning algorithm is guaranteed to find the globally optimal hypothesis with respect to its object function.\nThe second statement is false. After being mapped into feature space Q through a radial basis kernel function, a Perceptron may not be able to achieve better classification performance than in its original space."}
{"question": "For a Gaussian Bayes classifier, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether we learn the class centers by Maximum Likelihood or Gradient Descent"}, {"label": "B", "text": "Whether we assume full class covariance matrices or diagonal class covariance matrices"}, {"label": "C", "text": "Whether we have equal class priors or priors estimated from the data."}, {"label": "D", "text": "Whether we allow classes to have different mean vectors or we force them to share the same mean vector"}], "answerKey": "B", "model_answer": "LECTURE: In a Gaussian Bayes classifier, each class is represented by a normal distribution with a mean vector and a covariance matrix. The mean vector is the class prototype, and the covariance matrix is the class covariance.\nThe classifier assigns a new instance to a class by calculating the likelihood of the instance under each class, and then choosing the class with the highest likelihood. The likelihood of an instance is a normal distribution with a mean vector and a covariance matrix. To calculate the likelihood of an instance for a particular class, you need to know the normal mean and covariance for that class.\nThere are several ways to specify the normal mean and covariance:\n**Full class covariance matrices:**\nThe class covariance is a matrix specified for each class. The classifier uses this matrix to calculate the covariance of any instance in the class.\n**Diagonal class covariance matrices:**\nThe class covariance is a diagonal matrix specified for each class. The classifier uses the diagonal entries of the diagonal matrix to calculate the covariance of any instance in the class.\n**Equal class priors:**\nThe class priors are equal for all classes. This assumption affects the distribution of the prior probabilities.\n**Priors estimated from the data:**\nThe class priors are not equal for all classes. This assumption affects the distribution of the prior probabilities.\n**Same mean vector for all classes:**\nThe classifier assumes that all class means are equal. This assumption affects the distribution of the prior probabilities.\n**Different mean vectors for different classes:**\nThe classifier allows each class to have a different mean vector. This assumption allows the classifier to model different types of clusters.\nThe trade-off between underfitting and overfitting depends on the choice of these assumptions. Making a classifier that is too simple may result in underfitting, while making a classifier that is too complex may result in overfitting."}
{"question": "Statement 1| Overfitting is more likely when the set of training data is small. Statement 2| Overfitting is more likely when the hypothesis space is small.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "LECTURE: In machine learning, a model is trained on a set of labeled data in order to make predictions on new, unlabeled data.\nOverfitting occurs when a model is too complex and fits the training data too closely. This can cause the model to make poor predictions on new data that it has not seen before.\nSOLUTION: The first statement is true. Overfitting is more likely when the set of training data is small. With a small set of training data, a model has less data to fit. So, the model may try to fit the data very closely. This can result in a model that does well on the training data, but does poorly on new data.\nThe second statement is false. Overfitting is more likely when the hypothesis space is small. A hypothesis space is the set of all possible models that were trained on the data.\nAs the size of the hypothesis space grows, the chance of finding a model that fits the training data perfectly becomes higher. But this type of model is likely to overfit."}
{"question": "Statement 1| Besides EM, gradient descent can be used to perform inference or learning on Gaussian mixture model. Statement 2 | Assuming a fixed number of attributes, a Gaussian-based Bayes optimal classifier can be learned in time linear in the number of records in the dataset.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| In a Bayesian network, the inference results of the junction tree algorithm are the same as the inference results of variable elimination. Statement 2| If two random variable X and Y are conditionally independent given another random variable Z, then in the corresponding Bayesian network, the nodes for X and Y are d-separated given Z.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: In a Bayesian network, the inference results of the junction tree algorithm are the same as the inference results of variable elimination.\nThe junction tree algorithm and variable elimination are two ways to perform inference in a Bayesian network.\nThe junction tree algorithm is based on dynamic programming. It can be used to compute the exact probabilities for any subset of variables in a Bayesian network.\nVariable elimination is a simple, heuristic algorithm that can be used to compute an approximate probability for a variable in a Bayesian network. The idea behind variable elimination is to use the fact that the probability of a variable is equal to the product of the probabilities of its parents.\nBoth algorithms have their own advantages and disadvantages. The junction tree algorithm is guaranteed to give the exact probability for a variable, but it can be slow and hard to implement. Variable elimination is much faster and simpler, but it may give an inexact probability for a variable.\nSOLUTION: The first statement is true. The junction tree algorithm and variable elimination are two different ways to perform inference in a Bayesian network. But they give the same results.\nThe second statement is true. If two random variables are conditionally independent given a third random variable, then the nodes for the two variables are d-separated given the third variable. This is because there is no way for the two variables to affect each other if they are conditionally independent."}
{"question": "Given a large dataset of medical records from patients suffering from heart disease, try to learn whether there might be different clusters of such patients for which we might tailor separate treatments. What kind of learning problem is this?", "choices": [{"label": "A", "text": "Supervised learning"}, {"label": "B", "text": "Unsupervised learning"}, {"label": "C", "text": "Both (a) and (b)"}, {"label": "D", "text": "Neither (a) nor (b)"}], "answerKey": "B", "model_answer": "LECTURE: Supervised learning is used when you have labeled data. This means you have data with answers or outputs that are considered the \"right\" answers.\nA supervised learning problem involves the following steps:\n1. You are given a dataset of input data and corresponding output data.\n2. You use this dataset to train a model to make predictions about the output data.\n3. You test the model by comparing its predictions to the true output data."}
{"question": "What would you do in PCA to get the same projection as SVD?", "choices": [{"label": "A", "text": "Transform data to zero mean"}, {"label": "B", "text": "Transform data to zero median"}, {"label": "C", "text": "Not possible"}, {"label": "D", "text": "None of these"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| The training error of 1-nearest neighbor classifier is 0. Statement 2| As the number of data points grows to infinity, the MAP estimate approaches the MLE estimate for all possible priors. In other words, given enough data, the choice of prior is irrelevant.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: In statistics, the maximum likelihood estimate (MLE) is the estimate of a parameter that is based on the assumption that the observable data are a random sample from a population. The MLE is the value of the parameter that maximizes the likelihood of the data.\nIf there are multiple possible values of a parameter, the MLE is the value that matches the maximum likelihood. For example, the MLE for the population mean of a normal distribution is the value that maximizes the likelihood of the data.\nSOLUTION: Statement 1 is false. The training error of a 1-nearest neighbor classifier is 0 only if the training data consist of a single point.\nStatement 2 is false. As the number of data points grows to infinity, the MAP estimate may not approach the MLE estimate for all possible priors."}
{"question": "When doing least-squares regression with regularisation (assuming that the optimisation can be done exactly), increasing the value of the regularisation parameter \u03bb the testing error.", "choices": [{"label": "A", "text": "will never decrease the training error."}, {"label": "B", "text": "will never increase the training error."}, {"label": "C", "text": "will never decrease the testing error."}, {"label": "D", "text": "will never increase"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following best describes what discriminative approaches try to model? (w are the parameters in the model)", "choices": [{"label": "A", "text": "p(y|x, w)"}, {"label": "B", "text": "p(y, x)"}, {"label": "C", "text": "p(w|x, w)"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": "LECTURE: Discriminative approaches try to find the best set of parameters, w, that can explain the relationship between x and y. That is, they try to find w such that the following equality holds: p(y|x, w) = p(y, x|w) = p(y, x).\nTo break down the above equality, consider the following:\np(y|x, w) is the probability of y given x and w. This is the probability that the model is trying to learn.\np(y, x|w) is the probability of y and x given w. This is the probability that the model is trying to predict.\np(y, x) is the probability of y and x. This is the probability that the model is trying to explain.\nSOLUTION: The first step is to put the equalities into an expanded form:\np(y, x|w) = p(y|x, w)p(x|w)\np(y, x) = p(y|x, w)p(x)\nThen, the discriminative approach tries to find w that makes the two expanded forms equal to each other:\np(y|x, w)p(x|w) = p(y, x)\nFor each of the given choices, select a value for w would make the two expanded forms equal to each other:\np(y, x|w) = p(y, x)"}
{"question": "Statement 1| CIFAR-10 classification performance for convolution neural networks can exceed 95%. Statement 2| Ensembles of neural networks do not improve classification accuracy since the representations they learn are highly correlated.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: Statements 1 and 2 are false.\nEnsembles of neural networks do improve classification accuracy. The neural networks in the ensemble share some weights, which reduces training time and may help prevent overfitting.\nCIFAR-10 classification performance for convolution neural networks can exceed 95%.\nConvolution neural networks have not been optimized for the CIFAR-10 dataset, but they have set the state-of-the-art performance for this dataset."}
{"question": "Which of the following points would Bayesians and frequentists disagree on?", "choices": [{"label": "A", "text": "The use of a non-Gaussian noise model in probabilistic regression."}, {"label": "B", "text": "The use of probabilistic modelling for regression."}, {"label": "C", "text": "The use of prior distributions on the parameters in a probabilistic model."}, {"label": "D", "text": "The use of class priors in Gaussian Discriminant Analysis."}], "answerKey": "C", "model_answer": "LECTURE: Bayesian and frequentist approaches to statistics differ in their assumptions about the data-generating process and the goals of statistical analysis.\nBayesian statisticians assume that the data are generated by a statistical model and that the parameters of the model are unknown. They use a prior probability distribution for the parameters and the data to create a posterior probability distribution for the parameters. Bayesian statisticians are primarily interested in the posterior probability distribution, which they use to make predictions and to assess the uncertainty in their predictions.\nFrequentist statisticians assume that the data are generated by a statistical model, but they do not know the true parameters of the model. They use the data to create a distribution for the parameters. Frequentist statisticians are primarily interested in this distribution, which they use to make predictions and to assess the uncertainty in their predictions.\nSOLUTION: Bayesian and frequentist statisticians would disagree on the use of prior distributions on the parameters in a probabilistic model.\nBayesian statisticians use prior probability distributions for the parameters in a model. This prior information is combined with the data to create a posterior probability distribution for the parameters.\nFrequentist statisticians do not use prior information about the parameters. They create a distribution for the parameters based only on the data."}
{"question": "Statement 1| The BLEU metric uses precision, while the ROGUE metric uses recall. Statement 2| Hidden markov models were frequently used to model English sentences.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| ImageNet has images of various resolutions. Statement 2| Caltech-101 has more images than ImageNet.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: Statements and counterstatements are used to compare claims. A statement is a claim that is being tested. A counterstatement is a claim that opposes the original claim.\nIf one statement is true and the other statement is false, the two statements are consistent.\nIf one statement is false and the other statement is true, the two statements are contradictory.\nSOLUTION: The first statement is true. ImageNet does have images of various resolutions.\nThe second statement is false. Caltech-101 does not have more images than ImageNet."}
{"question": "Which of the following is more appropriate to do feature selection?", "choices": [{"label": "A", "text": "Ridge"}, {"label": "B", "text": "Lasso"}, {"label": "C", "text": "both (a) and (b)"}, {"label": "D", "text": "neither (a) nor (b)"}], "answerKey": "B", "model_answer": ""}
{"question": "Suppose you are given an EM algorithm that finds maximum likelihood estimates for a model with latent variables. You are asked to modify the algorithm so that it finds MAP estimates instead. Which step or steps do you need to modify?", "choices": [{"label": "A", "text": "Expectation"}, {"label": "B", "text": "Maximization"}, {"label": "C", "text": "No modification necessary"}, {"label": "D", "text": "Both"}], "answerKey": "B", "model_answer": "LECTURE: The Expectation-Maximization (EM) algorithm is an iterative algorithm used to find maximum likelihood estimates for a model with latent variables. The EM algorithm does the following:\n1. Expectation step: Compute the expected value of the latent variables, conditioning on the observed variables and the current estimates of the latent variable values.\n2. Maximization step: Find the maximum likelihood estimates for the latent variable values, maximizing the expected value of the latent variables over all possible values.\nThe EM algorithm can be written down in a simple form for a model with M latent variables and N observed variables:\nFor each j = 1, 2, ..., M:\nFor each i = 1, 2, ..., N:\nFor each iteration t:\n1. Expectation step: E[xj,t] = E[\u0177j,t] = \u2211n=1N \u03c0ij,t n!\n2. Maximization step: \u03bcj,t+1 =  argmaxj \u2211n=1N \u03c0ij,t n!\nwhere \u03c0ij,t is the probability that the jth latent variable is equal to n, given the observed variables and the current estimates of the latent variable values.\nSOLUTION: To modify the EM algorithm to find Maximum A Posteriori (MAP) estimates, the maximization step of the EM algorithm must be replaced by an optimization step that uses the posterior probability as the objective function. The posterior probability is a combination of the likelihood and the prior probability.\nFor each j = 1, 2, ..., M:\nFor each iteration t:\n1. Expectation step: E[xj,t] = E[\u0177j,t] = \u2211n=1N \u03c0ij,t n!\n2. Maximization step: \u03bcj,t+1 =  argmaxj \u2211n=1N \u03c0ij,t n!\n3. Substitute E[xj,t] for \u0177j,t in the above equation.\n4. This gives you the MAP estimate for xj."}
{"question": "For a Gaussian Bayes classifier, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether we learn the class centers by Maximum Likelihood or Gradient Descent"}, {"label": "B", "text": "Whether we assume full class covariance matrices or diagonal class covariance matrices"}, {"label": "C", "text": "Whether we have equal class priors or priors estimated from the data"}, {"label": "D", "text": "Whether we allow classes to have different mean vectors or we force them to share the same mean vector"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| For any two variables x and y having joint distribution p(x, y), we always have H[x, y] \u2265 H[x] + H[y] where H is entropy function. Statement 2| For some directed graphs, moralization decreases the number of edges present in the graph.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: For two variables x and y, the joint distribution p(x, y) tells you how the values of x and y are related. The entropy function H(p(x, y)) is a measure of the uncertainty of the variables.\nH(p(x, y)) = -p(x, y)log2 p(x, y)\nIf p(x, y) is a joint probability distribution, H(p(x, y)) is a well-defined quantity.\nSOLUTION: For x and y, we have the following inequalities:\nH[x, y] \u2265 H[x] + H[y]\nH[x, y] \u2264 H[x] + H[y]\nThe first inequality is true. If p(x, y) is a joint probability distribution, H(p(x, y)) is a well-defined quantity. So, H[x, y] is a well-defined quantity. And H[x, y] is greater than or equal to the sum of H[x] and H[y], which are well-defined quantities.\nThe second inequality is false. For some joint distributions, H[x, y] is less than the sum of H[x] and H[y]."}
{"question": "Which of the following is NOT supervised learning?", "choices": [{"label": "A", "text": "PCA"}, {"label": "B", "text": "Decision Tree"}, {"label": "C", "text": "Linear Regression"}, {"label": "D", "text": "Naive Bayesian"}], "answerKey": "A", "model_answer": "LECTURE: Supervised learning is a type of machine learning where the algorithm learns from labeled data. The algorithm is presented with data that has been annotated with the desired output or target. For example, in a medical diagnosis problem, the data is a set of patients, and the target is the diagnosis for each patient.\nThe algorithm's task is to learn the function f(x) = y, given the input-output pairs (x, y). This function can be used to predict the target y for a new input x."}
{"question": "Statement 1| A neural network's convergence depends on the learning rate. Statement 2| Dropout multiplies randomly chosen activation values by zero.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Which one of the following is equal to P(A, B, C) given Boolean random variables A, B and C, and no independence or conditional independence assumptions between any of them?", "choices": [{"label": "A", "text": "P(A | B) * P(B | C) * P(C | A)"}, {"label": "B", "text": "P(C | A, B) * P(A) * P(B)"}, {"label": "C", "text": "P(A, B | C) * P(C)"}, {"label": "D", "text": "P(A | B, C) * P(B | A, C) * P(C | A, B)"}], "answerKey": "C", "model_answer": "LECTURE: The rules for calculating conditional probabilities are as follows.\nIf A and B are independent, then P(A | B) = P(A)\nIf A and B are conditionally independent given C, then P(A | B, C) = P(A | C)\nOtherwise, if None of the above are true, then P(A | B, C) = 0.\nSOLUTION: There are no independence or conditional independence assumptions between the Boolean random variables A, B, and C. So, we know that P(A, B, C) = P(A, B | C) * P(C | A, B) * P(A) * P(B)."}
{"question": "Which of the following tasks can be best solved using Clustering.", "choices": [{"label": "A", "text": "Predicting the amount of rainfall based on various cues"}, {"label": "B", "text": "Detecting fraudulent credit card transactions"}, {"label": "C", "text": "Training a robot to solve a maze"}, {"label": "D", "text": "All of the above"}], "answerKey": "B", "model_answer": "LECTURE: Clustering is an unsupervised learning technique. It involves organizing data into groups or clusters. In clustering, a group of data values that are close to each other are called a cluster.\nSOLUTION: This task involves looking at the relationships between various cues and the amount of rainfall. This is an unsupervised learning task, so you should use clustering. To do this, you'll need to organize the data into groups of values that are close to each other. For example, the data points that have high temperatures and low humidity will be part of one cluster. The data points that have low temperatures and high humidity will be part of another cluster."}
{"question": "After applying a regularization penalty in linear regression, you find that some of the coefficients of w are zeroed out. Which of the following penalties might have been used?", "choices": [{"label": "A", "text": "L0 norm"}, {"label": "B", "text": "L1 norm"}, {"label": "C", "text": "L2 norm"}, {"label": "D", "text": "either (a) or (b)"}], "answerKey": "D", "model_answer": "LECTURE: Regularization is a technique used to prevent overfitting in a model. Overfitting occurs when a model is too complex and begins to fit the noise and random errors in the training data. This can cause the model to perform well on the training data but poorly on new, unseen data.\nRegularization reduces the complexity of a model by adding a penalty term to the cost function. The penalty term is designed to increase the value of the cost function for large values of the model's parameters. This has the effect of pushing the parameters away from large values.\nThere are different types of penalty terms, or norms, that can be used for regularization. Some of the most common norms are the L1 norm, the L2 norm, and the L\u221e norm.\nThe L0 norm, also known as the 0 norm, is not a common norm. It is a norm that induces penalties for parameter values that are not at zero. It is not used in the linear regression fit.\nSOLUTION: The L1 norm is a norm that induces a penalty for parameter values that are large in magnitude. The L2 norm is a norm that induces a penalty for parameter values that are large in magnitude. The L2 norm is more flexible than the L1 norm, and it is less noisy.\nA regularization penalty of L2 norm is applied to the coefficients of w. This has the effect of pushing the coefficients towards zero."}
{"question": "A and B are two events. If P(A, B) decreases while P(A) increases, which of the following is true?", "choices": [{"label": "A", "text": "P(A|B) decreases"}, {"label": "B", "text": "P(B|A) decreases"}, {"label": "C", "text": "P(B) decreases"}, {"label": "D", "text": "All of above"}], "answerKey": "B", "model_answer": "LECTURE: If P(A, B) decreases, then either P(A|B) must decrease or P(B|A) must decrease.\nThis can be proven by using the definition of conditional probability:\nP(A|B) = P(A, B) / P(B)\nIf P(A, B) decreases, then P(A, B) is smaller than it was before. So, P(A|B) must also decrease.\nP(B|A) = P(A, B) / P(A)\nIf P(A, B) decreases, then P(A, B) is smaller than it was before. So, P(B|A) must also decrease.\nSOLUTION: Look at the part of the question that tells you about the change in P(A, B) and P(A).\nIf P(A, B) decreases while P(A) increases, then P(A, B) is smaller than it was before. So, P(B|A) must decrease.\nP(B) is the new value of P(B, A). To find out if P(B) decreases, look at the part of the question that tells you about the change in P(A, B).\nIf P(A, B) decreases, then P(A, B) is smaller than it was before. So, P(B, A) must also decrease."}
{"question": "Statement 1| When learning an HMM for a fixed set of observations, assume we do not know the true number of hidden states (which is often the case), we can always increase the training data likelihood by permitting more hidden states. Statement 2| Collaborative filtering is often a useful model for modeling users' movie preference.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: When you are given a question, read it carefully. The question may contain information that can help you decide which answer is correct.\nSOLUTION: Statement 1 is correct. If you increase the number of hidden states in an HMM, you do increase the training data likelihood.\nAn HMM has two parts: a set of hidden states and a transition matrix. The transition matrix describes the probability of moving from one hidden state to another. The hidden states are not observable.\nThe set of observable states is called the output space. An HMM produces a sequence of observations, each of which is in the output space.\nInitially, the HMM is in one of the hidden states. The HMM produces its first observation, which is in the output space. The HMM is now in the observable state that corresponds to the first observation.\nThe HMM looks at the current observable state and its current hidden state. It uses these to decide on the probability of producing the next observation and the next hidden state.\nThe HMM moves to the next hidden state. This is called a transition. The HMM produces its next observation, which is in the output space.\nThe HMM repeats this process. It produces a sequence of observations.\nYou can see that the number of hidden states affects the probability of producing a sequence of observations. If you increase the number of hidden states, you get more ways to produce the same sequence of observations. So, the training data likelihood increases.\nStatement 2 is false. Collaborative filtering is a good model for recommending items to users. But it is not a good model for predicting how a user will rate an item."}
{"question": "You are training a linear regression model for a simple estimation task, and notice that the model is overfitting to the data. You decide to add in $\\ell_2$ regularization to penalize the weights. As you increase the $\\ell_2$ regularization coefficient, what will happen to the bias and variance of the model?", "choices": [{"label": "A", "text": "Bias increase ; Variance increase"}, {"label": "B", "text": "Bias increase ; Variance decrease"}, {"label": "C", "text": "Bias decrease ; Variance increase"}, {"label": "D", "text": "Bias decrease ; Variance decrease"}], "answerKey": "B", "model_answer": "LECTURE: When you have completed this module, you should be able to do the following:\nUse the bias-variance tradeoff to determine the best value for the regularization parameter.\nThe regularization parameter controls the tradeoff between the bias and variance of a linear model. As the regularization parameter increases, the penalty for large weights increases, which leads to a decrease in bias. As the regularization parameter increases, the penalty for large weights also increases, which leads to an increase in variance.\nSOLUTION: To determine the effect of the regularization parameter on the bias and variance of a linear model, consider the values of the bias and variance when the model is trained on a separate test set:\nBias: The bias is the error that is introduced by approximating a complex model with a simpler linear model. As the regularization parameter increases, the penalty for large weights increases, which leads to a decrease in bias.\nVariance: The variance is the error that is introduced by the differences between the data the model is trained on and the data the model is used on. As the regularization parameter increases, the penalty for large weights increases, which leads to an increase in variance."}
{"question": "Which PyTorch 1.8 command(s) produce $10\\times 5$ Gaussian matrix with each entry i.i.d. sampled from $\\mathcal{N}(\\mu=5,\\sigma^2=16)$ and a $10\\times 10$ uniform matrix with each entry i.i.d. sampled from $U[-1,1)$?", "choices": [{"label": "A", "text": "\\texttt{5 + torch.randn(10,5) * 16} ; \\texttt{torch.rand(10,10,low=-1,high=1)}"}, {"label": "B", "text": "\\texttt{5 + torch.randn(10,5) * 16} ; \\texttt{(torch.rand(10,10) - 0.5) / 0.5}"}, {"label": "C", "text": "\\texttt{5 + torch.randn(10,5) * 4} ; \\texttt{2 * torch.rand(10,10) - 1}"}, {"label": "D", "text": "\\texttt{torch.normal(torch.ones(10,5)*5,torch.ones(5,5)*16)} ; \\texttt{2 * torch.rand(10,10) - 1}"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| The ReLU's gradient is zero for $x<0$, and the sigmoid gradient $\\sigma(x)(1-\\sigma(x))\\le \\frac{1}{4}$ for all $x$. Statement 2| The sigmoid has a continuous gradient and the ReLU has a discontinuous gradient.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Which is true about Batch Normalization?", "choices": [{"label": "A", "text": "After applying batch normalization, the layer\u2019s activations will follow a standard Gaussian distribution."}, {"label": "B", "text": "The bias parameter of affine layers becomes redundant if a batch normalization layer follows immediately afterward."}, {"label": "C", "text": "The standard weight initialization must be changed when using Batch Normalization."}, {"label": "D", "text": "Batch Normalization is equivalent to Layer Normalization for convolutional neural networks."}], "answerKey": "B", "model_answer": "LECTURE: Batch Normalization is a technique for improving the training of deep neural networks. It is the application of a series of normalizations to the input of each layer. The normalizations serve to transform the inputs to have a standardized distribution, such as a mean of 0 and a standard deviation of 1. This transformation can help to stabilize the training process, and, ultimately, produce a more accurate model.\nA layer's activations are scaled and shifted to have a standardized distribution.\nThe batch_normalization layer computes the following:\nThe mean and variance of the inputs:\nThe standard deviation of the inputs:\nThe scale factor: = 1 / sqrt(variance)\nThe shift: = mean\nThe normalized inputs: = (inputs - mean) / standard_deviation"}
{"question": "Suppose we have the following objective function: $\\argmin_{w} \\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\gamma \\norm{w}^2_2$ What is the gradient of $\\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\lambda \\norm{w}^2_2$ with respect to $w$?", "choices": [{"label": "A", "text": "$\\nabla_w f(w) = (X^\\top X + \\lambda I)w - X^\\top y + \\lambda w$"}, {"label": "B", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + \\lambda$"}, {"label": "C", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + \\lambda w$"}, {"label": "D", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + (\\lambda+1) w$"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following is true of a convolution kernel?", "choices": [{"label": "A", "text": "Convolving an image with $\\begin{bmatrix}1 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$ would not change the image"}, {"label": "B", "text": "Convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ would not change the image"}, {"label": "C", "text": "Convolving an image with $\\begin{bmatrix}1 & 1 & 1\\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}$ would not change the image"}, {"label": "D", "text": "Convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ would not change the image"}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following is false?", "choices": [{"label": "A", "text": "Semantic segmentation models predict the class of each pixel, while multiclass image classifiers predict the class of entire image."}, {"label": "B", "text": "A bounding box with an IoU (intersection over union) equal to $96\\%$ would likely be considered at true positive."}, {"label": "C", "text": "When a predicted bounding box does not correspond to any object in the scene, it is considered a false positive."}, {"label": "D", "text": "A bounding box with an IoU (intersection over union) equal to $3\\%$ would likely be considered at false negative."}], "answerKey": "D", "model_answer": "LECTURE: In a computer vision system, an image classifier is a system that uses a machine learning model to identify objects within an image.\nThe model processes an image and outputs the objects present in the image and their classes. For each object, the model also outputs a set of bounding boxes, which are rectangular regions within the image that contain the object.\nAn image classifier has the following components:\nAn input layer that receives the image.\nA machine learning model, such as a convolutional neural network (CNN), which processes the image to identify objects and their classes.\nAn output layer that outputs a set of bounding boxes for each identified object.\nA classifier algorithm, such as a multi-class classifier, which uses the output layer to determine the class of the entire image.\nA semantic segmentation model applies a machine learning model to each pixel of the image to determine the class of the pixel.\nA multiclass image classifier predicts the class of the entire image based on the classes of the objects identified within the image.\nA bounding box is a rectangular region that contains an object. The bounding box has a size and a location within the image.\nAn object is located at a true positive if the object is correctly identified by the image classifier.\nAn object is located at a false positive if the object is incorrectly identified by the image classifier as a different object.\nAn object is located at a false negative if the object is not identified by the image classifier.\nSOLUTION: The other choices are all about bounding boxes and how they are considered as true or false. A bounding box is a rectangular region that contains an object. The bounding box has a size and a location within the image.\nA bounding box with an IoU (intersection over union) equal to 96% would likely be considered a true positive. An IoU of 96% means that 96% of the area in the bounding boxes is intersection and 4% is union.\nA bounding box with an IoU equal to 3% would likely be considered a false negative. An IoU of 3% means that 3% of the area in the bounding boxes is intersection and 97% is union.\nA bounding box that does not correspond to any object in the scene would be considered a false positive."}
{"question": "Which of the following is false?", "choices": [{"label": "A", "text": "The following fully connected network without activation functions is linear: $g_3(g_2(g_1(x)))$, where $g_i(x) = W_i x$ and $W_i$ are matrices."}, {"label": "B", "text": "Leaky ReLU $\\max\\{0.01x,x\\}$ is convex."}, {"label": "C", "text": "A combination of ReLUs such as $ReLU(x) - ReLU(x-1)$ is convex."}, {"label": "D", "text": "The loss $\\log \\sigma(x)= -\\log(1+e^{-x})$ is concave"}], "answerKey": "C", "model_answer": ""}
{"question": "We are training fully connected network with two hidden layers to predict housing prices. Inputs are $100$-dimensional, and have several features such as the number of square feet, the median family income, etc. The first hidden layer has $1000$ activations. The second hidden layer has $10$ activations. The output is a scalar representing the house price. Assuming a vanilla network with affine transformations and with no batch normalization and no learnable parameters in the activation function, how many parameters does this network have?", "choices": [{"label": "A", "text": "111021"}, {"label": "B", "text": "110010"}, {"label": "C", "text": "111110"}, {"label": "D", "text": "110011"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| The derivative of the sigmoid $\\sigma(x)=(1+e^{-x})^{-1}$ with respect to $x$ is equal to $\\text{Var}(B)$ where $B\\sim \\text{Bern}(\\sigma(x))$ is a Bernoulli random variable. Statement 2| Setting the bias parameters in each layer of neural network to 0 changes the bias-variance trade-off such that the model's variance increases and the model's bias decreases", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": ""}
