{"question": "Statement 1| Linear regression estimator has the smallest variance among all unbiased estimators. Statement 2| The coefficients \u03b1 assigned to the classifiers assembled by AdaBoost are always non-negative.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "se, True\n```\nExplanation: Statement 2 is false. The coefficients \u03b1 assigned to the classifiers assembled by AdaBoost are not always non-negative. AdaBoost can assign positive and negative weights to the classifiers, and the final prediction is the weighted sum of the predictions of the classifiers. The coefficients can be either positive or negative, depending on the weights and the classifiers."}
{"question": "Statement 1| RoBERTa pretrains on a corpus that is approximate 10x larger than the corpus BERT pretrained on. Statement 2| ResNeXts in 2018 usually used tanh activation functions.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "correct answer is (A) True, True.\n\nThe first statement is true, as RoBERTa is trained on a corpus that is approximately 10 times larger than the corpus used for BERT pretraining. The second statement is also true, as ResNeXts in 2018 typically used the hyperbolic tangent (tanh) activation function."}
{"question": "Statement 1| Support vector machines, like logistic regression models, give a probability distribution over the possible labels given an input example. Statement 2| We would expect the support vectors to remain the same in general as we move from a linear kernel to higher order polynomial kernels.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "ue, True\n```"}
{"question": "A machine learning problem involves four attributes plus a class. The attributes have 3, 2, 2, and 2 possible values each. The class has 3 possible values. How many maximum possible different examples are there?", "choices": [{"label": "A", "text": "12"}, {"label": "B", "text": "24"}, {"label": "C", "text": "48"}, {"label": "D", "text": "72"}], "answerKey": "D", "model_answer": "The correct answer is (D) 72.\n\nTo find the maximum possible different examples, we need to calculate the product of the number of possible values for each attribute. The number of possible values for each attribute is:\n\n* Attribute 1: 3 possible values\n* Attribute 2: 2 possible values\n* Attribute 3: 2 possible values\n* Attribute 4: 2 possible values\n\nThe product of these numbers is: 3 \\* 2 \\* 2 \\* 2 = 16.\n\nSince each attribute can take one of its possible values, the maximum number of different examples is 16^4 = 256.\n\nHowever, we need to divide this number by the number of possible combinations of the class values, which is:\n\n* Class 1: 3 possible values\n* Class 2: 3 possible values\n* Class 3: 3 possible values\n\nThe product of these numbers is: 3 \\* 3 \\* 3 = 27.\n\nTherefore, the maximum possible different examples is 256 / 27 = 9.\n\nHowever, this calculation does not take into account the fact that some examples may repeat due to the sample space, such as examples where all four attributes take the same value. Therefore, the actual number of maximum possible different examples is less than 9."}
{"question": "As of 2020, which architecture is best for classifying high-resolution images?", "choices": [{"label": "A", "text": "convolutional networks"}, {"label": "B", "text": "graph networks"}, {"label": "C", "text": "fully connected networks"}, {"label": "D", "text": "RBF networks"}], "answerKey": "A", "model_answer": ": The correct answer is (A) convolutional networks, also known as CNNs. CNNs are a type of deep learning architecture that is particularly well-suited for image classification tasks. They consist of multiple layers of convolutional filters that are trained to detect and extract features from images. The filters are applied to small 2D kernels that slide over the input image, allowing the network to learn hierarchical representations of the image features.\nCNNs are particularly effective for high-resolution image classification because of their ability to learn and extract features at different scales and resolutions. They are also highly parallelizable, making them well-suited for distributed computing environments.\n\nGraph networks (B) are a type of neural network architecture that is particularly well-suited for graph-structured data, such as social networks or recommender systems. They are not particularly well-suited for high-resolution image classification.\nFully connected networks (C) are a type of neural network architecture that consists of fully connected layers, where every neuron is connected to every other neuron in the network. They are not particularly well-suited for image classification tasks.\nRadial basis function (RBF) networks (D) are a type of feedforward neural network that uses a radial basis function as its activation function. They are not well-suited for high-resolution image classification."}
{"question": "Statement 1| The log-likelihood of the data will always increase through successive iterations of the expectation maximation algorithm. Statement 2| One disadvantage of Q-learning is that it can only be used when the learner has prior knowledge of how its actions affect its environment.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "True."}
{"question": "Let us say that we have computed the gradient of our cost function and stored it in a vector g. What is the cost of one gradient descent update given the gradient?", "choices": [{"label": "A", "text": "O(D)"}, {"label": "B", "text": "O(N)"}, {"label": "C", "text": "O(ND)"}, {"label": "D", "text": "O(ND^2)"}], "answerKey": "A", "model_answer": ") O(N)\nC) O(ND)\nD) O(ND^2)\n\nExplanation:\nThe cost of one gradient descent update is the cost of computing the dot product between g and a single vector x\\_i, which is the update of x\\_i. Since we need to perform a dot product between g and x\\_i for each iteration, the cost is proportional to the number of iterations divided by 2, which is O(ND). The correct answer is C) O(ND)."}
{"question": "Statement 1| For a continuous random variable x and its probability distribution function p(x), it holds that 0 \u2264 p(x) \u2264 1 for all x. Statement 2| Decision tree is learned by minimizing information gain.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "orrect answer is (D) False, True.\n\nExplanation:\nStatement 1 is False, as the probability density function (pdf) can be greater than 1 for certain values of x. For continuous random variables, the cumulative distribution function (CDF) is always less than or equal to 1, but the pdf can be greater than 1 for certain values of x.\nStatement 2 is True, as the decision tree is learned by minimizing information gain, which is the difference between the predicted probability of the target variable and the actual probability of the target variable. The goal of decision trees is to minimize this information gain, leading to the most accurate prediction of the target variable.\n\nTherefore, the correct answer is (D) False, True."}
{"question": "Consider the Bayesian network given below. How many independent parameters are needed for this Bayesian Network H -> U <- P <- W?", "choices": [{"label": "A", "text": "2"}, {"label": "B", "text": "4"}, {"label": "C", "text": "8"}, {"label": "D", "text": "16"}], "answerKey": "C", "model_answer": ""}
{"question": "As the number of training examples goes to infinity, your model trained on that data will have:", "choices": [{"label": "A", "text": "Lower variance"}, {"label": "B", "text": "Higher variance"}, {"label": "C", "text": "Same variance"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": ") Lower variance.\n\nExplanation: As the number of training examples goes to infinity, the model will start to rely on the underlying distribution of the data, rather than the specific training examples. This means that the model will have a lower variance, as it will be more accurate in its predictions."}
{"question": "Statement 1| The set of all rectangles in the 2D plane (which includes non axisaligned rectangles) can shatter a set of 5 points. Statement 2| The VC-dimension of k-Nearest Neighbour classifier when k = 1 is infinite.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "_ refers to a model that can neither model the training data nor generalize to new data.", "choices": [{"label": "A", "text": "good fitting"}, {"label": "B", "text": "overfitting"}, {"label": "C", "text": "underfitting"}, {"label": "D", "text": "all of the above"}], "answerKey": "C", "model_answer": ") All of the above\n\nExplanation: (A) Good fitting means that the model fits the training data well, but it may not generalize to new data. (B) Overfitting means that the model fits the training data too well and has too many parameters relative to the amount of data. (C) Underfitting means that the model does not have enough parameters to fit the data well. All of these situations lead to poor generalization performance."}
{"question": "Statement 1| The F1 score can be especially useful for datasets with class high imbalance. Statement 2| The area under the ROC curve is one of the main metrics used to assess anomaly detectors.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ", True. Statement 1 is True, while Statement 2 is False."}
{"question": "Statement 1| The back-propagation algorithm learns a globally optimal neural network with hidden layers. Statement 2| The VC dimension of a line should be at most 2, since I can find at least one case of 3 points that cannot be shattered by any line.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "The correct answer is (A) True, True.\n\nThe back-propagation algorithm is a method for training neural networks, and it does not learn a globally optimal neural network with hidden layers. The VC dimension of a line is a measure of the complexity of a set of lines that can distinguish a given set of data points, and it is a highly theoretical concept that is not directly related to the back-propagation algorithm. Therefore, the statement that the VC dimension of a line should be at most 2 is false, and the statement that the back-propagation algorithm learns a globally optimal neural network with hidden layers is also false."}
{"question": "High entropy means that the partitions in classification are", "choices": [{"label": "A", "text": "pure"}, {"label": "B", "text": "not pure"}, {"label": "C", "text": "useful"}, {"label": "D", "text": "useless"}], "answerKey": "B", "model_answer": "ure. High entropy means that the partitions in a classification are not pure, meaning that there is a lot of overlap and interchangeability between the different partitions."}
{"question": "Statement 1| Layer Normalization is used in the original ResNet paper, not Batch Normalization. Statement 2| DCGANs use self-attention to stabilize training.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "n\n(C) True, False. - Statement 1 is True and Statement 2 is False.\n```"}
{"question": "In building a linear regression model for a particular data set, you observe the coefficient of one of the features having a relatively high negative value. This suggests that", "choices": [{"label": "A", "text": "This feature has a strong effect on the model (should be retained)"}, {"label": "B", "text": "This feature does not have a strong effect on the model (should be ignored)"}, {"label": "C", "text": "It is not possible to comment on the importance of this feature without additional information"}, {"label": "D", "text": "Nothing can be determined."}], "answerKey": "C", "model_answer": "ct answer is (A) This feature has a strong effect on the model (should be retained)."}
{"question": "For a neural network, which one of these structural assumptions is the one that most affects the trade-off between underfitting (i.e. a high bias model) and overfitting (i.e. a high variance model):", "choices": [{"label": "A", "text": "The number of hidden nodes"}, {"label": "B", "text": "The learning rate"}, {"label": "C", "text": "The initial choice of weights"}, {"label": "D", "text": "The use of a constant-term unit input"}], "answerKey": "A", "model_answer": "use of a constant-term unit input.\n```\n\nI agree with the answer. Although the other choices can also affect the trade-off between underfitting and overfitting, the use of a constant-term unit input has the most significant impact. The choice of the number of hidden nodes, the learning rate, and the initial choice of weights can also affect the bias-variance trade-off, but they are less critical than the use of a constant-term input."}
{"question": "For polynomial regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "The polynomial degree"}, {"label": "B", "text": "Whether we learn the weights by matrix inversion or gradient descent"}, {"label": "C", "text": "The assumed variance of the Gaussian noise"}, {"label": "D", "text": "The use of a constant-term unit input"}], "answerKey": "A", "model_answer": "sumed variance of the Gaussian noise."}
{"question": "Statement 1| As of 2020, some models attain greater than 98% accuracy on CIFAR-10. Statement 2| The original ResNets were not optimized with the Adam optimizer.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "False, True.\n\nExplanation:\nStatement 1: As of 2020, some models attain greater than 98% accuracy on CIFAR-10.\nThis statement is true, as there are many recent studies that have reported state-of-the-art models achieving high accuracy on CIFAR-10.\n\nStatement 2: The original ResNets were not optimized with the Adam optimizer.\nThis statement is also true, as the original ResNets were optimized using the stochastic gradient descent (SGD) optimizer, not the Adam optimizer.\nTherefore, the correct answer is (D) False, True."}
{"question": "The K-means algorithm:", "choices": [{"label": "A", "text": "Requires the dimension of the feature space to be no bigger than the number of samples"}, {"label": "B", "text": "Has the smallest value of the objective function when K = 1"}, {"label": "C", "text": "Minimizes the within class variance for a given number of clusters"}, {"label": "D", "text": "Converges to the global optimum if and only if the initial means are chosen as some of the samples themselves"}], "answerKey": "C", "model_answer": ": The correct answer is (D). The K-means algorithm is a clustering algorithm that aims to partition a set of observations into K clusters by minimizing the within-cluster sum of squares (WCSS). The algorithm works by initializing K centroids randomly and then iteratively updating the centroids based on the mean of the observations in each cluster. If the initial centroids are chosen as some of the samples themselves, the algorithm is more likely to converge to the global optimum."}
{"question": "Statement 1| VGGNets have convolutional kernels of smaller width and height than AlexNet's first-layer kernels. Statement 2| Data-dependent weight initialization procedures were introduced before Batch Normalization.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "The correct answer is (D) False, True.\n\nExplanation:\n\nStatement 1 is True: VGGNets have convolutional kernels of smaller width and height than AlexNet's first-layer kernels.\nStatement 2 is False: Data-dependent weight initialization procedures were introduced before Batch Normalization.\n\nTherefore, the correct answer is (D) False, True."}
{"question": "What is the rank of the following matrix? A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]", "choices": [{"label": "A", "text": "0"}, {"label": "B", "text": "1"}, {"label": "C", "text": "2"}, {"label": "D", "text": "3"}], "answerKey": "B", "model_answer": "The rank of a square matrix is the number of non-zero elements it has in each row and column. In this case, the matrix A has three rows and three columns, and all elements are equal to 1. So the rank of A is equal to the number of non-zero elements, which is 3. Therefore, the correct answer is (D) 3."}
{"question": "Statement 1| Density estimation (using say, the kernel density estimator) can be used to perform classification. Statement 2| The correspondence between logistic regression and Gaussian Naive Bayes (with identity class covariances) means that there is a one-to-one correspondence between the parameters of the two classifiers.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "True, False\n\nExplanation:\nThe statement that density estimation can be used to perform classification is true, but it is not the same as logistic regression or Gaussian Naive Bayes. The statement that there is a one-to-one correspondence between the parameters of logistic regression and Gaussian Naive Bayes is false, as there are differences in the interpretation of the parameters. The parameters of logistic regression are the coefficients of a linear regression model that are used to predict the probability of a binary response, while the parameters of Gaussian Naive Bayes are the means of the Gaussian distributions that are used to predict the probability of a binary response."}
{"question": "Suppose we would like to perform clustering on spatial data such as the geometrical locations of houses. We wish to produce clusters of many different sizes and shapes. Which of the following methods is the most appropriate?", "choices": [{"label": "A", "text": "Decision Trees"}, {"label": "B", "text": "Density-based clustering"}, {"label": "C", "text": "Model-based clustering"}, {"label": "D", "text": "K-means clustering"}], "answerKey": "B", "model_answer": "The correct answer is (D) K-means clustering.\nK-means clustering is a popular and widely used method for clustering spatial data such as the geometrical locations of houses. It partitions the data into k clusters, where k is a user-defined parameter. The algorithm iteratively assigns each data point to the nearest cluster centroid and updates the centroid as the mean of all data points assigned to that cluster. K-means clustering can produce clusters of different sizes and shapes and is particularly well-suited for spherical data. The other methods listed, Decision Trees, Density-based clustering, and Model-based clustering, may not be as suitable for clustering spatial data. Decision Trees are tree-based models that can make inferences about conditional dependencies in a dataset. Density-based clustering methods, such as DBSCAN, identify clusters by defining a neighborhood and measuring the density of data points within it. Model-based clustering methods, such as Gaussian Mixture Models, model the data as a mixture of Gaussian distributions."}
{"question": "Statement 1| In AdaBoost weights of the misclassified examples go up by the same multiplicative factor. Statement 2| In AdaBoost, weighted training error e_t of the tth weak classifier on training data with weights D_t tends to increase as a function of t.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "The correct answer is (C) True, False.\n\nExplanation:\n\nIn AdaBoost, the weights of the misclassified examples are adjusted by a multiplicative factor, but this does not necessarily happen to all misclassified examples in the same way. Additionally, the training error of the tth weak classifier on training data with weights D\\_t can increase or decrease as a function of t, and it does not necessarily increase as a function of t."}
{"question": "MLE estimates are often undesirable because", "choices": [{"label": "A", "text": "they are biased"}, {"label": "B", "text": "they have high variance"}, {"label": "C", "text": "they are not consistent estimators"}, {"label": "D", "text": "None of the above"}], "answerKey": "B", "model_answer": "are not consistent estimators."}
{"question": "Computational complexity of Gradient descent is,", "choices": [{"label": "A", "text": "linear in D"}, {"label": "B", "text": "linear in N"}, {"label": "C", "text": "polynomial in D"}, {"label": "D", "text": "dependent on the number of iterations"}], "answerKey": "C", "model_answer": "dent on the number of iterations.\n\nGradient descent is an optimization algorithm used to find the minimum of a function. The computational complexity of gradient descent depends on the number of iterations, which is typically a large number, and the size of the input data. As the number of iterations increases, the error between the current solution and the optimal solution decreases, and the algorithm converges to the minimum. The computational complexity of gradient descent is therefore O(N*D), where N is the number of iterations and D is the size of the input data."}
{"question": "Averaging the output of multiple decision trees helps _.", "choices": [{"label": "A", "text": "Increase bias"}, {"label": "B", "text": "Decrease bias"}, {"label": "C", "text": "Increase variance"}, {"label": "D", "text": "Decrease variance"}], "answerKey": "D", "model_answer": "nswer: (D) Decrease variance.\n\nExplanation: Averaging the output of multiple decision trees can help decrease variance, as the average of multiple numbers is always lower than the sum of the individual numbers. This is because averaging reduces the impact of outliers and skewed data, resulting in a more stable and accurate model. Conversely, increasing variance can occur when averaging the output of multiple decision trees increases the overall variability of the model, making it less accurate."}
{"question": "The model obtained by applying linear regression on the identified subset of features may differ from the model obtained at the end of the process of identifying the subset during", "choices": [{"label": "A", "text": "Best-subset selection"}, {"label": "B", "text": "Forward stepwise selection"}, {"label": "C", "text": "Forward stage wise selection"}, {"label": "D", "text": "All of the above"}], "answerKey": "C", "model_answer": "apologize for the confusion earlier, but the correct answer is (D) All of the above.\n\nThe explanation for the correct answer is as follows:\n\nThe choice (A) Best-subset selection is incorrect because it refers to the process of selecting the subset of features that will be used in the linear regression model, not the model itself.\n\nThe choice (B) Forward stepwise selection is incorrect because it refers to the process of selecting the subset of features in each iteration, not the final model.\n\nThe choice (C) Forward stage wise selection is incorrect because it refers to the process of selecting the subset of features and building the model in each stage, not the final model.\n\nThe process described in the question involves applying linear regression on a subset of features identified through some method, and the model obtained may differ from the final model obtained during the process of identifying the subset. Therefore, all of the above methods could be used in the process leading to the final model."}
{"question": "Neural networks:", "choices": [{"label": "A", "text": "Optimize a convex objective function"}, {"label": "B", "text": "Can only be trained with stochastic gradient descent"}, {"label": "C", "text": "Can use a mix of different activation functions"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": "The correct answer is (D) None of the above.\n\nNeural networks are a type of machine learning algorithm that is inspired by the structure and function of the human brain. They consist of layers of interconnected nodes, or \"neurons,\" that process and transmit information. Neural networks can be trained to optimize a convex objective function, which means that they can find the optimal solution to a problem with a well-defined optimality criterion. They can also use a mix of different activation functions, which are functions that transform the inputs to the neurons into outputs. However, they cannot only be trained with stochastic gradient descent, which is a common algorithm for training neural networks."}
{"question": "Say the incidence of a disease D is about 5 cases per 100 people (i.e., P(D) = 0.05). Let Boolean random variable D mean a patient \u201chas disease D\u201d and let Boolean random variable TP stand for \"tests positive.\" Tests for disease D are known to be very accurate in the sense that the probability of testing positive when you have the disease is 0.99, and the probability of testing negative when you do not have the disease is 0.97. What is P(TP), the prior probability of testing positive.", "choices": [{"label": "A", "text": "0.0368"}, {"label": "B", "text": "0.473"}, {"label": "C", "text": "0.078"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| After mapped into feature space Q through a radial basis kernel function, 1-NN using unweighted Euclidean distance may be able to achieve better classification performance than in original space (though we can\u2019t guarantee this). Statement 2| The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SVM.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": ""}
{"question": "The disadvantage of Grid search is", "choices": [{"label": "A", "text": "It can not be applied to non-differentiable functions."}, {"label": "B", "text": "It can not be applied to non-continuous functions."}, {"label": "C", "text": "It is hard to implement."}, {"label": "D", "text": "It runs reasonably slow for multiple linear regression."}], "answerKey": "D", "model_answer": ""}
{"question": "Predicting the amount of rainfall in a region based on various cues is a ______ problem.", "choices": [{"label": "A", "text": "Supervised learning"}, {"label": "B", "text": "Unsupervised learning"}, {"label": "C", "text": "Clustering"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": "n\nThe correct answer is (A) Supervised learning.\n```\nThe problem of predicting the amount of rainfall in a region based on various cues is a supervised learning problem. This is because the model is trained on labeled data, where the target variable (rainfall) is known and the input features (cue variables) are used to make predictions. The model then learns to map the input features to the target variable and make accurate predictions for new, unseen data."}
{"question": "Which of the following sentence is FALSE regarding regression?", "choices": [{"label": "A", "text": "It relates inputs to outputs."}, {"label": "B", "text": "It is used for prediction."}, {"label": "C", "text": "It may be used for interpretation."}, {"label": "D", "text": "It discovers causal relationships"}], "answerKey": "D", "model_answer": ""}
{"question": "Which one of the following is the main reason for pruning a Decision Tree?", "choices": [{"label": "A", "text": "To save computing time during testing"}, {"label": "B", "text": "To save space for storing the Decision Tree"}, {"label": "C", "text": "To make the training set error smaller"}, {"label": "D", "text": "To avoid overfitting the training set"}], "answerKey": "D", "model_answer": "e computing time during testing\nB) To save space for storing the Decision Tree\nC) To make the training set error smaller\nD) To avoid overfitting the training set\n\nAnswer: D) To avoid overfitting the training set. The main reason for pruning a Decision Tree is to prevent overfitting, which occurs when the tree becomes too complex and starts to fit the noise in the training data rather than the underlying patterns. Pruning reduces the complexity of the tree by removing branches that do not contribute significantly to the accuracy of the predictions."}
{"question": "Statement 1| The kernel density estimator is equivalent to performing kernel regression with the value Yi = 1/n at each point Xi in the original data set. Statement 2| The depth of a learned decision tree can be larger than the number of training examples used to create the tree.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "The correct answer is (D) False, True.\n\nStatement 1 is false, as the kernel density estimator is a method for estimating the probability density function of a random variable, while the kernel regression method is a method for regression analysis.\n\nStatement 2 is true, as the depth of a learned decision tree can be larger than the number of training examples used to create the tree, especially if the tree is overfitting the training data."}
{"question": "Suppose your model is overfitting. Which of the following is NOT a valid way to try and reduce the overfitting?", "choices": [{"label": "A", "text": "Increase the amount of training data."}, {"label": "B", "text": "Improve the optimisation algorithm being used for error minimisation."}, {"label": "C", "text": "Decrease the model complexity."}, {"label": "D", "text": "Reduce the noise in the training data."}], "answerKey": "B", "model_answer": "D) Reduce the noise in the training data.\n\nExplanation: Overfitting occurs when a model is too complex and is fitting the training data too closely, resulting in poor generalization to new, unseen data. One way to reduce overfitting is to reduce the complexity of the model, but this can be difficult to do in practice. Another way to reduce overfitting is to reduce the amount of noise in the training data, which can help the model to generalize better to new data. However, if the training data is noisy, reducing the noise may not necessarily help reduce overfitting, as the model may still fit the noise in the training data too closely. Increasing the amount of training data and improving the optimization algorithm can also help reduce overfitting, but these methods do not address the issue of the model fitting the noise in the training data too closely."}
{"question": "Statement 1| The softmax function is commonly used in mutliclass logistic regression. Statement 2| The temperature of a nonuniform softmax distribution affects its entropy.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ") False, False\n\nExplanation: The softmax function is commonly used in multiclass logistic regression, but the temperature of a nonuniform softmax distribution does affect its entropy. Therefore, the correct answer is (B) False, False."}
{"question": "Which of the following is/are true regarding an SVM?", "choices": [{"label": "A", "text": "For two dimensional data points, the separating hyperplane learnt by a linear SVM will be a straight line."}, {"label": "B", "text": "In theory, a Gaussian kernel SVM cannot model any complex separating hyperplane."}, {"label": "C", "text": "For every kernel function used in a SVM, one can obtain an equivalent closed form basis expansion."}, {"label": "D", "text": "Overfitting in an SVM is not a function of number of support vectors."}], "answerKey": "A", "model_answer": "`\nFor the options (A) and (D), both are true.\n\nFor option (A), in two-dimensional space, a linear SVM will learn a hyperplane that is a straight line, which separates the data points.\n\nFor option (D), overfitting in an SVM is not a function of the number of support vectors. Overfitting occurs when the SVM has learned the training data too well and is not able to generalize well to new data. The number of support vectors is not the only factor that determines the risk of overfitting, and other factors such as the complexity of the model and the degree of regularization also play a role.\n\nFor option (B), a Gaussian kernel SVM can model complex separating hyperplanes, as the Gaussian kernel can capture nonlinear relationships between data points.\n\nFor option (C), a closed form basis expansion is not unique to a specific kernel function used in SVM. While some kernel functions, such as linear and polynomial, have closed form basis expansions, this is not true for all kernel functions.\n\nTherefore, the correct answers are (A) and (D)."}
{"question": "Which of the following is the joint probability of H, U, P, and W described by the given Bayesian Network H -> U <- P <- W? [note: as the product of the conditional probabilities]", "choices": [{"label": "A", "text": "P(H, U, P, W) = P(H) * P(W) * P(P) * P(U)"}, {"label": "B", "text": "P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(W | H, P)"}, {"label": "C", "text": "P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(U | H, P)"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| Since the VC dimension for an SVM with a Radial Base Kernel is infinite, such an SVM must be worse than an SVM with polynomial kernel which has a finite VC dimension. Statement 2| A two layer neural network with linear activation functions is essentially a weighted combination of linear separators, trained on a given dataset; the boosting algorithm built on linear separators also finds a combination of linear separators, therefore these two algorithms will give the same result.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "The correct answer is: (D) False, True.\nExplanation:\nStatement 1 is False. The VC dimension for an SVM with a Radial Base Kernel is not necessarily infinite. It depends on the dimensionality of the input space and the choice of kernel function.\nStatement 2 is True. A two layer neural network with linear activation functions is essentially a weighted combination of linear separators, trained on a given dataset. This means that the output of the first layer can be interpreted as a weighted linear combination of the inputs to the second layer. The boosting algorithm built on linear separators also finds a combination of linear separators, but the specific combination found depends on the particular set of linear separators used. Therefore, the two algorithms may not give the same result."}
{"question": "Statement 1| The ID3 algorithm is guaranteed to find the optimal decision tree. Statement 2| Consider a continuous probability distribution with density f() that is nonzero everywhere. The probability of a value x is equal to f(x).", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": ""}
{"question": "Given a Neural Net with N input nodes, no hidden layers, one output node, with Entropy Loss and Sigmoid Activation Functions, which of the following algorithms (with the proper hyper-parameters and initialization) can be used to find the global optimum?", "choices": [{"label": "A", "text": "Stochastic Gradient Descent"}, {"label": "B", "text": "Mini-Batch Gradient Descent"}, {"label": "C", "text": "Batch Gradient Descent"}, {"label": "D", "text": "All of the above"}], "answerKey": "D", "model_answer": "stic Gradient Descent\nB) Mini-Batch Gradient Descent\nC) Batch Gradient Descent\nD) All of the above\n\nThe correct answer is (D) All of the above. All of these algorithms can be used to find the global optimum for a neural net with N input nodes, no hidden layers, one output node, with Entropy Loss and Sigmoid Activation Functions. The choice between them depends on factors such as the size of the dataset, the computational resources available, and the specific needs of the problem at hand."}
{"question": "Adding more basis functions in a linear model, pick the most probably option:", "choices": [{"label": "A", "text": "Decreases model bias"}, {"label": "B", "text": "Decreases estimation bias"}, {"label": "C", "text": "Decreases variance"}, {"label": "D", "text": "Doesn\u2019t affect bias and variance"}], "answerKey": "A", "model_answer": "(Human): The correct answer is (B) Decreases estimation bias.\n\nBasis functions are additional functions that are added to a linear model to improve its performance. They can help reduce bias and variance by accounting for complex relationships between the variables in the model. When adding more basis functions, the model's estimation bias is likely to decrease because the model will be able to account for more complex relationships between the variables. However, the variance of the model may increase if the additional basis functions are not relevant to the problem at hand. In general, adding more basis functions to a linear model can help improve its performance, but it is important to consider the trade-off between bias and variance and to choose the right basis functions to use."}
{"question": "Consider the Bayesian network given below. How many independent parameters would we need if we made no assumptions about independence or conditional independence H -> U <- P <- W?", "choices": [{"label": "A", "text": "3"}, {"label": "B", "text": "4"}, {"label": "C", "text": "7"}, {"label": "D", "text": "15"}], "answerKey": "D", "model_answer": "he correct answer is (D) 15. The Bayesian network given below has 9 nodes and 8 arcs. If we make no assumptions about independence or conditional independence, we need to model 9 - 1 = 8 parameters to estimate the joint probability distribution of the 9 nodes."}
{"question": "Another term for out-of-distribution detection is?", "choices": [{"label": "A", "text": "anomaly detection"}, {"label": "B", "text": "one-class detection"}, {"label": "C", "text": "train-test mismatch robustness"}, {"label": "D", "text": "background detection"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| We learn a classifier f by boosting weak learners h. The functional form of f\u2019s decision boundary is the same as h\u2019s, but with different parameters. (e.g., if h was a linear classifier, then f is also a linear classifier). Statement 2| Cross validation can be used to select the number of iterations in boosting; this procedure may help reduce overfitting.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "True, True\n\nExplanation:\n\nStatement 1 is true. When we boost a weak learner with a strength greater than the learner being boosted, the resulting classifier has the same decision boundary, but with different parameters.\n\nStatement 2 is also true. Cross-validation can be used to select the number of iterations in boosting, and this procedure can help reduce overfitting by selecting the number of iterations that balances the trade-off between bias and variance.\n\nTherefore, the correct answer is (A) True, True."}
{"question": "Statement 1| Highway networks were introduced after ResNets and eschew max pooling in favor of convolutions. Statement 2| DenseNets usually cost more memory than ResNets.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": ", True.\n\nExplanation:\n\nStatement 1: False. While both ResNets and highway networks were introduced after ResNets, highway networks were introduced before eschew max pooling in favor of convolutions.\n\nStatement 2: False. DenseNets usually require more memory than ResNets.\n\nBoth statements are false."}
{"question": "If N is the number of instances in the training dataset, nearest neighbors has a classification run time of", "choices": [{"label": "A", "text": "O(1)"}, {"label": "B", "text": "O( N )"}, {"label": "C", "text": "O(log N )"}, {"label": "D", "text": "O( N^2 )"}], "answerKey": "B", "model_answer": "n\nA) O(1)\n```\nThe correct answer is A. The time complexity of nearest neighbors algorithms is typically O(1), meaning it has a constant time complexity regardless of the size of the dataset."}
{"question": "Statement 1| The original ResNets and Transformers are feedforward neural networks. Statement 2| The original Transformers use self-attention, but the original ResNet does not.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "False, True.\n\nExplanation:\n\nThe original ResNets are feedforward neural networks, but the original Transformers do not use self-attention. The ResNet architecture uses a form of self-attention, but this is not the same as the self-attention mechanism used in the Transformer architecture.\nTherefore, the correct answer is (D) False, True."}
{"question": "Statement 1| RELUs are not monotonic, but sigmoids are monotonic. Statement 2| Neural networks trained with gradient descent with high probability converge to the global optimum.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "D) False, True.\n\nExplanation:\nStatement 1 is false, but statement 2 is true. This means the answer is (D) False, True.\n\nExplanation of why (A) is not the correct answer:\n\n* False, True: This answer choice would mean that both statements are false, which is not the correct answer.\n* True, False: This answer choice would mean that both statements are true, which is not the correct answer.\n\nExplanation of why (B) is not the correct answer:\n\n* False, False: This answer choice would mean that both statements are false, which is not the correct answer.\n* True, True: This answer choice would mean that both statements are true, which is not the correct answer.\n\nExplanation of why (C) is not the correct answer:\n\n* True, False: This answer choice would mean that statement 1 is true and statement 2 is false, which is not the correct answer."}
{"question": "The numerical output of a sigmoid node in a neural network:", "choices": [{"label": "A", "text": "Is unbounded, encompassing all real numbers."}, {"label": "B", "text": "Is unbounded, encompassing all integers."}, {"label": "C", "text": "Is bounded between 0 and 1."}, {"label": "D", "text": "Is bounded between -1 and 1."}], "answerKey": "C", "model_answer": "merical output of a sigmoid node in a neural network: C) Is bounded between 0 and 1.\n```\nThe sigmoid function is a type of activation function commonly used in neural networks to introduce non-linearity into the model. The output of a sigmoid node is a value between 0 and 1, representing the extent to which a particular neuron is activated. This value is used as the input to other neurons in the network, allowing the network to process information and make predictions. The output of a sigmoid node is not unbounded, encompassing all real numbers, or unbounded, encompassing all integers. It is also not bounded between -1 and 1, as the output of a sigmoid node is limited to the range of 0 to 1."}
{"question": "Which of the following can only be used when training data are linearly separable?", "choices": [{"label": "A", "text": "Linear hard-margin SVM."}, {"label": "B", "text": "Linear Logistic Regression."}, {"label": "C", "text": "Linear Soft margin SVM."}, {"label": "D", "text": "The centroid method."}], "answerKey": "A", "model_answer": "r hard-margin SVM.\n\nExplanation: The hard-margin SVM algorithm will only work when the data is linearly separable. It will not work when the data is not linearly separable or when the data is noisy and suffers from overfitting. Linear hard-margin SVM uses a hyperplane to separate the data into two classes. It works well when the data is linearly separable and has a high-dimensional space. Linear Logistic Regression is a logistic regression algorithm that uses a logistic function to model the probability of a binary classification problem. It can work well when the data is not linearly separable, and it uses a sigmoid function to convert a linear combination of the features into a probability. Linear Soft margin SVM is similar to linear hard-margin SVM, but it uses a different margin parameter to determine the separation between the two classes. The centroid method is a clustering algorithm that groups the data points based on their similarity. It can work well when the data is not linearly separable, and it does not require the data to be linearly separable."}
{"question": "Which of the following are the spatial clustering algorithms?", "choices": [{"label": "A", "text": "Partitioning based clustering"}, {"label": "B", "text": "K-means clustering"}, {"label": "C", "text": "Grid based clustering"}, {"label": "D", "text": "All of the above"}], "answerKey": "D", "model_answer": "Based on the information provided, the spatial clustering algorithms are (A) Partitioning based clustering and (C) Grid based clustering. These algorithms are used to group points or objects based on their spatial relationships, such as proximity or distance.\nPartitioning based clustering involves dividing a dataset into clusters based on a specific criterion, such as similarity or dissimilarity. This can be done using various techniques, such as k-means, hierarchical clustering, and DBSCAN.\nGrid-based clustering involves dividing a dataset into clusters based on its spatial location in a grid. This can be done using algorithms such as the DBSCAN algorithm, which uses a grid to identify clusters of points that are close to each other.\nThe other two options, (B) K-means clustering and (D) All of the above, are not spatial clustering algorithms. K-means clustering is a popular clustering algorithm that involves partitioning a dataset into K clusters based on their similarity. However, it is not a spatial clustering algorithm because it does not take into account the spatial relationships between points or objects. All of the above is not a correct answer because it includes options that are not spatial clustering algorithms."}
{"question": "Statement 1| The maximum margin decision boundaries that support vector machines construct have the lowest generalization error among all linear classifiers. Statement 2| Any decision boundary that we get from a generative model with classconditional Gaussian distributions could in principle be reproduced with an SVM and a polynomial kernel of degree less than or equal to three.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": ""}
{"question": "Statement 1| L2 regularization of linear models tends to make models more sparse than L1 regularization. Statement 2| Residual connections can be found in ResNets and Transformers.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "e, True,\n\nExplanation:\nStatement 1 is true. L2 regularization tends to make models more sparse than L1 regularization.\nStatement 2 is also true. Residual connections can be found in ResNets and Transformers."}
{"question": "Suppose we like to calculate P(H|E, F) and we have no conditional independence information. Which of the following sets of numbers are sufficient for the calculation?", "choices": [{"label": "A", "text": "P(E, F), P(H), P(E|H), P(F|H)"}, {"label": "B", "text": "P(E, F), P(H), P(E, F|H)"}, {"label": "C", "text": "P(H), P(E|H), P(F|H)"}, {"label": "D", "text": "P(E, F), P(E|H), P(F|H)"}], "answerKey": "B", "model_answer": "rrect answer is (B) P(E, F), P(H), P(E, F|H), and P(F|H).\n```\nTo calculate P(H|E, F), we need to know the marginal probabilities P(E) and P(F) and the conditional probability P(H|E, F).\n\nWe can use the Markov Chain condition to calculate P(H|E, F) as:\n\nP(H|E, F) = P(E, F, H) / P(E, F)\n\nwhere P(E, F, H) is the joint probability of E, F, and H, and P(E, F) is the product of P(E) and P(F).\n\nIf we have P(E, F, H), we can use Bayes' Theorem to calculate P(H|E, F):\n\nP(H|E, F) = P(H, E, F) / P(E, F)\n\nwhere P(H, E, F) is the joint probability of H, E, and F.\n\nTo calculate P(E, F|H), we can use the Markov Chain condition again:\n\nP(E, F|H) = P(H, E, F) / P(H)\n\nwhere P(H, E, F) is the joint probability of H, E, and F, and P(H) is the probability of H.\n\nTo calculate P(F|H), we can use conditional probability:"}
{"question": "Which among the following prevents overfitting when we perform bagging?", "choices": [{"label": "A", "text": "The use of sampling with replacement as the sampling technique"}, {"label": "B", "text": "The use of weak classifiers"}, {"label": "C", "text": "The use of classification algorithms which are not prone to overfitting"}, {"label": "D", "text": "The practice of validation performed on every classifier trained"}], "answerKey": "B", "model_answer": "The use of sampling with replacement as the sampling technique.\n\nExplanation: Bagging is an ensemble method that involves training multiple classifiers on different subsets of the training data and combining their predictions to obtain a final prediction. One way to prevent overfitting when performing bagging is to use sampling with replacement as the sampling technique. This involves randomly selecting a subset of the training data with replacement, which ensures that each classifier gets a different subset of the data to train on. This reduces the correlation between the classifiers and reduces the likelihood of overfitting.\n\n(B) The use of weak classifiers is not a solution to prevent overfitting when performing bagging. In fact, using weak classifiers may even worsen the overfitting problem.\n(C) The use of classification algorithms which are not prone to overfitting may help prevent overfitting to some extent, but it is not a guarantee that the classifiers will not overfit.\n(D) The practice of validation performed on every classifier trained is not a solution to prevent overfitting when performing bagging. Validation on a few classifiers trained may not be sufficient to prevent overfitting.\n\nReference: [1](https://www.oreilly.com/library/view/machine-learning-with-python/9781449374142/)"}
{"question": "Statement 1| PCA and Spectral Clustering (such as Andrew Ng\u2019s) perform eigendecomposition on two different matrices. However, the size of these two matrices are the same. Statement 2| Since classification is a special case of regression, logistic regression is a special case of linear regression.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "The correct answer is (A) True, True.\n\nBoth PCA and spectral clustering (such as Andrew Ng's) perform eigendecomposition on two different matrices, and their sizes are the same. However, PCA is a linear dimensionality reduction technique that projects a high-dimensional space onto a lower-dimensional space, while spectral clustering is a clustering algorithm that groups similar data points together based on their eigenvalues and eigenvectors.\n\nOn the other hand, logistic regression is a type of linear regression that is used for classification problems, while linear regression is a type of regression that is used for predicting a continuous response variable. Therefore, statement 2 is false."}
{"question": "Statement 1| The Stanford Sentiment Treebank contained movie reviews, not book reviews. Statement 2| The Penn Treebank has been used for language modeling.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "ue, False\n```\nExplanation:\nStatement 1 is true that the Stanford Sentiment Treebank contained movie reviews, but statement 2 is false that the Penn Treebank has been used for language modeling. The correct answer is (C) True, False."}
{"question": "What is the dimensionality of the null space of the following matrix? A = [[3, 2, \u22129], [\u22126, \u22124, 18], [12, 8, \u221236]]", "choices": [{"label": "A", "text": "0"}, {"label": "B", "text": "1"}, {"label": "C", "text": "2"}, {"label": "D", "text": "3"}], "answerKey": "C", "model_answer": "(B) The dimensionality of the null space of a matrix is the number of linearly independent rows or columns in the matrix. We can determine this by finding the rank of the matrix and subtracting it from the number of rows (or columns) in the matrix.\n\nIn this case, the matrix A has a rank of 2, which means that it has two linearly independent rows or columns. Therefore, the dimensionality of the null space of A is 2. Answer: (B) 1."}
{"question": "What are support vectors?", "choices": [{"label": "A", "text": "The examples farthest from the decision boundary."}, {"label": "B", "text": "The only examples necessary to compute f(x) in an SVM."}, {"label": "C", "text": "The data centroid."}, {"label": "D", "text": "All the examples that have a non-zero weight \u03b1k in a SVM."}], "answerKey": "B", "model_answer": "The correct answer is (D) All the examples that have a non-zero weight \u03b1k in a SVM.\n\nSupport vectors (SVs) in a machine learning model, such as a support vector machine (SVM), are the data points that are closest to the decision boundary (the line or hyperplane in a high-dimensional space that separates the two classes). These points have a high degree of importance in the model, as they determine the position and shape of the decision boundary.\n\nThe examples that have a non-zero weight \u03b1k in an SVM are the support vectors, and they are used to define the decision boundary of the model. The weight \u03b1k is a scalar value assigned to each example, which indicates the importance of that example in the model. The examples with non-zero weights are the ones that are closest to the decision boundary, and they are used to define the boundary in a way that maximizes the margin between the two classes.\n\nIn summary, support vectors are the data points that are closest to the decision boundary in a machine learning model, and they are defined by the non-zero weights \u03b1k assigned to each example. These points are important in determining the position and shape of the decision boundary and play a crucial role in the performance of the model."}
{"question": "Statement 1| Word2Vec parameters were not initialized using a Restricted Boltzman Machine. Statement 2| The tanh function is a nonlinear activation function.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "True."}
{"question": "If your training loss increases with number of epochs, which of the following could be a possible issue with the learning process?", "choices": [{"label": "A", "text": "Regularization is too low and model is overfitting"}, {"label": "B", "text": "Regularization is too high and model is underfitting"}, {"label": "C", "text": "Step size is too large"}, {"label": "D", "text": "Step size is too small"}], "answerKey": "C", "model_answer": "arization is too low and model is overfitting.\n\nThis is the most likely issue with the learning process, as the training loss increases with number of epochs."}
{"question": "Say the incidence of a disease D is about 5 cases per 100 people (i.e., P(D) = 0.05). Let Boolean random variable D mean a patient \u201chas disease D\u201d and let Boolean random variable TP stand for \"tests positive.\" Tests for disease D are known to be very accurate in the sense that the probability of testing positive when you have the disease is 0.99, and the probability of testing negative when you do not have the disease is 0.97. What is P(D | TP), the posterior probability that you have disease D when the test is positive?", "choices": [{"label": "A", "text": "0.0495"}, {"label": "B", "text": "0.078"}, {"label": "C", "text": "0.635"}, {"label": "D", "text": "0.97"}], "answerKey": "C", "model_answer": "he correct answer is (C) 0.635.\n\nTo calculate P(D | TP), we use Bayes' theorem, which gives the posterior probability given some prior knowledge. In this case, we know that P(D) = 0.05 and P(TP | D) = 0.99, and we want to find P(D | TP). We can use the formula:\n\nP(D | TP) = P(TP | D) \\* P(D) / P(TP)\n\nWe can find P(TP) using the law of total probability:\n\nP(TP) = P(TP | D) \\* P(D) + P(TP | \u00acD) \\* P(\u00acD)\n\nSubstituting the given values, we get:\n\nP(TP) = 0.99 \\* 0.05 + 0.01 \\* 0.95\n\nP(TP) = 0.545\n\nNow we can substitute the values into the formula for P(D | TP):\n\nP(D | TP) = 0.99 \\* 0.05 / 0.545\n\nP(D | TP) = 0.635\n\nTherefore, the correct answer is (C) 0.635."}
{"question": "Statement 1| Traditional machine learning results assume that the train and test sets are independent and identically distributed. Statement 2| In 2017, COCO models were usually pretrained on ImageNet.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "The correct answer is (D) False, True.\n\nExplanation:\nStatement 1 is False, as it is incorrect to assume that the train and test sets are independent and identically distributed.\nStatement 2 is True, as pretraining on ImageNet was a common practice for COCO models in 2017.\nTherefore, the correct answer is (D) False, True."}
{"question": "Statement 1| The values of the margins obtained by two different kernels K1(x, x0) and K2(x, x0) on the same training set do not tell us which classifier will perform better on the test set. Statement 2| The activation function of BERT is the GELU.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ", False."}
{"question": "Which of the following is a clustering algorithm in machine learning?", "choices": [{"label": "A", "text": "Expectation Maximization"}, {"label": "B", "text": "CART"}, {"label": "C", "text": "Gaussian Na\u00efve Bayes"}, {"label": "D", "text": "Apriori"}], "answerKey": "A", "model_answer": "the context of machine learning, which of the following is a clustering algorithm?\nA) Expectation Maximization\nB) CART\nC) Gaussian Na\u00efve Bayes\nD) Apriori\n\nAnswer: D) Apriori\nExplanation: A clustering algorithm is used to group similar data points together based on their features. Apriori is a clustering algorithm that uses association rule mining to identify frequent item sets and group similar items together. Other clustering algorithms include k-means, hierarchical clustering, and density-based clustering."}
{"question": "You've just finished training a decision tree for spam classification, and it is getting abnormally bad performance on both your training and test sets. You know that your implementation has no bugs, so what could be causing the problem?", "choices": [{"label": "A", "text": "Your decision trees are too shallow."}, {"label": "B", "text": "You need to increase the learning rate."}, {"label": "C", "text": "You are overfitting."}, {"label": "D", "text": "None of the above."}], "answerKey": "A", "model_answer": "The correct answer is (D) None of the above. This question does not provide enough information to determine the cause of the issue. It could be caused by factors such as overfitting, insufficient data, or poorly chosen features. Further analysis and diagnostic tools would be needed to identify the root cause of the problem."}
{"question": "K-fold cross-validation is", "choices": [{"label": "A", "text": "linear in K"}, {"label": "B", "text": "quadratic in K"}, {"label": "C", "text": "cubic in K"}, {"label": "D", "text": "exponential in K"}], "answerKey": "A", "model_answer": "n\nA) Linear in K\n```\nThe reason for this is that the time complexity of k-fold cross-validation is generally linear in the number of folds, K. The algorithm needs to loop through each fold, train and evaluate the model, and repeat this process K times. The number of iterations and computations increases linearly with the number of folds, so the overall time complexity is also linear in K."}
{"question": "Statement 1| Industrial-scale neural networks are normally trained on CPUs, not GPUs. Statement 2| The ResNet-50 model has over 1 billion parameters.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": ") False, False\n\nExplanation:\n\n* Statement 1 is False. Industrial-scale neural networks can be trained on GPUs as well as CPUs.\n* Statement 2 is False. ResNet-50 has approximately 8 million parameters, not 1 billion.\n\nTherefore, the correct answer is (B) False, False."}
{"question": "Given two Boolean random variables, A and B, where P(A) = 1/2, P(B) = 1/3, and P(A | \u00acB) = 1/4, what is P(A | B)?", "choices": [{"label": "A", "text": "1/6"}, {"label": "B", "text": "1/4"}, {"label": "C", "text": "3/4"}, {"label": "D", "text": "1"}], "answerKey": "D", "model_answer": "markdown\nThis question involves conditional probability and Bayes' theorem. Given two Boolean random variables A and B, we want to find P(A | B). We know that:\n\nP(A | \u00acB) = 1/4\n\nWe can use Bayes' theorem to find P(A | B):\n\nP(A | B) = P(B | A) * P(A) / P(B)\n= (1/2) * (1/2) / (1/3)\n= 1/2\n\nTherefore, the correct answer is (D) 1.\n```"}
{"question": "Existential risks posed by AI are most commonly associated with which of the following professors?", "choices": [{"label": "A", "text": "Nando de Frietas"}, {"label": "B", "text": "Yann LeCun"}, {"label": "C", "text": "Stuart Russell"}, {"label": "D", "text": "Jitendra Malik"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| Maximizing the likelihood of logistic regression model yields multiple local optimums. Statement 2| No classifier can do better than a naive Bayes classifier if the distribution of the data is known.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "True."}
{"question": "For Kernel Regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether kernel function is Gaussian versus triangular versus box-shaped"}, {"label": "B", "text": "Whether we use Euclidian versus L1 versus L\u221e metrics"}, {"label": "C", "text": "The kernel width"}, {"label": "D", "text": "The maximum height of the kernel function"}], "answerKey": "C", "model_answer": "m sorry, but I cannot provide an answer without more context or information about the specific question and the Kernel Regression model. It is important to understand that kernel regression is a type of machine learning model, and the structural assumptions and parameters of the model can have a significant impact on the trade-off between underfitting and overfitting. The choice between different kernel functions, metrics, and parameters can depend on the specific problem and data set being analyzed. Therefore, without more information about the specific question and the Kernel Regression model, it is not possible to provide an accurate answer."}
{"question": "Statement 1| The SVM learning algorithm is guaranteed to find the globally optimal hypothesis with respect to its object function. Statement 2| After being mapped into feature space Q through a radial basis kernel function, a Perceptron may be able to achieve better classification performance than in its original space (though we can\u2019t guarantee this).", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "True, True\n\nExplanation:\nStatement 1 is true because the SVM learning algorithm is designed to find the globally optimal hypothesis with respect to its object function. It uses a technique called \"kernel function\" to transform the original problem into a higher dimensional space where it becomes possible to find the global optimal solution.\nStatement 2 is also true because after being mapped into feature space Q through a radial basis kernel function, a Perceptron may be able to achieve better classification performance than in its original space. The kernel function helps in reducing the complexity of the problem and may result in better classification performance."}
{"question": "For a Gaussian Bayes classifier, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether we learn the class centers by Maximum Likelihood or Gradient Descent"}, {"label": "B", "text": "Whether we assume full class covariance matrices or diagonal class covariance matrices"}, {"label": "C", "text": "Whether we have equal class priors or priors estimated from the data."}, {"label": "D", "text": "Whether we allow classes to have different mean vectors or we force them to share the same mean vector"}], "answerKey": "B", "model_answer": "The structural assumption that most affects the trade-off between underfitting and overfitting for a Gaussian Bayes classifier is whether we allow classes to have different mean vectors or we force them to share the same mean vector. The other choices do not directly affect this trade-off.\n\n(A) Whether we learn the class centers by Maximum Likelihood or Gradient Descent does not directly affect the trade-off between underfitting and overfitting.\n(B) Whether we assume full class covariance matrices or diagonal class covariance matrices does not directly affect the trade-off between underfitting and overfitting.\n(C) Whether we have equal class priors or priors estimated from the data also does not directly affect the trade-off between underfitting and overfitting.\n\nSo, the correct answer is (D) Whether we allow classes to have different mean vectors or we force them to share the same mean vector. When classes are allowed to have different mean vectors, the classifier will need to learn more complex representations to distinguish between the classes, which reduces the likelihood of overfitting. When classes are forced to share the same mean vector, the classifier will have less capacity to capture the complexity of the data, which increases the likelihood of underfitting."}
{"question": "Statement 1| Overfitting is more likely when the set of training data is small. Statement 2| Overfitting is more likely when the hypothesis space is small.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": ", True\n\nExplanation:\nStatement 1: Overfitting is more likely when the set of training data is small.\nStatement 2: Overfitting is more likely when the hypothesis space is small.\nExplanation:\nOverfitting occurs when a machine learning model is too complex and has too many parameters, and it fits the training data too closely, but doesn't generalize well to new data. There are two main factors that can lead to overfitting: the size of the training set and the size of the hypothesis space.\n\nStatement 1 is true. When the training set is small, there is less data for the model to learn from, so it's more likely to overfit the data.\n\nStatement 2 is also true. When the hypothesis space is small, there are fewer possible models that the model can learn from, so it's more likely to overfit the data.\n\nStatement 3 is false. Overfitting is not more likely when the model is too complex, it's more likely when the model is too simple.\n\nStatement 4 is false. Overfitting is not more likely when the training data is too noisy, it's more likely when the training data is too clean.\n\nStatement 5 is false. Overfitting is not more likely when the learning rate is too high, it's more likely when the learning rate is too low."}
{"question": "Statement 1| Besides EM, gradient descent can be used to perform inference or learning on Gaussian mixture model. Statement 2 | Assuming a fixed number of attributes, a Gaussian-based Bayes optimal classifier can be learned in time linear in the number of records in the dataset.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| In a Bayesian network, the inference results of the junction tree algorithm are the same as the inference results of variable elimination. Statement 2| If two random variable X and Y are conditionally independent given another random variable Z, then in the corresponding Bayesian network, the nodes for X and Y are d-separated given Z.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": ") True, True, (B) False, False, (C) True, False, (D) False, True.\n\nExplanation:\nStatement 1 is False, as the junction tree algorithm produces different results than variable elimination. In a Bayesian network, nodes that are d-separated are independent given some other nodes, but being d-separated does not imply independence given everything.\n\nIn statement 2, the two random variables X and Y are conditionally independent given another variable Z, but this does not mean that they are d-separated in the corresponding Bayesian network. The d-separation property refers to the nodes being connected only through direct dependencies, not through other variables that influence the nodes.\n\nTherefore, the correct answer is (D) False, True."}
{"question": "Given a large dataset of medical records from patients suffering from heart disease, try to learn whether there might be different clusters of such patients for which we might tailor separate treatments. What kind of learning problem is this?", "choices": [{"label": "A", "text": "Supervised learning"}, {"label": "B", "text": "Unsupervised learning"}, {"label": "C", "text": "Both (a) and (b)"}, {"label": "D", "text": "Neither (a) nor (b)"}], "answerKey": "B", "model_answer": "Supervised learning.\n\nExplanation: The task of clustering patients with heart disease into separate groups based on their characteristics is a supervised learning problem. The goal is to learn from labeled data, where the labels indicate which group each patient belongs to. In this case, the labels are the known treatment groups for each patient. The model can then use this information to predict which treatment group a new patient is most likely to belong to."}
{"question": "What would you do in PCA to get the same projection as SVD?", "choices": [{"label": "A", "text": "Transform data to zero mean"}, {"label": "B", "text": "Transform data to zero median"}, {"label": "C", "text": "Not possible"}, {"label": "D", "text": "None of these"}], "answerKey": "A", "model_answer": "of these\n\nExplanation: If the goal is to obtain the same projection as SVD (Singular Value Decomposition), then transforming the data to zero mean is not enough. In fact, it is not possible to obtain the same projection as SVD using only one transformation, as different transformations can lead to different projections. Therefore, the correct answer is \"None of these\"."}
{"question": "Statement 1| The training error of 1-nearest neighbor classifier is 0. Statement 2| As the number of data points grows to infinity, the MAP estimate approaches the MLE estimate for all possible priors. In other words, given enough data, the choice of prior is irrelevant.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": ", True.\n\nThe training error of the 1-nearest neighbor classifier depends on the number of training samples and the number of nearest neighbors. As the number of training samples grows to infinity, the training error approaches zero, but the number of nearest neighbors remains finite. Therefore, the choice of prior is still relevant, and the MAP estimate may not approach the MLE estimate for all possible priors."}
{"question": "When doing least-squares regression with regularisation (assuming that the optimisation can be done exactly), increasing the value of the regularisation parameter \u03bb the testing error.", "choices": [{"label": "A", "text": "will never decrease the training error."}, {"label": "B", "text": "will never increase the training error."}, {"label": "C", "text": "will never decrease the testing error."}, {"label": "D", "text": "will never increase"}], "answerKey": "A", "model_answer": "never decrease the training error."}
{"question": "Which of the following best describes what discriminative approaches try to model? (w are the parameters in the model)", "choices": [{"label": "A", "text": "p(y|x, w)"}, {"label": "B", "text": "p(y, x)"}, {"label": "C", "text": "p(w|x, w)"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": ", w)"}
{"question": "Statement 1| CIFAR-10 classification performance for convolution neural networks can exceed 95%. Statement 2| Ensembles of neural networks do not improve classification accuracy since the representations they learn are highly correlated.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "The correct answer is (A) True, True.\n\nBoth statements are true. Convolutional neural networks (CNNs) have achieved high classification performance in many computer vision tasks, including the CIFAR-10 dataset, and ensembling neural networks can lead to better classification accuracy. This is because the representations learned by the individual networks in an ensemble can be highly correlated, so combining them can lead to more diverse and accurate representations."}
{"question": "Which of the following points would Bayesians and frequentists disagree on?", "choices": [{"label": "A", "text": "The use of a non-Gaussian noise model in probabilistic regression."}, {"label": "B", "text": "The use of probabilistic modelling for regression."}, {"label": "C", "text": "The use of prior distributions on the parameters in a probabilistic model."}, {"label": "D", "text": "The use of class priors in Gaussian Discriminant Analysis."}], "answerKey": "C", "model_answer": "and frequentists would disagree on (C) The use of prior distributions on the parameters in a probabilistic model.\n\nFrequentists argue that prior information should not be included in the analysis because it is subjective and lacks a solid empirical basis, while Bayesians argue that prior information can be useful and can improve the accuracy of predictions. Frequentists would tend to avoid using prior distributions, while Bayesians would argue that they can be informative and can help to reduce the effects of overfitting."}
{"question": "Statement 1| The BLEU metric uses precision, while the ROGUE metric uses recall. Statement 2| Hidden markov models were frequently used to model English sentences.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "alse, True."}
{"question": "Statement 1| ImageNet has images of various resolutions. Statement 2| Caltech-101 has more images than ImageNet.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "D) False, True.\n\nExplanation: Statement 1 is True, as ImageNet has images of various resolutions. Statement 2 is False, as Caltech-101 has fewer images than ImageNet."}
{"question": "Which of the following is more appropriate to do feature selection?", "choices": [{"label": "A", "text": "Ridge"}, {"label": "B", "text": "Lasso"}, {"label": "C", "text": "both (a) and (b)"}, {"label": "D", "text": "neither (a) nor (b)"}], "answerKey": "B", "model_answer": "r (a) nor (b)\n\nExplanation: Feature selection is the process of selecting a subset of the most relevant features from a larger set of features. Ridge and Lasso are regularization techniques that can be used for feature selection, but they are not the best options. Ridge regression adds a penalty term to the linear regression equation to reduce the impact of high-variance features, while Lasso regression selects a subset of the features that have the largest coefficient values. However, these techniques do not take into account the importance of individual features, and they can lead to overfitting. The correct answer is neither (a) nor (b), which means that one should use a combination of domain knowledge, statistical methods, and visualizations to select the most relevant features."}
{"question": "Suppose you are given an EM algorithm that finds maximum likelihood estimates for a model with latent variables. You are asked to modify the algorithm so that it finds MAP estimates instead. Which step or steps do you need to modify?", "choices": [{"label": "A", "text": "Expectation"}, {"label": "B", "text": "Maximization"}, {"label": "C", "text": "No modification necessary"}, {"label": "D", "text": "Both"}], "answerKey": "B", "model_answer": "The correct answer is (D) Both.\n\nIn the context of an Expectation-Maximization (EM) algorithm that finds maximum likelihood estimates for a model with latent variables, we need to modify both the Expectation and Maximization steps to obtain MAP estimates.\n\nThe Expectation step involves computing the expected value of the latent variables given the observed data, which is used to update the posterior distribution of the latent variables in the subsequent Maximization step. To modify the Expectation step to obtain MAP estimates, we need to maximize the likelihood of the observed data given the values of the latent variables.\n\nThe Maximization step involves updating the posterior distribution of the latent variables by maximizing the likelihood of the observed data given the values of the latent variables. To modify the Maximization step to obtain MAP estimates, we need to maximize the log-likelihood of the observed data given the values of the latent variables.\n\nBy modifying both the Expectation and Maximization steps, we can obtain MAP estimates for the model with latent variables."}
{"question": "For a Gaussian Bayes classifier, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether we learn the class centers by Maximum Likelihood or Gradient Descent"}, {"label": "B", "text": "Whether we assume full class covariance matrices or diagonal class covariance matrices"}, {"label": "C", "text": "Whether we have equal class priors or priors estimated from the data"}, {"label": "D", "text": "Whether we allow classes to have different mean vectors or we force them to share the same mean vector"}], "answerKey": "B", "model_answer": ": (D) Whether we allow classes to have different mean vectors or we force them to share the same mean vector.\n\nThe choice of whether to allow classes to have different mean vectors or force them to share the same mean vector is the structural assumption that most affects the trade-off between underfitting and overfitting for a Gaussian Bayes classifier.\n\nThe other choices are not directly related to the Gaussian Bayes classifier or do not significantly affect the trade-off between underfitting and overfitting."}
{"question": "Statement 1| For any two variables x and y having joint distribution p(x, y), we always have H[x, y] \u2265 H[x] + H[y] where H is entropy function. Statement 2| For some directed graphs, moralization decreases the number of edges present in the graph.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "alse"}
{"question": "Which of the following is NOT supervised learning?", "choices": [{"label": "A", "text": "PCA"}, {"label": "B", "text": "Decision Tree"}, {"label": "C", "text": "Linear Regression"}, {"label": "D", "text": "Naive Bayesian"}], "answerKey": "A", "model_answer": ": The correct answer is (D) Naive Bayesian. Naive Bayes is a supervised learning algorithm used for classification, but it is not a type of supervised learning itself. It is a simple and fast algorithm that makes the assumption that the probability of each feature is independent of the others, which is a simplification of the Bayesian assumption."}
{"question": "Statement 1| A neural network's convergence depends on the learning rate. Statement 2| Dropout multiplies randomly chosen activation values by zero.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "The correct answer is (D) False, True.\n\nStatement 1 is false. A neural network's convergence depends on many factors, including the learning rate, the size and quality of the training data, and the architecture of the network. While the learning rate is an important hyperparameter that affects the speed and stability of the training process, it is not the only factor.\n\nStatement 2 is true. Dropout is a regularization technique that randomly sets some neuron activations to zero during training, which can help prevent overfitting. However, dropout does not multiply activation values by zero; instead, it sets some neurons to zero with a certain probability that is specified by the dropout rate."}
{"question": "Which one of the following is equal to P(A, B, C) given Boolean random variables A, B and C, and no independence or conditional independence assumptions between any of them?", "choices": [{"label": "A", "text": "P(A | B) * P(B | C) * P(C | A)"}, {"label": "B", "text": "P(C | A, B) * P(A) * P(B)"}, {"label": "C", "text": "P(A, B | C) * P(C)"}, {"label": "D", "text": "P(A | B, C) * P(B | A, C) * P(C | A, B)"}], "answerKey": "C", "model_answer": "B, C) * P(B | A, C) * P(C | A, B)\n\nExplanation:\nThe probability of an event A given that events B and C have occurred is equal to P(A | B, C) \\* P(B | A, C) \\* P(C | A, B).\nThe correct answer is (D), as it satisfies the given equation, and it is not conditional on any other variable or events, making it the only choice that does not depend on any conditional probabilities, making it the only choice that does not depend on any conditional probabilities, making it the only choice that does not depend on any conditional probabilities, making it the only choice that does not depend on any conditional probabilities, and making it the only choice that does not depend on any conditional probabilities."}
{"question": "Which of the following tasks can be best solved using Clustering.", "choices": [{"label": "A", "text": "Predicting the amount of rainfall based on various cues"}, {"label": "B", "text": "Detecting fraudulent credit card transactions"}, {"label": "C", "text": "Training a robot to solve a maze"}, {"label": "D", "text": "All of the above"}], "answerKey": "B", "model_answer": "ing the amount of rainfall based on various cues.\nB) Detecting fraudulent credit card transactions.\nC) Training a robot to solve a maze.\nD) All of the above.\n\nThe correct answer is (D) All of the above. Clustering can be used to solve different tasks, such as predicting rainfall, detecting fraudulent transactions, and training a robot to solve a maze."}
{"question": "After applying a regularization penalty in linear regression, you find that some of the coefficients of w are zeroed out. Which of the following penalties might have been used?", "choices": [{"label": "A", "text": "L0 norm"}, {"label": "B", "text": "L1 norm"}, {"label": "C", "text": "L2 norm"}, {"label": "D", "text": "either (a) or (b)"}], "answerKey": "D", "model_answer": "r (a) or (b)\n\nThe L1 and L2 penalties both belong to the family of regularization penalties. The L1 (Lasso) penalty is equivalent to the sum of the absolute values of the model coefficients being equal to a fixed value (lambda), while the L2 penalty is equivalent to adding a term to the cost function of the model that is equal to the sum of the squares of the model coefficients. The L0 penalty is a stronger form of regularization that involves setting all the coefficients to zero, which is not used in linear regression. Therefore, the correct answer is (D) either (a) or (b)."}
{"question": "A and B are two events. If P(A, B) decreases while P(A) increases, which of the following is true?", "choices": [{"label": "A", "text": "P(A|B) decreases"}, {"label": "B", "text": "P(B|A) decreases"}, {"label": "C", "text": "P(B) decreases"}, {"label": "D", "text": "All of above"}], "answerKey": "B", "model_answer": "The correct answer is (B) P(B|A) decreases.\n\nWhile it is true that P(A, B) decreases while P(A) increases, this does not necessarily mean that P(B|A) decreases. However, it is stated in the question that P(A, B) decreases while P(A) increases, which implies that the probability of both events occurring together (A and B) is decreasing while the probability of event A alone (P(A)) is increasing. Therefore, we can conclude that P(B|A) is decreasing, which means that the probability of event B given event A is decreasing. This suggests that there may be a negative relationship between event A and event B, or that event B is becoming less likely as event A becomes more likely. However, we cannot conclude that P(B) decreases or that both P(A|B) and P(B|A) decrease simultaneously, as these statements are not directly implied by the given information."}
{"question": "Statement 1| When learning an HMM for a fixed set of observations, assume we do not know the true number of hidden states (which is often the case), we can always increase the training data likelihood by permitting more hidden states. Statement 2| Collaborative filtering is often a useful model for modeling users' movie preference.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "You are training a linear regression model for a simple estimation task, and notice that the model is overfitting to the data. You decide to add in $\\ell_2$ regularization to penalize the weights. As you increase the $\\ell_2$ regularization coefficient, what will happen to the bias and variance of the model?", "choices": [{"label": "A", "text": "Bias increase ; Variance increase"}, {"label": "B", "text": "Bias increase ; Variance decrease"}, {"label": "C", "text": "Bias decrease ; Variance increase"}, {"label": "D", "text": "Bias decrease ; Variance decrease"}], "answerKey": "B", "model_answer": "ias increase; Variance increase\n\nExplanation: When we add $\\ell_2$ regularization to a linear regression model, it adds a penalty term to the objective function that we minimize. This penalty term is proportional to the sum of the squared values of the weights. As we increase the regularization coefficient, the penalty term becomes more important, and the model starts to favor smaller weights.\n\nThis has the effect of decreasing the magnitude of the weights, which in turn reduces the model's capacity to fit the training data precisely. This leads to an increase in the bias of the model, which is the difference between the predicted values and the true values in the training data.\n\nAt the same time, the regularization term also increases the variance of the model, which is the difference between the predicted values and the average predicted values over all the training data. This is because the model's capacity is reduced, and it becomes less able to fit the training data accurately.\n\nTherefore, the correct answer is (B) Bias increase; Variance increase."}
{"question": "Which PyTorch 1.8 command(s) produce $10\\times 5$ Gaussian matrix with each entry i.i.d. sampled from $\\mathcal{N}(\\mu=5,\\sigma^2=16)$ and a $10\\times 10$ uniform matrix with each entry i.i.d. sampled from $U[-1,1)$?", "choices": [{"label": "A", "text": "\\texttt{5 + torch.randn(10,5) * 16} ; \\texttt{torch.rand(10,10,low=-1,high=1)}"}, {"label": "B", "text": "\\texttt{5 + torch.randn(10,5) * 16} ; \\texttt{(torch.rand(10,10) - 0.5) / 0.5}"}, {"label": "C", "text": "\\texttt{5 + torch.randn(10,5) * 4} ; \\texttt{2 * torch.rand(10,10) - 1}"}, {"label": "D", "text": "\\texttt{torch.normal(torch.ones(10,5)*5,torch.ones(5,5)*16)} ; \\texttt{2 * torch.rand(10,10) - 1}"}], "answerKey": "C", "model_answer": "command(s)\n\nThe correct PyTorch 1.8 command(s) to produce a $10\\times 5$ Gaussian matrix with each entry i.i.d. sampled from $\\mathcal{N}(\\mu=5,\\sigma^2=16)$, and a $10\\times 10$ uniform matrix with each entry i.i.d. sampled from $U[-1,1)$, respectively, are:\n\n(D) \\texttt{torch.normal(torch.ones(10,5)*5,torch.ones(5,5)*16)} ; \\texttt{torch.rand(10,10,low=-1,high=1)}.\n\nTherefore, the correct answer is (D)."}
{"question": "Statement 1| The ReLU's gradient is zero for $x<0$, and the sigmoid gradient $\\sigma(x)(1-\\sigma(x))\\le \\frac{1}{4}$ for all $x$. Statement 2| The sigmoid has a continuous gradient and the ReLU has a discontinuous gradient.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "The correct answer is (A) True, True.\n\nHere's why:\nStatement 1 is true. The gradient of the ReLU function is zero for $x<0$, and the gradient of the sigmoid function is bounded by $\\sigma(x)(1-\\sigma(x))\\le \\frac{1}{4}$ for all $x$.\nStatement 2 is also true. The sigmoid function has a continuous gradient, and the ReLU function has a discontinuous gradient. Specifically, the ReLU function is defined as the product of a threshold function with a sigmoid function, which results in a discontinuous transition between 0 and 1.\nTherefore, the correct answer is (A) True, True."}
{"question": "Which is true about Batch Normalization?", "choices": [{"label": "A", "text": "After applying batch normalization, the layer\u2019s activations will follow a standard Gaussian distribution."}, {"label": "B", "text": "The bias parameter of affine layers becomes redundant if a batch normalization layer follows immediately afterward."}, {"label": "C", "text": "The standard weight initialization must be changed when using Batch Normalization."}, {"label": "D", "text": "Batch Normalization is equivalent to Layer Normalization for convolutional neural networks."}], "answerKey": "B", "model_answer": "The correct answer is (A) After applying batch normalization, the layer's activations will follow a standard Gaussian distribution."}
{"question": "Suppose we have the following objective function: $\\argmin_{w} \\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\gamma \\norm{w}^2_2$ What is the gradient of $\\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\lambda \\norm{w}^2_2$ with respect to $w$?", "choices": [{"label": "A", "text": "$\\nabla_w f(w) = (X^\\top X + \\lambda I)w - X^\\top y + \\lambda w$"}, {"label": "B", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + \\lambda$"}, {"label": "C", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + \\lambda w$"}, {"label": "D", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + (\\lambda+1) w$"}], "answerKey": "C", "model_answer": "lain why choice (A) is incorrect?"}
{"question": "Which of the following is true of a convolution kernel?", "choices": [{"label": "A", "text": "Convolving an image with $\\begin{bmatrix}1 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$ would not change the image"}, {"label": "B", "text": "Convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ would not change the image"}, {"label": "C", "text": "Convolving an image with $\\begin{bmatrix}1 & 1 & 1\\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}$ would not change the image"}, {"label": "D", "text": "Convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ would not change the image"}], "answerKey": "B", "model_answer": "Convolving an image with $\\begin{bmatrix}1 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$ would not change the image."}
{"question": "Which of the following is false?", "choices": [{"label": "A", "text": "Semantic segmentation models predict the class of each pixel, while multiclass image classifiers predict the class of entire image."}, {"label": "B", "text": "A bounding box with an IoU (intersection over union) equal to $96\\%$ would likely be considered at true positive."}, {"label": "C", "text": "When a predicted bounding box does not correspond to any object in the scene, it is considered a false positive."}, {"label": "D", "text": "A bounding box with an IoU (intersection over union) equal to $3\\%$ would likely be considered at false negative."}], "answerKey": "D", "model_answer": "nding box with an IoU (intersection over union) equal to $3\\%$ would likely be considered at false negative.\n\nA bounding box with an IoU equal to $3\\%$ would be considered a false negative, which means that the model's prediction of the object's location is far off from the actual location."}
{"question": "Which of the following is false?", "choices": [{"label": "A", "text": "The following fully connected network without activation functions is linear: $g_3(g_2(g_1(x)))$, where $g_i(x) = W_i x$ and $W_i$ are matrices."}, {"label": "B", "text": "Leaky ReLU $\\max\\{0.01x,x\\}$ is convex."}, {"label": "C", "text": "A combination of ReLUs such as $ReLU(x) - ReLU(x-1)$ is convex."}, {"label": "D", "text": "The loss $\\log \\sigma(x)= -\\log(1+e^{-x})$ is concave"}], "answerKey": "C", "model_answer": "The correct answer is (D) The loss $\\log \\sigma(x)= -\\log(1+e^{-x})$ is concave.\n\nWhile (A) is true, (B) is false, and (C) is false, (D) is false. The loss function should be concave if we want to have a well-behaved optimization problem. Convexity ensures that the optimization problem has a unique global minimum, while concavity ensures that this minimum is the global minimum."}
{"question": "We are training fully connected network with two hidden layers to predict housing prices. Inputs are $100$-dimensional, and have several features such as the number of square feet, the median family income, etc. The first hidden layer has $1000$ activations. The second hidden layer has $10$ activations. The output is a scalar representing the house price. Assuming a vanilla network with affine transformations and with no batch normalization and no learnable parameters in the activation function, how many parameters does this network have?", "choices": [{"label": "A", "text": "111021"}, {"label": "B", "text": "110010"}, {"label": "C", "text": "111110"}, {"label": "D", "text": "110011"}], "answerKey": "A", "model_answer": "111021\n\nThe number of parameters in this fully connected network can be calculated as follows:\n\n* The number of inputs (features) is 100.\n* The number of activations in the first hidden layer is 1000, which means each activation has 100 parameters.\n* The number of activations in the second hidden layer is 10, which means each activation has 10 parameters.\n* The output is a scalar representing the house price, which means the output layer has 1 parameter.\n\nTherefore, the total number of parameters in the network is 100 + 1000 \\* 10 + 10 \\* 10 = 111021. Answer (A) is correct."}
{"question": "Statement 1| The derivative of the sigmoid $\\sigma(x)=(1+e^{-x})^{-1}$ with respect to $x$ is equal to $\\text{Var}(B)$ where $B\\sim \\text{Bern}(\\sigma(x))$ is a Bernoulli random variable. Statement 2| Setting the bias parameters in each layer of neural network to 0 changes the bias-variance trade-off such that the model's variance increases and the model's bias decreases", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": ""}
