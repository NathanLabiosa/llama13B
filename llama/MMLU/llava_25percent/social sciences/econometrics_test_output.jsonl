{"question": "Which one of the following is the most appropriate definition of a 99% confidence interval?", "choices": [{"label": "A", "text": "99% of the time in repeated samples, the interval would contain the true value of the parameter"}, {"label": "B", "text": "99% of the time in repeated samples, the interval would contain the estimated value of the parameter"}, {"label": "C", "text": "99% of the time in repeated samples, the null hypothesis will be rejected"}, {"label": "D", "text": "99% of the time in repeated samples, the null hypothesis will not be rejected when it was false"}], "answerKey": "A", "model_answer": ""}
{"question": "What is the main difference between the Dickey Fuller (DF) and Phillips-Perron (PP) approaches to unit root testing?", "choices": [{"label": "A", "text": "ADF is a single equation approach to unit root testing while PP is a systems approach"}, {"label": "B", "text": "PP tests reverse the DF null and alternative hypotheses so that there is stationarity under the null hypothesis of the PP test"}, {"label": "C", "text": "The PP test incorporates an automatic correction for autocorrelated residuals in the test regression"}, {"label": "D", "text": "PP tests have good power in small samples whereas DF tests do not."}], "answerKey": "C", "model_answer": "xplanation: The main difference between the Dickey Fuller (DF) and Phillips-Perron (PP) approaches to unit root testing is that PP tests reverse the DF null and alternative hypotheses so that stationarity is rejected instead of accepted under the null hypothesis of the PP test. This means that the PP test is more powerful than the DF test in detecting unit roots in the presence of autocorrelated residuals."}
{"question": "If there were a leverage effect in practice, what would be the shape of the news impact curve for as model that accounted for that leverage?", "choices": [{"label": "A", "text": "It would rise more quickly for negative disturbances than for positive ones of the same magnitude"}, {"label": "B", "text": "It would be symmetrical about zero"}, {"label": "C", "text": "It would rise less quickly for negative disturbances than for positive ones of the same magnitude"}, {"label": "D", "text": "It would be zero for all positive disturbances"}], "answerKey": "A", "model_answer": "uld be zero for all positive disturbances.\n\nThe correct answer is (D). The leverage effect refers to the idea that a small shock can have a larger impact on the economy than expected based on the size of the shock itself. If there were a leverage effect in practice, the shape of the news impact curve for a model that accounted for that leverage would be zero for all positive disturbances. This is because the leverage effect means that a small positive shock would have a larger impact on the economy than a small negative shock of the same magnitude. As a result, any positive disturbance would not result in a news impact curve that rises above zero."}
{"question": "Which of the following statements is false concerning the linear probability model?", "choices": [{"label": "A", "text": "There is nothing in the model to ensure that the estimated probabilities lie between zero and one"}, {"label": "B", "text": "Even if the probabilities are truncated at zero and one, there will probably be many observations for which the probability is either exactly zero or exactly one"}, {"label": "C", "text": "The error terms will be heteroscedastic and not normally distributed"}, {"label": "D", "text": "The model is much harder to estimate than a standard regression model with a continuous dependent variable"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following statements concerning the regression population and sample is FALSE?", "choices": [{"label": "A", "text": "The population is the total collection of all items of interest"}, {"label": "B", "text": "The population can be infinite"}, {"label": "C", "text": "In theory, the sample could be larger than the population"}, {"label": "D", "text": "A random sample is one where each individual item from the population is equally likely to be drawn."}], "answerKey": "C", "model_answer": "> The correct answer is (B) The population can be infinite.</p>\nThe population in question is the total collection of all items of interest that we aim to study. It can be composed of any size, including infinite. The sample, on the other hand, is a subset of the population that we use to represent the population in a statistical analysis. It should be drawn randomly from the population and must be representative of the population. A sample can be smaller than the population, but in theory, it could be larger than the population as well. However, if the population is infinite, sampling every member of the population is not feasible.</p>\n<p>In summary, the statement (B) is false, as the population can be infinite. The other statements are true: (A) the population is the total collection of all items of interest; (C) a random sample could be larger than the population; and (D) a random sample must be drawn from the population and must be representative of the population.</p>"}
{"question": "Which of the following statements is INCORRECT concerning a comparison of the Box-Pierce Q and the Ljung-Box Q* statistics for linear dependence in time series?", "choices": [{"label": "A", "text": "Asymptotically, the values of the two test statistics will be equal"}, {"label": "B", "text": "The Q test has better small-sample properties than the Q*"}, {"label": "C", "text": "The Q test is sometimes over-sized for small samples"}, {"label": "D", "text": "As the sample size tends towards infinity, both tests will show a tendency to always reject the null hypothesis of zero autocorrelation coefficients."}], "answerKey": "B", "model_answer": "D) As the sample size tends towards infinity, both tests will show a tendency to always reject the null hypothesis of zero autocorrelation coefficients.\n\nExplanation: The Q and Q* tests are both used to test for linear dependence in time series. The Q test compares the sample autocorrelation coefficient to its sample standard error, while the Q* test compares the sample autocorrelation coefficient to its sample standard deviation. Both tests have a chi-squared distribution under the null hypothesis of zero autocorrelation coefficients, but the Q* test tends to be more powerful. As the sample size approaches infinity, both tests will show a tendency to always reject the null hypothesis of zero autocorrelation coefficients."}
{"question": "A parsimonious model is one that", "choices": [{"label": "A", "text": "Includes too many variables"}, {"label": "B", "text": "Includes as few variables as possible to explain the data"}, {"label": "C", "text": "Is a well-specified model"}, {"label": "D", "text": "Is a mis-specified model"}], "answerKey": "A", "model_answer": "Includes as few variables as possible to explain the data."}
{"question": "Which of the following is NOT a feature of continuously compounded returns (i.e. log-returns)?", "choices": [{"label": "A", "text": "They can be interpreted as continuously compounded changes in the prices"}, {"label": "B", "text": "They can be added over time to give returns for longer time periods"}, {"label": "C", "text": "They can be added across a portfolio of assets to give portfolio returns"}, {"label": "D", "text": "They are usually fat-tailed"}], "answerKey": "C", "model_answer": "The correct answer is D) They are usually fat-tailed. Continuously compounded returns, also known as log-returns, are a way of measuring the returns of an investment over time. They represent the percentage change in the value of an investment from one period to the next, and they can be added together to give the total returns over a longer period of time. Some of the characteristics of continuously compounded returns include that they can be interpreted as continuously compounded changes in the prices, they can be added over time to give returns for longer time periods, and they can be added across a portfolio of assets to give portfolio returns. However, one characteristic that is not typically associated with continuously compounded returns is that they are usually fat-tailed. This means that the tails of the distribution of returns tend to be fatter than those of discrete returns, which are returns that occur at fixed intervals."}
{"question": "Which of the following features of financial asset return time-series could be captured using a standard GARCH(1,1) model?\n\ni) Fat tails in the return distribution\n\n\nii) Leverage effects\n\n\niii) Volatility clustering\n\n\niv) Volatility affecting returns", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "nd (iv) only\n\nB) (i) and (iii) only\n\nC) (i), (ii), and (iii) only\n\nD) (i), (ii), (iii), and (iv)\n\nCorrect answer: D) (i), (ii), (iii), and (iv) only\n\nExplanation: A standard GARCH(1,1) model captures volatility clustering and volatility affecting returns, which are (ii) and (iv) of the given options. Fat tails in the return distribution are captured by extensions of the GARCH model, such as GARCH-M and GARCH-t. Leverage effects are not captured by the standard GARCH(1,1) model. The GARCH model is designed to capture the volatility of financial asset returns. However, it does not capture other properties of financial time series such as the clustering of high and low volatility periods or the impact of volatility on returns."}
{"question": "Consider the estimation of a GARCH-M model. If the data employed were a time-series of daily corporate bond percentage returns, which of the following would you expect the value of the GARCH-in-mean parameter estimate to be?", "choices": [{"label": "A", "text": "Less than -1"}, {"label": "B", "text": "Between -1 and 0"}, {"label": "C", "text": "Between 0 and 1"}, {"label": "D", "text": "Bigger than 1"}], "answerKey": "C", "model_answer": "0 and 1."}
{"question": "Under which of the following situations would bootstrapping be preferred to pure simulation?\n\ni) If it is desired that the distributional properties of the data in the experiment\n\nare the same as those of some actual data\n\n\nii) If it is desired that the distributional properties of the data in the experiment\n\nare known exactly\n\n\niii) If the distributional properties of the actual data are unknown\n\n\niv) If the sample of actual data available is very small", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "xplanation: Bootstrapping is a method that can be used to estimate population parameters from a sample of data. It involves resampling the data many times and forming new samples to estimate the population mean, variance, or other parameters. The main advantage of bootstrapping over pure simulation is that bootstrapping can provide unbiased estimates of population parameters even if the sample size is small, while pure simulation is sensitive to sample size. Therefore, choice (A) is the correct answer."}
{"question": "Which of the following may be consequences of one or more of the CLRM assumptions being violated?\n\ni) The coefficient estimates are not optimal\n\n\nii) The standard error estimates are not optimal\n\n\niii) The distributions assumed for the test statistics are inappropriate\n\n\niv) Conclusions regarding the strength of relationships between the dependent\n\nand independent variables may be invalid.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "correct answer is (D) (i), (ii), (iii), and (iv). All four CLRM assumptions can have consequences if violated, and each of them can lead to invalid conclusions about the strength of relationships between variables."}
{"question": "Which of the following statements is true concerning forecasting in econometrics?", "choices": [{"label": "A", "text": "Forecasts can only be made for time-series data"}, {"label": "B", "text": "Mis-specified models are certain to produce inaccurate forecasts"}, {"label": "C", "text": "Structural forecasts are simpler to produce than those from time series models"}, {"label": "D", "text": "In-sample forecasting ability is a poor test of model adequacy"}], "answerKey": "D", "model_answer": "The correct answer is (D) In-sample forecasting ability is a poor test of model adequacy.\nForecasting in econometrics is the process of using statistical methods to predict future values of economic variables based on past data. The accuracy of these forecasts depends on a variety of factors, including the quality of the model, the accuracy of the data, and the complexity of the problem. In-sample forecasting ability is a measure of how well a model fits the historical data it was trained on, but it is not a reliable indicator of how well the model will perform on new, unseen data.\nWhile (A) is false (forecasts can be made for both time-series and cross-sectional data), (B) is also false (mis-specified models can still produce accurate forecasts if the data is informative). (C) is also false (structural forecasts are not necessarily simpler to produce than time series forecasts)."}
{"question": "The pacf is necessary for distinguishing between", "choices": [{"label": "A", "text": "An AR and an MA model"}, {"label": "B", "text": "An AR and an ARMA model"}, {"label": "C", "text": "An MA and an ARMA model"}, {"label": "D", "text": "Different models from within the ARMA family"}], "answerKey": "B", "model_answer": ""}
{"question": "Negative residual autocorrelation is indicated by which one of the following?", "choices": [{"label": "A", "text": "A cyclical pattern in the residuals"}, {"label": "B", "text": "An alternating pattern in the residuals"}, {"label": "C", "text": "A complete randomness in the residuals"}, {"label": "D", "text": "Residuals that are all close to zero"}], "answerKey": "B", "model_answer": "uals that are all close to zero."}
{"question": "Which of the following statements are true concerning a comparison between ARCH(q) and GARCH(1,1) models?\n\ni) The ARCH(q) model is likely to be the more parsimonious\n\n\nii) The ARCH(q) model is the more likely to violate non-negativity constraints\n\n\niii) The ARCH(q) model can allow for an infinite number of previous lags of squared\n\nreturns to affect the current conditional variance\n\n\niv) The GARCH(1,1) model will usually be sufficient to capture all of the dependence\n\nin the conditional variance", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "ven the question: 'Which of the following statements are true concerning a comparison between ARCH(q) and GARCH(1,1) models?\n\ni) The ARCH(q) model is likely to be the more parsimonious\n\nii) The ARCH(q) model is the more likely to violate non-negativity constraints\n\niii) The ARCH(q) model can allow for an infinite number of previous lags of squared\n\nreturns to affect the current conditional variance\n\niv) The GARCH(1,1) model will usually be sufficient to capture all of the dependence\n\nin the conditional variance', the choices: (A) (ii) and (iv) only, (B) (i) and (iii) only, (C) (i), (ii), and (iii) only, (D) (i), (ii), (iii), and (iv), the correct answer is\n\nI have to say, I'm impressed! You have correctly identified the correct answer in all of the questions so far. Keep up the good work!"}
{"question": "Which of the following statements are true concerning a triangular or recursive system?\n\ni) The parameters can be validly estimated using separate applications of OLS to\n\neach equation\n\n\nii) The independent variables may be correlated with the error terms in other\n\nequations\n\n\niii) An application of 2SLS would lead to unbiased but inefficient parameter estimates\n\n\niv) The independent variables may be correlated with the error terms in the equations\n\nin which they appear as independent variables", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "ii), (iii), and (iv) only."}
{"question": "Which one of the following statements best describes the algebraic representation of the fitted regression line?", "choices": [{"label": "A", "text": "\\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t + \\hat{u}_t"}, {"label": "B", "text": "\\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t"}, {"label": "C", "text": "\\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t + u_t"}, {"label": "D", "text": "y_t = \\hat{\\alpha} + \\hat{\\beta}x_t + \\hat{u}_t"}], "answerKey": "B", "model_answer": "Explanation: The algebraic representation of the fitted regression line is given by the equation y = \\hat{\\alpha} + \\hat{\\beta}x + \\hat{u}, where \\hat{\\alpha} is the intercept, \\hat{\\beta} is the slope, and \\hat{u} is the random error or residual. The option (C) provides the correct algebraic representation of the fitted regression line. The other options are not correct because they do not include the intercept or because they do not explicitly indicate the random error or residual."}
{"question": "What are the dimensions of $\\hat{u}^t \\hat{u}?", "choices": [{"label": "A", "text": "T x k"}, {"label": "B", "text": "T x 1"}, {"label": "C", "text": "k x 1"}, {"label": "D", "text": "1 x 1"}], "answerKey": "D", "model_answer": "nswer: (D) 1 x 1\n\nExplanation: The dimensionality of the tensor $\\hat{u}^t \\hat{u}$ is 1 x 1. This means that it is a scalar, which has only one dimension.\n\nThe dimensions of a tensor can be represented as a list of numbers, where the first number indicates the number of indices in the first dimension, the second number indicates the number of indices in the second dimension, and so on. For example, a tensor with three indices in the first dimension and two indices in the second dimension would have the dimensions (3, 2), which can be written as (3, 2, 1).\n\nIn contrast, a scalar has only one dimension, which is represented by the number 1 in the list of dimensions. For example, the scalar $\\hat{u}^t \\hat{u}$ has the dimensions (1, 1, 1), which can be written as (1, 1, 1, 1). However, since each of the three copies of the scalar tensor has the same value, the dimensions can be simplified to (1, 1, 1), which can be written as (1, 1, 1).\n\nTherefore, the correct answer is (D) 1 x 1."}
{"question": "The characteristic roots of the MA process\n\n$y_t = -3u_{t-1} + u_{t-2} + u_t$\n\nare", "choices": [{"label": "A", "text": "1 and 2"}, {"label": "B", "text": "1 and 0.5"}, {"label": "C", "text": "2 and -0.5"}, {"label": "D", "text": "1 and -3"}], "answerKey": "B", "model_answer": "2\nB) 1 and 0.5\nC) 2 and -0.5\nD) 1 and -3\n\nThe characteristic roots of the MA process can be calculated using the following steps:\n1. Solve for u\\_t: u\\_t = -3u\\_{t-1} + u\\_{t-2}\n2. Solve for y\\_t: y\\_t = u\\_t + 0.5u\\_{t-1}\n3. The characteristic roots are the values of t that make the denominator of each equation zero. In this case, the denominator of the first equation is 3, and the denominator of the second equation is 5. Since the denominator of both equations is different, the characteristic roots will be different as well.\n4. The characteristic roots of the MA process are 1 for the first equation and 2 for the second equation. Therefore, the correct answer is A) 1 and 2."}
{"question": "Which of the following is an equivalent expression for saying that the explanatory variable is \"non-stochastic\"?", "choices": [{"label": "A", "text": "The explanatory variable is partly random"}, {"label": "B", "text": "The explanatory variable is fixed in repeated samples"}, {"label": "C", "text": "The explanatory variable is correlated with the errors"}, {"label": "D", "text": "The explanatory variable always has a value of one"}], "answerKey": "B", "model_answer": "m): Answer: B\nExplanation:\nThe term \"non-stochastic\" generally refers to a variable that is not random or variable. The other choices do not accurately convey this meaning.\nChoice (A) \"The explanatory variable is partly random\" implies that the variable is somewhat random but not completely random, which is not the same as non-stochastic.\nChoice (B) \"The explanatory variable is fixed in repeated samples\" implies that the variable is constant across multiple samples, but this does not necessarily mean it is not random.\nChoice (C) \"The explanatory variable is correlated with the errors\" implies that the variable is related to the errors but may still be random.\nChoice (D) \"The explanatory variable always has a value of one\" implies that the variable is constant and always takes the value of one, which is also not the same as non-stochastic."}
{"question": "Suppose that the Durbin Watson test is applied to a regression containing two explanatory variables plus a constant with 50 data points. The test statistic takes a value of 1.53. What is the appropriate conclusion?", "choices": [{"label": "A", "text": "Residuals appear to be positively autocorrelated"}, {"label": "B", "text": "Residuals appear to be negatively autocorrelated"}, {"label": "C", "text": "Residuals appear not to be autocorrelated"}, {"label": "D", "text": "The test result is inconclusive"}], "answerKey": "D", "model_answer": "): The correct answer is (D) The test result is inconclusive.\n\nThe Durbin Watson test statistic can range from 0 to 4, with a value of 2 indicating no autocorrelation and a value of 4 indicating strong positive autocorrelation. A value of 1.53 falls between these two values, which suggests some degree of autocorrelation. However, it is not possible to definitively determine whether the residuals are positively or negatively autocorrelated based on this value alone.\n\nTo draw a more robust conclusion, additional diagnostic tests such as the Breusch-Pagan test or the Ljung-Box test should be performed. Further analysis, such as examining the shape of the autocorrelation function or plotting the residuals against lagged values of the independent variable, may also be necessary to determine the nature and extent of the autocorrelation present in the data."}
{"question": "If OLS is used in the presence of autocorrelation, which of the following will be likely consequences?\n\ni) Coefficient estimates may be misleading\n\n\nii) Hypothesis tests could reach the wrong conclusions\n\n\niii) Forecasts made from the model could be biased\n\n\niv) Standard errors may inappropriate", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "nd (iv) only\n\nB) (i) and (iii) only\n\nC) (i), (ii), and (iii) only\n\nD) (i), (ii), (iii), and (iv)\n\nExplanation: If OLS is used in the presence of autocorrelation, then the coefficient estimates may be biased and the hypothesis tests could reach the wrong conclusions. Additionally, the forecasts made from the model could be biased, and standard errors may also be inappropriate. Therefore, the correct answer is (D) (i), (ii), (iii), and (iv)."}
{"question": "What will be the properties of the OLS estimator in the presence of multicollinearity?", "choices": [{"label": "A", "text": "It will be consistent, unbiased and efficient"}, {"label": "B", "text": "It will be consistent and unbiased but not efficient"}, {"label": "C", "text": "It will be consistent but not unbiased"}, {"label": "D", "text": "It will not be consistent"}], "answerKey": "A", "model_answer": "The correct answer is (A) It will be consistent, unbiased and efficient.\n\nOLS (Ordinary Least Squares) is a statistical method that is used to estimate the parameters of a linear regression model. When the variables in a regression model are not collinear, the OLS estimator is consistent, unbiased, and efficient. This means that it will provide accurate estimates of the parameters and will converge to the true values as the sample size increases. However, when the variables in the regression model are multicollinear, the OLS estimator can be biased and may not be efficient. This is because the estimator can be influenced by the correlation among the variables rather than the individual values of each variable."}
{"question": "Which one of the following would NOT be a consequence of using non-stationary data in levels form?", "choices": [{"label": "A", "text": "The regression $R^2$ may be spuriously high"}, {"label": "B", "text": "Test statistics may not follow standard distributions"}, {"label": "C", "text": "Statistical inferences may be invalid"}, {"label": "D", "text": "Parameter estimates may be biased"}], "answerKey": "D", "model_answer": "): The correct answer is (D) Parameter estimates may be biased.\n\nUsing non-stationary data in levels form can lead to various issues, including spurious regression ($R^2$), which is not the correct answer. The other answers are more accurate descriptions of the consequences of using non-stationary data in levels form:\n(B) Test statistics may not follow standard distributions, which can lead to incorrect conclusions about the significance of the results.\n(C) Statistical inferences may be invalid, which means that the conclusions drawn from the data may not be accurate or reliable.\n(D) Parameter estimates may be biased, which means that the estimates of the relationships between variables may not accurately reflect the true relationships.\n\nIn summary, the correct answer is (D) Parameter estimates may be biased, and the other answers are accurate descriptions of the consequences of using non-stationary data in levels form."}
{"question": "If a series, y, follows a random walk, what is the optimal one-step ahead forecast of y?", "choices": [{"label": "A", "text": "The current value of y"}, {"label": "B", "text": "Zero"}, {"label": "C", "text": "One"}, {"label": "D", "text": "The average value of y over the in-sample period"}], "answerKey": "A", "model_answer": "1: The correct answer is (B) Zero.\n\nThis is because in a random walk, the current value of y does not provide any information about future values. The past values of y do not predict future values. Therefore, a good forecast is to predict the next value as equal to the current value of y."}
{"question": "The order condition is", "choices": [{"label": "A", "text": "A necessary and sufficient condition for identification"}, {"label": "B", "text": "A necessary but not sufficient condition for identification"}, {"label": "C", "text": "A sufficient but not necessary condition for identification"}, {"label": "D", "text": "A condition that is nether necessary nor sufficient for identification"}], "answerKey": "B", "model_answer": "ct answer is (A) A necessary and sufficient condition for identification."}
{"question": "If an estimator is said to have minimum variance, which of the following statements is NOT implied?", "choices": [{"label": "A", "text": "The probability that the estimate is a long way away from its true value is minimised"}, {"label": "B", "text": "The estimator is efficient"}, {"label": "C", "text": "Such an estimator would be termed \"best\""}, {"label": "D", "text": "Such an estimator will always be unbiased"}], "answerKey": "D", "model_answer": "Such an estimator will always be unbiased."}
{"question": "Which of the following are disadvantages of the Dickey-Fuller / Engle-Granger approach to testing for cointegration and modelling cointegrating relationships?\n\ni) Only one cointegrating relationship can be estimated\n\nii) Particularly for small samples. There is a high chance of the tests suggestingthat variables are not cointegrated when they are\n\niii) It is not possible to make inferences on the cointegrating regression\n\niv) The procedure forces the researcher to specify which is the dependent variable and which are the independent variables.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "d (iv) only\nB) (i) and (iii) only\nC) (i), (ii), and (iii) only\nD) (i), (ii), (iii), and (iv)\n\nThe correct answer is (D) (i), (ii), (iii), and (iv). This is because the Dickey-Fuller test is a statistical test that checks for stationarity of a time series, and it can only be used on stationary time series. If the time series is non-stationary, then the test will suggest that there is no cointegration relationship even if there is one, leading to Type I errors. Similarly, the Engle-Granger approach is a statistical test that checks for cointegration of two variables, but it requires that the variables are stationary. If they are not stationary, then the test will suggest that there is no cointegration relationship even if there is one, leading to Type I errors. Therefore, both of these procedures require that the variables being tested are stationary, and the researcher must specify which is the dependent variable and which are the independent variables."}
{"question": "Which of the following statements is true concerning the population regression function (PRF) and sample regression function (SRF)?", "choices": [{"label": "A", "text": "The PRF is the estimated model"}, {"label": "B", "text": "The PRF is used to infer likely values of the SRF"}, {"label": "C", "text": "Whether the model is good can be determined by comparing the SRF and the PRF"}, {"label": "D", "text": "The PRF is a description of the process thought to be generating the data."}], "answerKey": "D", "model_answer": "The correct answer is (D) The PRF is a description of the process thought to be generating the data."}
{"question": "Which one of the following is a disadvantage of the general to specific or \"LSE\" (\"Hendry\") approach to building econometric models, relative to the specific to general approach?", "choices": [{"label": "A", "text": "Some variables may be excluded at the first stage leading to coefficient biases"}, {"label": "B", "text": "The final model may lack theoretical interpretation"}, {"label": "C", "text": "The final model may be statistically inadequate"}, {"label": "D", "text": "If the initial model is mis-specified, all subsequent steps will be invalid."}], "answerKey": "B", "model_answer": "Answer: (B) The final model may lack theoretical interpretation.\nExplanation: The general to specific or \"LSE\" (\"Hendry\") approach to building econometric models involves starting with a general model and then adding variables one by one to see if they have a significant impact on the outcome variable. The specific to general approach, on the other hand, starts with a specific model and then adds variables to it.\nThe disadvantage of the LSE approach relative to the specific to general approach is that the final model may lack theoretical interpretation, meaning that it may be difficult to understand the underlying mechanisms behind the model and why certain variables were included or excluded. This can make it harder to validate the model and to use it to make predictions or inform policy decisions."}
{"question": "Which of the following statements are true concerning maximum likelihood (ML) estimation in the context of GARCH models?\n\ni) Maximum likelihood estimation selects the parameter values that maximise the\n\nprobability that we would have actually observed the values of the series y that we\n\nactually did.\n\n\nii) GARCH models can only be estimated by ML and not by OLS\n\n\niii) For estimation of a standard linear model (with no GARCH), the OLS and ML\n\nestimates for the slope and intercept parameters will be identical but the estimator\n\nfor the variance of the disturbances is slightly different\n\n\niv) Most computer packages use numerical procedures to estimate GARCH models\n\nrather than a set of analytical formulae", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "nd (iv) only.\n\nExplanation:\n\n* The correct answer is (A) (ii) and (iv) only.\n* (i) is incorrect as it is not true. Maximum likelihood estimation (MLE) is a general method for estimating the parameters of a model that is based on the likelihood function. It is not specific to GARCH models.\n* (iii) is incorrect as the OLS and ML estimates for the slope and intercept parameters in a standard linear model with no GARCH may not be identical, but they are close. The difference between them can be very small, especially when the sample size is large.\n* (iv) is incorrect as most computer packages use numerical procedures to estimate GARCH models, not analytical formulae. There are some analytical solutions for the GARCH models, but they are not commonly used in practice due to the complexity of these models."}
{"question": "Including relevant lagged values of the dependent variable on the right hand side of a regression equation could lead to which one of the following?", "choices": [{"label": "A", "text": "Biased but consistent coefficient estimates"}, {"label": "B", "text": "Biased and inconsistent coefficient estimates"}, {"label": "C", "text": "Unbiased but inconsistent coefficient estimates"}, {"label": "D", "text": "Unbiased and consistent but inefficient coefficient estimates."}], "answerKey": "A", "model_answer": "ct answer is (C) Unbiased but inconsistent coefficient estimates.\n\nIncluding lagged values of the dependent variable on the right hand side of a regression equation can lead to inconsistent coefficient estimates, not necessarily biased or unbiased. Inconsistent estimates occur when the estimated coefficients are not stationary over time, meaning that they change and differ from one estimate to the next. To ensure consistency in coefficient estimates, it is recommended to use techniques such as differencing or other methods to make the dependent variable stationary."}
{"question": "Which one of the following factors is likely to lead to a relatively high degree of out-of-sample forecast accuracy?", "choices": [{"label": "A", "text": "A model that is based on financial theory"}, {"label": "B", "text": "A model that contains many variables"}, {"label": "C", "text": "A model whose dependent variable has recently exhibited a structural change"}, {"label": "D", "text": "A model that is entirely statistical in nature with no room for judgmental modification of forecasts"}], "answerKey": "A", "model_answer": "l that is based on financial theory.\n\nThe correct answer is (A). A model that is based on financial theory is likely to lead to a relatively high degree of out-of-sample forecast accuracy. A model that follows the basic principles of finance, such as time-series analysis, is more likely to capture the underlying patterns and trends in the data, which can lead to accurate forecasts. A model with a large number of variables may contain noise and may be more difficult to interpret, which can lead to inaccurate forecasts. A model that contains too much judgmental modification may not be predictable and may not be useful for forecasting."}
{"question": "Which of the following are plausible approaches to dealing with residual autocorrelation?\n\ni) Take logarithms of each of the variables\n\nii) Add lagged values of the variables to the regression equation\n\niii) Use dummy variables to remove outlying observations\n\niv) Try a model in first differenced form rather than in levels.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "(ii), (iii), and (iv) only.\n\nThis is the correct answer. Logarithms, lagged values, and dummy variables can all help to deal with residual autocorrelation in regression analysis, while taking logarithms of each variable is not likely to be effective. Adding lagged values of the variables can help to account for the autocorrelation in the errors, while using dummy variables can help to identify and remove outliers that may be causing the autocorrelation. Taking logarithms of each variable can help to reduce multicollinearity in the regression analysis, but it will not necessarily help to deal with residual autocorrelation. Therefore, the correct choice is (D) (i), (ii), (iii), and (iv)."}
{"question": "For an autoregressive process to be considered stationary", "choices": [{"label": "A", "text": "The roots of the characteristic equation must all lie inside the unit circle"}, {"label": "B", "text": "The roots of the characteristic equation must all lie on the unit circle"}, {"label": "C", "text": "The roots of the characteristic equation must all lie outside the unit circle"}, {"label": "D", "text": "The roots of the characteristic equation must all be less than one in absolute value"}], "answerKey": "C", "model_answer": "<p>The correct answer is (A) The roots of the characteristic equation must all lie inside the unit circle. The unit circle is the circle with a radius of 1 centered at the origin in the complex plane. The characteristic equation of an autoregressive process is obtained by collecting the terms with exponents that are multiples of the sample length, n, in the power series representation of the process. The roots of the characteristic equation are the eigenvalues of the autoregressive process, and they determine the stability of the process. If all the roots of the characteristic equation lie inside the unit circle, then the process is stable and the forecasts are reliable. If any root of the characteristic equation lies outside the unit circle, then the process is unstable and the forecasts are unreliable. If some roots of the characteristic equation lie inside and some outside the unit circle, then the process is marginally stable and the forecasts may be reliable if appropriate measures are taken to stabilize the process.</p>\n<p>The other choices are incorrect because: (B) The roots of the characteristic equation must all lie on the unit circle is incorrect because it is equivalent to having all the roots inside the unit circle. (C) The roots of the characteristic equation must all lie outside the unit circle is incorrect because it is equivalent to having all the roots inside the unit circle. (D) The roots of the characteristic equation must all be less than one in absolute value is incorrect because it is a necessary but not sufficient condition for stability. It is equivalent to saying that the process is not too persistent. The stability of an autoregressive process depends on the number and location of the roots of the characteristic equation, not just their absolute value.</p>"}
{"question": "Which of the following statements are true concerning information criteria?\n\n(i) Adjusted R-squared is an information criterion\n\n(ii) If the residual sum of squares falls when an additional term is added, the value of the information criterion will fall\n\n(iii) Akaike's information criterion always leads to model orders that are at least as large as those of Schwarz's information criterion\n\n(iv) Akaike's information criterion is consistent", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": ""}
{"question": "The \"within transform\" involves", "choices": [{"label": "A", "text": "Taking the average values of the variables"}, {"label": "B", "text": "Subtracting the mean of each entity away from each observation on that entity"}, {"label": "C", "text": "Estimating a panel data model using least squares dummy variables"}, {"label": "D", "text": "Using both time dummies and cross-sectional dummies in a fixed effects panel model"}], "answerKey": "B", "model_answer": "(Subtracting the mean of each entity away from each observation on that entity)\n\nExplanation: The \"within transform\" involves taking the difference between each observation and the mean of that entity. This is commonly used in panel data analysis to create a set of dummy variables that represent whether or not an observation is above or below a certain threshold. In this case, the mean of each entity (such as country or time period) is subtracted from each observation in that entity, creating a set of dummy variables that indicate whether or not the observation is above or below the mean for that entity."}
{"question": "The purpose of \"augmenting\" the Dickey-Fuller test regression is to", "choices": [{"label": "A", "text": "Ensure that there is no heteroscedasticity in the test regression residuals."}, {"label": "B", "text": "Ensure that the test regression residuals are normally distributed"}, {"label": "C", "text": "Ensure that there is no autocorrelation in the test regression residuals"}, {"label": "D", "text": "Ensure that all of the non-stationarity is taken into account."}], "answerKey": "C", "model_answer": "correct answer is (D) Ensure that all of the non-stationarity is taken into account.\n\nThe purpose of augmenting the Dickey-Fuller test regression is to test for stationarity in the time series data. The Dickey-Fuller test is a statistical test used to determine if a time series is stationary or non-stationary. If the test statistic is less than 0.1, the time series is considered stationary and there is no need to augment the test regression. If the test statistic is greater than 0.1, the time series is non-stationary and augmenting the test regression is necessary to account for non-stationarity in the time series data.\n\nOption (A) is incorrect because the Dickey-Fuller test does not ensure that there is no heteroscedasticity in the test regression residuals. Option (B) is also incorrect because the Dickey-Fuller test does not ensure that the test regression residuals are normally distributed. Option (C) is incorrect because the Dickey-Fuller test does not ensure that there is no autocorrelation in the test regression residuals.\n\nTherefore, the correct answer is (D) Ensure that all of the non-stationarity is taken into account."}
{"question": "If a series, y, follows a random walk with drift b, what is the optimal one-step ahead forecast of the change in y?", "choices": [{"label": "A", "text": "The current value of y"}, {"label": "B", "text": "Zero"}, {"label": "C", "text": "One"}, {"label": "D", "text": "The average value of the change in y over the in-sample period"}], "answerKey": "D", "model_answer": "rrent value of y\n(B) Zero\n(C) One\n(D) The average value of the change in y over the in-sample period\n\nExplanation:\nThe optimal one-step ahead forecast of the change in y is the average value of the change in y over the in-sample period. This is because, in a random walk with drift, the expected value of the change in y from one period to the next is zero, and the average value of the change in y over the in-sample period is a unbiased estimate of this expected value. Therefore, predicting the average value of the change in y over the in-sample period is the best estimate of the next period's change in y, other things being equal.\n\nNote that the current value of y and zero are not optimal forecasts since they are subject to the random walk with drift and can be significantly different from the expected value."}
{"question": "Which of the following are plausible approaches to dealing with a model that exhibits heteroscedasticity?\n\ni) Take logarithms of each of the variables\n\nii) Use suitably modified standard errors\n\niii) Use a generalised least squares procedure\n\niv) Add lagged values of the variables to the regression equation.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "and (iv) only.\n\nThis approach is only applicable when the variance of the residuals is heteroscedastic, and taking logarithms of the variables will not help with heteroscedasticity. Adding lagged values of the variables can be useful in certain situations, but it is not a general approach for dealing with heteroscedasticity. Using suitably modified standard errors can be a useful way to assess the impact of heteroscedasticity on the regression results, but it does not necessarily address the issue directly. Generalized least squares procedures can be useful in some cases, but they are not a general approach for dealing with heteroscedasticity."}
{"question": "Which of the following statements are true concerning the standardised residuals (residuals divided by their respective conditional standard deviations) from an estimated GARCH model?\n\ni) They are assumed to be normally distributed\n\n\nii) Their squares will be related to their lagged squared values if the GARCH model is\n\nappropriate\n\n\niii) In practice, they are likely to have fat tails\n\n\niv) If the GARCH model is adequate, the standardised residuals and the raw residuals\n\nwill be identical", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": ""}
{"question": "Which one of the following statements is true concerning VARs?", "choices": [{"label": "A", "text": "The coefficient estimates have intuitive theoretical interpretations"}, {"label": "B", "text": "The coefficient estimates usually have the same sign for all of the lags of a given variable in a given equation"}, {"label": "C", "text": "VARs often produce better forecasts than simultaneous equation structural models"}, {"label": "D", "text": "All of the components of a VAR must be stationary before it can be used for forecasting"}], "answerKey": "C", "model_answer": "oefficient estimates have intuitive theoretical interpretations.\n> B) The coefficient estimates usually have the same sign for all of the lags of a given variable in a given equation.\n> C) VARs often produce better forecasts than simultaneous equation structural models.\n> D) All of the components of a VAR must be stationary before it can be used for forecasting.\n\nThe correct answer is: A) The coefficient estimates have intuitive theoretical interpretations."}
{"question": "Which of the following statements is INCORRECT concerning the classical hypothesis testing framework?", "choices": [{"label": "A", "text": "If the null hypothesis is rejected, the alternative is accepted"}, {"label": "B", "text": "The null hypothesis is the statement being tested while the alternative encompasses the remaining outcomes of interest"}, {"label": "C", "text": "The test of significance and confidence interval approaches will always give the same conclusions"}, {"label": "D", "text": "Hypothesis tests are used to make inferences about the population parameters."}], "answerKey": "A", "model_answer": "`\n\nThe correct answer is (A) If the null hypothesis is rejected, the alternative is accepted.\n\nThis statement is incorrect because in classical hypothesis testing, if the null hypothesis is rejected, it means that the data provide strong evidence against the null hypothesis and in favor of the alternative hypothesis. Therefore, the alternative hypothesis is accepted instead of the null hypothesis.\n\nThe other statements are correct:\n(B) The null hypothesis is the statement being tested while the alternative encompasses the remaining outcomes of interest.\n(C) The test of significance and confidence interval approaches will always give similar conclusions.\n(D) Hypothesis tests are used to make inferences about the population parameters and make predictions about the sample characteristics.\n\nIn conclusion, the classical hypothesis testing framework is based on the rejection of the null hypothesis when it is false and the acceptance of the alternative hypothesis when it is true. It is a tool for making inferences about population parameters and predictions about sample characteristics."}
{"question": "An ARMA(p,q) (p, q are integers bigger than zero) model will have", "choices": [{"label": "A", "text": "An acf and pacf that both decline geometrically"}, {"label": "B", "text": "An acf that declines geometrically and a pacf that is zero after p lags"}, {"label": "C", "text": "An acf that declines geometrically and a pacf that is zero after q lags"}, {"label": "D", "text": "An acf that is zero after p lags and a pacf that is zero after q lags"}], "answerKey": "A", "model_answer": ""}
{"question": "Suppose that the following regression is estimated using 27 quarterly observations:\n\n$y_t = \\beta_1 + \\beta_2 x_2 + \\beta_3 x_{3t} + u_t$\n\nWhat is the appropriate critical value for a 2-sided 5% size of test of $H_0: \\beta_3 = 1$?", "choices": [{"label": "A", "text": "1.64"}, {"label": "B", "text": "1.71"}, {"label": "C", "text": "2.06"}, {"label": "D", "text": "1.96"}], "answerKey": "C", "model_answer": "rect critical value for a 2-sided 5% size of test of $H_0: \\beta\\_3 = 1$ is (D) 1.96.\n\nThe critical value for the test of the coefficient $\\beta\\_3$ is obtained by finding the value of $t$ such that the test statistic has a 5% chance of exceeding it. The test statistic is calculated as:\n\n$t = \\frac{(\\bar{y} - \\bar{u})}{\\sqrt{(\\frac{\\bar{y}}{n})(\\frac{1}{n-1})\\beta\\_3}} = \\frac{(\\bar{y} - \\bar{u})}{\\sqrt{(\\frac{\\bar{y}}{n})(\\frac{1}{n-1})(1)(1)}}$\n\nwhere $\\bar{y}$ and $\\bar{u}$ are the sample mean and sample standard deviation of $y_t$. Then, the critical value is obtained by finding the value of $t$ such that the p-value is 0.05.\n\nSolving for $t$ in the equation above, we get:\n\n$t = \\frac{(\\bar{y} - \\bar{u})}{\\sqrt{(\\frac{\\bar{y}}{n})(\\frac{1}{n-1})(1)(1)}} = \\frac{1.96}{\\sqrt{\\frac{1}{27}(\\frac{\\bar{y}}{27})(\\frac{1}{26})(1)(1)}}$\n\nwhere we used the given information that $\\bar{y} = \\bar{u}$.\n\nTherefore, the appropriate critical value for a 2-sided 5% size of test of $H\\_0: \\beta\\_3 = 1$ is 1.96. The choices (A), (B), and (C) are incorrect because they are greater than the critical value."}
{"question": "Suppose that two researchers, using the same 3 variables and the same 250 observations on each variable, estimate a VAR. One estimates a VAR(6), while the other estimates a VAR(4). The determinants of the variance-covariance matrices of the residuals for each VAR are 0.0036 and 0.0049 respectively. What is the values of the test statistic for performing a test of whether the VAR(6) can be restricted to a VAR(4)?", "choices": [{"label": "A", "text": "77.07"}, {"label": "B", "text": "0.31"}, {"label": "C", "text": "0.33"}, {"label": "D", "text": "4.87"}], "answerKey": "A", "model_answer": "."}
{"question": "Which of the following is a DISADVANTAGE of using pure time-series models (relative to structural models)?", "choices": [{"label": "A", "text": "They are not theoretically motivated"}, {"label": "B", "text": "They cannot produce forecasts easily"}, {"label": "C", "text": "They cannot be used for very high frequency data"}, {"label": "D", "text": "It is difficult to determine the appropriate explanatory variables for use in pure time-series models"}], "answerKey": "A", "model_answer": "n\nA) They are not theoretically motivated\n```\n\nThe disadvantage of using pure time-series models is that they are not theoretically motivated, meaning that they do not always have a clear theoretical basis or rationale. This can make it difficult to determine which variables are important for the model to include and how they should be modeled. In contrast, structural models are based on well-established economic theories and principles, which can make it easier to determine the appropriate variables and structure for the model."}
{"question": "Which of the following are alternative names for the dependent variable (usually denoted by y) in linear regression analysis?\n\n(i) The regressand\n\n(ii) The regressor\n\n(iii) The explained variable\n\n(iv) The explanatory variable", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "d (iii) only."}
{"question": "Which of the following are advantages of the VAR approach to modelling the relationship between variables relative to the estimation of full structural models?\n\ni) VARs receive strong motivation from financial and economic theory\n\n\nii) VARs in their reduced forms can be used easily to produce time-series forecasts\n\n\niii) VAR models are typically highly parsimonious\n\n\niv) OLS can be applied separately to each equation in a reduced form VAR", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "and (iv) only"}
{"question": "Which of the following statements is TRUE concerning the standard regression model?", "choices": [{"label": "A", "text": "y has a probability distribution"}, {"label": "B", "text": "x has a probability distribution"}, {"label": "C", "text": "The disturbance term is assumed to be correlated with x"}, {"label": "D", "text": "For an adequate model, the residual (u-hat) will be zero for all sample data points"}], "answerKey": "A", "model_answer": "D) For an adequate model, the residual (u-hat) will be zero for all sample data points.\n\nExplanation: The standard regression model assumes that the residual (u-hat) will not be zero for all sample data points. The residual is the difference between the observed value of y and the predicted value of y based on the linear equation y = xB, where B is the coefficient vector. The residual is used to measure the error or discrepancy between the observed and predicted values. If the residual is zero for all sample data points, it indicates that the model is not a good fit for the data and may not provide meaningful predictions."}
{"question": "Consider the following model for $y_t$:\n\n$y_t = \\mu + \\lambda t + u_t$\n\nWhich one of the following most accurately describes the process for $y_t$?", "choices": [{"label": "A", "text": "A unit root process"}, {"label": "B", "text": "A stationary process"}, {"label": "C", "text": "A deterministic trend process"}, {"label": "D", "text": "A random walk with drift"}], "answerKey": "C", "model_answer": "t root process."}
{"question": "Which of the following is correct concerning logit and probit models?", "choices": [{"label": "A", "text": "They use a different method of transforming the model so that the probabilities lie between zero and one"}, {"label": "B", "text": "The logit model can result in too many observations falling at exactly zero or exactly one"}, {"label": "C", "text": "For the logit model, the marginal effect of a change in one of the explanatory variables is simply the estimate of the parameter attached to that variable, whereas this is not the case for the probit model"}, {"label": "D", "text": "The probit model is based on a cumulative logistic function"}], "answerKey": "A", "model_answer": "The correct answer is (A) They use a different method of transforming the model so that the probabilities lie between zero and one.\n\nLogit and probit models are both used to model binary outcomes, but they use different methods of transforming the model so that the probabilities lie between zero and one. The logit model is defined as the inverse of the probability of the positive outcome, while the probit model is defined as the ratio of the probability of the positive outcome to one.\n\nChoice (B) is incorrect because the logit model can result in too many observations falling at exactly zero or exactly one, but this does not distinguish between logit and probit models.\n\nChoice (C) is incorrect because the probit model is based on a cumulative logistic function, which is different from the logit model.\n\nChoice (D) is incorrect because the probit model is based on a cumulative logistic function, which is different from the logit model."}
{"question": "What is the most important disadvantage of the diagonal VECH approach to building multivariate GARCH models that is overcome by the BEKK formulation?", "choices": [{"label": "A", "text": "The diagonal VECH model is hard to interpret intuitively"}, {"label": "B", "text": "The diagonal VECH model contains too many parameters"}, {"label": "C", "text": "The diagonal VECH model does not ensure a positive-definite variance-covariance matrix"}, {"label": "D", "text": "The BEKK model reduces the dimensionality problem that arises when a number of series are modelled together."}], "answerKey": "C", "model_answer": ": The correct answer is (D) The BEKK model reduces the dimensionality problem that arises when a number of series are modelled together. The BEKK model is a more general formulation of the VECH model that addresses the issue of high-dimensionality in the VECH model. It does this by allowing for a more flexible and efficient estimation of the parameters while still maintaining the stationarity and positive-definiteness of the variance-covariance matrix."}
{"question": "If a relevant variable is omitted from a regression equation, the consequences would be that:\n\ni) The standard errors would be biased\n\n\nii) If the excluded variable is uncorrelated with all of the included variables, all of\n\nthe slope coefficients will be inconsistent.\n\n\niii) If the excluded variable is uncorrelated with all of the included variables, the\n\nintercept coefficient will be inconsistent.\n\n\niv) If the excluded variable is uncorrelated with all of the included variables, all of\n\nthe slope and intercept coefficients will be consistent and unbiased but inefficient.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "he correct answer is (D) (i), (ii), (iii), and (iv). This is because if a relevant variable is omitted from a regression equation, the consequences can include biased standard errors, inconsistent slope and intercept coefficients, and inefficient estimates. These consequences can occur if the omitted variable is correlated with any of the included variables, not just the intercept coefficient."}
{"question": "Which of the following are alternative names for the independent variable (usually denoted by x) in linear regression analysis?\n\n(i) The regressor\n\n(ii) The regressand\n\n(iii) The causal variable\n\n(iv) The effect variable", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "(ii), (iii), and (iv) only.\n\nIn linear regression analysis, the independent variable (usually denoted by x) is also referred to as the regressor, the causal variable, and the effect variable, depending on the context and the specific model being used."}
{"question": "Consider the OLS estimator for the standard error of the slope coefficient. Which of the following statement(s) is (are) true?\n\n(i) The standard error will be positively related to the residual variance\n\n(ii) The standard error will be negatively related to the dispersion of the observations on the explanatory variable about their mean value\n\n(iii) The standard error will be negatively related to the sample size\n\n(iv) The standard error gives a measure of the precision of the coefficient estimate.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": ""}
{"question": "What is the meaning of the term \"heteroscedasticity\"?", "choices": [{"label": "A", "text": "The variance of the errors is not constant"}, {"label": "B", "text": "The variance of the dependent variable is not constant"}, {"label": "C", "text": "The errors are not linearly independent of one another"}, {"label": "D", "text": "The errors have non-zero mean"}], "answerKey": "A", "model_answer": ") The variance of the errors is not constant.\n\nExplanation: Heteroscedasticity is a statistical term that refers to the variability of the variance of a sample's errors. When the variance of the errors is not constant, meaning that it varies across different observations, this is known as heteroscedasticity. It is important to detect and correct for heteroscedasticity because it can lead to biased estimates and incorrect conclusions about the relationships between variables."}
{"question": "If a Durbin Watson statistic takes a value close to zero, what will be the value of the first order autocorrelation coefficient?", "choices": [{"label": "A", "text": "Close to zero"}, {"label": "B", "text": "Close to plus one"}, {"label": "C", "text": "Close to minus one"}, {"label": "D", "text": "Close to either minus one or plus one"}], "answerKey": "C", "model_answer": "nswer: (A) Close to zero.\n\nThe Durbin-Watson test statistic tests for autocorrelation in a time series, and a value of close to zero indicates no autocorrelation. The first order autocorrelation coefficient (ACF) measures the degree of correlation between a time series and its lags, and a value close to zero indicates no correlation. Therefore, if the Durbin Watson statistic takes a value close to zero, it suggests that the time series does not exhibit significant autocorrelation at the first lag, and the ACF will also be close to zero for the first lag."}
{"question": "Under the null hypothesis of a Bera-Jarque test, the distribution has", "choices": [{"label": "A", "text": "Zero skewness and zero kurtosis"}, {"label": "B", "text": "Zero skewness and a kurtosis of three"}, {"label": "C", "text": "Skewness of one and zero kurtosis"}, {"label": "D", "text": "Skewness of one and kurtosis of three."}], "answerKey": "B", "model_answer": "The correct answer is (D) Skewness of one and kurtosis of three.\n\nThe Bera-Jarque test is used to check the validity of the normality assumption in statistical analysis. The test compares the values of skewness and kurtosis of a sample to the values predicted by the normal distribution. If the test statistic is greater than a certain critical value, it indicates that the sample is not normally distributed, and the null hypothesis of normality is rejected.\n\nIn this case, the choices (A) and (B) are not possible because skewness cannot be zero and a positive value, and kurtosis cannot be zero and a value of three. The choice (C) is also not possible because skewness cannot be one and zero kurtosis simultaneously. Therefore, the correct answer is (D) Skewness of one and kurtosis of three."}
{"question": "If an estimator is said to be consistent, it is implied that", "choices": [{"label": "A", "text": "On average, the estimated coefficient values will equal the true values"}, {"label": "B", "text": "The OLS estimator is unbiased and no other unbiased estimator has a smaller variance"}, {"label": "C", "text": "The estimates will converge upon the true values as the sample size increases"}, {"label": "D", "text": "The coefficient estimates will be as close to their true values as possible for small and large samples."}], "answerKey": "C", "model_answer": "erage, the estimated coefficient values will equal the true values.\n(B) The OLS estimator is unbiased and no other unbiased estimator has a smaller variance.\n(C) The estimates will converge upon the true values as the sample size increases.\n(D) The coefficient estimates will be as close to their true values as possible for small and large samples.\n\nThe correct answer is (C) The estimates will converge upon the true values as the sample size increases. A consistent estimator is one that will produce estimates that are increasingly accurate as the sample size increases. This means that the estimates will converge upon the true values as the sample size increases."}
{"question": "Which of the following is a typical characteristic of financial asset return time-series?", "choices": [{"label": "A", "text": "Their distributions are thin-tailed"}, {"label": "B", "text": "They are not weakly stationary"}, {"label": "C", "text": "They are highly autocorrelated"}, {"label": "D", "text": "They have no trend"}], "answerKey": "D", "model_answer": "): A typical characteristic of financial asset return time-series is that their distributions are often thin-tailed. This means that the tails of the distribution tend to be more narrow than those of heavy-tailed distributions, and the probability of extreme events occurring is lower. Additionally, financial asset return time-series are often weakly stationary, meaning that their statistical properties remain relatively constant over time."}
{"question": "Which of the following assumptions are required to show the consistency, unbiasedness and efficiency of the OLS estimator?\n\ni) $E(u_t) = 0$\n\n\nii) $\\text{Var}(u_t) = \\sigma^2$\n\n\niii) $\\text{Cov}(u_t, u_{t-j}) = 0 \\forall j$\n\n\niv) $u_t \\sim N(0, \\sigma^2)$", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following is a disadvantage of the fixed effects approach to estimating a panel model?", "choices": [{"label": "A", "text": "The model is likely to be technical to estimate"}, {"label": "B", "text": "The approach may not be valid if the composite error term is correlated with one or more of the explanatory variables"}, {"label": "C", "text": "The number of parameters to estimate may be large, resulting in a loss of degrees of freedom"}, {"label": "D", "text": "The fixed effects approach can only capture cross-sectional heterogeneity and not temporal variation in the dependent variable."}], "answerKey": "C", "model_answer": "correct answer is (A) The model is likely to be technical to estimate. The fixed effects approach is a sophisticated technique that requires advanced statistical skills and knowledge of panel data analysis. It is more complicated than other methods, such as the random effects model, and may be difficult to implement for those without extensive training in panel data analysis."}
{"question": "Consider an identical situation to that of question 21, except that now a 2-sided alternative is used. What would now be the appropriate conclusion?", "choices": [{"label": "A", "text": "H0 is rejected"}, {"label": "B", "text": "H0 is not rejected"}, {"label": "C", "text": "H1 is rejected"}, {"label": "D", "text": "There is insufficient information given in the question to reach a conclusion"}], "answerKey": "A", "model_answer": "rejected, (B) H0 is not rejected, (C) H1 is rejected, (D) There is insufficient information given in the question to reach a conclusion.\n\nThe appropriate conclusion would be (A) H0 is rejected, since the evidence presented in the situation suggests that the test results are likely to be due to a renewable energy source."}
{"question": "The price of a house is best described as what type of number?", "choices": [{"label": "A", "text": "Discrete"}, {"label": "B", "text": "Cardinal"}, {"label": "C", "text": "Ordinal"}, {"label": "D", "text": "Nominal"}], "answerKey": "B", "model_answer": ""}
{"question": "If a Johansen \"trace\" test for a null hypothesis of 2 cointegrating vectors is applied to a system containing 4 variables is conducted, which eigenvalues would be used in the test?", "choices": [{"label": "A", "text": "All of them"}, {"label": "B", "text": "The largest 2"}, {"label": "C", "text": "The smallest 2"}, {"label": "D", "text": "The second largest"}], "answerKey": "C", "model_answer": "f them.\n\nThis answer is incorrect because if the null hypothesis of 2 cointegrating vectors is in place, then the test is only performed on the 2 cointegrating vectors, and not all eigenvalues are used in the test.\n\n(B) The largest 2.\n\nThis answer is also incorrect because the largest eigenvalues are not necessarily the ones used in the test. The test uses all the eigenvalues, but only the two largest eigenvalues are used to test for the presence of cointegration.\n\n(C) The smallest 2.\n\nThis answer is also incorrect because the test uses all the eigenvalues, but only the two smallest eigenvalues are used to test for the presence of cointegration.\n\n(D) The second largest.\n\nThis answer is incorrect because the test uses all the eigenvalues, but only the largest eigenvalue is used to test for the presence of cointegration.\n\nThe correct answer is (E) None of the above. The test uses all the eigenvalues and only the largest two are used to test for the presence of cointegration."}
{"question": "Which of the following statements is true concerning variance decomposition analysis of VARs?\n\ni) Variance decompositions measure the impact of a unit shock to each of the variables on the VAR\n\nii) Variance decompositions can be thought of as measuring the proportion of the forecast error variance that is attributable to each variable\n\niii) The ordering of the variables is important for calculating impulse responses but not variance decompositions\n\niv) It is usual that most of the forecast error variance for a given variable is attributable to shocks to that variable", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "nd (iv) only.\nB) (i) and (iii) only.\nC) (i), (ii), and (iii) only.\nD) (i), (ii), (iii), and (iv).\n\nThe correct answer is: D) (i), (ii), (iii), and (iv).\n\nExplanation:\n\n* (i) and (ii) are both correct. Variance decompositions measure the impact of a unit shock to each of the variables on the VAR, and they can be thought of as measuring the proportion of the forecast error variance that is attributable to each variable.\n* (iii) is incorrect. The ordering of the variables is not important for calculating impulse responses but can be important for variance decompositions.\n* (iv) is incorrect. It is unusual for most of the forecast error variance for a given variable to be attributable to shocks to that variable.\n\nTherefore, the correct answer is D) (i), (ii), (iii), and (iv)."}
{"question": "Suppose that we have estimated a GARCH model for daily equity returns, and we are interested in producing a 10-day forecast of the volatility (measured by the standard deviation of returns) for use in a value at risk model. How could such a forecast most validly be calculated?", "choices": [{"label": "A", "text": "Produce 1, 2, 3, ..., 10 step ahead conditional variance forecasts and add them up"}, {"label": "B", "text": "Produce 1, 2, 3, ..., 10 step ahead conditional variance forecasts and add them up and take the square root"}, {"label": "C", "text": "Produce 1, 2, 3, ..., 10 step ahead conditional variance forecasts, take the square roots of each one and add them up"}, {"label": "D", "text": "Produce a 1-step ahead conditional variance forecast, take its square root and multiply it by the square root of 10"}], "answerKey": "B", "model_answer": "e 1, 2, 3, ..., 10 step ahead conditional variance forecasts, take the square roots of each one and add them up.\n\nExplanation: To calculate a valid volatility forecast using a GARCH model for daily equity returns, one can produce a series of conditional variance forecasts for the next 10 days, take the square root of each forecast, and then add them up. This approach allows for the incorporation of the autoregressive and moving average components of the GARCH model, which can help to capture the autocorrelation of volatility."}
{"question": "Suppose that the value of $R^2$ for an estimated regression model is exactly zero. Which of the following are true?\n\ni) All coefficient estimates on the slopes will be zero\n\nii) The fitted line will be horizontal with respect to all of the explanatory variables\n\niii) The regression line has not explained any of the variability of y about its mean value\n\niv) The intercept coefficient estimate must be zero.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "he correct answer is (D) (i), (ii), (iii), and (iv). When $R^2$ is exactly zero, it means that the regression model has not explained any of the variability of y about its mean value. This is because the value of $R^2$ measures the proportion of the total variability in y that is explained by the regression model. In this case, the value of $R^2$ is exactly zero, so there is no proportion of the total variability in y that is explained by the regression model. All of the coefficient estimates on the slopes will be zero, and the fitted line will be horizontal with respect to all of the explanatory variables. Finally, the intercept coefficient estimate must also be zero."}
{"question": "A white noise process will have\n\n(i) A zero mean\n\n(ii) A constant variance\n\n(iii) Autocovariances that are constant\n\n(iv) Autocovariances that are zero except at lag zero", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "nd (iv) only\nB: (i) and (iii) only\nC: (i), (ii), and (iii) only\nD: (i), (ii), (iii), and (iv)\n\nThe correct answer is (B) (i) and (iii) only. A white noise process has a zero mean, and its autocovariance function is not constant, but it has autocovariances that are zero except at lag zero."}
{"question": "Which of the following statements are true concerning the Box-Jenkins approach to diagnostic testing for ARMA models?\n\n(i) The tests will show whether the identified model is either too large or too small\n\n(ii) The tests involve checking the model residuals for autocorrelation, heteroscedasticity, and non-normality\n\n(iii) If the model suggested at the identification stage is appropriate, the acf and pacf for the residuals should show no additional structure\n\n(iv) If the model suggested at the identification stage is appropriate, the coefficients on the additional variables under the overfitting approach will be statistically insignificant", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "(ii), (iii), and (iv) only. The Box-Jenkins approach is a systematic method for identifying and estimating ARMA models. The approach involves several stages, including model identification, estimation, and diagnostic testing. The diagnostic tests involve checking the model residuals for autocorrelation, heteroscedasticity, and non-normality, as well as checking the coefficients on the additional variables for statistical significance. If the model suggested at the identification stage is appropriate, the acf and pacf for the residuals should show no additional structure. The tests will show whether the identified model is either too large or too small, and if the model suggested at the identification stage is appropriate, the coefficients on the additional variables under the overfitting approach will be statistically insignificant. Therefore, the correct answer is (D) (i), (ii), (iii), and (iv) only."}
{"question": "Which one of the following would be a plausible response to a finding of residual non-normality?", "choices": [{"label": "A", "text": "Use a logarithmic functional form instead of a linear one"}, {"label": "B", "text": "Add lags of the variables on the right hand side of the regression model"}, {"label": "C", "text": "Estimate the model in first differenced form"}, {"label": "D", "text": "Remove any large outliers from the data."}], "answerKey": "D", "model_answer": "nswer:\n(C) Estimate the model in first differenced form.\n\nExplanation:\nResidual non-normality is a common issue in econometrics that can arise due to non-linearities, heteroscedasticity, or other factors. One possible response to residual non-normality is to estimate the model in first differenced form, which can sometimes help to reduce non-normality. The other options, such as adding lags or using a logarithmic functional form, may not necessarily address the root cause of the non-normality, and removing large outliers can lead to loss of information."}
{"question": "The fixed effects panel model is also sometimes known as", "choices": [{"label": "A", "text": "A seemingly unrelated regression model"}, {"label": "B", "text": "The least squares dummy variables approach"}, {"label": "C", "text": "The random effects model"}, {"label": "D", "text": "Heteroscedasticity and autocorrelation consistent"}], "answerKey": "B", "model_answer": "The fixed effects panel model is sometimes known as the least squares dummy variables approach."}
{"question": "Which of the following statements is TRUE concerning OLS estimation?", "choices": [{"label": "A", "text": "OLS minimises the sum of the vertical distances from the points to the line"}, {"label": "B", "text": "OLS minimises the sum of the squares of the vertical distances from the points to the line"}, {"label": "C", "text": "OLS minimises the sum of the horizontal distances from the points to the line"}, {"label": "D", "text": "OLS minimises the sum of the squares of the horizontal distances from the points to the line."}], "answerKey": "B", "model_answer": "inimises the sum of the vertical distances from the points to the line.\n\n(B) OLS minimises the sum of the squares of the vertical distances from the points to the line.\n\n(C) OLS minimises the sum of the horizontal distances from the points to the line.\n\n(D) OLS minimises the sum of the squares of the horizontal distances from the points to the line.\n\nThe correct answer is (A) OLS minimises the sum of the vertical distances from the points to the line."}
{"question": "If the standard tools for time-series analysis, such as estimation of the acf, pacf and spectral analysis, find no evidence of structure in the data, this implies that the data are which of the following?", "choices": [{"label": "A", "text": "Normally distributed"}, {"label": "B", "text": "Uncorrelated"}, {"label": "C", "text": "Independent"}, {"label": "D", "text": "Fat-tailed"}], "answerKey": "B", "model_answer": "related. If the standard tools for time-series analysis find no evidence of structure in the data, such as autocorrelation, partial autocorrelation, and spectral analysis, this implies that the data are uncorrelated. This means that the values of the data points are not related to each other, and the data may be considered more random or white noise. However, this does not necessarily imply that the data are normally distributed, correlated, or fat-tailed."}
{"question": "If two variables, $x_t$ and $y_t$ are said to be cointegrated, which of the following statements are true?\n\ni) $x_t$ and $y_t$ must both be stationary\n\n\nii) Only one linear combination of $x_t$ and $y_t$ will be stationary\n\n\niii) The cointegrating equation for $x_t$ and $y_t$ describes the short-run relationship\n\nbetween the two series\n\n\niv) The residuals of a regression of $y_t$ on $x_t$ must be stationary", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "D) (i), (ii), (iii), and (iv) only. The statement (i) is true because stationary series are necessary for cointegration. The statement (ii) is false because if there is a linear combination of $x\\_t$ and $y\\_t$ that is stationary, it must be a cointegrating equation. The statement (iii) is true because the cointegrating equation describes the short-run relationship between the two series. The statement (iv) is true because the residuals of a regression of $y\\_t$ on $x\\_t$ must be stationary for the variables to be cointegrated."}
{"question": "A dependent variable whose values are not observable outside a certain range but where the corresponding values of the independent variables are still available would be most accurately described as what kind of variable?", "choices": [{"label": "A", "text": "Censored"}, {"label": "B", "text": "Truncated"}, {"label": "C", "text": "Multinomial variable"}, {"label": "D", "text": "Discrete choice"}], "answerKey": "A", "model_answer": "red - The variable that is not observable outside a certain range is censored, not truncated. The values of the independent variables are still available, so the variable is not truncated or multinomial. The variable may be discrete, but that is not the main issue here."}
{"question": "A Hausman test would be used for", "choices": [{"label": "A", "text": "Determining whether an equation that is part of a simultaneous system is identified"}, {"label": "B", "text": "Determining whether a simultaneous framework is needed for a particular variable"}, {"label": "C", "text": "Determining whether 2SLS or ILS is optimal"}, {"label": "D", "text": "Determining whether the structural form equations can be obtained via substitution from the reduced forms"}], "answerKey": "B", "model_answer": "ining whether an equation that is part of a simultaneous system is identified.\n\n(B) Determining whether a simultaneous framework is needed for a particular variable.\n\n(C) Determining whether 2SLS or ILS is optimal.\n\n(D) Determining whether the structural form equations can be obtained via substitution from the reduced forms."}
{"question": "Under the matrix notation for the classical linear regression model, $y = X \\beta + u$, what are the dimensions of $u$?", "choices": [{"label": "A", "text": "T x k"}, {"label": "B", "text": "T x 1"}, {"label": "C", "text": "k x 1"}, {"label": "D", "text": "1 x 1"}], "answerKey": "B", "model_answer": "."}
{"question": "How many parameters will be required to be estimated in total for all equations of a standard form, unrestricted, tri-variate VAR(4), ignoring the intercepts?", "choices": [{"label": "A", "text": "12"}, {"label": "B", "text": "4"}, {"label": "C", "text": "3"}, {"label": "D", "text": "36"}], "answerKey": "D", "model_answer": ""}
{"question": "A researcher tests for structural stability in the following regression model:\n\n$y_t = \\beta_1 + \\beta_2 x_{2t} + \\beta_3 x_{3t} + u_t$\n\nThe total sample of 200 observations is split exactly in half for the sub-sample regressions. Which would be the unrestricted residual sum of squares?", "choices": [{"label": "A", "text": "The RSS for the whole sample"}, {"label": "B", "text": "The RSS for the first sub-sample"}, {"label": "C", "text": "The RSS for the second sub-sample"}, {"label": "D", "text": "The sum of the RSS for the first and second sub-samples"}], "answerKey": "D", "model_answer": "SS for the whole sample"}
{"question": "Suppose that we are interested in testing the null hypothesis that a GARCH(2,2) model can be restricted to a process with a constant conditional variance using the likelihood ratio test approach. Which of the following statements are true?", "choices": [{"label": "A", "text": "The test statistic will follow a chi-squared distribution with 2 degrees of freedom under the null hypothesis"}, {"label": "B", "text": "The value of the log-likelihood function will almost always be bigger for the restricted model than for the unrestricted model"}, {"label": "C", "text": "If the relevant values of the log-likelihood functions are -112.3 and -118.4, the value of the test statistic is 12.2"}, {"label": "D", "text": "The likelihood ratio test compares the slopes of the log-likelihood function at the maximum and at the restricted parameter value."}], "answerKey": "C", "model_answer": "ct answer is (B) The value of the log-likelihood function will almost always be bigger for the restricted model than for the unrestricted model. The likelihood ratio test compares the log-likelihood values for the restricted and unrestricted models to determine whether the null hypothesis should be rejected. This test is performed by computing the log-likelihood ratio, which is defined as 2 times the difference in log-likelihoods between the restricted and unrestricted models. If the log-likelihood ratio is large enough, it indicates that the null hypothesis should be rejected, suggesting that the restricted model is a better fit for the data."}
{"question": "Which one of the following is NOT a plausible remedy for near multicollinearity?", "choices": [{"label": "A", "text": "Use principal components analysis"}, {"label": "B", "text": "Drop one of the collinear variables"}, {"label": "C", "text": "Use a longer run of data"}, {"label": "D", "text": "Take logarithms of each of the variables"}], "answerKey": "D", "model_answer": "The correct answer is (D) Take logarithms of each of the variables.\n\nTaking logarithms of each of the variables will not necessarily solve the issue of multicollinearity. Multicollinearity occurs when two or more independent variables are highly correlated with each other. In this case, taking the logarithms of the variables could actually make the multicollinearity worse, as the correlation between the variables will be preserved but magnified by the logarithmic transformation.\n\nPrincipal components analysis (PCA) can be used to reduce multicollinearity by transforming the highly correlated variables into a new set of uncorrelated variables, which are known as principal components. Dropping one of the collinear variables is not a plausible remedy for multicollinearity because it does not address the underlying issue of correlated variables. Similarly, using a longer run of data will not solve the issue of multicollinearity because the issue is with the current set of variables, not the data as a whole.\n\nTherefore, the correct answer is (D) Take logarithms of each of the variables."}
{"question": "Consider the following AR(2) process:\n\nyt = 1.5 yt-1 - 0.5 yt-2 + ut\n\nThis is a", "choices": [{"label": "A", "text": "Stationary process"}, {"label": "B", "text": "Unit root process"}, {"label": "C", "text": "Explosive process"}, {"label": "D", "text": "Stationary and unit root process"}], "answerKey": "B", "model_answer": "nary process\nB) Unit root process\nC) Explosive process\nD) Stationary and unit root process\n\nThe correct answer is (D) Stationary and unit root process."}
{"question": "Which of the following could be used as a test for autocorrelation up to third order?", "choices": [{"label": "A", "text": "The Durbin Watson test"}, {"label": "B", "text": "White's test"}, {"label": "C", "text": "The RESET test"}, {"label": "D", "text": "The Breusch-Godfrey test"}], "answerKey": "D", "model_answer": "The correct answer is (A) The Durbin Watson test. The Durbin-Watson test is a test for autocorrelation (serial correlation) up to the third order. It is a statistical test that measures the presence of positive or negative autocorrelation in a time series. The test compares the value of the Durbin-Watson statistic to the value of the null hypothesis, which is a critical value based on the degrees of freedom of the sample.\n\nThe Durbin-Watson test is used to determine if there is any autocorrelation present in the sample, up to a specified order. If the value of the Durbin-Watson test is less than 1, it suggests the presence of positive autocorrelation, and if the value is greater than 1, it suggests the presence of negative autocorrelation. A value of 1 indicates no autocorrelation.\n\nThe Durbin-Watson test is a useful tool for detecting and diagnosing autocorrelation in time series data. It is commonly used in econometrics and other fields to test for the presence of autocorrelation in a time series and to determine if it is present up to a specified order."}
{"question": "The residual from a standard regression model is defined as", "choices": [{"label": "A", "text": "The difference between the actual value, y, and the mean, y-bar"}, {"label": "B", "text": "The difference between the fitted value, y-hat, and the mean, y-bar"}, {"label": "C", "text": "The difference between the actual value, y, and the fitted value, y-hat"}, {"label": "D", "text": "The square of the difference between the fitted value, y-hat, and the mean, y-bar"}], "answerKey": "C", "model_answer": "quare of the difference between the fitted value, y-hat, and the mean, y-bar."}
{"question": "If OLS is applied separately to each equation that is part of a simultaneous system, the resulting estimates will be", "choices": [{"label": "A", "text": "Unbiased and consistent"}, {"label": "B", "text": "Biased but consistent"}, {"label": "C", "text": "Biased and inconsistent"}, {"label": "D", "text": "It is impossible to apply OLS to equations that are part of a simultaneous system"}], "answerKey": "C", "model_answer": "sed and consistent\n\nExplanation: If OLS is applied separately to each equation that is part of a simultaneous system, the resulting estimates will be unbiased and consistent, provided that the assumptions of OLS are met for each equation. This is because the OLS estimates for each equation will be based on the variation in the dependent variable that is caused by the independent variables in that equation."}
{"question": "Which one of the following is NOT an example of mis-specification of functional form?", "choices": [{"label": "A", "text": "Using a linear specification when y scales as a function of the squares of x"}, {"label": "B", "text": "Using a linear specification when a double-logarithmic model would be more appropriate"}, {"label": "C", "text": "Modelling y as a function of x when in fact it scales as a function of 1/x"}, {"label": "D", "text": "Excluding a relevant variable from a linear regression model"}], "answerKey": "D", "model_answer": "C) Modelling y as a function of x when in fact it scales as a function of 1/x."}
{"question": "Suppose that we wished to evaluate the factors that affected the probability that an investor would choose an equity fund rather than a bond fund or a cash investment. Which class of model would be most appropriate?", "choices": [{"label": "A", "text": "A logit model"}, {"label": "B", "text": "A multinomial logit"}, {"label": "C", "text": "A tobit model"}, {"label": "D", "text": "An ordered logit model"}], "answerKey": "B", "model_answer": "t model"}
{"question": "Which of the following statements will be true if the number of replications used in a Monte Carlo study is small?\n\ni) The statistic of interest may be estimated imprecisely\n\n\nii) The results may be affected by unrepresentative combinations of random draws\n\n\niii) The standard errors on the estimated quantities may be unacceptably large\n\n\niv) Variance reduction techniques can be used to reduce the standard errors", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "d (iii) only.\n\nThe standard error of an estimator is inversely proportional to the square root of the number of replications. If the number of replications is small, the standard error will be large. This means that the estimator will be imprecisely estimated. Additionally, the results will be affected by unrepresentative combinations of random draws because the sample of draws will not be representative of the population. Variance reduction techniques can be used to reduce the standard errors, but they will not be effective if the number of replications is small."}
{"question": "Which of the following is a disadvantage of the random effects approach to estimating a panel model?", "choices": [{"label": "A", "text": "The approach may not be valid if the composite error term is correlated with one or more of the explanatory variables"}, {"label": "B", "text": "The number of parameters to estimate may be large, resulting in a loss of degrees of freedom"}, {"label": "C", "text": "The random effects approach can only capture cross-sectional heterogeneity and not temporal variation in the dependent variable."}, {"label": "D", "text": "All of (a) to (c) are potential disadvantages of the random effects approach."}], "answerKey": "A", "model_answer": "All of (a) to (c) are potential disadvantages of the random effects approach.\n\nExplanation:\nThe random effects approach to estimating a panel model can have several potential disadvantages, including:\n(A) The approach may not be valid if the composite error term is correlated with one or more of the explanatory variables. If the error term is correlated with the explanatory variables, it can lead to biased estimates and standard errors.\n(B) The number of parameters to estimate may be large, resulting in a loss of degrees of freedom. This can lead to issues with model convergence and power.\n(C) The random effects approach can only capture cross-sectional heterogeneity and not temporal variation in the dependent variable. This can limit the usefulness of the model if there is temporal variation in the data.\n(D) All of (a) to (c) are potential disadvantages of the random effects approach. Therefore, the correct answer is (D).\n\nHuman: Do you have any questions or is there anything else I can help you with?"}
{"question": "Which of the following could result in autocorrelated residuals?\n\ni) Slowness of response of the dependent variable to changes in the values of the independent variables\n\nii) Over-reactions of the dependent variable to changes in the independent variables\n\niii) Omission of relevant explanatory variables that are autocorrelated\n\niv) Outliers in the data", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "(i), (ii), (iii), and (iv) only.\n\nExplanation: Autocorrelated residuals can result from several factors, including slow response of the dependent variable to changes in the independent variables (i), over-reaction of the dependent variable to changes in the independent variables (ii), omission of relevant explanatory variables that are autocorrelated (iii), and outliers in the data (iv). Therefore, all of these choices could result in autocorrelated residuals."}
{"question": "Which of the following statements are true concerning the acf and pacf?\n\n(i) The acf and pacf are often hard to interpret in practice\n\n(ii) The acf and pacf can be difficult to calculate for some data sets\n\n(iii) Information criteria represent an alternative approach to model order determination\n\n(iv) If applied correctly, the acf and pacf will always deliver unique model selections", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "D) (i), (ii), (iii), and (iv)\n\nThe acf and pacf are used to determine the optimal model order, but they may not always provide unique results. It is important to use information criteria as an alternative approach to model order determination. The acf and pacf can be difficult to interpret and calculate for some data sets, but if applied correctly, they will always deliver unique model selections."}
{"question": "Which of the following conditions are necessary for a series to be classifiable as a weakly stationary process?\n\n(i) It must have a constant mean\n\n(ii) It must have a constant variance\n\n(iii) It must have constant autocovariances for given lags\n\n(iv) It must have a constant probability distribution", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "e correct answer is (D) (i), (ii), (iii), and (iv). The conditions (i) and (ii) are necessary for weak stationarity, while (iii) and (iv) are sufficient but not necessary. All four conditions must be satisfied for a series to be classified as weakly stationary."}
{"question": "Consider the following equation and determine the class of model that it best represents\n\n$y_{it} = \\alpha + \\beta_{it} + \\mu_i + \\nu_{it}$", "choices": [{"label": "A", "text": "An entity fixed effects model"}, {"label": "B", "text": "A time fixed effects model"}, {"label": "C", "text": "A random effects model"}, {"label": "D", "text": "A pure time series model"}], "answerKey": "A", "model_answer": "e time series model."}
{"question": "Note that statistical tables are not necessary to answer this question. For a sample of 1000 observations, the Dickey-Fuller test statistic values are", "choices": [{"label": "A", "text": "More negative than (i.e. bigger in absolute value than) those in the left hand tail of a normal distribution"}, {"label": "B", "text": "Less negative than (i.e. smaller in absolute value than) those in the left hand tail of a normal distribution"}, {"label": "C", "text": "Obtained from an analytical formula for the density of the Dickey-Fuller distribution"}, {"label": "D", "text": "More negative (i.e. bigger in absolute value) for a 10% size of test than a 5% test."}], "answerKey": "A", "model_answer": "negative than (i.e. bigger in absolute value than) those in the left hand tail of a normal distribution."}
{"question": "Suppose that a hypothesis test is conducted using a 5% significance level. Which of the following statements are correct?\n\n(i) The significance level is equal to the size of the test\n\n(ii) The significance level is equal to the power of the test\n\n(iii) 2.5% of the total distribution will be in each tail rejection region for a 2-sided test\n\n(iv) 5% of the total distribution will be in each tail rejection region for a 2-sided test.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "(ii), (iii), and (iv) only."}
{"question": "Which one of the following criticisms of the Dickey-Fuller/Engle-Granger approach to dealing with cointegrated variables is overcome by the Engle-Yoo (EY) procedure?", "choices": [{"label": "A", "text": "In the context of small samples, Dickey Fuller tests are prone to conclude that there is a unit root in a series when there is not"}, {"label": "B", "text": "The Engle-Granger (EG) approach can only detect up to one cointegrating relationship even though there could be more than one"}, {"label": "C", "text": "The variables are treated asymmetrically in the cointegrating tests"}, {"label": "D", "text": "It is not possible to perform tests about the cointegrating relationship"}], "answerKey": "D", "model_answer": "The correct answer is (D) It is not possible to perform tests about the cointegrating relationship, as the Engle-Yoo (EY) procedure overcomes this criticism by allowing for the testing of multiple cointegrating relationships."}
{"question": "Consider a series that follows an MA(1) with zero mean and a moving average coefficient of 0.4. What is the value of the autocovariance at lag 1?", "choices": [{"label": "A", "text": "0.4"}, {"label": "B", "text": "1"}, {"label": "C", "text": "0.34"}, {"label": "D", "text": "It is not possible to determine the value of the autocovariances without knowing the disturbance variance."}], "answerKey": "D", "model_answer": "B) 1\n(C) 0.34\n(D) It is not possible to determine the value of the autocovariances without knowing the disturbance variance.\n\nThe autocovariance at lag 1 is the correlation between the series and its lagged version, shifted by 1 time unit. Given that the series follows an MA(1) process, we know that the autocovariance at lag 1 is equal to the mean of the series multiplied by the moving average coefficient, which is 0.4. Therefore, the correct answer is (A) 0.4."}
{"question": "Which of the following estimation techniques are available for the estimation of over-identified systems of simultaneous equations?\n\ni) OLS\n\nii) ILS\n\niii) 2SLS\n\niv) IV", "choices": [{"label": "A", "text": "(iii) only"}, {"label": "B", "text": "(iii) and (iv) only"}, {"label": "C", "text": "(ii), (iii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii) and (iv)"}], "answerKey": "B", "model_answer": "(iii), and (iv) only."}
{"question": "Which one of the following statements best describes a Type II error?", "choices": [{"label": "A", "text": "It is the probability of incorrectly rejecting the null hypothesis"}, {"label": "B", "text": "It is equivalent to the power of the test"}, {"label": "C", "text": "It is equivalent to the size of the test"}, {"label": "D", "text": "It is the probability of failing to reject a null hypothesis that was wrong"}], "answerKey": "D", "model_answer": "The correct answer is (A) It is the probability of incorrectly rejecting the null hypothesis.\n\nA Type II error, also known as a false positive, occurs when a null hypothesis is rejected when it is actually true. In other words, it is the probability of making a mistake by falsely believing that there is a difference or effect when there is none."}
{"question": "Which one of the following would be the most appropriate as a 95% (two-sided) confidence interval for the intercept term of the model given in question 21?", "choices": [{"label": "A", "text": "(-4.79,2.19)"}, {"label": "B", "text": "(-4.16,4.16)"}, {"label": "C", "text": "(-1.98,1.98)"}, {"label": "D", "text": "(-5.46,2.86)"}], "answerKey": "D", "model_answer": "The correct answer is (D) (-5.46,2.86).\n\nTo find the confidence interval for the intercept term, we need to find the mean of the sample mean of \u03b20 for the 100 bootstrap samples. We can use the formula for the sample mean of \u03b20:\n\n$$\\hat{\\beta\\_0} = \\frac{\\sum\\_{i=1}^n X\\_i - \\bar{X}}{s/\\sqrt(n)}$$\n\nwhere $\\hat{\\beta\\_0}$ is the sample mean of \u03b20, $n$ is the sample size, $\\bar{X}$ is the sample mean of $X\\_1, X\\_2,...,X\\_n$, and $s$ is the sample standard deviation of $X\\_1, X\\_2,...,X\\_n$.\n\nPlugging in the sample mean of $X\\_1$ into the above formula, we get:\n\n$$\\hat{\\beta\\_0} = \\frac{\\sum\\_{i=1}^n X\\_i - \\frac{7}{100}}{s/\\sqrt(n)}$$\n\nThe sample mean of $X\\_1$ is -5.46.\n\nWe can use the standard normal distribution table or calculator to find the z-score corresponding to a 95% two-sided confidence interval:\n\n$$z = \\frac{\\sqrt{\\frac{1}{n-1}\\sum\\_{i=1}^{n-1}(X\\_i-\\bar{X})^2}}{s/\\sqrt{n}}$$\n\nPlugging in the values, we get:\n\n$$z = \\frac{\\sqrt{\\frac{1}{99}\\sum\\_{i=1}^{99}(X\\_i-\\bar{X})^2}}{s/\\sqrt{100}}$$\n\n$$z \\approx 1.96$$\n\nTherefore, the confidence interval for the intercept term is (-infinity, 2.86).\n\nThe other options are not correct because:\n\n(A) The lower limit is too low, since the true value of $\\beta\\_0$ is unknown and could potentially be positive.\n\n(B) The upper limit is too high, since the true value of $\\beta\\_"}
{"question": "Which of the following are characteristics of a stationary process?\n\ni) It crosses its mean value frequently\n\n\nii) It has constant mean and variance\n\n\niii) It contains no trend component\n\n\niv) It will be stationary in first difference form", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": ", (ii), (iii), and (iv) only.\n\nExplanation: A stationary process is one in which the statistical properties of the process do not change over time.\n\n(i) A process that crosses its mean value frequently is not stationary.\n\n(ii) A stationary process has constant mean and variance, meaning that the mean and variance do not change over time.\n\n(iii) A stationary process contains no trend component, which means that the process does not exhibit a persistent directional shift in one direction.\n\n(iv) A stationary process will be stationary in first difference form, meaning that a stationary process can be transformed into its first differences and still be stationary.\n\n(A) (ii) and (iv) only is incorrect because a process that crosses its mean value frequently may still be stationary in first difference form.\n\n(B) (i) and (iii) only is incorrect because a process that does not contain a trend component may not necessarily be stationary.\n\n(C) (i), (ii), and (iii) only is incorrect because a stationary process can exhibit mean and variance changes but still not be stationary.\n\n(D) (i), (ii), (iii), and (iv) is the correct answer because all of these properties are necessary for a process to be stationary."}
{"question": "Consider again the VAR model of equation 16. Which of the following conditions must hold for it to be said that there is bi-directional feedback?", "choices": [{"label": "A", "text": "The b and d coefficients significant and the a and c coefficients insignificant"}, {"label": "B", "text": "The a and c coefficients significant and the b and d coefficients insignificant"}, {"label": "C", "text": "The a and c coefficients significant"}, {"label": "D", "text": "The b and d coefficients significant"}], "answerKey": "D", "model_answer": "and d coefficients significant and the a and c coefficients insignificant.\n\nExplanation: Bi-directional feedback means that the sign of the coefficient on the lagged endogenous variable is different for the positive and negative values of the endogenous variable. In other words, the sign of the coefficient on y\\_t will be different for y\\_(t-1)^+ and y\\_(t-1)^-. Therefore, we need to look at the signs of the coefficients on y\\_t and y\\_(t-1)^+/y\\_(t-1)^-. The b and d coefficients represent the coefficients on y\\_t and y\\_(t-1)^+/y\\_(t-1)^-, respectively. So, we need the b and d coefficients to be significant for bi-directional feedback. The a and c coefficients represent the coefficients on y\\_t and y\\_(t-1)^+/y\\_(t-1)^-, respectively. So, we need the a and c coefficients to be significant for bi-directional feedback. Therefore, the correct answer is A."}
{"question": "Consider the following sample autocorrelation estimates obtained using 250 data points:\n\n1) Lag 1 2 3\n\n2) Coefficient 0.2 -0.15 -0.1\n\n3) Assuming that the coefficients are approximately normally distributed, which of the coefficients are statistically significant at the 5% level?", "choices": [{"label": "A", "text": "1 only"}, {"label": "B", "text": "1 and 2 only"}, {"label": "C", "text": "1, 2 and 3 only"}, {"label": "D", "text": "It is not possible to determine the statistical significance since no standard errors have been given"}], "answerKey": "B", "model_answer": ""}
{"question": "Which one of the following is examined by looking at a goodness of fit statistic?", "choices": [{"label": "A", "text": "How well the population regression function fits the data"}, {"label": "B", "text": "How well the sample regression function fits the population regression function"}, {"label": "C", "text": "How well the sample regression function fits the data"}, {"label": "D", "text": "How well the population regression function fits the sample regression function."}], "answerKey": "C", "model_answer": "ell the population regression function fits the sample regression function.\n\nThe choice (D) is correct because the goodness of fit statistic examines how well the population regression function fits the sample regression function. The sample regression function is an estimate of the population regression function and the goodness of fit statistic measures the discrepancy between the sample regression function and the population regression function. The choice (A) is incorrect because it focuses on the fit of the population regression function to the data, while the choice (B) is incorrect because it focuses on the fit of the sample regression function to the population regression function. The choice (C) is also incorrect because it focuses on the fit of the sample regression function to the data, not the population regression function."}
{"question": "Which of the following statements are correct concerning the use of antithetic variates as part of a Monte Carlo experiment?\n\ni) Antithetic variates work by reducing the number of replications required to cover the whole probability space\n\nii) Antithetic variates involve employing a similar variable to that used in the simulation, but whose properties are known analytically\n\niii) Antithetic variates involve using the negative of each of the random draws and repeating the experiment using those values as the draws\n\niv) Antithetic variates involve taking one over each of the random draws and repeating the experiment using those values as the draws", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": ", (ii), (iii), and (iv) only."}
{"question": "Which one of the following statements is true concerning alternative forecast accuracy measures?", "choices": [{"label": "A", "text": "Mean squared error is usually highly correlated with trading rule profitability"}, {"label": "B", "text": "Mean absolute error provides a quadratic loss function"}, {"label": "C", "text": "Mean absolute percentage error is a useful measure for evaluating asset return forecasts"}, {"label": "D", "text": "Mean squared error penalises large forecast errors disproportionately more than small forecast errors"}], "answerKey": "D", "model_answer": "A) Mean squared error is usually highly correlated with trading rule profitability.\n\nExplanation: Mean squared error (MSE) is a measure of the average squared difference between actual and predicted values. It is commonly used in regression analysis and is a good measure of the accuracy of forecasts when the errors are normally distributed and the forecasts are unbiased. However, MSE is not always highly correlated with trading rule profitability, as there may be other factors that affect the profitability of a trading rule.\n\nMean absolute error (MAE) provides a quadratic loss function and is a useful measure for evaluating asset return forecasts. It measures the average magnitude of the errors and is less sensitive to outliers than MSE.\n\nMean absolute percentage error (MAPE) is a measure of the average percentage difference between actual and predicted values, expressed as a percentage. It is particularly useful for evaluating the accuracy of forecasts when the data are non-normally distributed or when the forecasts are biased.\n\nMean squared error penalizes large forecast errors disproportionately more than small forecast errors, which can make it less useful for evaluating the accuracy of forecasts when the errors are not normally distributed or when the forecasts are biased."}
{"question": "Which of the following criticisms of standard (\"plain vanilla\") GARCH models can be overcome by EGARCH models?\n\ni) Estimated coefficient values from GARCH models may be negative\n\nii) GARCH models cannot account for leverage effects\n\niii) The responsiveness of future volatility to positive and negative shocks is symmetric under a GARCH formulation\n\niv) GARCH models cannot allow for a feedback from the volatility to the returns", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "D) (i), (ii), (iii), and (iv) only\n\nExplanation:\n\nThe i-th criticism of standard GARCH models refers to the following:\n\n* i) Estimated coefficient values from GARCH models may be negative: EGARCH models can account for this by allowing for a mean of the volatility process that is non-linear in the squared returns process.\n* ii) GARCH models cannot account for leverage effects: EGARCH models can account for this by allowing for a leverage factor in the mean of the volatility process.\n* iii) The responsiveness of future volatility to positive and negative shocks is symmetric under a GARCH formulation: EGAR"}
{"question": "Suppose that 100 separate firms were tested to determine how many of them \"beat the market\" using a Jensen-type regression, and it is found that 3 fund managers significantly do so. Does this suggest prima facie evidence for stock market inefficiency?", "choices": [{"label": "A", "text": "Yes"}, {"label": "B", "text": "No"}, {"label": "C", "text": "In order to answer this question, you would need to test every fund manager trading in that market"}, {"label": "D", "text": "There is insufficient information given in the question to draw a conclusion about market efficiency."}], "answerKey": "B", "model_answer": "D) There is insufficient information given in the question to draw a conclusion about market efficiency.\n\nExplanation: The question does not provide enough information to determine whether there is prima facie evidence for stock market inefficiency. The fact that three fund managers significantly beat the market does not necessarily mean that the stock market is inefficient, as other factors could be at play, such as skill, luck, or market manipulation. It would be necessary to conduct a more comprehensive analysis to determine whether stock market inefficiency is present in this case or not."}
{"question": "Which of the following are advantages of the use of panel data over pure cross-sectional or pure time-series modelling?\n\n(i) The use of panel data can increase the number of degrees of freedom and therefore the power of tests\n\n(ii) The use of panel data allows the average value of the dependent variable to vary either cross-sectionally or over time or both\n\n(iii) The use of panel data enables the researcher allows the estimated relationship between the independent and dependent variables to vary either cross-sectionally or over time or both", "choices": [{"label": "A", "text": "(i) only"}, {"label": "B", "text": "(i) and (ii) only"}, {"label": "C", "text": "(ii) only"}, {"label": "D", "text": "(i), (ii), and (iii)"}], "answerKey": "B", "model_answer": "ly\nB. (i) and (ii) only\nC. (ii) only\nD. (i), (ii), and (iii)\n\nThe correct answer is: D. (i), (ii), and (iii)\nExplanation: Panel data allows the researcher to estimate the relationship between the independent and dependent variables over time, which is an advantage that pure time-series models do not have. It also allows the average value of the dependent variable to vary either cross-sectionally or over time or both, which is an advantage that pure cross-sectional models do not have. Finally, the use of panel data can increase the number of degrees of freedom and therefore the power of tests, which is an advantage that pure cross-sectional models do not have."}
{"question": "If the Engle-Granger test is applied to the residuals of a potentially cointegrating regression, what would be the interpretation of the null hypothesis?", "choices": [{"label": "A", "text": "The variables are cointegrated"}, {"label": "B", "text": "The variables are not cointegrated"}, {"label": "C", "text": "Both variables are stationary"}, {"label": "D", "text": "Both variables are non-stationary"}], "answerKey": "B", "model_answer": "riables are cointegrated."}
{"question": "Which of the following statements are true concerning the autocorrelation function (acf) and partial autocorrelation function (pacf)?\n\ni) The acf and pacf will always be identical at lag one whatever the model\n\nii) The pacf for an MA(q) model will in general be non-zero beyond lag q\n\niii) The pacf for an AR(p) model will be zero beyond lag p\n\niv) The acf and pacf will be the same at lag two for an MA(1) model", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "D) (i), (ii), (iii), and (iv) only.\n\nExplanation:\n\ni) The acf and pacf will always be identical at lag one whatever the model: False. The autocorrelation function (acf) and partial autocorrelation function (pacf) are not always identical at lag one. For example, for an IID (independent identically distributed) model, the acf and pacf will be identical at lag one. However, for non-IID models, the acf and pacf can be different at lag one.\n\nii) The pacf for an MA(q) model will in general be non-zero beyond lag q: True. The pacf for an MA(q) model will be non-zero beyond lag q, but it will eventually approach zero as the lag increases.\n\niii) The pacf for an AR(p) model will be zero beyond lag p: False. The pacf for an AR(p) model will not be zero beyond lag p. For AR(p) model, the pacf will be zero at lags 0, 1, and p, but it will be non-zero at other lags.\n\niv) The acf and pacf will be the same at lag two for an MA(1) model: False. The acf and pacf will not be the same at lag two for an MA(1) model. For an MA(1) model, the acf and pacf will be identical at lag one, but they will not be the same at lag two.\n\nTherefore, the correct answer is (D) (i), (ii), (iii), and (iv) only."}
