{"question": "Statement 1| Linear regression estimator has the smallest variance among all unbiased estimators. Statement 2| The coefficients \u03b1 assigned to the classifiers assembled by AdaBoost are always non-negative.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "LECTURE: When a predictor variable is added to a linear regression model, the variance of the linear regression estimator is decreased.\nSo, the variance of the linear regression estimator is minimized when only one predictor variable is included in the model.\nSOLUTION: To have the smallest variance, a linear regression model should have only one predictor variable. So, the classifiers assembled by AdaBoost will have the smallest variance among all unbiased estimators.\nAlso, the coefficients assigned to the classifiers are always non-negative. So, Statement 2 is true."}
{"question": "Statement 1| RoBERTa pretrains on a corpus that is approximate 10x larger than the corpus BERT pretrained on. Statement 2| ResNeXts in 2018 usually used tanh activation functions.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "SOLUTION: Statement 1 tells you that RoBERTa was pretrained on a larger corpus than BERT. Statement 2 tells you that ResNeXts in 2018 usually used tanh activation functions.\nThese two statements are talking about two different things. Statement 1 is talking about the pretraining corpus, while Statement 2 is talking about the activation functions used in ResNeXts in 2018.\nSo, these statements do not have a relationship with each other."}
{"question": "Statement 1| Support vector machines, like logistic regression models, give a probability distribution over the possible labels given an input example. Statement 2| We would expect the support vectors to remain the same in general as we move from a linear kernel to higher order polynomial kernels.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "SOLUTION: Both statement 1 and statement 2 are false.\nA support vector machine uses a kernel to transform the input data into a high-dimensional space. In this transformed space, the apriori probability of an example having a certain label is estimated. This probability is then transformed back to the input space to get a probability prediction.\nA logistic regression model is a type of support vector machine. Like other support vector machines, it gives a probability distribution over the possible labels.\nPolynomial kernels are not limited to just higher-order terms. A polynomial kernel can include terms of degree 0, and such a kernel is equivalent to a linear kernel.\nThe support vectors do not remain the same when you change the type of polynomial kernel used."}
{"question": "A machine learning problem involves four attributes plus a class. The attributes have 3, 2, 2, and 2 possible values each. The class has 3 possible values. How many maximum possible different examples are there?", "choices": [{"label": "A", "text": "12"}, {"label": "B", "text": "24"}, {"label": "C", "text": "48"}, {"label": "D", "text": "72"}], "answerKey": "D", "model_answer": "LECTURE: A machine learning problem involves multiple attributes and a class.\nAn example is a set of data points, each with a set of values for the attributes.\nA classification is a type of problem in which the class can have one of several values.\nFor a classification problem, the class is an attribute.\nThe number of maximum possible different examples is a function of the number of values each attribute can have and the number of possible values for the class.\nThis number is calculated by raising the number of values each attribute can have to the number of possible values for the class.\nFor example, if an example involves an attribute with two possible values and a class with three possible values, then there are 2 x 3 = 6 maximum possible different examples.\nSOLUTION: For this problem, each attribute has 3, 2, 2, and 2 possible values, respectively. The class has 3 possible values.\nSo, the number of maximum possible different examples is 3^4 = 81."}
{"question": "As of 2020, which architecture is best for classifying high-resolution images?", "choices": [{"label": "A", "text": "convolutional networks"}, {"label": "B", "text": "graph networks"}, {"label": "C", "text": "fully connected networks"}, {"label": "D", "text": "RBF networks"}], "answerKey": "A", "model_answer": "SOLUTION: Convolutional networks, graph networks, and RBF networks are not classication algorithms. They are types of neural networks.\nFully connected networks are a type of neural network. They are called \"fully connected\" because each layer is connected to every layer in the next layer.\nScientists use the word \"architecture\" to describe the design of a network. The design of a convolutional network is called a convolutional architecture. The design of a graph network is called a graph architecture. The design of an RBF network is called an RBF architecture."}
{"question": "Statement 1| The log-likelihood of the data will always increase through successive iterations of the expectation maximation algorithm. Statement 2| One disadvantage of Q-learning is that it can only be used when the learner has prior knowledge of how its actions affect its environment.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: The Expectation-Maximization (EM) algorithm is an iterative method for finding maximum likelihood estimates of parameters in hidden variable models. In hidden variable models, there are observed variables and unobserved variables. The observed variables are used to calculate the likelihood of the model. The unobserved variables are used to calculate the expectations of the observed variables.\nThe EM algorithm uses an iterative process to estimate the parameters of a model using the maximum likelihood estimate at each step. The log-likelihood of the data will always increase through successive iterations of the EM algorithm.\nOne disadvantage of Q-learning is that it can only be used when the learner has prior knowledge of how its actions affect its environment. This is because Q-learning uses a table of Q-values, which are updated based on the difference between expected and actual rewards. This difference is called the Q-error. To calculate the Q-error, the learner must have an estimate of the expected rewards. This estimate is based on the learner's prior knowledge.\nSOLUTION: The log-likelihood of the data will always increase through successive iterations of the EM algorithm. This is because the EM algorithm uses the maximum likelihood estimate at each step.\nOne disadvantage of Q-learning is that it can only be used when the learner has prior knowledge of how its actions affect its environment. This is because Q-learning uses a table of Q-values, which are updated based on the difference between expected and actual rewards. This difference is called the Q-error. To calculate the Q-error, the learner must have an estimate of the expected rewards. This estimate is based on the learner's prior knowledge."}
{"question": "Let us say that we have computed the gradient of our cost function and stored it in a vector g. What is the cost of one gradient descent update given the gradient?", "choices": [{"label": "A", "text": "O(D)"}, {"label": "B", "text": "O(N)"}, {"label": "C", "text": "O(ND)"}, {"label": "D", "text": "O(ND^2)"}], "answerKey": "A", "model_answer": "LECTURE: The gradient of a function gives you the rate of change of the function with respect to each variable. For example, if f(x,y) is a function of two variables, and the gradient is \u2207f, this tells you how much f changes when x changes, and how much f changes when y changes.\nIf you want to find the minimum of a function, you can use gradient descent. This method involves iteratively updating your variables in the direction of the negative gradient. That is, you move in the direction of the negative gradient to find the minimum.\nOne update of gradient descent consists of the following steps:\n1. Compute the gradient of the function.\n2. Set the previous gradient to the current gradient.\n3. Move in the direction of the negative gradient by updating your variables.\n4. Repeat until you find the minimum.\nThe key question is how much each of these steps costs. The answer depends on the size of the function and the size of the gradient.\nThe size of the function is a constant, so the cost of one update is O(ND), where N is the number of variables and D is the number of updates.\nThe size of the gradient is also a constant, so the cost of computing the gradient is O(N).\nThe remaining question is how much each of the other steps costs. Updating the variables takes O(ND) time, so the total cost of each update is O(ND)."}
{"question": "Statement 1| For a continuous random variable x and its probability distribution function p(x), it holds that 0 \u2264 p(x) \u2264 1 for all x. Statement 2| Decision tree is learned by minimizing information gain.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: A decision tree is a flowchart-like structure in which each internal node represents a test on a feature, each branch represents the outcome of the test, and each leaf node represents a class label. For a given data set, a decision tree is learned by the following process:\n1. Calculate the information gain of each possible test on each feature.\n2. Choose the test with the highest information gain as the root node of the tree.\n3. Repeat the process for each non-leaf node.\n\nThe information gain of a test on a feature is a measure of the ability of the test to distinguish between classes. It is calculated as follows:\nInformation gain = Entropy(class labels) - Entropy(conditional class labels)\nwhere Entropy(x) is the entropy of a set of class labels x.\nThe entropy of a set of class labels is a measure of the impurity of the class labels. For a set of pure class labels, the entropy is 0. For a set of mixed class labels, the entropy is a positive value.\nThe entropy of the conditional class labels is a measure of the impurity of the class labels, given the test outcome. This can be calculated as follows:\nConditional entropy = -p(outcome) \\* log2(p(outcome))\nEntropy(conditional class labels) = entropy(class labels) - conditional entropy\nwhere p(outcome) is the probability of the test outcome.\nThe test with the highest information gain as the root node of the tree will predict the class label with the highest entropy. This is consistent with the decision tree's ability to maximize information gain.\nSOLUTION: To show that this process does indeed minimize information gain, consider the following:\nSuppose that the process selects a decision tree with a certain information gain. Then, by definition of information gain, this tree has the highest information gain of all decision trees. So, the process has found the decision tree that minimizes information gain."}
{"question": "Consider the Bayesian network given below. How many independent parameters are needed for this Bayesian Network H -> U <- P <- W?", "choices": [{"label": "A", "text": "2"}, {"label": "B", "text": "4"}, {"label": "C", "text": "8"}, {"label": "D", "text": "16"}], "answerKey": "C", "model_answer": "SOLUTION: To determine how many independent parameters are needed, use the following rule: Each node in the network represents one independent parameter.\nThere are 4 nodes in the network: H, U, P, and W.\nH and U are conditioned on P and W. So, these two nodes in the network do not represent independent parameters.\nP and W are not conditioned on anything. So, these two nodes in the network represent independent parameters.\nThere are 2 independent parameters in the network."}
{"question": "As the number of training examples goes to infinity, your model trained on that data will have:", "choices": [{"label": "A", "text": "Lower variance"}, {"label": "B", "text": "Higher variance"}, {"label": "C", "text": "Same variance"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": "LECTURE: The variance of a model is a measure of how much the model's predictions can differ from each other. In other words, a model with a lower variance is more consistent in its predictions, while a model with a higher variance is more uncertain in its predictions.\nFor a model trained on a finite set of training examples, the variance is determined by the size of the set and the complexity of the model. As the size of the set goes to infinity, the variance of the model goes to zero. This means that the model's predictions become more consistent (or less uncertain).\nSOLUTION: The phrase 'As the number of training examples goes to infinity, your model trained on that data will have:' tells you that infinite data will be used to train the model. This means that the size of the set is infinite, and therefore, the variance of the model will go to zero."}
{"question": "Statement 1| The set of all rectangles in the 2D plane (which includes non axisaligned rectangles) can shatter a set of 5 points. Statement 2| The VC-dimension of k-Nearest Neighbour classifier when k = 1 is infinite.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "SOLUTION: Both statements are true.\nThe VC-dimension of a classifier is a measure of its ability to distinguish between training examples. A lower VC-dimension indicates a more powerful classifier. The VC-dimension is infinite when the classifier can distinguish between any two points. This suggests that the set of all rectangles in the 2D plane can shatter a set of five points.\nSOLUTION: To figure out whether both statements are true, consider whether they can both be true.\nThe set of all rectangles in the 2D plane includes non-axis-aligned rectangles. This means that the set of all rectangles in the 2D plane can shatter a set of five points.\nThe VC-dimension of a k-Nearest Neighbour classifier is infinite when k=1. This means that the classifier can distinguish between any two points.\nBoth statements are true."}
{"question": "_ refers to a model that can neither model the training data nor generalize to new data.", "choices": [{"label": "A", "text": "good fitting"}, {"label": "B", "text": "overfitting"}, {"label": "C", "text": "underfitting"}, {"label": "D", "text": "all of the above"}], "answerKey": "C", "model_answer": "SOLUTION: An underfitting model is a model that can't capture the patterns in the training data. A good fitting model is a model that is able to capture the patterns in the training data. An overfitting model is a model that is able to fit the training data perfectly, but does not have the ability to generalize to new data."}
{"question": "Statement 1| The F1 score can be especially useful for datasets with class high imbalance. Statement 2| The area under the ROC curve is one of the main metrics used to assess anomaly detectors.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "SOLUTION: Both statements are talking about different things.\nStatement 1 is talking about the F1 score, which can be useful for datasets with class imbalance. The F1 score measures the balance between two types of errors you can make: false alarms and missed detections.\nStatement 2 is talking about the ROC curve, which is a way to visualize a classifier's performance, and the area under the ROC curve, which is a way to quantify that performance. The area under the ROC curve is a main metric used to assess anomaly detectors.\nSo, the two statements are not directly related."}
{"question": "Statement 1| The back-propagation algorithm learns a globally optimal neural network with hidden layers. Statement 2| The VC dimension of a line should be at most 2, since I can find at least one case of 3 points that cannot be shattered by any line.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "SOLUTION: The back-propagation algorithm is used to train neural networks with hidden layers. To train a neural network, the algorithm adjusts the weights and biases of the neurons to minimize the error between the predicted outputs and the true outputs. This process is called learning.\nWhen a neural network is trained with back-propagation, it learns a mapping from inputs to outputs that is globally optimal. This means that the neural network has learned the globally optimal mapping that cannot be improved by any other mapping that is computed by a neural network with the same number of neurons.\nThe value of the VC dimension of a line is a measure of the maximum number of points that a line can shatter. The VC dimension of a line is at most 2. This means that a line can shatter at most two points.\nConsider three points that are not shattered by any line. Choose any three points that are not on a line. The line that is closest to these points will not shatter them. This shows that the VC dimension of a line is at most 2."}
{"question": "High entropy means that the partitions in classification are", "choices": [{"label": "A", "text": "pure"}, {"label": "B", "text": "not pure"}, {"label": "C", "text": "useful"}, {"label": "D", "text": "useless"}], "answerKey": "B", "model_answer": "LECTURE: The entropy of a set is a measure of the amount of order in the set.\nA set with high entropy has many partitions. A set with low entropy has few partitions.\nA pure set has only one element. A set that is not pure has at least two elements.\nA useful partition can be used to put the elements of a set into groups. A not useful partition cannot be used to put the elements of a set into groups.\nSOLUTION: High entropy means that the partitions in classification are not pure.\nA not pure partition can put elements into more than one group. A pure partition can only put elements into one group.\nA useful partition can put elements into groups. A not useful partition cannot put elements into groups."}
{"question": "Statement 1| Layer Normalization is used in the original ResNet paper, not Batch Normalization. Statement 2| DCGANs use self-attention to stabilize training.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": ""}
{"question": "In building a linear regression model for a particular data set, you observe the coefficient of one of the features having a relatively high negative value. This suggests that", "choices": [{"label": "A", "text": "This feature has a strong effect on the model (should be retained)"}, {"label": "B", "text": "This feature does not have a strong effect on the model (should be ignored)"}, {"label": "C", "text": "It is not possible to comment on the importance of this feature without additional information"}, {"label": "D", "text": "Nothing can be determined."}], "answerKey": "C", "model_answer": "LECTURE: A coefficient in a regression model can have a high negative value, but this does not necessarily mean that the feature has a strong effect on the model. The magnitude of the coefficient is one factor that is considered when deciding whether a feature has a strong effect on the model, but it is not the only one.\nOther factors that are considered include the value of the constant term in the regression equation, the values of the other features in the model, and the size of the dataset.\nSOLUTION: To decide which of these statements are true, you need to consider the magnitude of the coefficient, the value of the constant term, and the values of the other features in the model.\nThe coefficient for this feature is negative and has a high magnitude, which means that this feature has a strong effect on the model.\nThe constant term is positive, which means that this effect is negative. This is not what you want.\nThe values of the other features in the model are not relevant to this feature."}
{"question": "For a neural network, which one of these structural assumptions is the one that most affects the trade-off between underfitting (i.e. a high bias model) and overfitting (i.e. a high variance model):", "choices": [{"label": "A", "text": "The number of hidden nodes"}, {"label": "B", "text": "The learning rate"}, {"label": "C", "text": "The initial choice of weights"}, {"label": "D", "text": "The use of a constant-term unit input"}], "answerKey": "A", "model_answer": "LECTURE: A neural network is a machine learning model that is inspired by the way that biological neurons communicate with each other. A neural network has one or more layers of interconnected nodes, called neurons.\nEach neuron has a set of inputs and a set of outputs. The inputs are the signals that the neuron receives from other neurons in the network. The outputs are the signals that the neuron sends to other neurons in the network.\nThe output of a neuron is determined by the inputs it receives and the function that is applied to those inputs. One common function is a linear function. With a linear function, the output of a neuron is the sum of the weights and biases.\nThe weights are the parameters of the model. The weights determine the strength of the connections between neurons. The biases are constants that can affect the output of a neuron.\nSOLUTION: The use of a constant-term unit input affects the trade-off between underfitting and overfitting. A constant-term unit input is a node in the input layer that is always active. This node affects the outputs of all the neurons in the network.\nHaving a constant-term unit input can help prevent a neural network from underfitting. Underfitting occurs when a neural network is too simple to model the relationships in the data. A constant-term unit input can help ensure that the neural network is always active, which can help prevent underfitting."}
{"question": "For polynomial regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "The polynomial degree"}, {"label": "B", "text": "Whether we learn the weights by matrix inversion or gradient descent"}, {"label": "C", "text": "The assumed variance of the Gaussian noise"}, {"label": "D", "text": "The use of a constant-term unit input"}], "answerKey": "A", "model_answer": "SOLUTION: The polynomial degree affects the trade-off between underfitting and overfitting.\nThe degree of the polynomial affects how well the model can fit the data. Increasing the degree of the polynomial can help the model fit the data better. However, increasing the degree also increases the complexity of the model. This can make the model more prone to overfitting."}
{"question": "Statement 1| As of 2020, some models attain greater than 98% accuracy on CIFAR-10. Statement 2| The original ResNets were not optimized with the Adam optimizer.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: For a claim to be true, it must be backed by evidence. For a claim to be false, it must be backed by evidence.\nExamples of evidence include but are not limited to experiments, studies, research, and opinions of experts.\nExamples of claims include but are not limited to statements, conclusions, and arguments.\nTests can be designed to investigate whether a claim is true or false.\nHow do you design a test to investigate whether a claim is true?\nFirst, identify the evidence needed to support the claim.\nThen, use this evidence to design a test that can investigate whether the claim is true.\nOne of the criteria for the models is greater than 98% accuracy on CIFAR-10.\nThis criteria can be met by a model that is optimized with a different optimizer.\nSo, the accuracy of a model is not determined by the optimizer used."}
{"question": "The K-means algorithm:", "choices": [{"label": "A", "text": "Requires the dimension of the feature space to be no bigger than the number of samples"}, {"label": "B", "text": "Has the smallest value of the objective function when K = 1"}, {"label": "C", "text": "Minimizes the within class variance for a given number of clusters"}, {"label": "D", "text": "Converges to the global optimum if and only if the initial means are chosen as some of the samples themselves"}], "answerKey": "C", "model_answer": "LECTURE: The K-means algorithm is a method for clustering data into K clusters. The algorithm begins with K initial means, chosen randomly or by some other method. Then, each point in the data is assigned to the cluster whose mean is closest. After all points have been assigned, the means are updated by taking the mean of all the points in each cluster. This process of assigning points to clusters and updating means is repeated for a number of iterations.\nThe K-means algorithm has the following properties:\n1. Requires the dimension of the feature space to be no bigger than the number of samples.\nThis property ensures that there are no missing values in the data.\n2. Has the smallest value of the objective function when K = 1.\nThe objective function measures how well the algorithm is performing. Minimizing the objective function is one of the goals of the K-means algorithm.\n3. Minimizes the within class variance for a given number of clusters.\nWithin class variance is a measure of how much the points in each cluster differ from their mean. For a given number of clusters, minimizing within class variance is one of the goals of the K-means algorithm.\n4. Converges to the global optimum if and only if the initial means are chosen as some of the samples themselves.\nThe global optimum is the best possible outcome for the algorithm. Converging to the global optimum is one of the goals of the K-means algorithm.\nSOLUTION: The K-means algorithm has the following properties:\n1. Requires the dimension of the feature space to be no bigger than the number of samples.\n2. Has the smallest value of the objective function when K = 1.\n3. Minimizes the within class variance for a given number of clusters.\n4. Converges to the global optimum if and only if the initial means are chosen as some of the samples themselves.\nThe first three properties are not affected by the dimension of the feature space. So, the K-means algorithm does not require the dimension of the feature space to be no bigger than the number of samples."}
{"question": "Statement 1| VGGNets have convolutional kernels of smaller width and height than AlexNet's first-layer kernels. Statement 2| Data-dependent weight initialization procedures were introduced before Batch Normalization.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "SOLUTION: Both statements are about the differences between VGGNets and AlexNets.\nStatement 1 says that VGGNets have convolutional kernels of smaller width and height than AlexNet's first-layer kernels. This means that the filters in the first layers of VGGNets have smaller sizes than the filters in the first layers of AlexNet.\nStatement 2 says that data-dependent weight initialization procedures were introduced before Batch Normalization. This means that techniques for using data to initialize the weights of a network were developed before Batch Normalization was proposed."}
{"question": "What is the rank of the following matrix? A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]", "choices": [{"label": "A", "text": "0"}, {"label": "B", "text": "1"}, {"label": "C", "text": "2"}, {"label": "D", "text": "3"}], "answerKey": "B", "model_answer": "LECTURE: A matrix is a grid of numbers. The rank of a matrix is a measure of the number of columns in the matrix that are determined by the rows.\nFor example, consider the matrix below:\n| 1 | 2 | 3 |\n| 4 | 5 | 6 |\n| 7 | 8 | 9 |\nThe rank of this matrix is 2. You can use one of the rows to determine the first column, and then the other rows determine the second and third columns.\n\nSOLUTION: The rank of a matrix is equal to the number of rows in the matrix. This matrix has 3 rows and 3 columns, so the rank of A is 3."}
{"question": "Statement 1| Density estimation (using say, the kernel density estimator) can be used to perform classification. Statement 2| The correspondence between logistic regression and Gaussian Naive Bayes (with identity class covariances) means that there is a one-to-one correspondence between the parameters of the two classifiers.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": ""}
{"question": "Suppose we would like to perform clustering on spatial data such as the geometrical locations of houses. We wish to produce clusters of many different sizes and shapes. Which of the following methods is the most appropriate?", "choices": [{"label": "A", "text": "Decision Trees"}, {"label": "B", "text": "Density-based clustering"}, {"label": "C", "text": "Model-based clustering"}, {"label": "D", "text": "K-means clustering"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| In AdaBoost weights of the misclassified examples go up by the same multiplicative factor. Statement 2| In AdaBoost, weighted training error e_t of the tth weak classifier on training data with weights D_t tends to increase as a function of t.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "SOLUTION: Statement 1 tells you that the weights of the misclassified examples increase by the same multiplicative factor. So, the weights of the correctly classified examples decrease by the same multiplicative factor. Since the weights of the correctly classified examples decrease, the weights of the misclassified examples must increase.\nStatement 2 tells you that the weighted training error tends to increase as a function of the number of weak classifiers. So, the weights of the misclassified examples must increase."}
{"question": "MLE estimates are often undesirable because", "choices": [{"label": "A", "text": "they are biased"}, {"label": "B", "text": "they have high variance"}, {"label": "C", "text": "they are not consistent estimators"}, {"label": "D", "text": "None of the above"}], "answerKey": "B", "model_answer": "SOLUTION: MLE estimates are biased, which means that they systematically over- or underestimate the parameter. This happens because MLE estimates use the sample data to calculate the parameter, but the data are typically only a sample from the underlying population. So, the MLE estimates may not accurately reflect the true population parameter."}
{"question": "Computational complexity of Gradient descent is,", "choices": [{"label": "A", "text": "linear in D"}, {"label": "B", "text": "linear in N"}, {"label": "C", "text": "polynomial in D"}, {"label": "D", "text": "dependent on the number of iterations"}], "answerKey": "C", "model_answer": "LECTURE: The computational complexity of an algorithm is a measure of the amount of resources the algorithm uses. In the case of gradient descent, the resources that are relevant are the number of operations performed on the data.\nGradient descent has three stages: the forward pass, the backward pass, and the update. The forward pass performs n operations on n data points. The backward pass performs n operations on n data points. The update performs n^2 operations on n data points. So, the number of operations is linear in the number of data points n.\nSince the number of operations is linear in n, the computational complexity of gradient descent is linear in n."}
{"question": "Averaging the output of multiple decision trees helps _.", "choices": [{"label": "A", "text": "Increase bias"}, {"label": "B", "text": "Decrease bias"}, {"label": "C", "text": "Increase variance"}, {"label": "D", "text": "Decrease variance"}], "answerKey": "D", "model_answer": "LECTURE: One of the advantages of using a committee of decision trees is that it can decrease bias. This is because the committee has multiple trees that are trained on different data.\nDecreasing bias is one of the goals of an ensemble method.\nAn ensemble method is a set of weak learners that are combined to make a strong learner. Ensemble methods have two main benefits:\nThey can decrease bias: The results of an ensemble method are less biased than the results of a single decision tree.\nThey can increase accuracy: Ensemble methods can improve the accuracy of a classifier.\nAveraging the output of multiple decision trees helps decrease bias.\nImagine that you have 5 decision trees. The output of each tree is either 0 or 1. To make a final decision, you can use a simple majority vote. This means that you use the output of most of the trees as the final decision.\nFor example, imagine that the 5 trees output 0, 1, 0, 1, and 0. The majority vote is 0.\nBy using a majority vote, you can decrease the bias of your decision.\nIncreasing variance is not a way to decrease bias.\nIncreasing variance means that the outputs of the decision trees have a wider range. This can make the final decision less certain.\nDecreasing variance is not a way to decrease bias.\nDecreasing variance means that the outputs of the decision trees have a smaller range. This can make the final decision less flexible."}
{"question": "The model obtained by applying linear regression on the identified subset of features may differ from the model obtained at the end of the process of identifying the subset during", "choices": [{"label": "A", "text": "Best-subset selection"}, {"label": "B", "text": "Forward stepwise selection"}, {"label": "C", "text": "Forward stage wise selection"}, {"label": "D", "text": "All of the above"}], "answerKey": "C", "model_answer": "SOLUTION: The difference between forward stepwise selection and forward stage wise selection is that stepwise selection selects a single variable at a time, while stage-wise selection selects a subset of variables at a time. So, forward stepwise selection is a form of stepwise selection, while forward stage wise selection is a form of stage-wise selection.\nThe answer is B."}
{"question": "Neural networks:", "choices": [{"label": "A", "text": "Optimize a convex objective function"}, {"label": "B", "text": "Can only be trained with stochastic gradient descent"}, {"label": "C", "text": "Can use a mix of different activation functions"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": "SOLUTION: This is not a false statement. This is a description of how neural networks can be trained.\nA neural network can use backpropagation to optimize a convex objective function. A convex objective function has the property that the function is smaller when the parameters are larger. This is a property that can make it easier to train a neural network.\nA neural network can be trained with stochastic gradient descent. This is a type of optimization algorithm. It is called stochastic because the algorithm takes small steps, or gradual steps, towards the answer. This can help the algorithm avoid getting stuck in a local minimum, or a low point, in the objective function.\nA neural network can use a mix of different activation functions. Activation functions are functions that are applied to the output of each neuron. Different activation functions can have different properties. For example, some activation functions may help the neural network to learn complex tasks."}
{"question": "Say the incidence of a disease D is about 5 cases per 100 people (i.e., P(D) = 0.05). Let Boolean random variable D mean a patient \u201chas disease D\u201d and let Boolean random variable TP stand for \"tests positive.\" Tests for disease D are known to be very accurate in the sense that the probability of testing positive when you have the disease is 0.99, and the probability of testing negative when you do not have the disease is 0.97. What is P(TP), the prior probability of testing positive.", "choices": [{"label": "A", "text": "0.0368"}, {"label": "B", "text": "0.473"}, {"label": "C", "text": "0.078"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": "LECTURE: The probability of a disease is called the incidence of the disease. The incidence of a disease D is a measure of the proportion of people who have the disease. This probability is often written as P(D).\nA Boolean random variable is a variable that can take on only the values false or true. In the context of disease diagnosis, a Boolean random variable D can represent the idea that a patient \"has disease D.\" The probability of a Boolean random variable D is a measure of how likely the variable is to take the value true. This probability is often written as P(D).\nSOLUTION: P(D) is the incidence of the disease.\nP(D) = 0.05.\nSo, the probability of testing positive when you have the disease is 0.99. The probability of testing positive is 0.99.\nThe probability of testing negative when you do not have the disease is 0.97. The probability of testing negative is 0.97.\nSo, P(TP) = 0.99 x 0.97 = 0.96."}
{"question": "Statement 1| After mapped into feature space Q through a radial basis kernel function, 1-NN using unweighted Euclidean distance may be able to achieve better classification performance than in original space (though we can\u2019t guarantee this). Statement 2| The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SVM.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: The VC dimension of a model is a measure of its ability to classify new data.\nA model has a larger VC dimension than an earlier model if it is able to classify some of the examples that the earlier model could not.\nSOLUTION: The first statement says that using a 1-NN classifier with unweighted Euclidean distance may be able to achieve better classification performance than in the original space. It does not guarantee that performance will be better. So, the first statement is true.\nThe second statement says that the VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SVM. This means that a Perceptron is a simpler model than a simple linear SVM. It also means that a Perceptron has a smaller VC dimension than a simple linear SVM. So, the second statement is true."}
{"question": "The disadvantage of Grid search is", "choices": [{"label": "A", "text": "It can not be applied to non-differentiable functions."}, {"label": "B", "text": "It can not be applied to non-continuous functions."}, {"label": "C", "text": "It is hard to implement."}, {"label": "D", "text": "It runs reasonably slow for multiple linear regression."}], "answerKey": "D", "model_answer": "SOLUTION: Grid search is a brute-force method that tries all combinations of model hyperparameters to find the best set. One disadvantage of Grid search is that it can be difficult to implement. For example, if you have a large number of hyperparameters or a large search space, you may need to write a lot of code to define your model with all the different hyperparameters.\nAnother disadva-tage of Grid search is that it can be slow. For example, if you are doing a Grid search over 10 different values of a hyperparameter, with 10-fold cross-validation, and each fold takes 1 second to evaluate, then the total time to finish the Grid search will be 10 times longer than a single run of your model with the best hyperparameters!\nA third disadvantage of Grid search is that it can be hard to interpret. For example, consider a situation where you are trying to choose the best value of k for a k-nearest neighbor model. You do a Grid search over k values from 1 to 10, and the best value of k is 5. But how do you know if k = 5 is a good choice, or if k = 5 is just a random lucky number?"}
{"question": "Predicting the amount of rainfall in a region based on various cues is a ______ problem.", "choices": [{"label": "A", "text": "Supervised learning"}, {"label": "B", "text": "Unsupervised learning"}, {"label": "C", "text": "Clustering"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": "LECTURE: A problem is a question that needs to be answered. In machine learning, you can use algorithms to answer questions and solve problems.\nThere are two main types of machine learning problems:\nSupervised learning. In supervised learning, you are given a set of labeled examples. A labeled example consists of an input object and a output label. The goal of supervised learning is to learn a function that can map inputs to outputs.\nFor example, consider a problem where you are given a set of images of cat and dog. Your job is to use this information to predict whether a new image depicts a cat or a dog. This is a supervised learning problem because you are given labeled examples of both cat and dog images.\nUnsupervised learning. In unsupervised learning, you are given a set of unlabeled examples. The goal of unsupervised learning is to learn a structure from the data.\nFor example, consider a problem where you are given a set of data points. Your job is to use this information to identify the underlying structure of the data. This is an unsupervised learning problem because there is no labeled information.\nClustering. Clustering is a type of unsupervised learning. In clustering, you are given a set of unlabeled data points. The goal of clustering is to group the data points into clusters.\nFor example, consider a problem where you are given a set of data points. Your job is to use this information to group the data points into clusters. This is a clustering problem.\nSOLUTION: Predicting the amount of rainfall in a region based on various cues is a supervised learning problem. You are given data on rainfall and other factors. The goal is to learn a function that can predict the amount of rainfall based on the other factors."}
{"question": "Which of the following sentence is FALSE regarding regression?", "choices": [{"label": "A", "text": "It relates inputs to outputs."}, {"label": "B", "text": "It is used for prediction."}, {"label": "C", "text": "It may be used for interpretation."}, {"label": "D", "text": "It discovers causal relationships"}], "answerKey": "D", "model_answer": "LECTURE: Regression is a method for predicting a numeric outcome.\nWhen you regress a numeric outcome on one or more predictor variables, you estimate a set of parameters that can be used to predict the outcome for new values of the predictor variables. For example, you can use a regression model to predict a person's weight based on their height.\nSOLUTION: The following sentence is false regarding regression:\n\"It discovers causal relationships.\"\nRegression can uncover patterns in the data that suggest a causal relationship between the predictor variables and the outcome. However, regression does not establish a causal relationship."}
{"question": "Which one of the following is the main reason for pruning a Decision Tree?", "choices": [{"label": "A", "text": "To save computing time during testing"}, {"label": "B", "text": "To save space for storing the Decision Tree"}, {"label": "C", "text": "To make the training set error smaller"}, {"label": "D", "text": "To avoid overfitting the training set"}], "answerKey": "D", "model_answer": "LECTURE: A decision tree is a flowchart-like model of a decision. Each decision in the decision tree is represented by a node, and each arm of the decision is represented by a branch.\nOne of the main uses of decision trees is in testing. You can use a decision tree to simulate a decision and identify the outcome. For example, if you have a decision tree that rules out certain outputs, the decision tree can tell you what inputs cause certain outputs.\nPruning a decision tree is a way to improve its performance. In this case, the training set error is a measure of the error of the decision tree.\nSOLUTION: The main reason for pruning a decision tree is to reduce the training set error. Pruning can make the decision tree faster and smaller, but these are not the main reasons for pruning."}
{"question": "Statement 1| The kernel density estimator is equivalent to performing kernel regression with the value Yi = 1/n at each point Xi in the original data set. Statement 2| The depth of a learned decision tree can be larger than the number of training examples used to create the tree.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "SOLUTION: The kernel density estimator is a non-parametric method that can be used to estimate the probability density function of a random variable. It does not make any assumptions about the form of the density.\nKernel regression is a method for predicting the value of a target variable. It does not estimate the probability density function of a random variable.\nSo, the kernel density estimator is not equivalent to performing kernel regression with the value Yi = 1/n at each point Xi in the original data set.\nThe depth of a decision tree is a measure of the maximum number of levels in the tree. This depth is determined by the number of training examples used to create the tree.\nSo, the depth of a learned decision tree can be larger than the number of training examples used to create the tree."}
{"question": "Suppose your model is overfitting. Which of the following is NOT a valid way to try and reduce the overfitting?", "choices": [{"label": "A", "text": "Increase the amount of training data."}, {"label": "B", "text": "Improve the optimisation algorithm being used for error minimisation."}, {"label": "C", "text": "Decrease the model complexity."}, {"label": "D", "text": "Reduce the noise in the training data."}], "answerKey": "B", "model_answer": "LECTURE: In a machine learning model, overfitting occurs when the model is too complex and starts to learn the noise in the training data. This can result in a model that performs well on the training data but poorly on new, unseen data.\nSOLUTION: If a model is overfitting, one way to try and reduce the overfitting is to decrease the model complexity. This means using a simpler model that has fewer parameters.\nIncreasing the amount of training data, reducing the noise in the training data, and improving the optimization algorithm being used for error minimization are not ways to decrease model complexity."}
{"question": "Statement 1| The softmax function is commonly used in mutliclass logistic regression. Statement 2| The temperature of a nonuniform softmax distribution affects its entropy.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "SOLUTION: The softmax function is used in multiclass logistic regression.\nMulticlass logistic regression is a type of regression analysis in which the dependent variable is a categorical variable with more than two categories. The softmax function is used to determine the probabilities that a particular class will be chosen.\nThe temperature of a nonuniform softmax distribution affects its entropy.\nEntropy is a measure of the amount of uncertainty in a distribution. The temperature of a softmax distribution affects the shape of the distribution. So, the temperature of a nonuniform softmax distribution affects its entropy."}
{"question": "Which of the following is/are true regarding an SVM?", "choices": [{"label": "A", "text": "For two dimensional data points, the separating hyperplane learnt by a linear SVM will be a straight line."}, {"label": "B", "text": "In theory, a Gaussian kernel SVM cannot model any complex separating hyperplane."}, {"label": "C", "text": "For every kernel function used in a SVM, one can obtain an equivalent closed form basis expansion."}, {"label": "D", "text": "Overfitting in an SVM is not a function of number of support vectors."}], "answerKey": "A", "model_answer": "SOLUTION: An SVM can use a Gaussian kernel to find a non-linear separating hyperplane. But in theory, a Gaussian kernel SVM cannot model any complex separating hyperplane. So, in theory, a Gaussian kernel SVM can only find linear separating hyperplanes.\nFor two dimensional data points, the separating hyperplane learnt by a linear SVM will be a straight line. So, for two dimensional data points, a linear SVM can model any complex separating hyperplane.\nFor every kernel function used in a SVM, one can obtain an equivalent closed form basis expansion. This means that you can use a different kernel function to find an equivalent separating hyperplane. But if you find the separating hyperplane using a different kernel function, it may not be equivalent to the separating hyperplane found by the original kernel function.\nOverfitting in a SVM is not a function of the number of support vectors. Overfitting in a SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: SOLUTION: S"}
{"question": "Which of the following is the joint probability of H, U, P, and W described by the given Bayesian Network H -> U <- P <- W? [note: as the product of the conditional probabilities]", "choices": [{"label": "A", "text": "P(H, U, P, W) = P(H) * P(W) * P(P) * P(U)"}, {"label": "B", "text": "P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(W | H, P)"}, {"label": "C", "text": "P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(U | H, P)"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": "SOLUTION: The given Bayesian Network is:\nH -> U <- P <- W\nThe joint probability of H, U, P, and W is the product of the conditional probabilities:\nP(H, U, P, W) = P(H) * P(W) * P(P) * P(U)\n= P(H) * P(W) * 1 / 3 * P(U)\n= P(H) * P(W) * 1 / 3 * P(U | H, P)\n= P(H) * P(W) * 1 / 3 * P(P | W) * P(U | H, P)\n= P(H) * P(W) * 1 / 3 * P(P | W) * P(U) | H, P\n= P(H) * P(W) * 1 / 3 * P(P | W) * P(U)\n= P(H) * P(W) * 1 / 3 * P(U) | H, P, P\n= P(H) * P(W) * 1 / 3 * P(U)\n= P(H) * P(W) * 1 / 3 * 1 / 3\n= P(H) * 1 / 9 * P(U)\n= P(H) * 1 / 9 * P(U | H, P)\n= P(U | H, P)\nThe table shows the values of each variable. Each cell in the table represents the value of the variable for a particular value of the other variables in the network. For example, the cell P(H, U, P, W) represents the joint probability that H is true, U is true, P is true, and W is true, given the values of the other variables in the network. This cell has the value P(H) * P(W) * P(P) * P(U), which is equal to 1/9 * 1/9 * 1/3 * 1/3."}
{"question": "Statement 1| Since the VC dimension for an SVM with a Radial Base Kernel is infinite, such an SVM must be worse than an SVM with polynomial kernel which has a finite VC dimension. Statement 2| A two layer neural network with linear activation functions is essentially a weighted combination of linear separators, trained on a given dataset; the boosting algorithm built on linear separators also finds a combination of linear separators, therefore these two algorithms will give the same result.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "SOLUTION: The first statement is true. Since the VC dimension for an SVM with a Radial Base Kernel is infinite, the SVM must have a lower VC dimension than an SVM with a polynomial kernel which has a finite VC dimension.\nThe second statement is true. A two layer neural network with linear activation functions is a weighted combination of linear functions, which are linear separators. The boosting algorithm is a way to combine linear separators to improve their accuracy. So, a two layer neural network with linear activation functions and the boosting algorithm will give the same result."}
{"question": "Statement 1| The ID3 algorithm is guaranteed to find the optimal decision tree. Statement 2| Consider a continuous probability distribution with density f() that is nonzero everywhere. The probability of a value x is equal to f(x).", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: The ID3 algorithm is a decision tree-based learning algorithm.\nA decision tree is a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility.\nID3 stands for \"Iterative Dichotomizer 3\". The algorithm uses a top-down approach to construct a decision tree by sorting the data by one of the variables, and then constructing a tree that splits the data based on the value of that variable.\nFor example, consider the following data:\n| Name | Age | Income | Wealth |\n|---|---|---|---|\n| Alice | 28 | 50000 | 10000 |\n| Bob | 35 | 100000 | 50000 |\n| Carol | 50 | 150000 | 100000 |\n| David | 40 | 120000 | 80000 |\n| Eve | 25 | 60000 | 30000 |\n| Frank | 35 | 120000 | 90000 |\n| Grace | 28 | 70000 | 50000 |\n|\nThe algorithm starts by sorting the data by age.\n| Name | Age | Income | Wealth |\n|---|---|---|---|\n| Bob | 35 | 100000 | 50000 |\n| Carol | 50 | 150000 | 100000 |\n| David | 40 | 120000 | 80000 |\n| Eve | 25 | 60000 | 30000 |\n| Frank | 35 | 120000 | 90000 |\n| Grace | 28 | 70000 | 50000 |\n| Alice | 28 | 50000 | 10000 |\n|\nThen, it constructs a tree that splits the data based on age.\n| Name | Age | Income | Wealth |\n|---|---|---|---|\n| Bob | 35 | 100000 | 50000 |\n| Carol | 50 | 150000 | 100000 |\n| David | 40 | 120000 | 80000 |\n| Eve | 25 | 60000 | 30000 |\n| Frank | 35 | 120000 | 90000 |\n| Grace | 28 | 70000 | 50000 |\n| Alice | 28 | 50000 | 10000 |\n|  |  |  |  |\n|"}
{"question": "Given a Neural Net with N input nodes, no hidden layers, one output node, with Entropy Loss and Sigmoid Activation Functions, which of the following algorithms (with the proper hyper-parameters and initialization) can be used to find the global optimum?", "choices": [{"label": "A", "text": "Stochastic Gradient Descent"}, {"label": "B", "text": "Mini-Batch Gradient Descent"}, {"label": "C", "text": "Batch Gradient Descent"}, {"label": "D", "text": "All of the above"}], "answerKey": "D", "model_answer": "SOLUTION: Batch Gradient Descent does not use an entropy loss or a sigmoid activation function. So, Batch Gradient Descent cannot be used to find the global optimum.\nStochastic Gradient Descent, Mini-Batch Gradient Descent, and Batch Gradient Descent are different types of gradient descent algorithms. These algorithms find the minimum of a function.\nTo find the global optimum, you can use one of these gradient descent algorithms. These algorithms will help you find the lowest point of the function."}
{"question": "Adding more basis functions in a linear model, pick the most probably option:", "choices": [{"label": "A", "text": "Decreases model bias"}, {"label": "B", "text": "Decreases estimation bias"}, {"label": "C", "text": "Decreases variance"}, {"label": "D", "text": "Doesn\u2019t affect bias and variance"}], "answerKey": "A", "model_answer": "LECTURE: In machine learning, a model is trained on a dataset to make predictions on new data. One of the criteria for a model is that it has low bias and low variance.\nBias is the expected difference between the model's prediction and the true output. Low bias means that, on average, the model's predictions are accurate.\nVariance is a measure of how much the model's predictions deviate from the average prediction. Low variance means that, on average, the model's predictions are close to the average prediction.\nSOLUTION: When you add more basis functions to a linear model, you decrease the variance of the model. This means that the model's predictions are more likely to be close to the average prediction.\nHowever, adding more basis functions also increases the complexity of the model. This can increase the bias of the model. So, adding more basis functions to a linear model will decrease variance but may increase bias."}
{"question": "Consider the Bayesian network given below. How many independent parameters would we need if we made no assumptions about independence or conditional independence H -> U <- P <- W?", "choices": [{"label": "A", "text": "3"}, {"label": "B", "text": "4"}, {"label": "C", "text": "7"}, {"label": "D", "text": "15"}], "answerKey": "D", "model_answer": "SOLUTION: To determine the number of independent parameters, you need to find the number of nodes in the network that do not have any incoming edges.\nIn the network H -> U <- P <- W, there are five nodes: H, U, P, W, and L. The three leaves of the network are U, P, and W. The other two nodes, H and L, have incoming edges from the three leaves. So, H and L depend on the three observations.\nThere is one independent parameter. It is the probability of the evidence, P(H), which does not depend on the specific values of the conditions."}
{"question": "Another term for out-of-distribution detection is?", "choices": [{"label": "A", "text": "anomaly detection"}, {"label": "B", "text": "one-class detection"}, {"label": "C", "text": "train-test mismatch robustness"}, {"label": "D", "text": "background detection"}], "answerKey": "A", "model_answer": "SOLUTION: Out-of-distribution detection is also known as anomaly detection.\nAnomaly detection is the task of identifying data that does not conform to the normal or expected pattern. This is often called an outlier or an anomaly."}
{"question": "Statement 1| We learn a classifier f by boosting weak learners h. The functional form of f\u2019s decision boundary is the same as h\u2019s, but with different parameters. (e.g., if h was a linear classifier, then f is also a linear classifier). Statement 2| Cross validation can be used to select the number of iterations in boosting; this procedure may help reduce overfitting.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "LECTURE: A classifier is a function that maps observations about an object to a classification of the object. For example, a classifier may use an observation about a person to determine the person's age. In this case, the classification is a number.\nA decision boundary is a boundary that separates observations into classes. For example, a decision boundary in a two-dimensional space might separate observations with odd numbers of points from observations with even numbers of points.\nIn the problem of boosting, we have a set of weak learners, which are classifiers with a decision boundary that is a linear boundary with different parameters. We can use these weak learners to build a stronger classifier, called a meta-classifier or booster. The meta-classifier is also a linear classifier, but with different parameters.\nThe goal of boosting is to reduce overfitting by building a classifier that is less likely to fit the noise in the data. This is done by combining the decisions of the weak learners. The meta-classifier calculates the weight of each weak learner and combines their decisions using these weights. The weights are based on the errors of the weak learners.\nThe procedure for boosting is as follows:\n1. Fit each weak learner on the training data.\n2. Calculate the errors of the weak learners on the training data.\n3. Use the errors to calculate the weights for each weak learner.\n4. Fit the meta-classifier on the training data, using the weights from step 3.\n5. Test the meta-classifier on the testing data.\n6. Repeat steps 1-5 for each iteration.\n7. Select the number of iterations using cross-validation.\nCross-validation can be used to select the number of iterations because it can be used to measure the performance of the meta-classifier. The goal is to find the number of iterations that produce the highest average accuracy on the training data.\nSOLUTION: Both statements are true.\nStatement 1 tells you how the meta-classifier is built. It is built by combining the decisions of the weak learners. The functional form of the meta-classifier's decision boundary is the same as the decision boundary of a weak learner, but with different parameters.\nStatement 2 tells you how to reduce overfitting. This can be done by using cross-validation to select the number of iterations. Cross-validation can measure the performance of the meta-classifier."}
{"question": "Statement 1| Highway networks were introduced after ResNets and eschew max pooling in favor of convolutions. Statement 2| DenseNets usually cost more memory than ResNets.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "SOLUTION: Both statements are about network architectures for image classification.\nStatement 1 says that ResNets were introduced after highway networks and that they use convolutions instead of max pooling.\nStatement 2 says that DenseNets usually cost more memory than ResNets.\nAll of the network architectures mentioned in these statements are for image classification."}
{"question": "If N is the number of instances in the training dataset, nearest neighbors has a classification run time of", "choices": [{"label": "A", "text": "O(1)"}, {"label": "B", "text": "O( N )"}, {"label": "C", "text": "O(log N )"}, {"label": "D", "text": "O( N^2 )"}], "answerKey": "B", "model_answer": "SOLUTION: With nearest neighbors, you have to compare each test instance to all the training instances. So, the run time is O(N)."}
{"question": "Statement 1| The original ResNets and Transformers are feedforward neural networks. Statement 2| The original Transformers use self-attention, but the original ResNet does not.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: Feedforward neural networks are a type of neural network. They have a forward pass and a backward pass.\nThe forward pass starts from the input layers and produces the output. The backward pass starts from the output and produces the loss.\nSelf-attention is an attention mechanism used in the Transformer architecture. It allows the model to weigh the importance of each word in a sequence relative to every other word in the sequence.\nThe original ResNet uses a type of attention called residual attention. It allows the model to weigh the importance of each layer in a block relative to every other layer in the block.\nSOLUTION: The original ResNets and Transformers are feedforward neural networks.\nThe original Transformers use self-attention, but the original ResNet does not."}
{"question": "Statement 1| RELUs are not monotonic, but sigmoids are monotonic. Statement 2| Neural networks trained with gradient descent with high probability converge to the global optimum.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "LECTURE: A function f is a monotonic function if it is either always increasing or always decreasing.\nA sigmoid is a monotonic function.\nA RELU is not a monotonic function.\nSOLUTION: A sigmoid is a function that has the form f(x) = a/1 + bx. It is a monotonic function.\nFor a function to converge to a global optimum, it must be monotonic. So, statement 2 is true.\nA RELU function is not monotonic. So, statement 1 is false."}
{"question": "The numerical output of a sigmoid node in a neural network:", "choices": [{"label": "A", "text": "Is unbounded, encompassing all real numbers."}, {"label": "B", "text": "Is unbounded, encompassing all integers."}, {"label": "C", "text": "Is bounded between 0 and 1."}, {"label": "D", "text": "Is bounded between -1 and 1."}], "answerKey": "C", "model_answer": "SOLUTION: The output of a sigmoid node is a value between 0 and 1. This means that the output is bounded between -1 and 1."}
{"question": "Which of the following can only be used when training data are linearly separable?", "choices": [{"label": "A", "text": "Linear hard-margin SVM."}, {"label": "B", "text": "Linear Logistic Regression."}, {"label": "C", "text": "Linear Soft margin SVM."}, {"label": "D", "text": "The centroid method."}], "answerKey": "A", "model_answer": "LECTURE: A classifier is a function that takes in data as input and outputs the classification of that input. One common type of classifier is a support vector machine (SVM).\nAn SVM is a classifier that tries to find a hyperplane that separates the data into classified pieces. This hyperplane is called the decision boundary.\nThere are several ways to define a decision boundary. One way is to use a linear hyperplane. A linear hyperplane is a hyperplane that is defined by a linear equation.\nLinear hard-margin SOLUTION: A linear hard-margin SVM uses a linear decision boundary. This type of SVM always tries to find a decision boundary that is as far from the nearest data point as possible. This means that the decision boundary will be a linear hyperplane that is as close as possible to being able to linearly separate the data.\nLinear soft-margin SVM and linear logistic regression are similar to linear hard-margin SVM, but they allow for a margin of error. This means that the decision boundary will be a linear hyperplane, but it will not be as far from the nearest data point as possible. Instead, the boundary will be closer to the data point, as long as the data point is far enough from the boundary to satisfy the margin of error.\nThe centroid method is a method of classification that does not use a decision boundary. Instead, it uses the centroid, or average location, of each class to determine the classification of a point. This method can only be used if the classes are separated by a distance."}
{"question": "Which of the following are the spatial clustering algorithms?", "choices": [{"label": "A", "text": "Partitioning based clustering"}, {"label": "B", "text": "K-means clustering"}, {"label": "C", "text": "Grid based clustering"}, {"label": "D", "text": "All of the above"}], "answerKey": "D", "model_answer": "LECTURE: Spatial clustering is a type of data clustering that is used to groups points that are geographically close to each other. The purpose of spatial clustering is to find groups of points that are close to each other in space.\nThere are several algorithms that can be used for spatial clustering. Here are some ways in which spatial clustering algorithms differ from each other:\nPartitioning based clustering cuts the space into a set of non-overlapping regions, and assigns each point to the region in which it is located.\nK-means clustering is an iterative algorithm that starts with a random selection of k points in the space and assigns each point to the nearest point. It then assigns each group of k or more points to a cluster. The algorithm repeats this process until the clusters no longer change.\nGrid based clustering is a brute-force algorithm that searches every possible combination of k points in the space.\nSOLUTION: Grid-based clustering is a spatial clustering algorithm. It is a brute-force algorithm that searches every possible combination of k points in the space."}
{"question": "Statement 1| The maximum margin decision boundaries that support vector machines construct have the lowest generalization error among all linear classifiers. Statement 2| Any decision boundary that we get from a generative model with classconditional Gaussian distributions could in principle be reproduced with an SVM and a polynomial kernel of degree less than or equal to three.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "SOLUTION: Both statements are about the relationship between different types of classifiers.\nStatement 1 says that the maximum margin decision boundaries that support vector machines construct have the lowest generalization error among all linear classifiers.\nStatement 2 says that any decision boundary that we get from a generative model with class-conditional Gaussian distributions could in principle be reproduced with an SVM and a polynomial kernel of degree less than or equal to three.\nBoth statements are about the relationship between support vector machines and other classifiers.\nSince both statements are about the relationship between support vector machines and other classifiers, we can conclude that they are talking about the same type of classifiers.\nSo, the two statements are not contradictory."}
{"question": "Statement 1| L2 regularization of linear models tends to make models more sparse than L1 regularization. Statement 2| Residual connections can be found in ResNets and Transformers.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "LECTURE: Statement 1: L2 regularization of linear models tends to make models more sparse than L1 regularization.\nSOLUTION: This statement is true.\nL2 regularization adds a term to the linear model's cost function that is equal to the square of the model's parameters. This has the effect of \"weighing\" the model's parameters, making them smaller. The effect of L2 regularization is to make the model's parameters more sparse, because smaller parameters are usually sparse.\nL1 regularization, on the other hand, adds a term to the linear model's cost function that is equal to the absolute value of the model's parameters. This has the effect of \"weighing\" the model's parameters, making them larger. The effect of L1 regularization is to make the model's parameters less sparse, because larger parameters are usually less sparse.\nSo, L2 regularization tends to make models more sparse than L1 regularization.\nStatement 2: Residual connections can be found in ResNets and Transformers.\nThis statement is true.\nResidual connections are a type of connection used in neural networks. They are called \"residual\" connections because they allow the network to add its original input to its output. This can help the network to overcome the vanishing gradient problem, which occurs when the gradients of the network's parameters become very small.\nResidual connections can be found in ResNets and Transformers. ResNets (short for \"residual networks\") are a type of neural network. They were introduced in 2015 by Microsoft and were used by the team that trained the ImageNet model in 2017 to achieve a top-5 error rate of 2.97%.\nTransformers are a type of neural network that was introduced in 2017. They use residual connections to connect layers of the network. This allows the network to add its original input to its output, which can help the network to overcome the vanishing gradient problem."}
{"question": "Suppose we like to calculate P(H|E, F) and we have no conditional independence information. Which of the following sets of numbers are sufficient for the calculation?", "choices": [{"label": "A", "text": "P(E, F), P(H), P(E|H), P(F|H)"}, {"label": "B", "text": "P(E, F), P(H), P(E, F|H)"}, {"label": "C", "text": "P(H), P(E|H), P(F|H)"}, {"label": "D", "text": "P(E, F), P(E|H), P(F|H)"}], "answerKey": "B", "model_answer": "LECTURE: Conditional independence refers to the situation where the information in one variable does not affect the uncertainty in another variable.\nFor example, consider the following variables:\nA.B.\nInformation in A does not affect the uncertainty in B.\nThey are conditionally independent.\nNow consider the following condition:\nH.\nTake a closer look at the condition.\nIt says that good weather leads to an increase in sales. But how many rainy days there were last month has no effect on how many sales were made today. So, good weather and rainy days are conditionally independent.\nSOLUTION: To calculate P(H|E, F), you need to use the following formula:\nP(H|E, F) = P(H) / P(E, F)\nYou can calculate the right-hand side of the equation using the following numbers:\nP(H)\nP(E, F)\nP(H) / P(E, F)\n= P(H) / P(E, F)\n= P(H) / P(E, F)\n= P(H) / P(E, F)\n= P(E, F) / P(H)\n= P(E, F) / P(H)\n= P(E, F) / P(H)\n= P(F|H) / P(H)\n= P(F|H) / P(H)\n= P(E, F|H) / P(H)\n= P(E, F|H) / P(H)\n= P(E|H) / P(H)\n= P(E|H) / P(H)\n= P(F, E|H) / P(H)\n= P(F, E|H) / P(H)\n= P(F|H) / P(H)\n= P(F|H) / P(H)\n= P(E|H) / P(H)\n= P(E|H) / P(H)\n= P(F|H) / P(H)\n= P(F|H) / P(H)\n= P(E|H) / P(H)\n= P(E|H) / P(H)\n= P(F|H) / P(H)\n= P(F|H) / P(H)\n= P(E|H) / P(H)\n= P(E|H) / P(H)\n= P(F|H) / P(H)\n= P(F|H) / P(H)\n= P(E|H) / P(H)\n= P(E|H) / P(H)\n= P(F|H) / P(H)\n= P(F|H) / P(H)\n= P(E|H) / P(H)\n= P(E|H) / P(H)\n= P(F|H) / P(H)\n= P(F|H) / P(H)\n= P(H) / P(E, F)\n= P(E, F|H) / P(H)\n= P(E|H) / P(H)\n= P(E|H) / P(H)\n= P(F|H) / P(H)\n= P(F|H) / P(H)\n= P(E|H) / P(H)\n= P(E|H) / P(H)\n= P(F|H) / P(H)\n= P(F|H) / P(H)\n= P(E|H) / P(H)\n= P(E|H) / P(H)\n= P(F|H) / P(H)\n= P(F|H) / P(H)\n= P(E|H) / P(H)\n= P(E|H) / P(H)\n= P(F|H) / P(H)\n= P(F|H) / P(H)\n= P(E|H) / P(H)\n= P(E|H) / P(H)\n= P(F|H) / P(H)\n= P(F|H) / P(H)\n= P(E|H) / P(H)\n= P(E|H) / P(H)\n= P(F|H) / P(H)\n= P(F|H"}
{"question": "Which among the following prevents overfitting when we perform bagging?", "choices": [{"label": "A", "text": "The use of sampling with replacement as the sampling technique"}, {"label": "B", "text": "The use of weak classifiers"}, {"label": "C", "text": "The use of classification algorithms which are not prone to overfitting"}, {"label": "D", "text": "The practice of validation performed on every classifier trained"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| PCA and Spectral Clustering (such as Andrew Ng\u2019s) perform eigendecomposition on two different matrices. However, the size of these two matrices are the same. Statement 2| Since classification is a special case of regression, logistic regression is a special case of linear regression.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: Principal Component Analysis (PCA) and spectral clustering are two unsupervised learning techniques. They can be used to find the structure in a dataset.\nPCA and spectral clustering use eigendecomposition on two different matrices. The size of the two matrices is the same. The matrix to which PCA is applied is the matrix of correlations. The matrix to which spectral clustering is applied is the matrix of similarities.\nAndrew Ng is a computer scientist who taught an online course in which he used PCA and spectral clustering.\nLogistic regression is a type of regression. Regression is a type of machine learning. Logistic regression is a special case of linear regression. This means that logistic regression has the same structure as linear regression, but the function that is used to calculate the output is different. Instead of calculating the average of the input variables, logistic regression uses a different function that is called the sigmoid.\nThe sigmoid is an S-shaped function. It can be used to model the probability that a particular event will occur. For example, the sigmoid can be used to model the probability that a patient has a disease. The output of logistic regression is a continuous value between 0 and 1. This value can be interpreted as the probability that the input variables belong to a particular class."}
{"question": "Statement 1| The Stanford Sentiment Treebank contained movie reviews, not book reviews. Statement 2| The Penn Treebank has been used for language modeling.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "SOLUTION: Both statements are about the Stanford Sentiment Treebank and the Penn Treebank.\nThe first statement says that the Stanford Sentiment Treebank contained movie reviews, not book reviews. This means that the Stanford Sentiment Treebank was not used for language modeling with book reviews.\nThe second statement says that the Penn Treebank has been used for language modeling. This means that the Penn Treebank has been used to create a language model that can predict the next word in a sentence.\nSo, the Penn Treebank has been used for language modeling, but the Stanford Sentiment Treebank was not."}
{"question": "What is the dimensionality of the null space of the following matrix? A = [[3, 2, \u22129], [\u22126, \u22124, 18], [12, 8, \u221236]]", "choices": [{"label": "A", "text": "0"}, {"label": "B", "text": "1"}, {"label": "C", "text": "2"}, {"label": "D", "text": "3"}], "answerKey": "C", "model_answer": "LECTURE: A matrix has a null space, which is a set of vectors that do not map to a particular vector. The dimension of the null space is called the nullity of the matrix.\nThe nullity of a matrix is equal to the number of rows in the matrix.\nSOLUTION: The nullity of a matrix is equal to the number of rows in the matrix. This matrix has 3 rows.\nSo, the null space of the matrix has 0 as its only element. The null space is a 0-dimensional space."}
{"question": "What are support vectors?", "choices": [{"label": "A", "text": "The examples farthest from the decision boundary."}, {"label": "B", "text": "The only examples necessary to compute f(x) in an SVM."}, {"label": "C", "text": "The data centroid."}, {"label": "D", "text": "All the examples that have a non-zero weight \u03b1k in a SVM."}], "answerKey": "B", "model_answer": "SOLUTION: Support vectors are the data points that have a non-zero weight \u03b1k in a SVM. These data points lie on the decision boundary or are within a small distance of it.\nAll the examples that have a non-zero weight \u03b1k in a SOLUTION: An optimizer is a set of algorithms that are designed to find the optimal solution to a problem. Different types of optimization problems have different types of optimizers. Some optimizers are designed to find the optimal solution to a problem with a single objective and multiple constraints. Other optimizers are designed to find the optimal solution to a problem with multiple objectives and multiple constraints."}
{"question": "Statement 1| Word2Vec parameters were not initialized using a Restricted Boltzman Machine. Statement 2| The tanh function is a nonlinear activation function.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: A neural network is a machine learning algorithm that is inspired by the human brain.\nThe brain is made up of many interconnected neurons. Neural networks are made up of many interconnected nodes, which are called artificial neurons.\nAn artificial neuron can have many inputs, but it has only one output. An artificial neuron uses an activation function to determine its output. An activation function is a function that takes an input and produces an output. The most common activation function is the sigmoid function. The sigmoid function produces an output between 0 and 1.\nThe output of an artificial neuron can be used as input to other artificial neurons. This is called propagating forward.\nYou can use a neural network to predict a target value by propagating forward from the inputs to the target.\nSOLUTION: A Restricted Boltzmann Machine (RBM) is a type of neural network. An RBM has two sets of nodes: input nodes and hidden nodes. An RBM uses a special type of activation function called a nonlinear activation function. The most common nonlinear activation function is the tanh function.\nThe tanh function takes an input and produces an output between -1 and 1.\nThe Word2Vec algorithm is a technique for training a neural network to predict words. The Word2Vec algorithm uses a type of neural network called a Word2Vec model. A Word2Vec model has two sets of nodes: input nodes and output nodes. The input nodes represent words. The output nodes represent real-valued vectors.\nThe Word2Vec algorithm does not use a Restricted Boltzmann Machine. So, the Word2Vec parameters were not initialized using a Restricted Boltzmann Machine.\nThe tanh function is a nonlinear activation function. So, the Word2Vec parameters were not initialized using a Restricted Boltzmann Machine, but the tanh function is a nonlinear activation function."}
{"question": "If your training loss increases with number of epochs, which of the following could be a possible issue with the learning process?", "choices": [{"label": "A", "text": "Regularization is too low and model is overfitting"}, {"label": "B", "text": "Regularization is too high and model is underfitting"}, {"label": "C", "text": "Step size is too large"}, {"label": "D", "text": "Step size is too small"}], "answerKey": "C", "model_answer": "LECTURE: A model's training loss decreasing during training is a common example of a model underfitting the data. Underfitting occurs when a model is too simple to capture the patterns in the data.\nA model's training loss increasing during training is a common example of a model overfitting the data. Overfitting occurs when a model is too complex and captures too much noise in the data.\nRegularization is a technique that can help prevent overfitting. Regularization works by adding a term to the loss function that punishes large weights. This has the effect of shrinking the weights to smaller, more reasonable values.\nThe optimal value of the regularization term is a trade-off between the training loss and the generalization performance of the model. If the regularization term is too low, the model will overfit. If the regularization term is too high, the model will underfit.\nThe step size is the size of the changes the model makes to its weights in each iteration. A larger step size can cause a model to overshoot the optimal weights. This can lead to a training loss that increases during training.\nSOLUTION: If your training loss increases with the number of epochs, it is likely that the model is overfitting. Overfitting occurs when a model is too complex and captures too much noise in the data. So, regularization is too high, and the model is underfitting."}
{"question": "Say the incidence of a disease D is about 5 cases per 100 people (i.e., P(D) = 0.05). Let Boolean random variable D mean a patient \u201chas disease D\u201d and let Boolean random variable TP stand for \"tests positive.\" Tests for disease D are known to be very accurate in the sense that the probability of testing positive when you have the disease is 0.99, and the probability of testing negative when you do not have the disease is 0.97. What is P(D | TP), the posterior probability that you have disease D when the test is positive?", "choices": [{"label": "A", "text": "0.0495"}, {"label": "B", "text": "0.078"}, {"label": "C", "text": "0.635"}, {"label": "D", "text": "0.97"}], "answerKey": "C", "model_answer": "SOLUTION: P(D | TP) is the probability that you have disease D given that the test is positive. This can be calculated using Bayes' theorem:\nP(D | TP) = P(TP | D) \\* P(D) / P(TP)\nP(TP | D) is the probability that the test will be positive given that you have the disease. This is 0.99.\nP(D) is the probability that you have the disease, which is 0.05.\nP(TP) is the probability that the test will be positive. This can be calculated as:\nP(TP) = P(TP | D) \\* P(D) + P(TP | not D) \\* P(not D)\nP(TP | not D) is the probability that the test will be positive given that you do not have the disease. This is 0.97.\nP(not D) is the probability that you do not have the disease, which is 1 - P(D) = 1 - 0.05 = 0.95.\nPlugging in the values, we get:\nP(TP) = 0.99 \\* 0.05 + 0.97 \\* 0.95 = 0.502 + 0.923 = 0.525.\nSo, P(D | TP) is:\nP(D | TP) = P(TP | D) \\* P(D) / P(TP) = 0.99 \\* 0.05 / 0.525 = 0.0495."}
{"question": "Statement 1| Traditional machine learning results assume that the train and test sets are independent and identically distributed. Statement 2| In 2017, COCO models were usually pretrained on ImageNet.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "SOLUTION: Statement 1 is true.\nThe assumption of independent and identically distributed data is a key assumption of traditional machine learning. It means that the data is generated from a distribution and that each data point is drawn from the same distribution as every other data point. This assumption is important for many machine learning methods.\nStatement 2 is true.\nPretraining on ImageNet was a common practice for COCO models in 2017."}
{"question": "Statement 1| The values of the margins obtained by two different kernels K1(x, x0) and K2(x, x0) on the same training set do not tell us which classifier will perform better on the test set. Statement 2| The activation function of BERT is the GELU.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: The values of the margins obtained by two different kernels K1(x, x0) and K2(x, x0) on the same training set do not tell you which classifier will perform better on the test set.\nA margin is a measure of the distance between two classes. In other words, a margin is a measure of how easily a classifier can tell the two classes apart.\nSOLUTION: The values of the margins obtained by two different kernels on the same training set do not tell you which classifier will perform better on the test set. This is because the margins are calculated on the training set, and the classifier that performs better on the test set may not be the same as the classifier that has the higher margins on the training set.\nThe activation function of BERT is the GELU. The GELU function is a special type of activation function called a \"normalizing\" activation function. Normalizing activation functions are designed to keep the output of the network between 0 and 1. They do this by mapping the output to a value between 0 and 1."}
{"question": "Which of the following is a clustering algorithm in machine learning?", "choices": [{"label": "A", "text": "Expectation Maximization"}, {"label": "B", "text": "CART"}, {"label": "C", "text": "Gaussian Na\u00efve Bayes"}, {"label": "D", "text": "Apriori"}], "answerKey": "A", "model_answer": "LECTURE: Machine learning algorithms can be divided into three main types:\nSOLUTION: An expectation maximization algorithm is a clustering algorithm. It is used to find the hidden variables in a data set.\nThe other algorithms are not clustering algorithms."}
{"question": "You've just finished training a decision tree for spam classification, and it is getting abnormally bad performance on both your training and test sets. You know that your implementation has no bugs, so what could be causing the problem?", "choices": [{"label": "A", "text": "Your decision trees are too shallow."}, {"label": "B", "text": "You need to increase the learning rate."}, {"label": "C", "text": "You are overfitting."}, {"label": "D", "text": "None of the above."}], "answerKey": "A", "model_answer": "SOLUTION: There are several reasons why a decision tree might get abnormally bad performance on a classification task.\nOne reason is that the decision trees are too shallow. A decision tree is said to be shallow if it has a small number of nodes. Decision trees that are too shallow can overfit the training data.\nOverfitting occurs when a model is too complex and fits the noise in the training data. Overfitting can lead to poor generalization on new, unseen data.\nAnother reason for poor performance is that you are overfitting. Overfitting occurs when a model is too complex and fits the noise in the training data. Overfitting can lead to poor generalization on new, unseen data.\nA third reason is that you need to increase the learning rate. The learning rate controls the step size that the tree takes at each node. A higher learning rate means that the tree will grow faster.\nA lower learning rate can cause the tree to get stuck in local minima and lead to poor performance.\nThe fourth reason is that you are using a decision tree for classification. Decision trees are not designed to do classification. Decision trees come from a different family of machine learning algorithms called \"divide and conquer\".\nClassification algorithms are designed to do classification."}
{"question": "K-fold cross-validation is", "choices": [{"label": "A", "text": "linear in K"}, {"label": "B", "text": "quadratic in K"}, {"label": "C", "text": "cubic in K"}, {"label": "D", "text": "exponential in K"}], "answerKey": "A", "model_answer": "SOLUTION: Cross-validation is a technique for evaluating a model's performance on a dataset by splitting the data into multiple parts. K-fold cross-validation is a specific type of cross-validation where the dataset is split into K parts, and the model is evaluated K times, each time using a different part of the data as the test set.\nThe choice of K affects the number of times the model is evaluated. So, K-fold cross-validation is quadratic in K."}
{"question": "Statement 1| Industrial-scale neural networks are normally trained on CPUs, not GPUs. Statement 2| The ResNet-50 model has over 1 billion parameters.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "SOLUTION: Statement 1 is false. Statement 2 is true.\nTraining deep neural networks requires processing large amounts of data. Traditionally, this has been done on CPUs (central processing units), but in the last few years, GPUs (graphics processing units) have become popular for this task. A GPU is a specialized processor with a large number of cores that can perform the same type of operation as a CPU, but much faster.\nOne billion is a large number. It is difficult to train a neural network with over 1 billion parameters. However, it is not impossible. With the right tools and a large enough computing infrastructure, you could train a ResNet-50 model with over 1 billion parameters."}
{"question": "Given two Boolean random variables, A and B, where P(A) = 1/2, P(B) = 1/3, and P(A | \u00acB) = 1/4, what is P(A | B)?", "choices": [{"label": "A", "text": "1/6"}, {"label": "B", "text": "1/4"}, {"label": "C", "text": "3/4"}, {"label": "D", "text": "1"}], "answerKey": "D", "model_answer": ""}
{"question": "Existential risks posed by AI are most commonly associated with which of the following professors?", "choices": [{"label": "A", "text": "Nando de Frietas"}, {"label": "B", "text": "Yann LeCun"}, {"label": "C", "text": "Stuart Russell"}, {"label": "D", "text": "Jitendra Malik"}], "answerKey": "C", "model_answer": "SOLUTION: Yann LeCun is a prominent AI researcher who has worked on machine learning and deep learning. He is known for his work on backpropagation, a key algorithm in deep learning. LeCun is one of the founding members of the Computational Learning Theory group at Microsoft Research. He is also a professor at New York University.\nStuart Russell is a professor of computer science and Smith-Zadeh Chair in Engineering at the University of California, Berkeley. He is known for his work on artificial intelligence safety and the potential risks of AI. Russell is the co-author of a popular textbook on artificial intelligence.\nJitendra Malik is a professor of computer science and electrical engineering at Stanford University. His research interests include computer vision, machine learning, and deep learning. Malik has been a principal investigator for the Defense Advanced Research Projects Agency (DARPA) and has served as the program chair for the Conference on Computer Vision and Pattern Recognition.\nNando de Frietas is a professor of computer science and electrical engineering at the University of California, Los Angeles. His research interests include computer vision, machine learning, and image processing. He has published more than 200 papers and is a fellow of the IEEE."}
{"question": "Statement 1| Maximizing the likelihood of logistic regression model yields multiple local optimums. Statement 2| No classifier can do better than a naive Bayes classifier if the distribution of the data is known.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "SOLUTION: Both statements are about logistic regression and classification in general, not about logistic regression with multiple local optima.\nSo, Statement 1 is true. Maximizing the likelihood of a logistic regression model can indeed yield multiple local optima.\nStatement 2 is also true. The naive Bayes classifier is a probabilistic classifier that assumes independence between the features. If the distribution of the data is known, then no classifier can do better than a naive Bayes classifier."}
{"question": "For Kernel Regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether kernel function is Gaussian versus triangular versus box-shaped"}, {"label": "B", "text": "Whether we use Euclidian versus L1 versus L\u221e metrics"}, {"label": "C", "text": "The kernel width"}, {"label": "D", "text": "The maximum height of the kernel function"}], "answerKey": "C", "model_answer": "SOLUTION: The kernel width affects the trade-off between underfitting and overfitting.\nA narrow kernel width results in a shallow function with a sharp transition from the input to the output. Such a function may have trouble learning complex patterns and may underfit the training data.\nA wide kernel width results in a deep function with a more gradual transition from the input to the output. Such a function may be able to learn complex patterns and may overfit the training data.\nThe other choices affect the structure of the function, but they do not directly affect the trade-off between underfitting and overfitting."}
{"question": "Statement 1| The SVM learning algorithm is guaranteed to find the globally optimal hypothesis with respect to its object function. Statement 2| After being mapped into feature space Q through a radial basis kernel function, a Perceptron may be able to achieve better classification performance than in its original space (though we can\u2019t guarantee this).", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: A classifier is a function that maps an input to a class. A hypothesis is a function that takes as input a set of features and maps it to an output class.\nThe SOLUTION: The SVM learning algorithm aims to find the hypothesis that achieves the best generalization performance, which is the ability to make accurate predictions on new, unseen data. Finding the globally optimal hypothesis with respect to the object function is one way to measure generalization performance.\nA radial basis kernel function can be used to map the data to a higher-dimensional space, where a Perceptron may be able to achieve better classification performance than in its original space. Improved classification performance in this higher-dimensional space does not necessarily mean that the Perceptron will achieve better generalization performance, but it is a stepping stone to achieve better generalization performance."}
{"question": "For a Gaussian Bayes classifier, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether we learn the class centers by Maximum Likelihood or Gradient Descent"}, {"label": "B", "text": "Whether we assume full class covariance matrices or diagonal class covariance matrices"}, {"label": "C", "text": "Whether we have equal class priors or priors estimated from the data."}, {"label": "D", "text": "Whether we allow classes to have different mean vectors or we force them to share the same mean vector"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| Overfitting is more likely when the set of training data is small. Statement 2| Overfitting is more likely when the hypothesis space is small.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "SOLUTION: Overfitting occurs when a model is too complex and fits the training data too closely. In other words, the model can fit the noise in the training data.\nStatement 1 says that overfitting is more likely when the set of training data is small. This means that with a small set of training data, it is more difficult to fit the noise, so a model that is too complex may be more likely to fit the training data too closely.\nStatement 2 says that overfitting is more likely when the hypothesis space is small. This means that with a small hypothesis space, there are fewer models that can be considered. So, a model that is too complex may be more likely to fit the training data too closely."}
{"question": "Statement 1| Besides EM, gradient descent can be used to perform inference or learning on Gaussian mixture model. Statement 2 | Assuming a fixed number of attributes, a Gaussian-based Bayes optimal classifier can be learned in time linear in the number of records in the dataset.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "SOLUTION: Both statement 1 and statement 2 are false."}
{"question": "Statement 1| In a Bayesian network, the inference results of the junction tree algorithm are the same as the inference results of variable elimination. Statement 2| If two random variable X and Y are conditionally independent given another random variable Z, then in the corresponding Bayesian network, the nodes for X and Y are d-separated given Z.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: In a Bayesian network, the inference results of the junction tree algorithm are the same as the inference results of variable elimination.\nThe junction tree algorithm is a method for finding the Set of All Variable Elimination (SAVE) table. This algorithm uses a tree-like structure, called a junction tree, to store information about which variables have been eliminated from each node. The algorithm proceeds by recursively constructing the junction tree and using it to fill in the SOLUTION: The junction tree algorithm and the variable elimination algorithm are two different methods for performing inference in a Bayesian network. They are, however, guaranteed to produce the same results.\nThis guarantee is based on the fact that the variable elimination algorithm can be implemented as a depth-first search of the junction tree.\nSo, the inference results of the junction tree algorithm are the same as the inference results of variable elimination.\nIf two random variable X and Y are conditionally independent given another random variable Z, then in the corresponding Bayesian network, the nodes for X and Y are d-separated given Z.\nThis statement asserts that if the conditional probability distribution of Y given X and Z is nonzero, then there is a directed path from Z to Y in the Bayesian network.\nThis statement is true.\nIf there is a nonzero probability that Y follows a certain distribution, given that X takes a certain value and Z takes a certain value, then there must be a path of arrows in the Bayesian network from Z to Y. This path can be used to calculate the probability that Y follows a certain distribution, given that X takes a certain value and Z takes a certain value.\nSo, the nodes for X and Y are d-separated given Z."}
{"question": "Given a large dataset of medical records from patients suffering from heart disease, try to learn whether there might be different clusters of such patients for which we might tailor separate treatments. What kind of learning problem is this?", "choices": [{"label": "A", "text": "Supervised learning"}, {"label": "B", "text": "Unsupervised learning"}, {"label": "C", "text": "Both (a) and (b)"}, {"label": "D", "text": "Neither (a) nor (b)"}], "answerKey": "B", "model_answer": ""}
{"question": "What would you do in PCA to get the same projection as SVD?", "choices": [{"label": "A", "text": "Transform data to zero mean"}, {"label": "B", "text": "Transform data to zero median"}, {"label": "C", "text": "Not possible"}, {"label": "D", "text": "None of these"}], "answerKey": "A", "model_answer": "SOLUTION: SVD and PCA are two unsupervised learning techniques that can be used to transform data.\nSVD and PCA can be used to get the same projection as each other. To do this, you would use the same value for the parameter that determines the number of dimensions to keep.\nSVD and PCA have different default values for this parameter. SVD has a default of keeping 50 or 100 components, and PCA has a default of keeping 5 or 10 components. As a result, if you use the same number of components for both methods, you will get the same projection.\nTo transform the data to have a zero mean or a zero median, you can use the mean or median of each feature as the baseline. This is called centering.\nCentered data has a mean of zero. This can make it easier to interpret the results, because the first component will represent the average value of the data.\nThere are several ways you can transform the data to have a zero mean or a zero median. One way is to use the mean or median of each feature as the baseline. This is called centering.\nFor example, if a feature has a mean of 10 and a standard deviation of 2, the first component of the data will be centered at -5.\nAnother way to transform the data to have a zero mean or a zero median is to use the minimum or maximum value of each feature as the baseline. This is called normalization.\nFor example, if a feature has a minimum of 0 and a maximum of 100, the first component of the data will be centered at 0."}
{"question": "Statement 1| The training error of 1-nearest neighbor classifier is 0. Statement 2| As the number of data points grows to infinity, the MAP estimate approaches the MLE estimate for all possible priors. In other words, given enough data, the choice of prior is irrelevant.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: When you have a classification problem, you want to figure out which types of things are represented by each data point. A 1-nearest neighbor classifier does this by choosing the category that is most common among your training data.\nFor example, suppose you want to classify some flowers into two types: daffodil or tulip. A 1-nearest neighbor classifier would look at which type of flower is most common among your training data. If 75% of your training data are daffodils, the classifier would identify daffodil as the usual type of flower in your data.\nTo extend this to a discussion of the two statements:\nThe training error of a 1-nearest neighbor classifier is 0. This means that a 1-nearest neighbor classifier can perfectly classify your training data. However, this does not mean that the classifier will be able to classify new data points correctly. In fact, as soon as you have a new data point, the 1-nearest neighbor classifier will change its predictions.\nThis is because the 1-nearest neighbor classifier does not take into account the fact that the two classes are equally likely to appear. So, for a 1-nearest neighbor classifier, the choice of prior is important.\nAs the number of data points grows to infinity, the MAP estimate approaches the MLE estimate for all possible priors. This is a statement about how the different types of estimates of the parameters of a statistical model can change as more data becomes available.\nAn estimate is a value that can help you figure out the value of a parameter. There are many ways to estimate the parameters of a statistical model. One way is to use the maximum likelihood estimate (MLE). Another way is to use the maximum a posteriori estimate (MAP).\nThe MLE is based on the likelihood of the data. The likelihood of the data is a function of the parameters of the model. For any given value of the parameters, the MLE is the value of the parameters that makes the likelihood as high as possible.\nThe MAP is based on the posterior distribution. The posterior distribution is a function of the likelihood and the prior. The MAP is the value of the parameters that maximizes the posterior distribution.\nThe statement says that as the number of data points grows to infinity, the MAP estimate approaches the MLE estimate for all possible priors. This means that, for large values of n, the choices of prior will affect the MLE, but they will not affect the MAP. In other words, as the number of data points grows to infinity, the MAP estimate will approach the MLE estimate, and the choice of prior will not matter."}
{"question": "When doing least-squares regression with regularisation (assuming that the optimisation can be done exactly), increasing the value of the regularisation parameter \u03bb the testing error.", "choices": [{"label": "A", "text": "will never decrease the training error."}, {"label": "B", "text": "will never increase the training error."}, {"label": "C", "text": "will never decrease the testing error."}, {"label": "D", "text": "will never increase"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following best describes what discriminative approaches try to model? (w are the parameters in the model)", "choices": [{"label": "A", "text": "p(y|x, w)"}, {"label": "B", "text": "p(y, x)"}, {"label": "C", "text": "p(w|x, w)"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": "LECTURE: Discriminative approaches are a type of machine learning approach. They try to optimize a model to predict a target variable. In the case of image classification, the target variable is a category.\nA model can have multiple parameters. These parameters represent what the model has learned. Discriminative approaches try to model the parameters that are useful for predicting the target variable.\nSOLUTION: Discriminative approaches try to model p(y|x, w).\nIn this equation, x is the input and w is one of the parameters. The model looks at the input and the parameters to predict the target variable y."}
{"question": "Statement 1| CIFAR-10 classification performance for convolution neural networks can exceed 95%. Statement 2| Ensembles of neural networks do not improve classification accuracy since the representations they learn are highly correlated.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: When evaluating the accuracy of a classification model, 95% is a common threshold for considering the model's performance to be \"good.\" This threshold is based on the specific use case and the specific costs of a false classification.\nIf a model's accuracy is below this threshold, it may be useful to improve the model. For example, you might try using a different type of neural network or adding more layers to the network.\nSOLUTION: Statement 1 and Statement 2 are not necessarily contradictory. It is possible for a convolution neural network to achieve a CIFAR-10 classification accuracy exceeding 95%, but ensembles of neural networks do not improve classification accuracy.\nThis is because the representations learned by the neural networks in the ensemble are highly correlated. This means that the neural networks are learning similar things from the data. When the representations are highly correlated, the ensemble as a whole does not learn anything new that would improve classification accuracy."}
{"question": "Which of the following points would Bayesians and frequentists disagree on?", "choices": [{"label": "A", "text": "The use of a non-Gaussian noise model in probabilistic regression."}, {"label": "B", "text": "The use of probabilistic modelling for regression."}, {"label": "C", "text": "The use of prior distributions on the parameters in a probabilistic model."}, {"label": "D", "text": "The use of class priors in Gaussian Discriminant Analysis."}], "answerKey": "C", "model_answer": "SOLUTION: Bayesian and frequentist approaches to statistics have different views on the use of prior knowledge.\nBayesian statisticians use prior knowledge to create a posterior distribution, which combines the prior and the data to calculate the probabilities of different parameters.\nFrequentist statisticians use data to estimate a parameter, and they do not use prior knowledge. Instead, they use techniques such as hypothesis testing to calculate p-values.\nThe use of prior distributions on the parameters in a probabilistic model is a key difference between Bayesian and frequentist approaches. Bayesian statisticians use prior distributions to create a posterior distribution, while frequentist statisticians do not use prior distributions."}
{"question": "Statement 1| The BLEU metric uses precision, while the ROGUE metric uses recall. Statement 2| Hidden markov models were frequently used to model English sentences.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: Precision and recall are used to evaluate the performance of a text classifier. Precision refers to the proportion of the classifier's judgments that are correct. Recall refers to the proportion of actually present cases that the classifier identifies.\nThe BLEU metric uses precision. It uses n-gram precision, which is the proportion of n-grams in the reference text that are in the classifier's output.\nThe ROGUE metric uses recall. It uses unigram recall, which is the proportion of unigram phrases in the reference text that are in the classifier's output.\nHidden Markov models were frequently used to model English sentences. A hidden Markov model is a statistical model that uses a set of probabilities to describe a sequence of events. In a hidden Markov model, the events are usually the transitions between states. The events are not observable. The states are observed.\nSOLUTION: True.\nStatement 1 uses the word \"uses\" to describe the relationship between precision and the BLEU metric. Statement 2 uses the word \"frequently\" to describe the relationship between hidden Markov models and English sentences."}
{"question": "Statement 1| ImageNet has images of various resolutions. Statement 2| Caltech-101 has more images than ImageNet.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "SOLUTION: Statement 1 tells you that ImageNet has images of various resolutions.\nStatement 2 tells you that Caltech-101 has more images than ImageNet.\nMore images does not necessarily mean images of various resolutions. So, Statement 2 could be false."}
{"question": "Which of the following is more appropriate to do feature selection?", "choices": [{"label": "A", "text": "Ridge"}, {"label": "B", "text": "Lasso"}, {"label": "C", "text": "both (a) and (b)"}, {"label": "D", "text": "neither (a) nor (b)"}], "answerKey": "B", "model_answer": "LECTURE: Feature selection is the process of selecting a subset of the variables in a dataset.\nA. Ridge is a linear regression model that can handle multicollinearity. Ridge regression is a form of regularization, which is a technique that helps prevent overfitting.\nB. Lasso is a linear regression model that can handle multicollinearity. Lasso is a form of regularization, which is a technique that helps prevent overfitting.\nBoth (a) and (b) are appropriate for feature selection.\nBoth ridge regression and lasso regularization can be used for feature selection. These techniques can be used to produce a subset of features that are most useful for predicting the outcome.\nD. Neither (a) nor (b) is appropriate for feature selection.\nRidge and lasso are types of regularization that can be used for feature selection."}
{"question": "Suppose you are given an EM algorithm that finds maximum likelihood estimates for a model with latent variables. You are asked to modify the algorithm so that it finds MAP estimates instead. Which step or steps do you need to modify?", "choices": [{"label": "A", "text": "Expectation"}, {"label": "B", "text": "Maximization"}, {"label": "C", "text": "No modification necessary"}, {"label": "D", "text": "Both"}], "answerKey": "B", "model_answer": "LECTURE: The expectation (E) step in an EM algorithm operates on the observed data to obtain the expected complete-data log-likelihood function. The maximization (M) step operates on the expected complete-data log-likelihood to obtained the MAP estimates.\nTo convert an EM algorithm from finding maximum likelihood estimates to finding MAP estimates, you need to modify the maximization step. Specifically, you need to change the criterion that is used to determine the values of the latent variables in the maximization step.\nWhen finding maximum likelihood estimates, the criterion is to set the latent variables to values that maximize the expected complete-data log-likelihood. When finding MAP estimates, the criterion is to set the latent variables to values that maximize the expected complete-data log-likelihood subject to the constraint that the latent variables must be non-negative.\nSOLUTION: The maximization step in an EM algorithm is responsible for finding the MAP estimates. To modify the EM algorithm to find MAP estimates, you need to modify the maximization step to include the non-negativity constraint."}
{"question": "For a Gaussian Bayes classifier, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether we learn the class centers by Maximum Likelihood or Gradient Descent"}, {"label": "B", "text": "Whether we assume full class covariance matrices or diagonal class covariance matrices"}, {"label": "C", "text": "Whether we have equal class priors or priors estimated from the data"}, {"label": "D", "text": "Whether we allow classes to have different mean vectors or we force them to share the same mean vector"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| For any two variables x and y having joint distribution p(x, y), we always have H[x, y] \u2265 H[x] + H[y] where H is entropy function. Statement 2| For some directed graphs, moralization decreases the number of edges present in the graph.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "SOLUTION: Statement 1 discusses the relationship between the entropy of a joint distribution and the entropy of the individual distributions. Entropy is a measure of the uncertainty or randomness of a variable.\nFor any two variables x and y, the entropy of their joint distribution, H[x, y], is always greater than or equal to the sum of their individual entropies, H[x] + H[y].\nThis means that the uncertainty of the variables as a pair is greater than the uncertainty of the variables individually.\nStatement 2 discusses the effect of moralization on the number of edges in a directed graph. Moralization involves identifying groups of adjacent nodes in a graph and merging them into a single node.\nMoralization can decrease the number of edges present in a graph. For example, consider a directed graph with 10 nodes and 20 edges. After moralization, the number of nodes might be reduced to 5, and the number of edges might be reduced to 10."}
{"question": "Which of the following is NOT supervised learning?", "choices": [{"label": "A", "text": "PCA"}, {"label": "B", "text": "Decision Tree"}, {"label": "C", "text": "Linear Regression"}, {"label": "D", "text": "Naive Bayesian"}], "answerKey": "A", "model_answer": "LECTURE: Supervised learning is a type of machine learning. In supervised learning, you train a model on labeled data. The model can then be used to make predictions on new, unlabeled data.\nSOLUTION: Principal component analysis (PCA) is a type of unsupervised learning. In unsupervised learning, you train a model on unlabeled data.\nA decision tree is a type of supervised learning. In a decision tree, the model uses labeled data to create a tree-like model of decisions and their possible consequences.\nLinear regression is a type of supervised learning. In linear regression, you train a model on labeled data to predict a continuous variable.\nNaive Bayesian is a type of supervised learning. In naive Bayesian, you train a model on labeled data to predict a categorical variable."}
{"question": "Statement 1| A neural network's convergence depends on the learning rate. Statement 2| Dropout multiplies randomly chosen activation values by zero.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: In a neural network, the learning rate controls the size of the weight updates after each iteration. A larger learning rate means larger weight updates.\nWhen the learning rate is too large, the updates may be larger than the network can support. This can cause the network to stop converging. On the other hand, a smaller learning rate may lead to slower convergence.\nDropout is a regularization technique that helps prevent overfitting. When using dropout, each neuron in a neural network is randomly dropped out, or disabled, with a certain probability. This means that each forward pass of the network uses a different subset of the neurons.\nWhen a neuron is dropped out, its output is set to zero. This means that the output of the network is multiplied by zero.\nSOLUTION: Both statements are true.\nThe learning rate controls the convergence of a neural network. A smaller learning rate lets the network converge more slowly. A larger learning rate may lead to slower convergence.\nDropout multiplies the output of a neuron by zero with a certain probability. This has the effect of dropping out, or disabling, the neuron."}
{"question": "Which one of the following is equal to P(A, B, C) given Boolean random variables A, B and C, and no independence or conditional independence assumptions between any of them?", "choices": [{"label": "A", "text": "P(A | B) * P(B | C) * P(C | A)"}, {"label": "B", "text": "P(C | A, B) * P(A) * P(B)"}, {"label": "C", "text": "P(A, B | C) * P(C)"}, {"label": "D", "text": "P(A | B, C) * P(B | A, C) * P(C | A, B)"}], "answerKey": "C", "model_answer": "SOLUTION: P(A, B, C) is equal to the probability of every outcome. Every outcome is covered by the events A, B, and C. So, P(A, B, C) is equal to the product of the probabilities that each of these events occurs:\nP(A, B, C) = P(A) * P(B) * P(C)\nNow, look at each choice. Figure out which one matches the formula above.\nP(A | B) * P(B | C) * P(C | A) is a conditional probability formula. It is not equal to the formula for P(A, B, C).\nP(C | A, B) * P(A) * P(B) is a conditional probability formula. It is not equal to the formula for P(A, B, C).\nP(A, B | C) * P(C) is a conditional probability formula. It is not equal to the formula for P(A, B, C).\nP(A | B, C) * P(B | A, C) * P(C | A, B) is a conditional probability formula. It is not equal to the formula for P(A, B, C)."}
{"question": "Which of the following tasks can be best solved using Clustering.", "choices": [{"label": "A", "text": "Predicting the amount of rainfall based on various cues"}, {"label": "B", "text": "Detecting fraudulent credit card transactions"}, {"label": "C", "text": "Training a robot to solve a maze"}, {"label": "D", "text": "All of the above"}], "answerKey": "B", "model_answer": "SOLUTION: Clustering can be used to group data into clusters based on similarities.\nPredicting the amount of rainfall based on various cues does not involve clustering data.\nTraining a robot to solve a maze involves using a supervised learning technique.\nDetecting fraudulent credit card transactions involves using a supervised learning technique.\nAll of the above refers to tasks that can be solved using clustering."}
{"question": "After applying a regularization penalty in linear regression, you find that some of the coefficients of w are zeroed out. Which of the following penalties might have been used?", "choices": [{"label": "A", "text": "L0 norm"}, {"label": "B", "text": "L1 norm"}, {"label": "C", "text": "L2 norm"}, {"label": "D", "text": "either (a) or (b)"}], "answerKey": "D", "model_answer": "LECTURE: When you have more variables in your linear regression model than observations, you may have fewer observations than variables. In this case, the values of the variables are estimated. These estimated values are then used to make predictions.\nOne way to make sure that your estimated variables have reasonable values is to use a regularization penalty. This penalty is added to the sum of the squares of the coefficients. The result is called the regularized sum of squares.\nThe L2 norm is the regularization penalty that is used in ordinary least squares (OLS) linear regression. The L2 norm is the sum of the squares of the coefficients.\nThe L1 norm is a regularization penalty that has the effect of setting to zero the coefficients of the variables that are not used in the prediction. This is called L1 regularization.\nThe L0 norm is the restriction that all coefficients must be zero. This is called L0 regularization.\nSOLUTION: The L2 norm is the regularization penalty that is used in ordinary least squares (OLS) linear regression. The L2 norm is the sum of the squares of the coefficients."}
{"question": "A and B are two events. If P(A, B) decreases while P(A) increases, which of the following is true?", "choices": [{"label": "A", "text": "P(A|B) decreases"}, {"label": "B", "text": "P(B|A) decreases"}, {"label": "C", "text": "P(B) decreases"}, {"label": "D", "text": "All of above"}], "answerKey": "B", "model_answer": "LECTURE: The probability of a event is a measure of how likely the event is to happen. This probability can be written as a fraction:\nprobability of an event = number of ways the event can happen / number of equally likely outcomes\nFor example, the probability of rolling a 6 on a six-sided die is given by the following fraction:\nnumber of ways the event can happen / number of equally likely outcomes = number of sides with a 6 / total number of sides = 6 / 6\nThis probability is equal to 1.0, which is the maximum possible probability.\nSOLUTION: Imagine an event with two outcomes, A and B. The probability of both outcomes happening is written as P(A,B).\nWe want to find out what happens to P(A,B) when P(A) increases and P(B) decreases.\nFirst, note that P(A,B) = P(B|A)P(A), where P(B|A) is the probability of B happening given that A happens, and P(A) is the probability of A happening.\nSo, if P(A,B) decreases, either P(B|A) decreases or P(A) increases.\nP(A,B) decreases when P(B|A) decreases. This is because P(A,B) is made up of two parts that are multiplied together: P(B|A) and P(A). If one of these parts decreases, the value of P(A,B) decreases.\nSo, we know that P(B|A) decreases.\nNow look at the answer choices.\nP(B|A) decreases. This occurs when P(A) increases.\nP(B) decreases. This does not occur.\nP(A|B) decreases. This does not occur.\nAll of the above. This is incorrect."}
{"question": "Statement 1| When learning an HMM for a fixed set of observations, assume we do not know the true number of hidden states (which is often the case), we can always increase the training data likelihood by permitting more hidden states. Statement 2| Collaborative filtering is often a useful model for modeling users' movie preference.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "SOLUTION: Statement 1 is false. The number of hidden states in an HMM affects the model's ability to fit the data. Adding more hidden states to an HMM may help improve the model's ability to fit the data, but there is no guarantee that the likelihood of the training data will increase. In fact, adding more hidden states may increase the complexity of the model and lead to overfitting.\nStatement 2 is true. Collaborative filtering is a type of model that can be used to predict a user's movie preferences based on the preferences of other users. This type of model can be effective because many users have similar preferences."}
{"question": "You are training a linear regression model for a simple estimation task, and notice that the model is overfitting to the data. You decide to add in $\\ell_2$ regularization to penalize the weights. As you increase the $\\ell_2$ regularization coefficient, what will happen to the bias and variance of the model?", "choices": [{"label": "A", "text": "Bias increase ; Variance increase"}, {"label": "B", "text": "Bias increase ; Variance decrease"}, {"label": "C", "text": "Bias decrease ; Variance increase"}, {"label": "D", "text": "Bias decrease ; Variance decrease"}], "answerKey": "B", "model_answer": "LECTURE: When you add regularization to a model, you decrease the flexibility of the model. This causes the model to have a higher bias and a lower variance.\nBias is a measure of the expected error of the model. A model with a high bias has a large expected error.\nVariance is a measure of the expected distance of the model's predictions from each other. A model with a high variance has a large expected distance between its predictions.\nSOLUTION: When you increase the magnitude of the $\\ell_2$ regularization coefficient, you decrease the magnitude of the weights. This has two effects:\nFirst, it increases the bias of the model. This is because the weights are smaller, and so the model's predictions have a higher expected error.\nSecond, it decreases the variance of the model. This is because the weights are smaller, and so the model's predictions have a lower expected distance from each other."}
{"question": "Which PyTorch 1.8 command(s) produce $10\\times 5$ Gaussian matrix with each entry i.i.d. sampled from $\\mathcal{N}(\\mu=5,\\sigma^2=16)$ and a $10\\times 10$ uniform matrix with each entry i.i.d. sampled from $U[-1,1)$?", "choices": [{"label": "A", "text": "\\texttt{5 + torch.randn(10,5) * 16} ; \\texttt{torch.rand(10,10,low=-1,high=1)}"}, {"label": "B", "text": "\\texttt{5 + torch.randn(10,5) * 16} ; \\texttt{(torch.rand(10,10) - 0.5) / 0.5}"}, {"label": "C", "text": "\\texttt{5 + torch.randn(10,5) * 4} ; \\texttt{2 * torch.rand(10,10) - 1}"}, {"label": "D", "text": "\\texttt{torch.normal(torch.ones(10,5)*5,torch.ones(5,5)*16)} ; \\texttt{2 * torch.rand(10,10) - 1}"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| The ReLU's gradient is zero for $x<0$, and the sigmoid gradient $\\sigma(x)(1-\\sigma(x))\\le \\frac{1}{4}$ for all $x$. Statement 2| The sigmoid has a continuous gradient and the ReLU has a discontinuous gradient.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: A graph has a continuous gradient at a point if the function is continuously differentiable at that point. A graph has a discontinuous gradient at a point if the function is not continuously differentiable at that point.\nThe ReLU function is not continuously differentiable at x = 0. So, the ReLU's gradient is discontinuous at x = 0.\nThe sigmoid function is continuously differentiable at all points. So, the sigmoid's gradient is continuous at all points.\nSOLUTION: The first statement says that the ReLU's gradient is zero for x < 0, and the second statement says that the sigmoid gradient is less than 0.4 for all x. Since x < 0 for x that have a gradient of zero, these two statements are contradictory.\nChoice \"False, False\" is incorrect.\nChoice \"True, False\" is incorrect.\nChoice \"False, True\" is incorrect.\nChoice \"True, True\" is incorrect."}
{"question": "Which is true about Batch Normalization?", "choices": [{"label": "A", "text": "After applying batch normalization, the layer\u2019s activations will follow a standard Gaussian distribution."}, {"label": "B", "text": "The bias parameter of affine layers becomes redundant if a batch normalization layer follows immediately afterward."}, {"label": "C", "text": "The standard weight initialization must be changed when using Batch Normalization."}, {"label": "D", "text": "Batch Normalization is equivalent to Layer Normalization for convolutional neural networks."}], "answerKey": "B", "model_answer": "SOLUTION: Batch Normalization is a technique used to improve the training of deep neural networks. It works by normalizing the activations of the layers in a neural network.\nThe key idea behind batch normalization is to apply a transformation that converts the outputs of a layer to a distribution that is either a standard Gaussian distribution or a standard distribution for the activation function of the layer. This transformation is applied to each element of the output of the layer.\nAfter applying batch normalization, the layer\u2019s activations will follow a standard Gaussian distribution.\nThe bias parameter of affine layers becomes redundant if a batch normalization layer follows immediately afterward.\nThis means that if a batch normalization layer is used, the bias parameter of an affine layer can be disregarded. But this is not true for other types of layers.\nThe standard weight initialization must be changed when using Batch Normalization.\nWhen using batch normalization, the standard weight initialization should be replaced with a weight initialization that takes into account the fact that the activations are normalized.\nBatch Normalization is equivalent to Layer Normalization for convolutional neural networks.\nBatch normalization and layer normalization are two different techniques for normalizing data. But they are not equivalent."}
{"question": "Suppose we have the following objective function: $\\argmin_{w} \\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\gamma \\norm{w}^2_2$ What is the gradient of $\\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\lambda \\norm{w}^2_2$ with respect to $w$?", "choices": [{"label": "A", "text": "$\\nabla_w f(w) = (X^\\top X + \\lambda I)w - X^\\top y + \\lambda w$"}, {"label": "B", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + \\lambda$"}, {"label": "C", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + \\lambda w$"}, {"label": "D", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + (\\lambda+1) w$"}], "answerKey": "C", "model_answer": "SOLUTION: The gradient tells you how the function changes as the inputs change. In this case, the gradient is equal to the derivative of the objective function with respect to w.\nThe derivative of $\\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\gamma \\norm{w}^2_2$ with respect to w is:\n$\\nabla_w f(w) = \\frac{\\partial}{\\partial w} \\left(\\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\gamma \\norm{w}^2_2\\right)\n= \\frac{X^\\top X w - X^\\top y}{\\sqrt{2\\gamma}\\lambda^{1/2}}\n= \\frac{X^\\top X w - X^\\top y}{\\sqrt{2}\\lambda^{1/2}}\n= (X^\\top X + \\lambda I) w - X^\\top y + \\lambda w\n= \\left(X^\\top X w - X^\\top y + \\lambda w\\right) \\div \\sqrt{2}\\lambda^{1/2}\n= \\left(X^\\top X w - X^\\top y + \\lambda\\right) \\div \\sqrt{2}\\lambda^{1/2}\n= X^\\top X w - X^\\top y + \\lambda w\n$"}
{"question": "Which of the following is true of a convolution kernel?", "choices": [{"label": "A", "text": "Convolving an image with $\\begin{bmatrix}1 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$ would not change the image"}, {"label": "B", "text": "Convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ would not change the image"}, {"label": "C", "text": "Convolving an image with $\\begin{bmatrix}1 & 1 & 1\\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}$ would not change the image"}, {"label": "D", "text": "Convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ would not change the image"}], "answerKey": "B", "model_answer": "SOLUTION: A convolution kernel is a set of numbers that are convolved with an image. The result of this convolution is a new image.\nConvolving an image with a kernel will not change the image if the kernel is the identity kernel. The identity kernel is the kernel that, when convolved with an image, produces that same image. In the case of images, the identity kernel is the one with 1s along its diagonal and 0s everywhere else.\nSo, convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ would not change the image.\nIf a kernel does not have 1s along its diagonal, it is not the identity kernel. So, convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0\\end{bmatrix}$ or $\\begin{bmatrix}1 & 1 & 1\\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1\\end\\rangle$ would change the image."}
{"question": "Which of the following is false?", "choices": [{"label": "A", "text": "Semantic segmentation models predict the class of each pixel, while multiclass image classifiers predict the class of entire image."}, {"label": "B", "text": "A bounding box with an IoU (intersection over union) equal to $96\\%$ would likely be considered at true positive."}, {"label": "C", "text": "When a predicted bounding box does not correspond to any object in the scene, it is considered a false positive."}, {"label": "D", "text": "A bounding box with an IoU (intersection over union) equal to $3\\%$ would likely be considered at false negative."}], "answerKey": "D", "model_answer": "SOLUTION: A bounding box with an IoU equal to $3%$ would likely be considered a false negative.\nIoU is a measure of the similarity between the true labels and the predicted labels for each pixel. For instance, an IoU of $96%$ would indicate that the true label and the predicted label for each pixel are identical in $96%$ of the cases.\nIoU is usually used to evaluate the performance of object detectors. One common criterion is that a bounding box is considered a true positive if and only if its IoU with the ground truth is greater than a certain threshold. The threshold is typically around $0.5$ or $0.55$, which means that a bounding box is considered a true positive if its IoU with the ground truth is greater than $55%$.\nA bounding box with an IoU equal to $3%$ would not meet this criterion. So, such a bounding box would likely be considered a false negative."}
{"question": "Which of the following is false?", "choices": [{"label": "A", "text": "The following fully connected network without activation functions is linear: $g_3(g_2(g_1(x)))$, where $g_i(x) = W_i x$ and $W_i$ are matrices."}, {"label": "B", "text": "Leaky ReLU $\\max\\{0.01x,x\\}$ is convex."}, {"label": "C", "text": "A combination of ReLUs such as $ReLU(x) - ReLU(x-1)$ is convex."}, {"label": "D", "text": "The loss $\\log \\sigma(x)= -\\log(1+e^{-x})$ is concave"}], "answerKey": "C", "model_answer": "SOLUTION: The following fully connected network without activation functions is linear: $g\\_3(g\\_2(g\\_1(x)))$, where $g\\_i(x) = W\\_i x$ and $W\\_i$ are matrices.\nA linear function has the form $f(x) = mx + b$, where $m$ and $b$ are constants. A fully connected network with only linear functions as activation functions is a linear network.\nSo, the given network is linear.\nLeaky ReLU $\\max\\{0.01x,x\\}$ is convex.\nA function $f(x)$ is convex if $f(x_1) \\le f(x_2)$ for all $x_1 \\le x_2$.\nFor a Leaky ReLU activation function, $f(x) = x$ if $x \\ge 0.01$, and $f(x) = x$ if $x < 0.01$. So, Leaky ReLU is a convex function.\nA combination of ReLUs such as $ReLU(x) - ReLU(x-1)$ is convex.\nTo add two convex functions, take their minimum. So, $f(x) = ReLU(x) - ReLU(x-1)$ is a convex function.\nThe loss $\\log \\sigma(x)= -\\log(1+e^{-x})$ is concave.\nA loss function is concave if the loss is minimized when the error is minimized. So, the given loss function is concave."}
{"question": "We are training fully connected network with two hidden layers to predict housing prices. Inputs are $100$-dimensional, and have several features such as the number of square feet, the median family income, etc. The first hidden layer has $1000$ activations. The second hidden layer has $10$ activations. The output is a scalar representing the house price. Assuming a vanilla network with affine transformations and with no batch normalization and no learnable parameters in the activation function, how many parameters does this network have?", "choices": [{"label": "A", "text": "111021"}, {"label": "B", "text": "110010"}, {"label": "C", "text": "111110"}, {"label": "D", "text": "110011"}], "answerKey": "A", "model_answer": "SOLUTION: The first hidden layer has 1000 activations and each activation has one weight. So, the first hidden layer has 1000 weights.\nThe second hidden layer has 10 activations and each activation has one weight. So, the second hidden layer has 10 weights.\nThe output layer has one weight and one bias. So, the output layer has two parameters.\nThe total number of parameters is 1000 (weights in the first hidden layer) + 10 (weights in the second hidden layer) + 2 (weights and bias in the output layer) = 1010."}
{"question": "Statement 1| The derivative of the sigmoid $\\sigma(x)=(1+e^{-x})^{-1}$ with respect to $x$ is equal to $\\text{Var}(B)$ where $B\\sim \\text{Bern}(\\sigma(x))$ is a Bernoulli random variable. Statement 2| Setting the bias parameters in each layer of neural network to 0 changes the bias-variance trade-off such that the model's variance increases and the model's bias decreases", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: The bias-variance trade-off is a fundamental property of models. It describes the trade-off between the flexibility of a model (i.e., its ability to fit complex data) and the amount of noise in the model's predictions.\nA model with a high bias has a high mean squared error. This type of model is prone to overfitting. Overfitting happens when a model is too complex and fits the noise in the training data.\nA model with a high variance has a high standard deviation of the predictions. This type of model is prone to underfitting. Underfitting happens when a model is too simple and cannot fit the underlying pattern in the data.\nSOLUTION: The derivative of the sigmoid function is equal to the variance of a Bernoulli random variable. So, setting the bias parameters to zero changes the bias-variance trade-off of a neural network in such a way that the model's variance increases and the model's bias decreases."}
