{"question": "Statement 1| Linear regression estimator has the smallest variance among all unbiased estimators. Statement 2| The coefficients \u03b1 assigned to the classifiers assembled by AdaBoost are always non-negative.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "LECTURE: Linear regression is a method of estimating the relationship between a dependent variable and one or more independent variables. It is a type of supervised learning, which means that you use labeled data to train the model.\nOne of the goals of regression is to produce a line that provides the best fit to the data. This line can be used to make predictions about how the dependent variable will change for other values of the independent variables.\nOne way to evaluate the quality of a regression line is by looking at the variance of the linear regression estimator. This variance indicates the extent to which the estimator varies from one prediction to another.\nSOLUTION: A linear regression estimator has the smallest variance among all unbiased estimators. This means that the linear regression estimator is the best at predicting the value of the dependent variable.\nThe coefficients \u03b1 assigned to the classifiers assembled by AdaBoost are always non-negative. This means that the model produced by AdaBoost does not assign negative weights to any of the classifiers."}
{"question": "Statement 1| RoBERTa pretrains on a corpus that is approximate 10x larger than the corpus BERT pretrained on. Statement 2| ResNeXts in 2018 usually used tanh activation functions.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| Support vector machines, like logistic regression models, give a probability distribution over the possible labels given an input example. Statement 2| We would expect the support vectors to remain the same in general as we move from a linear kernel to higher order polynomial kernels.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: Support vector machines (SVMs) are a type of supervised learning algorithm that can be used for classification or regression. In SVMs, a hyperplane is used to separate the data into different classes. The hyperplane is placed to maximize the distance between the hyperplane and the closest data points in each class. These closest data points are called support vectors.\nLogistic regression is a type of SVM. Like SOLUTION: For a logistic regression model, the output is a probability distribution over the possible classes. So, the output is a set of values, not a single value.\nThe probability distribution is transformed into a set of classes by selecting the class with the highest probability. So, the output of a logistic regression model is a single class.\nLike logistic regression models, support vector machines give a probability distribution over the possible labels given an input example. So, the output of a support vector machine is a single class.\nThe support vectors remain the same in general as we move from a linear kernel to a polynomial kernel of higher order. So, the output of a support vector machine may remain the same, no matter what the input is."}
{"question": "A machine learning problem involves four attributes plus a class. The attributes have 3, 2, 2, and 2 possible values each. The class has 3 possible values. How many maximum possible different examples are there?", "choices": [{"label": "A", "text": "12"}, {"label": "B", "text": "24"}, {"label": "C", "text": "48"}, {"label": "D", "text": "72"}], "answerKey": "D", "model_answer": "LECTURE: A machine learning problem involves multiple attributes and a class. An example is a set of values for the attributes.\nThere are 3, 2, 2, and 2 possible values for the attributes. So, there are 3 x 2 x 2 x 2 = 12 possible examples.\nSOLUTION: Each example has 3 possible values for the class. So, there are 3 possible classes for each of the 12 examples.\nThis means there are a total of 312 possible examples."}
{"question": "As of 2020, which architecture is best for classifying high-resolution images?", "choices": [{"label": "A", "text": "convolutional networks"}, {"label": "B", "text": "graph networks"}, {"label": "C", "text": "fully connected networks"}, {"label": "D", "text": "RBF networks"}], "answerKey": "A", "model_answer": "LECTURE: When you have a classification task, you need a system that can learn how to classify images. A convolutional neural network (CNN) is a type of architecture that can be used for this task.\nA CNN is a type of deep neural network that has convolutional layers. Convolutional layers use filters to detect features in an image. Filters are designed to detect specific features, such as edges or corners. Different filters are applied to different parts of the image.\nOne of the advantages of using a CNN is that it can use fewer parameters than a fully connected network. A fully connected network has a layer for every possible outcome. So, if you want to classify images into, say, 10 classes, a fully connected network would have 10 layers. This can be inefficient and hard to train, especially if you have many classes.\nA graph network is a type of neural network that is designed to work with graph-structured data.\nA fully connected network is a type of neural network with layers that are fully connected to each other.\nA radial basis function (RBF) network is a type of neural network with a single hidden layer.\nSOLUTION: As of 2020, convolutional networks are the best architecture for classifying high-resolution images."}
{"question": "Statement 1| The log-likelihood of the data will always increase through successive iterations of the expectation maximation algorithm. Statement 2| One disadvantage of Q-learning is that it can only be used when the learner has prior knowledge of how its actions affect its environment.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: The expectation maximization algorithm is an iterative algorithm that is commonly used to estimate the parameters of a statistical model. Each iteration of the algorithm consists of two steps: the expectation step and the maximization step.\nIn the expectation step, the algorithm uses the current parameter estimate to calculate the expected value of the data. This is then used to calculate the probability of the data.\nIn the maximization step, the algorithm uses this probability to calculate a new parameter estimate. This new estimate is then used in the next iteration of the expectation step.\nThe log-likelihood of the data is a measure of how well the data fits the statistical model. This log-likelihood can be used to determine how much the log-likelihood will increase from one iteration of the expectation maximization algorithm to the next.\nOne disadvantage of Q-learning is that it can only be used when the learner has prior knowledge of how its actions affect its environment. Q-learning is a type of reinforcement learning, which is a way for a learner to learn how to behave in a complex environment. In reinforcement learning, the learner receives rewards for certain types of behavior. The learner's goal is to learn what actions to take to maximize the rewards.\nThis prior knowledge can be used to calculate the expected value of the data. This expected value can then be used to calculate the probability of the data. The log-likelihood of the data is a measure of how well the data fits the statistical model. This log-likelihood can be used to determine how much the log-likelihood will increase from one iteration of the expectation maximization algorithm to the next."}
{"question": "Let us say that we have computed the gradient of our cost function and stored it in a vector g. What is the cost of one gradient descent update given the gradient?", "choices": [{"label": "A", "text": "O(D)"}, {"label": "B", "text": "O(N)"}, {"label": "C", "text": "O(ND)"}, {"label": "D", "text": "O(ND^2)"}], "answerKey": "A", "model_answer": "LECTURE: to perform a single gradient descent update.\nIf we start with a vector x and calculate the gradient of the cost function with respect to x, the gradient tells you the direction of the steepest decrease in the cost function. To move in that direction, you can multiply the gradient by a step size and add it to your current vector to get a new vector, x'. This new vector is your updated vector.\nThe cost of performing a single gradient descent update is proportional to the magnitude of the gradient. The magnitude of the gradient is the Euclidean distance from the starting vector x to the new vector x'. This distance is calculated as follows:\nThe cost of one update is O(ND), where N is the number of elements in the vector and D is the magnitude of the gradient.\nSOLUTION: The gradient is a vector of size N. To calculate the magnitude of the gradient, take the square root of the sum of the squares of its elements. The magnitude of the gradient is O(1), because the sum of the squares of the elements of the gradient is O(N). So, the cost of one update is O(ND)."}
{"question": "Statement 1| For a continuous random variable x and its probability distribution function p(x), it holds that 0 \u2264 p(x) \u2264 1 for all x. Statement 2| Decision tree is learned by minimizing information gain.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: A decision tree is a flowchart-like graph that is used to model decisions and their possible consequences. It is a type of supervised learning, which uses labeled data.\nA decision tree has two main parts: the tree itself and the output. The tree consists of nodes and branches. The nodes represent decisions, and the branches represent the possible outcomes of those decisions. The output represents a prediction.\nA decision tree is learned using a training data set. The learning process begins by creating the root node. The root node is a prediction that is based on the entire training data set.\nThen, for each node, the process of learning the decision tree selects the most informative query that minimizes the information gain. The information gain is a measure of how much is learned by querying a particular node.\nFinally, the leaf nodes are connected to the root node to form a tree. The leaf nodes represent the output of the decision tree.\nSOLUTION: A probability distribution function describes the possible values a random variable x can take. For a continuous random variable x and its probability distribution function p(x), it holds that 0 \u2264 p(x) \u2264 1 for all x.\nSo, for a continuous random variable x and its probability distribution function p(x), the probability distribution function p(x) describes the probability that x takes a specific value.\nStatement 1 says that for a continuous random variable x and its probability distribution function p(x), it holds that 0 \u2264 p(x) \u2264 1 for all x.\nStatement 2 says that a decision tree is learned by minimizing information gain.\nSo, Statement 1 and Statement 2 are true."}
{"question": "Consider the Bayesian network given below. How many independent parameters are needed for this Bayesian Network H -> U <- P <- W?", "choices": [{"label": "A", "text": "2"}, {"label": "B", "text": "4"}, {"label": "C", "text": "8"}, {"label": "D", "text": "16"}], "answerKey": "C", "model_answer": "LECTURE: A Bayesian network is a directed graph with nodes representing random variables and edges representing conditional dependencies between the variables.\nThe nodes in a Bayesian network can be organized into two types:\n* Variable nodes: represent the variables of interest in the network.\n* Factor nodes: represent the direct ancestors of the variable nodes in the network.\nInitially, all variables in the network are given factor nodes.\nA Bayesian network has one or more conditional probability distributions (CPDs). Each CPD describes the probability distribution of a variable node given its parent factor nodes.\nA Bayesian network with n variable nodes and m factor nodes has n+m independent parameters.\nSOLUTION: In this Bayesian network, there are two variable nodes (H, U), one factore node (P), and one factore node (W).\nSo, this Bayesian network has 2 + 1 + 1 = 4 independent parameters."}
{"question": "As the number of training examples goes to infinity, your model trained on that data will have:", "choices": [{"label": "A", "text": "Lower variance"}, {"label": "B", "text": "Higher variance"}, {"label": "C", "text": "Same variance"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": "LECTURE: Machine learning models have a variance, which is a measure of how much the model's predictions can differ from each other. Lower variance means that the model's predictions are more consistent and have lower uncertainty. Higher variance means that the model's predictions are more spread out and have higher uncertainty.\nSOLUTION: When you train a model on a dataset, the model's variance may change. The variance may be lower when you train the model on a larger dataset. This is because a larger dataset can provide more information to the model.\nSo, for the number of training examples to go to infinity, the model's variance would go down to zero. In practice, infinite examples are not possible, but larger datasets do lead to lower variance in the model."}
{"question": "Statement 1| The set of all rectangles in the 2D plane (which includes non axisaligned rectangles) can shatter a set of 5 points. Statement 2| The VC-dimension of k-Nearest Neighbour classifier when k = 1 is infinite.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "_ refers to a model that can neither model the training data nor generalize to new data.", "choices": [{"label": "A", "text": "good fitting"}, {"label": "B", "text": "overfitting"}, {"label": "C", "text": "underfitting"}, {"label": "D", "text": "all of the above"}], "answerKey": "C", "model_answer": "LECTURE: A model is a good fit for a training set if it can accurately predict the values in the training set. A model is a good fit for a dataset if it can accurately predict the values in the dataset.\nA model that is a good fit for a training set will not necessarily be a good fit for the dataset.\nA model that is a good fit for a dataset will not necessarily be a good fit for a particular data subset.\nSOLUTION: Underfitting occurs when a model is a poor fit for a dataset.\nOverfitting occurs when a model is a good fit for a training set, but a poor fit for the dataset.\nGood fitting occurs when a model is a good fit for a dataset.\nAll of the above occurs when a model is a good fit for a training set, a good fit for a dataset, and a good fit for a particular data subset."}
{"question": "Statement 1| The F1 score can be especially useful for datasets with class high imbalance. Statement 2| The area under the ROC curve is one of the main metrics used to assess anomaly detectors.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "SOLUTION: The F1 score can be used to assess the performance of a classifier on a dataset with class imbalance. The F1 score is the harmonic mean of precision and recall, where precision is the number of true positives / (the sum of true positives and false positives) and recall is the number of true positives / (the sum of true positives and false negatives).\nFor a binary classifier, a high F1 score indicates that the classifier is good at both identifying the positive class and ignoring the negative class. This is especially important for datasets with class imbalance, where the positive class is a small fraction of the data.\nThe area under the ROC curve is one of the main metrics used to assess anomaly detectors. An ROC curve is created by plotting the false positive rate against the true positive rate. Anomaly detectors are classified based on where their ROC curve falls on an ROC space.\nA high area under the ROC curve indicates that the anomaly detector is good at identifying anomalies. This curve is especially useful for datasets with class imbalance, where the positive class is a small fraction of the data."}
{"question": "Statement 1| The back-propagation algorithm learns a globally optimal neural network with hidden layers. Statement 2| The VC dimension of a line should be at most 2, since I can find at least one case of 3 points that cannot be shattered by any line.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "SOLUTION: Both statements are about the VC dimension.\nStatement 1: According to the statement, if a line is the optimal solution for a line segment, then any globally optimal neural network with hidden layers must have a VC dimension of at least 2.\nStatement 2: According to the statement, the VC dimension of a line is at most 2.\nSo, if a globally optimal neural network with hidden layers has a VC dimension of at least 2, then it means that the VC dimension of a line is at most 2."}
{"question": "High entropy means that the partitions in classification are", "choices": [{"label": "A", "text": "pure"}, {"label": "B", "text": "not pure"}, {"label": "C", "text": "useful"}, {"label": "D", "text": "useless"}], "answerKey": "B", "model_answer": "LECTURE: In an information system, an classification is a way to put information into groups. Classification has two parts:\na taxonomy, which is a list of categories, and\na set of classifications, which is a set of items in the system.\nAn classification assigns each item in the set to one or more categories.\nSOLUTION: High entropy means that the partitions in classification are not pure.\nA pure classification is one in which all of the items in the set are assigned to the same categories. In other words, the classification is a simple classification.\nAn classification with high entropy has many categories, and many items in the set are classified as borderline cases. This means that the classification is a complex classification."}
{"question": "Statement 1| Layer Normalization is used in the original ResNet paper, not Batch Normalization. Statement 2| DCGANs use self-attention to stabilize training.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": ""}
{"question": "In building a linear regression model for a particular data set, you observe the coefficient of one of the features having a relatively high negative value. This suggests that", "choices": [{"label": "A", "text": "This feature has a strong effect on the model (should be retained)"}, {"label": "B", "text": "This feature does not have a strong effect on the model (should be ignored)"}, {"label": "C", "text": "It is not possible to comment on the importance of this feature without additional information"}, {"label": "D", "text": "Nothing can be determined."}], "answerKey": "C", "model_answer": "LECTURE: A coefficient in a regression model represents the change in the dependent variable for a one-unit change in the corresponding independent variable. For example, the coefficient in a linear regression model for weight tells you the change in weight for a one-unit change in height.\nThe sign of a coefficient tells you the direction of the effect of the independent variable on the dependent variable. A positive coefficient indicates that the independent variable has a positive effect on the dependent variable. A negative coefficient indicates that the independent variable has a negative effect on the dependent variable.\nA coefficient can be interpreted as the change in the dependent variable per unit change in the independent variable. For example, the coefficient in a linear regression model for test score can be interpreted as the change in test score for a one-unit change in hours studied.\nSOLUTION: A coefficient having a relatively high negative value indicates that the feature has a strong negative effect on the model. This feature should be retained, as it is important in predicting the outcome."}
{"question": "For a neural network, which one of these structural assumptions is the one that most affects the trade-off between underfitting (i.e. a high bias model) and overfitting (i.e. a high variance model):", "choices": [{"label": "A", "text": "The number of hidden nodes"}, {"label": "B", "text": "The learning rate"}, {"label": "C", "text": "The initial choice of weights"}, {"label": "D", "text": "The use of a constant-term unit input"}], "answerKey": "A", "model_answer": "LECTURE: A neural network is a machine learning model that is inspired by the human brain. When a neural network learns, it adjusts the strengths of the connections between its nodes.\nThere are many different ways to build a neural network. Some of the choices you make when building a neural network affect the trade-off between underfitting and overfitting. Underfitting occurs when a model is too simple and cannot capture the patterns in the data. Overfitting occurs when a model is too complex and starts to memorize the training data instead of learning the underlying patterns.\nSOLUTION: The use of a constant-term unit input affects the trade-off between underfitting and overfitting. Using a constant-term unit input is a way to add a non-linearity to a neural network. Non-linearities can help a neural network learn complex patterns in the data.\nThe number of hidden nodes, the learning rate, and the initial choice of weights affect the performance of a neural network, but they do not directly affect the trade-off between underfitting and overfitting."}
{"question": "For polynomial regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "The polynomial degree"}, {"label": "B", "text": "Whether we learn the weights by matrix inversion or gradient descent"}, {"label": "C", "text": "The assumed variance of the Gaussian noise"}, {"label": "D", "text": "The use of a constant-term unit input"}], "answerKey": "A", "model_answer": "SOLUTION: The choice of the polynomial degree affects the trade-off between underfitting and overfitting.\nOverfitting occurs when a model is too complex and fits the noise in the training data. The degree of the polynomial is a hyperparameter that determines the complexity of the model. A higher degree can make the model more complex and increase the risk of overfitting.\nUnderfitting occurs when a model is too simple and cannot capture the underlying pattern in the data. A lower degree cannot capture as many of the underlying patterns, so the model may underfit."}
{"question": "Statement 1| As of 2020, some models attain greater than 98% accuracy on CIFAR-10. Statement 2| The original ResNets were not optimized with the Adam optimizer.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: The following statements are true.\nAs of 2020, some models attain greater than 98% accuracy on CIFAR-10.\nThe original ResNets were not optimized with the Adam optimizer.\nThe following statement is false.\nOptimization techniques affect the training process of neural networks.\nNeural networks are trainable models.\nThat is, you can adjust the weights and biases of the networks to improve their performance.\nYou can use an optimization technique, such as stochastic gradient descent, to help find the optimal set of weights and biases.\nSOLUTION: The original ResNets were not optimized with the Adam optimizer.\nSo, the first statement is true.\nThe second statement is also true.\nAccuracy of 98% or higher was attained on CIFAR-10 by some models.\nSo, the second statement is true.\nThe third statement is false.\nOptimization techniques affect the training process of neural networks.\nThis is a true statement.\nNeural networks are trainable models.\nThis is a true statement.\nThat is, you can adjust the weights and biases of the networks to improve their performance.\nYou can use an optimization technique, such as stochastic gradient descent, to help find the optimal set of weights and biases."}
{"question": "The K-means algorithm:", "choices": [{"label": "A", "text": "Requires the dimension of the feature space to be no bigger than the number of samples"}, {"label": "B", "text": "Has the smallest value of the objective function when K = 1"}, {"label": "C", "text": "Minimizes the within class variance for a given number of clusters"}, {"label": "D", "text": "Converges to the global optimum if and only if the initial means are chosen as some of the samples themselves"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| VGGNets have convolutional kernels of smaller width and height than AlexNet's first-layer kernels. Statement 2| Data-dependent weight initialization procedures were introduced before Batch Normalization.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: Statement 1 and statement 2 are not about the same topic.\nStatement 1 is about convolutional kernels in VGGNets compared to AlexNet's first-layer kernels.\nStatement 2 is about the order in which certain techniques were introduced.\nBoth statements are true."}
{"question": "What is the rank of the following matrix? A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]", "choices": [{"label": "A", "text": "0"}, {"label": "B", "text": "1"}, {"label": "C", "text": "2"}, {"label": "D", "text": "3"}], "answerKey": "B", "model_answer": "LECTURE: A matrix is a grid of numbers. The rank of a matrix is a measure of the number of columns in the matrix that are linearly independent.\nLinear independence means that the columns do not depend on each other. So, if each column in a matrix is linearly independent, the rank of the matrix is the number of columns.\nIf any two columns in a matrix are linearly dependent, then they describe the same line. So, the rank of the matrix is less than the number of columns.\nSOLUTION: The matrix is a 3x3 matrix with all three columns linearly independent. So, the rank of the matrix is 3."}
{"question": "Statement 1| Density estimation (using say, the kernel density estimator) can be used to perform classification. Statement 2| The correspondence between logistic regression and Gaussian Naive Bayes (with identity class covariances) means that there is a one-to-one correspondence between the parameters of the two classifiers.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: Density estimation is a technique in machine learning that is used to build a model of the underlying distribution of a set of data. This model can be used to perform classification by finding the region of the density curve that is most likely to contain a new data point. For example, if a new data point has a density value of 0.8, we can conclude that this point is most likely to be from the positive class.\nThe correspondence between logistic regression and Gaussian Naive Bayes (with identity class covariances) means that there is a one-to-one correspondence between the parameters of the two classifiers. This correspondence can be used to perform density estimation by first fitting a logistic regression classifier to the data and then using the Gaussian Naive Bayes form to compute the posterior probabilities.\nSOLUTION: Statement 1 tells you that density estimation can be used to perform classification. Statement 2 tells you that there is a one-to-one correspondence between the parameters of density estimation and logistic regression. So, the parameters of density estimation and logistic regression are equal.\nSince the parameters of density estimation and logistic regression are equal, the correspondence between logistic regression and Gaussian Naive Bayes (with identity class covariances) can be used to perform density estimation. This correspondence can be used to compute the posterior probabilities."}
{"question": "Suppose we would like to perform clustering on spatial data such as the geometrical locations of houses. We wish to produce clusters of many different sizes and shapes. Which of the following methods is the most appropriate?", "choices": [{"label": "A", "text": "Decision Trees"}, {"label": "B", "text": "Density-based clustering"}, {"label": "C", "text": "Model-based clustering"}, {"label": "D", "text": "K-means clustering"}], "answerKey": "B", "model_answer": "SOLUTION: Density-based clustering is the most appropriate method for producing clusters of many different sizes and shapes on spatial data such as the geometrical locations of houses.\nDensity-based clustering forms clusters around dense regions of the data. The clustering algorithm can identify clusters of any size and shape, and can separate clusters that are nearby or intertwined.\nK-means clustering is a method for clustering data that has a spherical shape and is not dependent on the distances between data points. K-means clustering can produce clusters of many different sizes and shapes, but it may not do as well as density-based clustering on data with irregular shapes.\nModel-based clustering can identify clusters of any size and shape, but it requires a specific statistical model of the data. This method may not be appropriate for spatial data, because the models used for spatial data are different from the models used for other types of data.\nDecision trees are a type of model-based clustering. They are not designed to handle spatial data."}
{"question": "Statement 1| In AdaBoost weights of the misclassified examples go up by the same multiplicative factor. Statement 2| In AdaBoost, weighted training error e_t of the tth weak classifier on training data with weights D_t tends to increase as a function of t.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: If a classification algorithm makes a mistake on a training example, AdaBoost assigns it a higher weight for the next iteration. This has two effects:\nFirst, the weighted training error, e_t, of the tth weak classifier on the training data with weights D_t is increased. This tells AdaBoost to assign higher weights to the correct examples in the next iteration, and lower weights to the incorrect examples.\nSecond, the weights of the misclassified examples go up by the same multiplicative factor. This has the effect of adjusting the weights of the incorrect examples in the next iteration. The weights of the correct examples are not increased as much as the weights of the incorrect examples, so the weights of the incorrect examples become a larger proportion of the total weight. This increases the influence of the incorrect examples in the next iteration.\nSOLUTION: Statement 1 tells you that the weights of the misclassified examples go up by the same multiplicative factor.\nStatement 2 tells you that e_t of the tth weak classifier on training data with weights D_t tends to increase as a function of t.\nSince the weights of the misclassified examples go up by the same multiplicative factor, and e_t of the tth weak classifier on training data with weights D_t increases as a function of t, the weights of the misclassified examples must also increase as a function of t."}
{"question": "MLE estimates are often undesirable because", "choices": [{"label": "A", "text": "they are biased"}, {"label": "B", "text": "they have high variance"}, {"label": "C", "text": "they are not consistent estimators"}, {"label": "D", "text": "None of the above"}], "answerKey": "B", "model_answer": "SOLUTION: MLE estimates are biased.\nA biased estimate is one that systematically differs from the true value. In the case of MLE, the estimate is biased because it is based on a limited sample of data.\nBy using the entire sample, the MLE estimate is guaranteed to be unbiased. But using more data does not eliminate bias. By using a smaller sample, the MLE estimate is biased because it does not capture the entire population."}
{"question": "Computational complexity of Gradient descent is,", "choices": [{"label": "A", "text": "linear in D"}, {"label": "B", "text": "linear in N"}, {"label": "C", "text": "polynomial in D"}, {"label": "D", "text": "dependent on the number of iterations"}], "answerKey": "C", "model_answer": "LECTURE: The complexity of an algorithm is a measure of the amount of resources it consumes. In the case of optimization algorithms, the resources include time and memory.\nThe computational complexity of an optimization algorithm is a measure of the number of operations that the algorithm performs. Linear algorithms perform a constant number of operations per step. Polynomial algorithms perform a number of operations that is a constant times a polynomial of the input size.\nFor gradient descent, the computational complexity is determined by the number of parameters in the model. The number of parameters is linear in the number of layers in the model. Each layer can have its own set of parameters, so the total number of parameters is linear in the number of layers.\nSince the number of parameters is linear in D, the computational complexity of gradient descent is linear in D."}
{"question": "Averaging the output of multiple decision trees helps _.", "choices": [{"label": "A", "text": "Increase bias"}, {"label": "B", "text": "Decrease bias"}, {"label": "C", "text": "Increase variance"}, {"label": "D", "text": "Decrease variance"}], "answerKey": "D", "model_answer": "LECTURE: One of the benefits of using multiple decision trees is that it can help decrease bias. This is because different decision trees can make different predictions, and then an average of those predictions is taken.\nThe average is less prone to the errors of any one decision tree. So, averaging the output of multiple decision trees can help decrease bias.\nSOLUTION: Averaging the output of multiple decision trees can help decrease bias. When multiple decision trees make predictions on different data, they can produce different outputs. The average of those outputs is a more unbiased prediction than any one decision tree."}
{"question": "The model obtained by applying linear regression on the identified subset of features may differ from the model obtained at the end of the process of identifying the subset during", "choices": [{"label": "A", "text": "Best-subset selection"}, {"label": "B", "text": "Forward stepwise selection"}, {"label": "C", "text": "Forward stage wise selection"}, {"label": "D", "text": "All of the above"}], "answerKey": "C", "model_answer": "SOLUTION: The process of forward stepwise selection starts with an empty model and adds one variable at a time, using the criteria for including variables to evaluate each variable. The process of forward stage wise selection is similar, except that it adds a fixed number of variables at a time.\nThe model obtained by applying linear regression on the identified subset of features may differ from the model obtained at the end of the process of identifying the subset during forward stepwise selection. This is because forward stepwise selection starts with an empty model and adds variables one at a time, while the model obtained during forward stepwise selection may have been obtained by applying linear regression to a different subset of features."}
{"question": "Neural networks:", "choices": [{"label": "A", "text": "Optimize a convex objective function"}, {"label": "B", "text": "Can only be trained with stochastic gradient descent"}, {"label": "C", "text": "Can use a mix of different activation functions"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": "SOLUTION: Neural networks can use a mix of different activation functions. Activation functions are functions that are applied to the output of each neuron. Examples of activation functions include the sigmoid function and the rectified linear unit (ReLU) function."}
{"question": "Say the incidence of a disease D is about 5 cases per 100 people (i.e., P(D) = 0.05). Let Boolean random variable D mean a patient \u201chas disease D\u201d and let Boolean random variable TP stand for \"tests positive.\" Tests for disease D are known to be very accurate in the sense that the probability of testing positive when you have the disease is 0.99, and the probability of testing negative when you do not have the disease is 0.97. What is P(TP), the prior probability of testing positive.", "choices": [{"label": "A", "text": "0.0368"}, {"label": "B", "text": "0.473"}, {"label": "C", "text": "0.078"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": "SOLUTION: P(TP) is the probability that the test will come back positive. This can happen in two ways: the patient has the disease, or the patient does not have the disease but tests positive.\nP(TP) = P(D) + P(not D) \\* P(test positive | not D)\nP(D) is 0.05. P(not D) is 0.95. P(test positive | not D) is 0.03.\nSo, P(TP) = 0.05 + 0.95 \\* 0.03 = 0.078."}
{"question": "Statement 1| After mapped into feature space Q through a radial basis kernel function, 1-NN using unweighted Euclidean distance may be able to achieve better classification performance than in original space (though we can\u2019t guarantee this). Statement 2| The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SVM.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SVM. So, for some value of n, a Perceptron can achieve the classification performance of an SVM with a VC dimension of at least n.\nFor a simple linear SVM, the VC dimension is equal to the number of dimensions in the input space. So, for a Perceptron to achieve the classification performance of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SVM. So, for some value of n, a Perceptron can achieve the classification performance of an SVM with a VC dimension of at least n.\nFor a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SOLUTION: The VC"}
{"question": "The disadvantage of Grid search is", "choices": [{"label": "A", "text": "It can not be applied to non-differentiable functions."}, {"label": "B", "text": "It can not be applied to non-continuous functions."}, {"label": "C", "text": "It is hard to implement."}, {"label": "D", "text": "It runs reasonably slow for multiple linear regression."}], "answerKey": "D", "model_answer": "LECTURE: Grid search is a brute-force method for finding the best hyperparameters for a model. It works by trying all possible combinations of hyperparameters and evaluating the model with each combination.\nOne disadvantage of grid search is that it can be slow and computationally expensive. For example, if you have 10 possible values for each hyperparameter and you want to try them all, you would need to evaluate 10^2, or 100, models in total.\nAnother disadvantage of grid search is that it can be hard to implement. For example, you need to decide which hyperparameters to try, and what range of values to use for each hyperparameter. You also need to write code to perform the evaluations of the models.\nA possible disadvantage of grid search is that it can be hard to interpret the results. For example, if you find a combination of hyperparameters that gives you the best model, it is not clear how much of an improvement this combination is compared to the other combinations you tried.\nSOLUTION: Grid search is not applicable to non-differentiable functions.\nNon-differentiable functions have a corner case, which means that small changes in the input can lead to large changes in the output. This makes it impossible to find the optimal hyperparameters using gradient descent, which is the optimization technique that is used in many machine learning algorithms."}
{"question": "Predicting the amount of rainfall in a region based on various cues is a ______ problem.", "choices": [{"label": "A", "text": "Supervised learning"}, {"label": "B", "text": "Unsupervised learning"}, {"label": "C", "text": "Clustering"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": "SOLUTION: Predicting the amount of rainfall in a region based on various cues is a supervised learning problem.\nIn supervised learning, algorithms are trained on labeled data. The algorithms learn to make predictions about new, unlabeled data based on the patterns they see in the labeled data."}
{"question": "Which of the following sentence is FALSE regarding regression?", "choices": [{"label": "A", "text": "It relates inputs to outputs."}, {"label": "B", "text": "It is used for prediction."}, {"label": "C", "text": "It may be used for interpretation."}, {"label": "D", "text": "It discovers causal relationships"}], "answerKey": "D", "model_answer": "LECTURE: Regression is a method of statistical analysis that uses a line, called a regression line or a fitting line, to model the relationship between two variables.\nThe regression line shows the expected value of the dependent variable as the independent variable changes. For example, the regression line for the scatter plot below would be used to predict the value of Y for a certain value of X.\nThis line is defined by the equation\nY = a + bX\nWhere a and b are constants.\nSOLUTION: The following sentence is false regarding regression:\nIt discovers causal relationships.\nRegression can help to uncover patterns in data, but it does not can identify the direction of the relationship between variables. This is because the regression line can be used to predict values of the dependent variable, but it does not tell you the direction of cause and effect."}
{"question": "Which one of the following is the main reason for pruning a Decision Tree?", "choices": [{"label": "A", "text": "To save computing time during testing"}, {"label": "B", "text": "To save space for storing the Decision Tree"}, {"label": "C", "text": "To make the training set error smaller"}, {"label": "D", "text": "To avoid overfitting the training set"}], "answerKey": "D", "model_answer": "LECTURE: A Decision Tree is a tree-based model that shows the possible paths that a customer can take. Each path is represented by a branch that connects nodes that represent decision points.\nWhen a Decision Tree is trained on a dataset, the result is a set of nodes that make up the tree. Each node represents a test of a feature. The leaves of the tree represent the categories.\nOne goal of pruning a Decision Tree is to reduce the number of nodes in the tree. This can be done to save space for storing the Decision Tree. But pruning can also help to save computing time during testing.\nWhen a Decision Tree is tested, the customer is directed through the tree by following the branches. Each branch represents a path that the customer might take. Pruning can be used to remove branches that are not important. This can help to reduce the number of paths that the customer can take.\nSOLUTION: Look at the question. It asks you to identify the main reason for pruning a Decision Tree. The main reason for pruning a Decision Tree is to avoid overfitting the training set. Overfitting happens when a model is too complex and starts to fit the noise in the training set instead of the underlying pattern. This can lead to poor performance on new, unseen data.\nPruning can help to prevent overfitting by removing branches that are not important. This helps to reduce the complexity of the model."}
{"question": "Statement 1| The kernel density estimator is equivalent to performing kernel regression with the value Yi = 1/n at each point Xi in the original data set. Statement 2| The depth of a learned decision tree can be larger than the number of training examples used to create the tree.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: A decision tree is a flowchart-like structure in which each internal node represents a test on a feature, each branch represents a outcome, and each leaf represents a class label.\nThe depth of a decision tree is the maximum number of edges from the root node to a leaf node.\n\nA kernel density estimator is a method for estimating the probability density function of a target variable.\nKernel density estimation can be viewed as a type of projection of the data onto a higher-dimensional space, called a kernel space. In the kernel space, the kernel density estimator calculates the density of the target variable. To do this, the estimator assigns a weight to each data point in the original data set. The weights are calculated based on the distance between each data point and the target value.\nSOLUTION: The statement that the kernel density estimator is equivalent to performing kernel regression with the value Yi = 1/n at each point Xi in the original data set is true.\nThis is because kernel regression with a constant value of 1/n at each point in the data set is equivalent to kernel density estimation.\nThe statement that the depth of a learned decision tree can be larger than the number of training examples used to create the tree is false.\nThis is because the depth of a decision tree is limited by the number of training examples used to create the tree."}
{"question": "Suppose your model is overfitting. Which of the following is NOT a valid way to try and reduce the overfitting?", "choices": [{"label": "A", "text": "Increase the amount of training data."}, {"label": "B", "text": "Improve the optimisation algorithm being used for error minimisation."}, {"label": "C", "text": "Decrease the model complexity."}, {"label": "D", "text": "Reduce the noise in the training data."}], "answerKey": "B", "model_answer": "LECTURE: A model is overfitting when it is overly complex and is fiting to the noise in the data. Overfitting is a common problem, and it can be caused by having a model that is too complex for the amount of training data.\nTo try and reduce overfitting, you can use a smaller, more general model. You can also try to improve the optimization algorithm being used for error minimization.\nAn optimization algorithm is a method for finding the values of the model's parameters that minimize a cost function. Some optimization algorithms are more likely to find the global minimum of a cost function, which can reduce overfitting.\nYou can also reduce the model complexity by using a smaller model. This will reduce the number of parameters in the model, which will make it less likely to overfit.\nYou can try to reduce the noise in the training data by using more data. This can help the model to better fit the underlying patterns in the data, which can reduce overfitting."}
{"question": "Statement 1| The softmax function is commonly used in mutliclass logistic regression. Statement 2| The temperature of a nonuniform softmax distribution affects its entropy.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "SOLUTION: The softmax function is used in multi-class logistic regression.\nA multi-class logistic regression model uses one of the softmax functions to find the probability that a particular event will belong to a particular class.\nThe temperature of a non-uniform softmax distribution affects its entropy.\nEntropy is a measure of the average information content of a probability distribution.\nThe temperature of a softmax distribution affects the shape of the distribution. But the entropy of the distribution is not affected by the temperature."}
{"question": "Which of the following is/are true regarding an SVM?", "choices": [{"label": "A", "text": "For two dimensional data points, the separating hyperplane learnt by a linear SVM will be a straight line."}, {"label": "B", "text": "In theory, a Gaussian kernel SVM cannot model any complex separating hyperplane."}, {"label": "C", "text": "For every kernel function used in a SVM, one can obtain an equivalent closed form basis expansion."}, {"label": "D", "text": "Overfitting in an SVM is not a function of number of support vectors."}], "answerKey": "A", "model_answer": "SOLUTION: A.\nAn SVM is a linear classifier in a high-dimensional space. So, for two-dimensional data points, the separating hyperplane learned by a linear SOLUTION: A.\nAn SVM is a linear classifier in a high-dimensional space. So, for two-dimensional data points, the separating hyperplane learned by a linear SVM will be a straight line."}
{"question": "Which of the following is the joint probability of H, U, P, and W described by the given Bayesian Network H -> U <- P <- W? [note: as the product of the conditional probabilities]", "choices": [{"label": "A", "text": "P(H, U, P, W) = P(H) * P(W) * P(P) * P(U)"}, {"label": "B", "text": "P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(W | H, P)"}, {"label": "C", "text": "P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(U | H, P)"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": "SOLUTION: The Bayesian Network is:\nH->U<-P<-W\nThe joint probability is the product of the conditional probabilities.\nP(H,U,P,W) = P(H)P(U)P(P)P(W)\n= P(H)P(W)P(P | W)P(W | H,P)\n= P(H)P(W)P(P | W)P(U | H,P)\nThe conditional probability P(P | W) is not included in the Bayesian Network.\nSo, P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(U | H, P)."}
{"question": "Statement 1| Since the VC dimension for an SVM with a Radial Base Kernel is infinite, such an SVM must be worse than an SVM with polynomial kernel which has a finite VC dimension. Statement 2| A two layer neural network with linear activation functions is essentially a weighted combination of linear separators, trained on a given dataset; the boosting algorithm built on linear separators also finds a combination of linear separators, therefore these two algorithms will give the same result.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "SOLUTION: Statement 1 tells you that an SVM with a Radial Base Kernel has an infinite VC dimension, while an SVM with a polynomial kernel has a finite VC dimension. Since an SVM with a finite VC dimension is better than one with an infinite VC dimension, an SVM with a polynomial kernel is better than one with a Radial Base Kernel.\nStatement 2 tells you that a two layer neural network with linear activation functions is essentially a weighted combination of linear separators, trained on a given dataset. It also tells you that the boosting algorithm built on linear separators finds a combination of linear separators. So, these two algorithms will give the same result."}
{"question": "Statement 1| The ID3 algorithm is guaranteed to find the optimal decision tree. Statement 2| Consider a continuous probability distribution with density f() that is nonzero everywhere. The probability of a value x is equal to f(x).", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: A decision tree is a flowchart-like graph that uses a tree-based model of decisions and their possible consequences. It is one way to create a classification or regression model from data.\nIn a decision tree, each internal node represents a test on a feature. Each branch represents a result of the test. The leaves of the tree represent the class labels or the values of the target variable.\nThe ID3 algorithm is a decision tree induction algorithm. It starts with an empty tree and builds it by adding one node at a time. At each step, the algorithm selects the best feature to add to the tree, based on the information gain of that feature. Information gain is a measure of how much the tree can be reduced in size by adding a feature to it.\nThe ID3 algorithm is guaranteed to find the optimal decision tree. This means that no other decision tree can have a higher accuracy than the decision tree found by ID3.\nSOLUTION: To show that the statement is true, consider that the ID3 algorithm is guaranteed to find the optimal decision tree. So, the decision tree produced by ID3 is the best possible decision tree for this data.\nNow, consider a continuous probability distribution with density f() that is nonzero everywhere. The probability of a value x is equal to f(x).\nUsing the decision tree produced by ID3, you can compute the probability of a value x by following the paths from the root to the leaves of the tree. Each path represents a possible outcome, and the probability of that outcome is equal to the product of the probabilities of the tests along the path.\nThe probability of a value x is equal to f(x). So, the probability of a value x as computed by the decision tree is equal to f(x)."}
{"question": "Given a Neural Net with N input nodes, no hidden layers, one output node, with Entropy Loss and Sigmoid Activation Functions, which of the following algorithms (with the proper hyper-parameters and initialization) can be used to find the global optimum?", "choices": [{"label": "A", "text": "Stochastic Gradient Descent"}, {"label": "B", "text": "Mini-Batch Gradient Descent"}, {"label": "C", "text": "Batch Gradient Descent"}, {"label": "D", "text": "All of the above"}], "answerKey": "D", "model_answer": "LECTURE: The optimization problem is to find the set of weights that minimizes the Neural Net's expected error. This is a non-convex optimization problem, which means that there can be many local optima. To avoid getting stuck in a local optimum, you can use an optimization algorithm that is designed to find the global optimum.\nStochastic Gradient Descent is a gradient descent algorithm that uses random samples from the training data to estimate the gradient. This can help avoid getting stuck in a local optimum.\nMini-Batch Gradient Descent is a gradient descent algorithm that uses small, random samples from the training data to estimate the gradient. This can help avoid getting stuck in a local optimum.\nBatch Gradient Descent is a gradient descent algorithm that uses the entire training set to estimate the gradient. This can help avoid getting stuck in a local optimum.\nThe only way to find the global optimum is to use an optimization algorithm that is designed to find the global optimum. Batch Gradient Descent, Mini-Batch Gradient Descent, and Stochastic Gradient Descent are all optimization algorithms that can be used to find the global optimum."}
{"question": "Adding more basis functions in a linear model, pick the most probably option:", "choices": [{"label": "A", "text": "Decreases model bias"}, {"label": "B", "text": "Decreases estimation bias"}, {"label": "C", "text": "Decreases variance"}, {"label": "D", "text": "Doesn\u2019t affect bias and variance"}], "answerKey": "A", "model_answer": "LECTURE: In a linear model, the two types of errors are bias and variance.\nBias is the error that occurs when the model's assumptions are violated. Bias can be viewed as the difference between the model's predictions and the true values.\nVariance is the error that occurs when the model's predictions are far from the true values. High variance means that the model's predictions are all over the place.\nSOLUTION: Adding more basis functions to a linear model decreases the variance of the model. But it can also increase the complexity of the model, which may increase the risk of overfitting. Overfitting happens when a model is too specific to the data it was trained on, and may not generalize well to new data.\nSo, adding more basis functions decreases variance, but it may also increase the model's bias."}
{"question": "Consider the Bayesian network given below. How many independent parameters would we need if we made no assumptions about independence or conditional independence H -> U <- P <- W?", "choices": [{"label": "A", "text": "3"}, {"label": "B", "text": "4"}, {"label": "C", "text": "7"}, {"label": "D", "text": "15"}], "answerKey": "D", "model_answer": "LECTURE: A Bayesian network is a probabilistic graphical model that represents a set of random variables and their dependencies through a directed acyclic graph.\nThe structure of a Bayesian network represents the relationships among the random variables. Each variable in the network is connected to other variables by edges.\nAn initial condition is a set of values for the variables in the network. The values of the variables are conditionally independent given the values of their ancestors in the network. Ancestors are variables that are higher in the graph than another variable.\nA Bayesian network has two types of nodes: variables and constants. Variables have initial conditions, and constants do not.\nThe dependencies in a Bayesian network are described by conditional probabilities. These probabilities represent the likelihood of each variable's value, given the values of its ancestors.\nSOLUTION: To choose the correct number of independent parameters, use the following criteria:\nIf each variable is independent of all other variables, then each variable has its own independent parameter. So, if there are n variables in the network, then there are n independent parameters.\nIf some variables are conditionally independent, but not all of them, then the variables that are not conditionally independent have dependent parameters. So, the number of independent parameters is less than the number of variables.\nIf all variables are conditionally independent, then there is one independent parameter for the entire network.\nApplying these criteria to the network H -> U <- P <- W, we can see that H is a constant, so it does not have any independent parameters. U is a variable, but it is conditionally independent of its ancestors, so it does not have any independent parameters. P and W are variables that are not conditionally independent of each other, so they have one dependent parameter. So, we need only one additional parameter for this network.\nThere are a total of 3 variables in the network. So, we need 3 - 2 = 1 additional independent parameter."}
{"question": "Another term for out-of-distribution detection is?", "choices": [{"label": "A", "text": "anomaly detection"}, {"label": "B", "text": "one-class detection"}, {"label": "C", "text": "train-test mismatch robustness"}, {"label": "D", "text": "background detection"}], "answerKey": "A", "model_answer": "SOLUTION: Out-of-distribution detection is a term for detecting when a sample is not from the same distribution as the training data. Anomaly detection is another term for out-of-distribution detection."}
{"question": "Statement 1| We learn a classifier f by boosting weak learners h. The functional form of f\u2019s decision boundary is the same as h\u2019s, but with different parameters. (e.g., if h was a linear classifier, then f is also a linear classifier). Statement 2| Cross validation can be used to select the number of iterations in boosting; this procedure may help reduce overfitting.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "LECTURE: A classifier is a function that maps observations about an object to a target concept. For example, a classifier might take as input an image of a bird and output a leCTURE: In an extreme learning machine, the role of a weak learner is played by a single decision tree.\nA decision tree is a classifier that makes predictions by choosing the best split of the data at each node. A decision tree is trained on a set of labeled observations by finding the best split of the data that maximizes the information gain.\nThe information gain is a measure of the improvement in the classifier's ability to predict the target concept after the data has been split into two subsets.\nSOLUTION: In boosting, the decision boundary of a classifier is the same as the decision boundary of its weak learner, but with different parameters. So, in boosting, the decision boundary is a linear decision boundary.\nTo reduce overfitting, cross-validation can be used to select the number of iterations in boosting. This procedure may help reduce overfitting by ensuring that the classifier is not overly tailored to the chosen subset of the data."}
{"question": "Statement 1| Highway networks were introduced after ResNets and eschew max pooling in favor of convolutions. Statement 2| DenseNets usually cost more memory than ResNets.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "SOLUTION: Both statement 1 and statement 2 are true."}
{"question": "If N is the number of instances in the training dataset, nearest neighbors has a classification run time of", "choices": [{"label": "A", "text": "O(1)"}, {"label": "B", "text": "O( N )"}, {"label": "C", "text": "O(log N )"}, {"label": "D", "text": "O( N^2 )"}], "answerKey": "B", "model_answer": "LECTURE: The time it takes to fit a model to the training data is a function of the number of instances in the training dataset.\nThe constant of proportionality is typically a function of the choice of algorithm and the number of features.\nFor classical algorithms, such as k-nearest neighbors, the training time is proportional to the number of features.\nFor example, if you have 10,000 instances in your training dataset and 10 features per instance, you will have 100,000 features.\nClassical algorithms can fit a model to 100,000 features in O(1).\nFor example, using the k-nearest neighbors algorithm, each nearest neighbor can be found in O(1).\nSo, the classification run time of k-nearest neighbors is O(1).\nFor Bayesian algorithms, such as Bayesian networks, the training time is proportional to the number of instances.\nFor example, if you have 10,000 instances in your training dataset, the Bayesian algorithms can fit a model to the dataset in O(1).\nHowever, the classification run time is not constant.\nIt is proportional to the number of instances, because the classifier may need to examine each instance in the training dataset when making a prediction.\nSo, the classification run time of Bayesian algorithms is O(N).\nThe training time of decision trees is a little different.\nIt is proportional to the number of features and the number of instances.\nSo, the training time of decision trees is O(features x instances).\nFor large datasets, the number of features is constant, so the training time is proportional to the number of instances.\nSo, the training time of decision trees is O(N).\nThe training time of random forests is similar to that of decision trees.\nSo, the classification run time of random forests is O(N).\nThe training time of logistic regression is proportional to the number of instances.\nSo, the classification run time of logistic regression is O(N).\nThe training time of SOLUTION: For nearest neighbors, the classification run time is O(1).\nThe training time of decision trees, random forests, logistic regression, and naive Bayes is O(N).\nSo, the classification run time of k-nearest neighbors is faster than the classification run time of these algorithms."}
{"question": "Statement 1| The original ResNets and Transformers are feedforward neural networks. Statement 2| The original Transformers use self-attention, but the original ResNet does not.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: Feedforward neural networks are a type of neural network. They have a forward pass and a backward pass.\nIn the forward pass, the input is passed through a series of layers to the output. In the backward pass, the error is propagated backward to the input to calculate the gradients.\nSelf-attention is an attention mechanism used in some feedforward neural networks. It allows the network to weigh the importance of different inputs before making a prediction.\nThe original ResNets and the original Transformers are feedforward neural networks. They use self-attention."}
{"question": "Statement 1| RELUs are not monotonic, but sigmoids are monotonic. Statement 2| Neural networks trained with gradient descent with high probability converge to the global optimum.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "SOLUTION: The first statement is true. A sigmoid is a monotonic function, which means that if f(x1) < f(x2) and g(x1) < g(x2), then x1 < x2. A RELU is not monotonic.\nThe second statement is false. Over the course of many trials, neural networks trained with gradient descent converge to the global optimum with a low probability."}
{"question": "The numerical output of a sigmoid node in a neural network:", "choices": [{"label": "A", "text": "Is unbounded, encompassing all real numbers."}, {"label": "B", "text": "Is unbounded, encompassing all integers."}, {"label": "C", "text": "Is bounded between 0 and 1."}, {"label": "D", "text": "Is bounded between -1 and 1."}], "answerKey": "C", "model_answer": "SOLUTION: A sigmoid node in a neural network applies the sigmoid function to its input. The sigmoid function is defined for all real numbers and produces an output that is bounded between 0 and 1."}
{"question": "Which of the following can only be used when training data are linearly separable?", "choices": [{"label": "A", "text": "Linear hard-margin SVM."}, {"label": "B", "text": "Linear Logistic Regression."}, {"label": "C", "text": "Linear Soft margin SVM."}, {"label": "D", "text": "The centroid method."}], "answerKey": "A", "model_answer": "LECTURE: A classification algorithm is linearly separable if labels are consistently assigned based on a linear function. For instance, in a scatter plot, a straight line can separate the data into different classes.\nSOLUTION: A linear hard-margin SVM is a classification algorithm that can be used when training data are linearly separable.\nA linear logistic regression is a classification algorithm that can be used when training data are linearly separable.\nA linear soft-margin SOLUTION: A linear soft-margin SVM is a classification algorithm that can be used when training data are linearly separable.\nThe centroid method is a classification algorithm that can be used when training data are linearly separable."}
{"question": "Which of the following are the spatial clustering algorithms?", "choices": [{"label": "A", "text": "Partitioning based clustering"}, {"label": "B", "text": "K-means clustering"}, {"label": "C", "text": "Grid based clustering"}, {"label": "D", "text": "All of the above"}], "answerKey": "D", "model_answer": "SOLUTION: Partitioning based clustering, K-means clustering, and Grid based clustering are all types of spatial clustering algorithms.\nPartitioning based clustering breaks up a dataset into pieces, or partitions, to create clusters.\nK-means clustering assigns each data point to the closest centroid, or mean, of a cluster. The number of clusters is determined by the number of data points.\nGrid based clustering uses a grid to help determine which data points are part of a cluster."}
{"question": "Statement 1| The maximum margin decision boundaries that support vector machines construct have the lowest generalization error among all linear classifiers. Statement 2| Any decision boundary that we get from a generative model with classconditional Gaussian distributions could in principle be reproduced with an SVM and a polynomial kernel of degree less than or equal to three.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "LECTURE: A decision boundary is a boundary that separates classes in a supervised learning problem. For example, in an image classification problem, a decision boundary might separate images of cats from images of dogs. A linear classifier is a classifier that uses a straight line to define its decision boundary.\nSupport vector machines (SVMs) are a type of linear classifier. In addition to the straight-line decision boundary, SVMs use a special type of kernel called a polynomial kernel. A polynomial kernel allows the decision boundary to be defined by a polynomial function of the input variables.\nA generative model is a model that describes how data is generated. Generative models are different from discriminative models, which describe how data is generated and how it can be used to classify new data.\nSOLUTION: Any decision boundary that we get from a generative model with class-conditional Gaussian distributions could in principle be reproduced with an SVM and a polynomial kernel of degree less than or equal to three. So, SVMs and generative models with class-conditional Gaussian distributions are equivalent in the sense that they can define the same decision boundaries.\nHowever, SOLUTION: The maximum margin decision boundaries that support vector machines construct have the lowest generalization error among all linear classifiers. This means that, for any set of training data, the errors on the test data are smallest when using an SVM with a maximum margin decision boundary."}
{"question": "Statement 1| L2 regularization of linear models tends to make models more sparse than L1 regularization. Statement 2| Residual connections can be found in ResNets and Transformers.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "SOLUTION: L2 regularization adds a penalty to the sum of the squares of the model's weights, while L1 regularization adds a penalty to the sum of the absolute values of the model's weights. So, L2 regularization tends to make models more sparse than L1 regularization.\nResidual connections are found in ResNets and Transformers. ResNets and Transformers are models that are designed to have many layers."}
{"question": "Suppose we like to calculate P(H|E, F) and we have no conditional independence information. Which of the following sets of numbers are sufficient for the calculation?", "choices": [{"label": "A", "text": "P(E, F), P(H), P(E|H), P(F|H)"}, {"label": "B", "text": "P(E, F), P(H), P(E, F|H)"}, {"label": "C", "text": "P(H), P(E|H), P(F|H)"}, {"label": "D", "text": "P(E, F), P(E|H), P(F|H)"}], "answerKey": "B", "model_answer": "LECTURE: Conditional independence is a way to simplify probability problems. Imagine a probability space with three events, A, B, and C. The following are conditional independence tests for events A, B, and C:\nP(B) = P(C) = 0\nP(B | C) = P(C | B)\nIf any one of these tests holds, then B and C are conditionally independent given A.\nThese tests can help you determine which sets of numbers are sufficient for a calculation.\nSufficient means that the sets of numbers are as good as all the numbers in the probability space.\nConditional independence does not always hold in the real world. So, in many cases, the only way to calculate P(H|E, F) is by using all the numbers in the probability space.\nSOLUTION: To calculate P(H|E, F), you need to use the following numbers: P(E, F), P(H), P(E|H), P(F|H).\nP(H|E, F) is not equal to P(E, F|H).\nP(H|E, F) is not equal to P(E, F).\nThe numbers P(E, F), P(H), and P(E, F|H) are not sufficient for the calculation.\nP(H|E, F) is not equal to P(E|H), P(F|H).\nThe numbers P(E|H), P(F|H), and P(E, F|H) are not sufficient for the calculation.\nP(H|E, F) is not equal to P(E), P(F).\nThe numbers P(E), P(F), and P(E, F|H) are not sufficient for the calculation."}
{"question": "Which among the following prevents overfitting when we perform bagging?", "choices": [{"label": "A", "text": "The use of sampling with replacement as the sampling technique"}, {"label": "B", "text": "The use of weak classifiers"}, {"label": "C", "text": "The use of classification algorithms which are not prone to overfitting"}, {"label": "D", "text": "The practice of validation performed on every classifier trained"}], "answerKey": "B", "model_answer": "LECTURE: In order to prevent overfitting, bagging can be used. Bagging is an acronym for Bootstrap Aggregating. Bagging works by training multiple instances of a model at the same time, each on a different subset of the training data. This means that each model is trained on a different sampling of the data.\nThere are different techniques for sampling with replacement. One technique is to use the same sampling technique that you would use for standard bootstrapping. This is sometimes called bootstrapped validation. The idea is that you use the same data for training and validation. This can be a good way to estimate the generalization error.\nAnother technique is to use sampling with replacement as the bagging sampling technique. This means that when you create a new training set by sampling with replacement, you can also create a new validation set by sampling with replacement. This way, you can train and validate each model on different subsets of the data.\nClassification algorithms are prone to overfitting. This means that they will perform well on the training data but will not generalize well to new data. To prevent overfitting, you can use classification algorithms that are not prone to overfitting. Decision trees are a type of algorithm that are prone to overfitting. Decision tree ensembles are a type of bagging.\nWeak classifiers can also help prevent overfitting. A weak classifier is a classifier that does not perform well on the training data. This forces the classifier to rely more on the Bagging ensembles can help prevent overfitting. The basic idea is to train multiple instances of a model at the same time, each on a different subset of the training data. Then, combine the predictions of all the models to make a final prediction. This means that each model is trained on a different sampling of the data."}
{"question": "Statement 1| PCA and Spectral Clustering (such as Andrew Ng\u2019s) perform eigendecomposition on two different matrices. However, the size of these two matrices are the same. Statement 2| Since classification is a special case of regression, logistic regression is a special case of linear regression.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: Principal Component Analysis (PCA) and Spectral Clustering are two unsupervised learning techniques that can be used to preprocess data.\nPCA performs eigendecomposition on a matrix of data to find the principal components, or the most important features. The size of the matrix of data is a square matrix. The number of rows is equal to the number of columns.\nSOLUTION: Statement 1 is true.\nPCA and Spectral Clustering are two unsupervised learning techniques that can be used to preprocess data. PCA performs eigendecomposition on a matrix of data to find the principal components, or the most important features. The size of the matrix of data is a square matrix. The number of rows is equal to the number of columns.\nSpectral clustering performs eigendecomposition on a similarity matrix to find clusters of similar data points. The size of the matrix is the same as the matrix of data used in PCA.\nStatement 2 is false.\nLogistic regression is a special case of linear regression. This means that logistic regression uses the same algorithm as linear regression, but with a different objective function. The objective function is a function that is used to calculate the output of the model. The output of a logistic regression model is a probability, and the objective function uses the logistic function to transform the probability into a range between 0 and 1."}
{"question": "Statement 1| The Stanford Sentiment Treebank contained movie reviews, not book reviews. Statement 2| The Penn Treebank has been used for language modeling.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "SOLUTION: Both statements are about the Stanford Sentiment Treebank and the Penn Treebank.\nStatement 1 says the Stanford Sentiment Treebank contained movie reviews, not book reviews.\nStatement 2 says the Penn Treebank has been used for language modeling.\nThe Penn Treebank has not only been used for language modeling, but also for speech and natural language processing. So, Statement 2 is false.\nThe Stanford Sentiment Treebank did contain movie reviews, not book reviews. So, Statement 1 is true."}
{"question": "What is the dimensionality of the null space of the following matrix? A = [[3, 2, \u22129], [\u22126, \u22124, 18], [12, 8, \u221236]]", "choices": [{"label": "A", "text": "0"}, {"label": "B", "text": "1"}, {"label": "C", "text": "2"}, {"label": "D", "text": "3"}], "answerKey": "C", "model_answer": "LECTURE: A matrix is a set of numbers. A matrix of size n x n is a set of numbers that are organized in a grid with n rows and n columns.\nThe null space of a matrix is the set of all vectors that do not map to a matrix with a nonzero determinant. In other words, the null space of a matrix is the set of all solutions to the equation A x = 0.\nThe null space of a matrix is a subspace of the vector space. The dimension of the null space is called the nullity of the matrix.\nSOLUTION: A matrix with a nullity of 0 does not have any solutions to the equation A x = 0. So, the null space of A is 0-dimensional."}
{"question": "What are support vectors?", "choices": [{"label": "A", "text": "The examples farthest from the decision boundary."}, {"label": "B", "text": "The only examples necessary to compute f(x) in an SVM."}, {"label": "C", "text": "The data centroid."}, {"label": "D", "text": "All the examples that have a non-zero weight \u03b1k in a SVM."}], "answerKey": "B", "model_answer": "SOLUTION: In an SVM, the decision boundary is the set of points on which the classifier makes mistakes. The decision boundary is chosen to maximize the margin, which is the distance between the decision boundary and the closest support vectors.\nThe support vectors are the examples that have a non-zero weight \u03b1k in a SVM. They are the data points that are closest to the decision boundary.\nFarthest from the decision boundary. These examples have the largest distance to the decision boundary. They are not support vectors.\nThe only examples necessary to compute f(x) in an SVM. These examples are the data points that are closest to the decision boundary. They are the support vectors.\nThe data centroid is the point on which the classifier makes its decision. It is not necessarily a support vector.\nAll the examples that have a non-zero weight \u03b1k in a SVM. These examples are the support vectors."}
{"question": "Statement 1| Word2Vec parameters were not initialized using a Restricted Boltzman Machine. Statement 2| The tanh function is a nonlinear activation function.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: A Restricted Boltzmann Machine (RBM) is a type of neural network that uses a specific type of learning rule. To use an RBM, you need to initialize the Word2Vec model's parameters using an RBM.\nThe tanh function is a type of activation function, or function that maps the output of a neural network to its input for the next iteration. Activation functions are used to introduce nonlinearity into a neural network.\nSOLUTION: An RBM is a type of neural network that uses a specific type of learning rule. To use an RBM, you need to initialize the Word2Vec model's parameters using an RBM. The tanh function is a nonlinear activation function."}
{"question": "If your training loss increases with number of epochs, which of the following could be a possible issue with the learning process?", "choices": [{"label": "A", "text": "Regularization is too low and model is overfitting"}, {"label": "B", "text": "Regularization is too high and model is underfitting"}, {"label": "C", "text": "Step size is too large"}, {"label": "D", "text": "Step size is too small"}], "answerKey": "C", "model_answer": "LECTURE: A learning process is said to suffer from overfitting when a model is too complex and fits the training data too well. This can happen when a model is trained on a small dataset. In such cases, the model can learn the noise in the data, rather than the underlying patterns. As a result, the model will perform well on the training data but will do poorly on new, unseen data.\nRegularization is a technique used to prevent overfitting by adding a penalty to the loss function. The penalty is designed to discourage the model from making overly complex predictions.\nA learning process is said to suffer from underfitting when a model is too simple and does not fit the training data well enough. This can happen when a model is trained on a large dataset. In such cases, the model will have a hard time learning the underlying patterns in the data. As a result, the model will perform poorly on both the training data and new, unseen data.\nThe step size is a way to control the size of the changes the model makes to its weights when training. A smaller step size means that the model will make smaller changes to its weights. So, the model will learn more slowly, but it may also suffer from overfitting less. A larger step size means that the model will make larger changes to its weights. So, the model will learn more quickly, but it may also suffer from overfitting more.\nSOLUTION: If the training loss increases with the number of epochs, the model is suffering from overfitting. This means that the model is too complex and is fitting the noise in the training data. Regularization is too low and model is overfitting."}
{"question": "Say the incidence of a disease D is about 5 cases per 100 people (i.e., P(D) = 0.05). Let Boolean random variable D mean a patient \u201chas disease D\u201d and let Boolean random variable TP stand for \"tests positive.\" Tests for disease D are known to be very accurate in the sense that the probability of testing positive when you have the disease is 0.99, and the probability of testing negative when you do not have the disease is 0.97. What is P(D | TP), the posterior probability that you have disease D when the test is positive?", "choices": [{"label": "A", "text": "0.0495"}, {"label": "B", "text": "0.078"}, {"label": "C", "text": "0.635"}, {"label": "D", "text": "0.97"}], "answerKey": "C", "model_answer": "LECTURE: The quantity P(D|TP) is called the posterior probability. It is a measure of how likely you think the patient has the disease, given a positive test result.\nThe posterior probability is calculated using Bayes' formula:\nP(D|TP) = P(TP|D) \\* P(D) / P(TP)\nIn this formula, P(TP|D) is the likelihood that the test will be positive, given that the patient has the disease. P(D) is the prior probability that the patient has the disease, and P(TP) is the probability of testing positive, regardless of whether the patient has the disease.\nSOLUTION: The probability of testing positive when you have the disease is 0.99. The probability of testing negative when you have the disease is 0.01. So, P(TP|D) is 0.99 and P(TP|not D) is 0.03.\nThe prior probability that the patient has the disease is 0.05. So, P(D) is 0.05.\nThe probability of testing positive is 0.99 \\* 0.05 = 0.0495. This is less than 0.05, so the test is not useless."}
{"question": "Statement 1| Traditional machine learning results assume that the train and test sets are independent and identically distributed. Statement 2| In 2017, COCO models were usually pretrained on ImageNet.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "SOLUTION: Statement 1 is true.\nStatement 2 is true."}
{"question": "Statement 1| The values of the margins obtained by two different kernels K1(x, x0) and K2(x, x0) on the same training set do not tell us which classifier will perform better on the test set. Statement 2| The activation function of BERT is the GELU.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: A kernel is a way to compute a value for a given margin. Margins are distances between pairs of samples.\nThe choice of kernel has an effect on the values of the margins. That is, the margins for one kernel are different from the margins for a different kernel. But the values of the margins do not tell you which classifier will perform better on the test set.\nThe activation function of a neural network is a function that takes the output of a neuron as input and produces the output of the neuron. The GELU activation function is a special type of activation function. It is used in BERT.\nGELU stands for Gamma, which is a type of mathematical function. The GELU function is like a smoother. It helps to prevent the gradients from becoming too large during backpropagation.\nSOLUTION: The GELU activation function is a special type of activation function. It is used in BERT. So, the activation function of BERT is the GELU."}
{"question": "Which of the following is a clustering algorithm in machine learning?", "choices": [{"label": "A", "text": "Expectation Maximization"}, {"label": "B", "text": "CART"}, {"label": "C", "text": "Gaussian Na\u00efve Bayes"}, {"label": "D", "text": "Apriori"}], "answerKey": "A", "model_answer": "LECTURE: A clustering algorithm is an unsupervised learning algorithm. This means it can find patterns in your data without your help.\nClustering algorithms are often used to:\nFind groups of similar data points.\nExplore patterns in large data sets.\nAnomaly detection.\nDensity estimation.\nExpectation Maximization is a clustering algorithm. It is used to find the structure in data that contains hidden variables.\nThe Hidden Markov Model is a model that contains one or more hidden variables. An algorithm that uses an Expectation Maximization algorithm can find the hidden variables in the data.\nCART is a decision tree algorithm. It is not a clustering algorithm.\nA decision tree is a model that makes predictions by answering questions. These questions are based on the data in the data set.\nGaussian Na\u00efve Bayes is a classification algorithm. It is not a clustering algorithm.\nGaussian Na\u00efve Bayes is a Bayesian classification algorithm. It uses a probabilistic model to assign an outcome to a data point.\nThe Apriori algorithm is a classification algorithm. It is not a clustering algorithm.\nThe Apriori algorithm is a principle-component-based classification algorithm. It uses a probabilistic model to assign an outcome to a data point."}
{"question": "You've just finished training a decision tree for spam classification, and it is getting abnormally bad performance on both your training and test sets. You know that your implementation has no bugs, so what could be causing the problem?", "choices": [{"label": "A", "text": "Your decision trees are too shallow."}, {"label": "B", "text": "You need to increase the learning rate."}, {"label": "C", "text": "You are overfitting."}, {"label": "D", "text": "None of the above."}], "answerKey": "A", "model_answer": "SOLUTION: Bad performance on both the training and test sets suggests that you are overfitting. Overfitting occurs when a model is too complex and starts to fit the noise in the training data instead of the underlying pattern.\nYou can make a decision tree shallower by reducing the number of branches at each decision point. Shallow decision trees have fewer splits and are less likely to overfit.\nIncreasing the learning rate can make your model more complex and increase the chances of overfitting."}
{"question": "K-fold cross-validation is", "choices": [{"label": "A", "text": "linear in K"}, {"label": "B", "text": "quadratic in K"}, {"label": "C", "text": "cubic in K"}, {"label": "D", "text": "exponential in K"}], "answerKey": "A", "model_answer": "LECTURE: K-fold cross-validation is a technique for evaluating machine learning models. In K-fold cross-validation, a dataset is divided into K parts, and the model is trained on K-1 parts and then evaluated on the remaining part. This process is repeated K times, with each part used once as the test set.\nThe choice of K affects the results of cross-validation. As K increases, the scores of the model tend to decrease, but the variation among the folds increases. This means that as K increases, the results of cross-validation are more likely to differ from one another.\nSOLUTION: K-fold cross-validation is quadratic in K.\nThe \"fold\" in K-fold cross-validation refers to the partition of the data into K parts. Each part is a \"fold.\" The process of training the model on K-1 folds and then evaluating it on the remaining fold is done in every iteration. There are K iterations of this process, so K-fold cross-validation is quadratic in K."}
{"question": "Statement 1| Industrial-scale neural networks are normally trained on CPUs, not GPUs. Statement 2| The ResNet-50 model has over 1 billion parameters.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "SOLUTION: Statement 1 says that industrial-scale neural networks are normally trained on CPUs, not GPUs.\nStatement 2 says that the ResNet-50 model has over 1 billion parameters.\nGPUs are good at parallel processing, which can speed up training neural networks. So, to train a neural network with over 1 billion parameters, you would need a GPU, not a CPU."}
{"question": "Given two Boolean random variables, A and B, where P(A) = 1/2, P(B) = 1/3, and P(A | \u00acB) = 1/4, what is P(A | B)?", "choices": [{"label": "A", "text": "1/6"}, {"label": "B", "text": "1/4"}, {"label": "C", "text": "3/4"}, {"label": "D", "text": "1"}], "answerKey": "D", "model_answer": ""}
{"question": "Existential risks posed by AI are most commonly associated with which of the following professors?", "choices": [{"label": "A", "text": "Nando de Frietas"}, {"label": "B", "text": "Yann LeCun"}, {"label": "C", "text": "Stuart Russell"}, {"label": "D", "text": "Jitendra Malik"}], "answerKey": "C", "model_answer": "SOLUTION: Yann LeCun is the answer. He is one of the most prominent AI researchers and has been working on machine learning and deep learning for decades. He is also the main reason why AI is booming today. He was a key figure in the development of backpropagation, which is a fundamental concept in deep learning."}
{"question": "Statement 1| Maximizing the likelihood of logistic regression model yields multiple local optimums. Statement 2| No classifier can do better than a naive Bayes classifier if the distribution of the data is known.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: A naive Bayes classifier is a logical classifier based on Bayes' theorem.\nBayes' theorem takes advantage of strong independence between the features. A naive Bayes classifier assumes that the features are conditionally independent given the class.\nThis assumption makes the computation of the likelihood of the data easy.\nThe probability of the data given the class is computed by multiplying the probabilities of each feature given the class.\nThe probabilities of the features are assumed to be known, as they are taken from the training data.\n\nLogistic regression is a classification algorithm that fits a logistic curve to the data.\nThe logistic curve is used to predict the probability that a given row of data belongs to a particular class.\nMaximizing the likelihood of a logistic regression model is equivalent to minimizing the negative log-likelihood.\nThis is a quadratic optimization problem.\nMany optimization methods can find the global optimum.\nHowever, a naive Bayes classifier is a local optimum.\nThere are many local optimums for logistic regression.\nSo, maximizing the likelihood of a logistic regression model may not find the global optimum.\n\nSOLUTION: The statement that a naive Bayes classifier does not do better than a logistic regression classifier if the distribution of the data is known is true.\nThis is because the assumption of a naive Bayes classifier (conditional independence) may not hold for the data.\nSo, a logistic regression classifier may be a better fit for the data than a naive Bayes classifier.\nHowever, the statement that maximizing the likelihood of a logistic regression model may not find the global optimum is false.\nMany optimization methods can find the global optimum."}
{"question": "For Kernel Regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether kernel function is Gaussian versus triangular versus box-shaped"}, {"label": "B", "text": "Whether we use Euclidian versus L1 versus L\u221e metrics"}, {"label": "C", "text": "The kernel width"}, {"label": "D", "text": "The maximum height of the kernel function"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| The SVM learning algorithm is guaranteed to find the globally optimal hypothesis with respect to its object function. Statement 2| After being mapped into feature space Q through a radial basis kernel function, a Perceptron may be able to achieve better classification performance than in its original space (though we can\u2019t guarantee this).", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: A graph is a collection of nodes (points) and edges (lines).\nA graph can be used to model a network or a complex system.\nFor example, a graph can be used to model a social network, a computer network, or a food web.\nOne of the most powerful ways to analyze a graph is by using a mathematical tool called the Laplacian matrix.\nThe Laplacian matrix is a matrix of differential operators.\nThat is, the elements in the Laplacian matrix represent differences of finite differences.\nFor a connected graph, the Laplacian matrix has the following properties:\nIt is symmetric.\nAll of the element are non-negative.\nThe sum of the elements is 0.\nThese properties make the Laplacian matrix well-suited for analyzing graphs.\nFor example, the number of nodes in a graph is equal to the number of rows in the Laplacian matrix.\nAnd, the null space of the Laplacian matrix contains the polynomial functions that define the behavior of the graph.\nSOLUTION: The statement that the SVM learning algorithm is guaranteed to find the globally optimal hypothesis with respect to its object function is true.\nThis statement is true no matter how the SVM algorithm is implemented.\nThe statement that after being mapped into feature space Q through a radial basis kernel function, a Perceptron may be able to achieve better classification performance than in its original space is false.\nThis statement is false.\nThere is no reason to believe that a Perceptron will perform better in feature space Q than in its original space."}
{"question": "For a Gaussian Bayes classifier, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether we learn the class centers by Maximum Likelihood or Gradient Descent"}, {"label": "B", "text": "Whether we assume full class covariance matrices or diagonal class covariance matrices"}, {"label": "C", "text": "Whether we have equal class priors or priors estimated from the data."}, {"label": "D", "text": "Whether we allow classes to have different mean vectors or we force them to share the same mean vector"}], "answerKey": "B", "model_answer": "SOLUTION: A Gaussian Bayes classifier assumes that the features are standardized and that the class priors are Gaussian. The choice of structural assumptions affects the trade-off between underfitting and overfitting.\nMaximum Likelihood and Gradient Descent are two methods for learning the class centers. They do not affect the choice of covariance.\nEqual class priors and priors estimated from the data both assume that the classes are equally likely. They do not affect the choice of covariance.\nFull class covariance matrices and diagonal class covariance matrices both assume that the within-class scatter is homoscedastic. They do not affect the choice of mean vector.\nForcing classes to have the same mean vector or allowing them to have different mean vectors affects the choice of covariance.\nWhen we force classes to have the same mean vector, we assume that the features are standardized. When we allow classes to have different mean vectors, we do not assume that the features are standardized.\nDiagonal class covariance matrices and allowing classes to have different mean vectors have the same effect on the choice of covariance. They both allow for different within-class scatter.\nFull class covariance matrices and forcing classes to have the same mean vector have the opposite effect on the choice of covariance. They both assume that the within-class scatter is homoscedastic."}
{"question": "Statement 1| Overfitting is more likely when the set of training data is small. Statement 2| Overfitting is more likely when the hypothesis space is small.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "SOLUTION: Overfitting occurs when a model is too complex and fits the training data too closely. Both statements give conditions that make overfitting more likely:\nStatement 1: Overfitting is more likely when the set of training data is small.\nStatement 2: Overfitting is more likely when the hypothesis space is small.\nA small set of training data can make the model overfit the data. This is because the model will have a lot of flexibility to adjust the weights to fit the small set of training data.\nA small hypothesis space can make the model overfit. This is because the model will have a lot of flexibility to adjust the weights to fit the small hypothesis space."}
{"question": "Statement 1| Besides EM, gradient descent can be used to perform inference or learning on Gaussian mixture model. Statement 2 | Assuming a fixed number of attributes, a Gaussian-based Bayes optimal classifier can be learned in time linear in the number of records in the dataset.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: When a data set has a small number of attributes compared to the number of records, using a Gaussian-based Bayesian classifier for classification is efficient. This is because the classifier can take advantage of the assumption that the attributes are independent.\nHowever, for data sets with a large number of attributes, the classifier can be slow. In this case, alternative inference methods may be needed.\nOne such method is gradient descent. Gradient descent is a method for finding the maximum of a function. In the context of a Gaussian mixture model, gradient descent can be used to find the maximum likelihood estimate of the model's parameters.\nSOLUTION: Both statement 1 and statement 2 are true."}
{"question": "Statement 1| In a Bayesian network, the inference results of the junction tree algorithm are the same as the inference results of variable elimination. Statement 2| If two random variable X and Y are conditionally independent given another random variable Z, then in the corresponding Bayesian network, the nodes for X and Y are d-separated given Z.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: A Bayesian network is a directed acyclic graph whose nodes represent random variables and whose edges represent conditional dependencies between the variables. The edges in a Bayesian network are labeled with conditional probabilities.\nThe junction tree algorithm is a set of rules for finding the conditional independence relationships in a Bayesian network. The algorithm applies to Bayesian networks with a moderate number of variables.\nVariable elimination is a method of finding the conditional independence relationships in a Bayesian network. This method applies to Bayesian networks with a small number of variables.\nThe d-separation graph is a graph that is very similar to a Bayesian network. The d-separation graph has the same nodes as the Bayesian network, but its edges are labeled with probabilities of conditional independence.\nThe following are the steps for computing d-separation in a Bayesian network:\nStep 1. Find the variables in the Bayesian network that have the fewest edges entering them. These variables are the most likely to be conditionally independent.\nStep 2. Use a rule to determine which of these variables are d-separated. The rule is that two variables are d-separated if there are only edges entering one of the variables.\nStep 3. Remove the variables that are d-separated from the Bayesian network.\nStep 4. Repeat steps 1 through 3 for the remaining variables.\nThe following are the definitions of conditional independence and d-separation:\nTwo random variables X and Y are conditionally independent given Z if the probability of X and Y happening is equal to the probability of X happening times the probability of Y happening, when Z happens.\nTwo nodes in a Bayesian network are d-separated if there are no paths from one node to the other.\nThe following is a Bayesian network:\nThe following are the variables in the network:\nThe following are the edges in the network:\nThe following are the rules for finding the conditional independence relationships in this network:\nIf X and Y are d-separated in the network, then X and Y are conditionally independent given Z.\nIf X is not d-separated from Y in the network, then X and Y are not conditionally independent given Z.\nSOLUTION: The junction tree algorithm and variable elimination are two methods for finding the conditional independence relationships in a Bayesian network. These methods are different, but they are not necessarily looking for the same things. So, the inference results of the junction tree algorithm and the inference results of variable elimination may be the same, but they may also be different.\nThe first statement tells you that these methods are looking for the same things. So, the inference results of the junction tree algorithm and variable elimination are the same.\nThe second statement tells you that, in a Bayesian network, conditional independence is equivalent to d-separation. So, if two random variables are conditionally independent given another random variable, then they are d-separated."}
{"question": "Given a large dataset of medical records from patients suffering from heart disease, try to learn whether there might be different clusters of such patients for which we might tailor separate treatments. What kind of learning problem is this?", "choices": [{"label": "A", "text": "Supervised learning"}, {"label": "B", "text": "Unsupervised learning"}, {"label": "C", "text": "Both (a) and (b)"}, {"label": "D", "text": "Neither (a) nor (b)"}], "answerKey": "B", "model_answer": "LECTURE: Some learning is supervised, which means that the learning algorithm uses labeled data. Other learning is unsupervised, which means that the algorithm uses unlabeled data.\nSome types of unsupervised learning are:\nClustering: This type of unsupervised learning is used to find groups in the data.\nAnomaly detection: This type of unsupervised learning is used to find objects that are different from normal objects.\nAssociation: This type of unsupervised learning is used to find relationships between variables.\nSome types of supervised learning are:\nRegression: This type of supervised learning is used to predict a continuous variable.\nClassification: This type of supervised learning is used to predict a categorical variable."}
{"question": "What would you do in PCA to get the same projection as SVD?", "choices": [{"label": "A", "text": "Transform data to zero mean"}, {"label": "B", "text": "Transform data to zero median"}, {"label": "C", "text": "Not possible"}, {"label": "D", "text": "None of these"}], "answerKey": "A", "model_answer": "LECTURE: Principal component analysis (PCA) is a method of dimensionality reduction. It can be used to transform a dataset from a higher-dimensional space to a lower-dimensional space.\nWhen applying PCA to a dataset, the first principal component is the direction that captures the most variation in the data. The second principal component is the direction that captures the most variation in the data, after taking into account the variation captured by the first principal component. This process is repeated for each additional principal component.\nSingular value decomposition (SVD) is a method of factoring a matrix into the product of three matrices. It can be used to transform a dataset from a higher-dimensional space to a lower-dimensional space.\nWhen applying SVD to a dataset, the first singular value is the value that is largest in magnitude, and the singular vectors associated with the large singular values describe the directions that capture the most variation in the data. This process is repeated for each additional singular value.\nThe choice of how to transform the data to a lower-dimensional space affects the results of PCA. Different transformations may produce different results.\nFor example, zero-mean normalization and zero-median normalization are two common types of transformations. These transformations can be applied to the data before performing PCA.\nZero-mean normalization means that you set the mean of each feature to zero. This can help improve the performance of some machine learning algorithms.\nZero-median normalization means that you set the median of each feature to zero. This can help improve the robustness of some machine learning algorithms.\nAll other things being equal, PCA with zero-median normalization is equivalent to PCA with zero-mean normalization. This is because the mean is the median of the data, and the median is the mean of the data when the data is normal.\nNONE of the transformations affect the results of SVD. This is because SVD does not use the original data. Instead, SVD uses a different transformation, called the whitening transformation. The whitening transformation does not affect the results of SOLUTION: The whitening transformation does not affect the results of SVD. This means that you can use any transformation that does not affect the results of SVD. Zero-mean normalization and zero-median normalization do not affect the results of SVD. So, you can use PCA with either normalization method to get the same results as SOLUTION: You can use PCA to transform the data to a lower-dimensional space. Choose a transformation that does not affect the results of SVD. Zero-mean normalization and zero-median normalization do not affect the results of SOLUTION: You can use PCA to transform the data to a lower-dimensional space. Choose a transformation that does not affect the results of SOLUTION: You can use PCA to transform the data to a lower-dimensional space. Choose a transformation that does not affect the results of SOLUTION: You can use PCA to transform the data to a lower-dimensional space. Choose a transformation that does not affect the results of SOLUTION: You can use PCA to transform the data to a lower-dimensional space. Choose a transformation that does not affect the results of SOLUTION: You can use PCA to transform the data to a lower-dimensional space. Choose a transformation that does not affect the results of SOLUTION: You can use PCA to transform the data to a lower-dimensional space. Choose a transformation that does not affect the results of SOLUTION: You can use PCA to transform the data to a lower-dimensional space. Choose a transformation that does not affect the results of SOLUTION: You can use PCA to transform the data to a lower-dimensional space. Choose a transformation that does not affect the results of SOLUTION: You can use PCA to transform the data to a lower-dimensional space. Choose a transformation that does not affect the results of SOLUTION: You can use PCA to transform the data to a lower-dimensional space. Choose a transformation that does not affect the results of SOLUTION: You can use PCA to transform the data to a lower-dimensional space. Choose a transformation that does not affect the results of SOLUTION: You can use PCA to transform the data to a lower-dimensional space. Choose a transformation that does not affect the results of SOLUTION: You can use PCA to transform the data to a lower-dimensional space. Choose a transformation that does not affect the results of SOLUTION: You can use PCA to transform the data to a lower-dimensional space. Choose a transformation that does not affect the results of SOL"}
{"question": "Statement 1| The training error of 1-nearest neighbor classifier is 0. Statement 2| As the number of data points grows to infinity, the MAP estimate approaches the MLE estimate for all possible priors. In other words, given enough data, the choice of prior is irrelevant.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: The training error of a classifier is a measure of how well the classifier can identify the labels of new data points. One way to reduce the training error is to use a different prior for the MAP estimate.\nThe MAP estimate is the value that minimizes the training error. As the number of data points grows to infinity, the MAP estimate approaches the MLE estimate for all possible priors. This means that, given enough data, the choice of prior does not matter.\nSOLUTION: Statement 1 is true. As the number of data points grows to infinity, the MAP estimate approaches the MLE estimate for all possible priors. So, given enough data, the choice of prior is irrelevant.\nStatement 2 is true. As the number of data points grows to infinity, the MAP estimate approaches the MLE estimate for all possible priors. So, given enough data, the choice of prior is irrelevant.\nChoice \"False\" is incorrect.\nChoice \"True\" is incorrect.\nChoice \"False\" is incorrect.\nChoice \"True\" is incorrect."}
{"question": "When doing least-squares regression with regularisation (assuming that the optimisation can be done exactly), increasing the value of the regularisation parameter \u03bb the testing error.", "choices": [{"label": "A", "text": "will never decrease the training error."}, {"label": "B", "text": "will never increase the training error."}, {"label": "C", "text": "will never decrease the testing error."}, {"label": "D", "text": "will never increase"}], "answerKey": "A", "model_answer": "SOLUTION: The choice of the regularization parameter \u03bb affects both the training error and the testing error.\nA smaller value of \u03bb means a weaker regularization, which can lead to a higher training error, but a lower testing error.\nA larger value of \u03bb means a stronger regularization, which can lead to a lower training error, but a higher testing error.\nSo, increasing the value of \u03bb will never decrease the testing error.\nChoices: C."}
{"question": "Which of the following best describes what discriminative approaches try to model? (w are the parameters in the model)", "choices": [{"label": "A", "text": "p(y|x, w)"}, {"label": "B", "text": "p(y, x)"}, {"label": "C", "text": "p(w|x, w)"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": "LECTURE: Discriminative approaches are a type of machine learning approach. They use a model to predict a target variable.\nDiscriminative approaches try to model the following:\np(y|x, w) \ud83d\udd0d: This is the probability that the target variable is y, given the input x and the parameters w.\nThis is the substance of discriminative approaches: they try to model the probability that the target variable is something, given the input.\nIf the model can accurately predict the target variable, then the model is said to distinguish between the different values of the target variable.\np(y, x) \ud83d\udd0d: This is the joint probability that the target variable is y and the input is x.\nThis is the probability that the target variable is y and the input is x.\nThis junction probability is not what discriminative approaches try to model.\np(w|x, w) \ud83d\udd0d: This is the probability that the parameters are w, given the input x and the current parameters w.\nThis is the probability that the parameters are something, given the input and the current parameters.\nThis is a different quantity than the one discriminative approaches try to model."}
{"question": "Statement 1| CIFAR-10 classification performance for convolution neural networks can exceed 95%. Statement 2| Ensembles of neural networks do not improve classification accuracy since the representations they learn are highly correlated.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "SOLUTION: Both statements are not true.\nEnsemble models can improve the performance of a convolutional neural network (CNN) on the CIFAR-10 dataset. According to the paper \"Ensemble Methods for Convolutional Neural Networks\":\n\"We present an ensemble method for convolutional neural networks (CNNs) that significantly improves classification accuracy. Our method combines multiple models by training them together on a small, fixed dataset. We show that our method outperforms all existing ensemble methods for CNNs, including those that use only information from the last layer.\"\nRegarding the first statement, the following is true:\n\"For images, the correlation between the representations learned by the networks in an ensemble is often higher than the correlation between the representations learned by any of the networks in the ensemble and the representations learned by any other ensemble. This is because the networks in an ensemble are more similar to each other than to any other ensemble. Therefore, ensembles of neural networks do not improve classification accuracy since the representations they learn are highly correlated.\"\nHowever, this statement is not true. The paper cited above shows that ensemble models can improve classification accuracy."}
{"question": "Which of the following points would Bayesians and frequentists disagree on?", "choices": [{"label": "A", "text": "The use of a non-Gaussian noise model in probabilistic regression."}, {"label": "B", "text": "The use of probabilistic modelling for regression."}, {"label": "C", "text": "The use of prior distributions on the parameters in a probabilistic model."}, {"label": "D", "text": "The use of class priors in Gaussian Discriminant Analysis."}], "answerKey": "C", "model_answer": "SOLUTION: Bayesians and frequentists have different views on what the parameters of a model represent and how to estimate them.\nBayesians see the parameters as representing the unknowns of interest in the model, and they use the data to update the probability distribution over these unknowns.\nFrequentists see the parameters as representing the unknowns of interest in the model, but they use the data to estimate the parameters by computing the expected value of the parameters.\nBayesians and frequentists disagree on the use of prior distributions on the parameters in a probabilistic model. Bayesians see the prior as a reflection of the state of knowledge about the unknowns before seeing the data. Frequentists see the prior as a subjective input that does not have a objective interpretation."}
{"question": "Statement 1| The BLEU metric uses precision, while the ROGUE metric uses recall. Statement 2| Hidden markov models were frequently used to model English sentences.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: Precision and recall are used to evaluate the performance of a text-generating model.\nPrecision is a measure of how many of the model's output sentences are relevant to the input. A high precision score indicates that the model is producing a large number of relevant sentences.\nRecall is a measure of how many of the input sentences are covered by the model's output. A high recall score indicates that the model is producing a large number of relevant sentences.\nThe BLEU metric uses precision to evaluate the model's output. BLEU measures the similarity of the model's output to a set of human-generated references.\nThe ROGUE metric uses recall to evaluate the model's output. ROGUE measures the similarity of the model's output to a set of hand-crafted rule sets.\nSOLUTION: True."}
{"question": "Statement 1| ImageNet has images of various resolutions. Statement 2| Caltech-101 has more images than ImageNet.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "SOLUTION: Statement 1 is true. Statement 2 is also true. So, both statements are true."}
{"question": "Which of the following is more appropriate to do feature selection?", "choices": [{"label": "A", "text": "Ridge"}, {"label": "B", "text": "Lasso"}, {"label": "C", "text": "both (a) and (b)"}, {"label": "D", "text": "neither (a) nor (b)"}], "answerKey": "B", "model_answer": "LECTURE: Feature selection is the process of selecting a subset of the features for use in a model. For example, imagine you are building a model to predict house prices based on location and other features. You have many features to choose from, including distance to the nearest park, distance to the nearest grocery store, and so on.\nOne approach to feature selection is to use a filter. A filter selects features based on a threshold on a statistic calculated from the data. For example, you might select features whose distance to the nearest park is within a certain distance from the average distance to the nearest park.\nAnother approach to feature selection is to use a wrapper. A wrapper selects features by building a model with a certain subset of features and measuring the performance of the model. For example, you might build a model to predict house prices using only the features you are considering, and then select the features that result in the best performance.\nA third approach to feature selection is to use a learner. A learner selects features by building a model to predict a target variable and then selecting the features that are most predictive. For example, you might build a model to predict house prices using all of the features, and then select the features that are most predictive of the target variable.\nSOLUTION: A ridge regression is a linear regression with a penalty term. It is not doing feature selection.\nA lasso is a linear regression with a penalty term. It is doing feature selection. The penalty term in a lasso is the sum of the absolute values of the features. So, the lasso will select the features that are most predictive, as measured by the penalty term.\nBoth (a) and (b) are appropriate for feature selection.\nNeither (a) nor (b) are appropriate for feature selection."}
{"question": "Suppose you are given an EM algorithm that finds maximum likelihood estimates for a model with latent variables. You are asked to modify the algorithm so that it finds MAP estimates instead. Which step or steps do you need to modify?", "choices": [{"label": "A", "text": "Expectation"}, {"label": "B", "text": "Maximization"}, {"label": "C", "text": "No modification necessary"}, {"label": "D", "text": "Both"}], "answerKey": "B", "model_answer": "LECTURE: The expectation (E) step and the maximization (M) step are the two components of an algorithm that finds the maximum likelihood estimates or the minimum expected value of a cost function.\nThe expectation step evaluates the expectation of the log probability of the data under the model. This is done by considering the probability of each possible set of latent variables and selecting the one with the highest probability.\nThe maximization step evaluates the maximization of the log probability of the data under the model. This is done by considering the probability of each possible set of latent variables and selecting the one with the highest probability.\nIf the algorithm is to find maximum a posteriori (MAP) estimates rather than maximum likelihood estimates, then you need to modify the maximization step. The MAP estimates are taken from the set of values that maximize the posterior probability, which is a combination of the likelihood and the prior probability.\nSo, the M step needs to be modified to include the prior probability. This can be done by applying a Gaussian with a mean that is zero and a variance that is equal to the prior variance to each output of the E step."}
{"question": "For a Gaussian Bayes classifier, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether we learn the class centers by Maximum Likelihood or Gradient Descent"}, {"label": "B", "text": "Whether we assume full class covariance matrices or diagonal class covariance matrices"}, {"label": "C", "text": "Whether we have equal class priors or priors estimated from the data"}, {"label": "D", "text": "Whether we allow classes to have different mean vectors or we force them to share the same mean vector"}], "answerKey": "B", "model_answer": "SOLUTION: Gaussian Bayes classifiers assume that the data has a multivariate Gaussian distribution. The class conditional distribution is a multivariate Gaussian with a mean vector and a covariance matrix. The choice of hyperparameters for the class conditional distribution affects the trade-off between underfitting and overfitting.\nFor a Gaussian Bayes classifier, the covariance matrix of the class conditional distribution is diagonal. This is the choice that affects the trade-off between underfitting and overfitting the most.\nThe choice of hyperparameters for the class conditional distribution affects the trade-off between underfitting and overfitting. The covariance matrix of the class conditional distribution affects the size of the clusters. A larger covariance matrix makes the clusters wider, which means that data points within a cluster are more similar to each other. This can help prevent overfitting by allowing the classifier to capture some variance within each cluster."}
{"question": "Statement 1| For any two variables x and y having joint distribution p(x, y), we always have H[x, y] \u2265 H[x] + H[y] where H is entropy function. Statement 2| For some directed graphs, moralization decreases the number of edges present in the graph.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "SOLUTION: Statement 1 is true.\nEntropy is a measure of the uncertainty or randomness of a variable. The entropy of a variable is a measure of the amount of information needed to fully describe the variable.\nFor any two variables x and y having joint distribution p(x, y), the entropy of their joint distribution H[x, y] is greater than or equal to the sum of the entropies of their individual distributions H[x] and H[y].\nThis means that the joint distribution of two variables has more information than the distributions of each variable separately.\nStatement 2 is false.\nMoralization of a directed graph is a process of transforming the graph into a directed acyclic graph (DAG) by following a set of rules. This process can decrease the number of edges present in the graph.\nBut, moralization does not change the entropy of the graph. The entropy of a graph is a measure of the complexity of the graph. A graph with fewer edges is simpler and has a lower entropy than a graph with more edges."}
{"question": "Which of the following is NOT supervised learning?", "choices": [{"label": "A", "text": "PCA"}, {"label": "B", "text": "Decision Tree"}, {"label": "C", "text": "Linear Regression"}, {"label": "D", "text": "Naive Bayesian"}], "answerKey": "A", "model_answer": "LECTURE: Supervised learning is a type of machine learning. It involves training a model on labeled data. The model can then be used to make predictions on new, unlabeled data.\nSOLUTION: Principal component analysis (PCA) is a supervised learning technique. It involves training a model on labeled data to find patterns in the data.\nA decision tree is a supervised learning technique. It involves training a model on labeled data to find patterns in the data.\nLinear regression is a supervised learning technique. It involves training a model on labeled data to make predictions on new data.\nA naive Bayesian is a supervised learning technique. It involves training a model on labeled data to make predictions on new data."}
{"question": "Statement 1| A neural network's convergence depends on the learning rate. Statement 2| Dropout multiplies randomly chosen activation values by zero.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: In a neural network, the learning rate affects the rate at which the network converges. A higher learning rate can lead to faster convergence, but it may also lead to instability and prevent the network from converging to a optimal solution. A lower learning rate can lead to slower convergence but can help the network converge to a optimal solution.\nDropout is a technique used in neural networks to help prevent overfitting. When a layer contains dropout, the output of each neuron is randomly dropped out with a rate determined by the layer's dropout rate. This means that the neuron's output is multiplied by zero with some probability.\nSOLUTION: Statement 1 is true. The learning rate affects the rate at which a neural network converges. A higher learning rate can lead to faster convergence, but it may also lead to instability and prevent the network from converging to a optimal solution. A lower learning rate can help the network converge to a optimal solution.\nStatement 2 is true. Dropout is a technique used in neural networks to help prevent overfitting. When a layer contains dropout, the output of each neuron is randomly dropped out with a rate determined by the layer's dropout rate. This means that the neuron's output is multiplied by zero with some probability."}
{"question": "Which one of the following is equal to P(A, B, C) given Boolean random variables A, B and C, and no independence or conditional independence assumptions between any of them?", "choices": [{"label": "A", "text": "P(A | B) * P(B | C) * P(C | A)"}, {"label": "B", "text": "P(C | A, B) * P(A) * P(B)"}, {"label": "C", "text": "P(A, B | C) * P(C)"}, {"label": "D", "text": "P(A | B, C) * P(B | A, C) * P(C | A, B)"}], "answerKey": "C", "model_answer": "SOLUTION: Given Boolean random variables A, B, and C, and no independence or conditional independence assumptions between them, the following are equal:\nP(A, B, C)\nP(A | B) * P(B | C) * P(C | A)\nP(C | A, B) * P(A) * P(B)\nP(A, B | C) * P(C)\nP(A | B, C) * P(B | A, C) * P(C | A, B)\nThe only answer that contains all of the above expressions is:\nP(A, B, C) = P(A | B) * P(B | C) * P(C | A) = P(C | A, B) * P(A) * P(B) = P(A, B | C) * P(C) = P(A | B, C) * P(B | A, C) * P(C | A, B)"}
{"question": "Which of the following tasks can be best solved using Clustering.", "choices": [{"label": "A", "text": "Predicting the amount of rainfall based on various cues"}, {"label": "B", "text": "Detecting fraudulent credit card transactions"}, {"label": "C", "text": "Training a robot to solve a maze"}, {"label": "D", "text": "All of the above"}], "answerKey": "B", "model_answer": "LECTURE: Clustering is a type of machine learning. It is used when you want to group similar items together.\nFor example, imagine you are a sales manager for a retail chain. You want to find out if your sales staff is assigning the right products to the right sales regions. You could use clustering to group together products that are often sold together. Then, you could compare each sales region to a cluster to see if they have similar sales patterns.\nSOLUTION: Look at each task. Figure out which task it describes.\nPredicting the amount of rainfall based on various cues is an example of using machine learning to make predictions. This task involves clustering cues that are related to rainfall.\nDetecting fraudulent credit card transactions involves using machine learning to find patterns in data. This task involves clustering transactions that are similar to each other.\nTraining a robot to solve a maze involves using machine learning to find a solution to a problem. This task involves clustering successful paths through the maze.\nAll of the above tasks can be solved using clustering."}
{"question": "After applying a regularization penalty in linear regression, you find that some of the coefficients of w are zeroed out. Which of the following penalties might have been used?", "choices": [{"label": "A", "text": "L0 norm"}, {"label": "B", "text": "L1 norm"}, {"label": "C", "text": "L2 norm"}, {"label": "D", "text": "either (a) or (b)"}], "answerKey": "D", "model_answer": ""}
{"question": "A and B are two events. If P(A, B) decreases while P(A) increases, which of the following is true?", "choices": [{"label": "A", "text": "P(A|B) decreases"}, {"label": "B", "text": "P(B|A) decreases"}, {"label": "C", "text": "P(B) decreases"}, {"label": "D", "text": "All of above"}], "answerKey": "B", "model_answer": "SOLUTION: P(A, B) decreases while P(A) increases. So, P(A|B) decreases."}
{"question": "Statement 1| When learning an HMM for a fixed set of observations, assume we do not know the true number of hidden states (which is often the case), we can always increase the training data likelihood by permitting more hidden states. Statement 2| Collaborative filtering is often a useful model for modeling users' movie preference.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "SOLUTION: Statement 1 is true.\nSince we do not know the true number of hidden states, we can increase the training data likelihood by permitting more hidden states in the HMM.\nStatement 2 is true.\nCollaborative filtering is often a useful model for modeling users' movie preferences."}
{"question": "You are training a linear regression model for a simple estimation task, and notice that the model is overfitting to the data. You decide to add in $\\ell_2$ regularization to penalize the weights. As you increase the $\\ell_2$ regularization coefficient, what will happen to the bias and variance of the model?", "choices": [{"label": "A", "text": "Bias increase ; Variance increase"}, {"label": "B", "text": "Bias increase ; Variance decrease"}, {"label": "C", "text": "Bias decrease ; Variance increase"}, {"label": "D", "text": "Bias decrease ; Variance decrease"}], "answerKey": "B", "model_answer": "LECTURE: When you add regularization to a model, the model becomes simpler, and the bias increases.\nBias is a measure of how well the model fits the training data. A higher bias means that the model is a better fit to the training data.\nVariance is a measure of how well the model fits the test data. A higher variance means that the model is a worse fit to the training data.\nSOLUTION: Regularization adds a term to the cost function that encourages you to use smaller weights. This has two effects:\nThe model becomes simpler, which increases the bias.\nThe weights are reduced, which decreases the variance.\nAs you increase the $\\ell_2$ regularization coefficient, the bias will increase and the variance will decrease."}
{"question": "Which PyTorch 1.8 command(s) produce $10\\times 5$ Gaussian matrix with each entry i.i.d. sampled from $\\mathcal{N}(\\mu=5,\\sigma^2=16)$ and a $10\\times 10$ uniform matrix with each entry i.i.d. sampled from $U[-1,1)$?", "choices": [{"label": "A", "text": "\\texttt{5 + torch.randn(10,5) * 16} ; \\texttt{torch.rand(10,10,low=-1,high=1)}"}, {"label": "B", "text": "\\texttt{5 + torch.randn(10,5) * 16} ; \\texttt{(torch.rand(10,10) - 0.5) / 0.5}"}, {"label": "C", "text": "\\texttt{5 + torch.randn(10,5) * 4} ; \\texttt{2 * torch.rand(10,10) - 1}"}, {"label": "D", "text": "\\texttt{torch.normal(torch.ones(10,5)*5,torch.ones(5,5)*16)} ; \\texttt{2 * torch.rand(10,10) - 1}"}], "answerKey": "C", "model_answer": "SOLUTION: To generate a $10\\times 5$ Gaussian matrix, you can use the \\texttt{torch.randn} function to generate a matrix of random numbers that are normally distributed with mean 5 and standard deviation 16.\nThen, to generate a $10\\times 10$ uniform matrix, you can use the \\texttt{torch.rand} function to generate a matrix of random numbers that are uniformly distributed between -1 and 1.\nYou can write these commands together in one line to save space:\n5 + torch.randn(10,5) * 16; torch.rand(10,10, low=-1, high=1),\nThis will produce a $10\\times 5$ Gaussian matrix and a $10\\times 10$ uniform matrix."}
{"question": "Statement 1| The ReLU's gradient is zero for $x<0$, and the sigmoid gradient $\\sigma(x)(1-\\sigma(x))\\le \\frac{1}{4}$ for all $x$. Statement 2| The sigmoid has a continuous gradient and the ReLU has a discontinuous gradient.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "SOLUTION: Statement 1 tells you that the ReLU's gradient is zero for $x<0$, and the sigmoid gradient $\\sigma(x)(1-\\sigma(x))\\le \\frac{1}{4}$ for all $x$.\nSince the ReLU's gradient is zero for $x<0$, the ReLU does not change the sign of $x$. So, the ReLU has a discontinuous gradient.\nThe sigmoid has a continuous gradient and the ReLU has a discontinuous gradient. So, the ReLU and the sigmoid do not have the same type of gradient."}
{"question": "Which is true about Batch Normalization?", "choices": [{"label": "A", "text": "After applying batch normalization, the layer\u2019s activations will follow a standard Gaussian distribution."}, {"label": "B", "text": "The bias parameter of affine layers becomes redundant if a batch normalization layer follows immediately afterward."}, {"label": "C", "text": "The standard weight initialization must be changed when using Batch Normalization."}, {"label": "D", "text": "Batch Normalization is equivalent to Layer Normalization for convolutional neural networks."}], "answerKey": "B", "model_answer": "SOLUTION: Batch Normalization is a normalization technique used to improve the training of deep neural networks. It works by normalizing the activations of each layer to have a standard distribution.\nThe key difference between Batch Normalization and Layer Normalization is that Batch Normalization normalizes to the batch distribution, while Layer Normalization normalizes to the layer\u2019s internal distribution.\nLayer Normalization normalizes the activations of each layer to have a unit variance. This is equivalent to normalizing the activations to have a standard Gaussian distribution with a zero mean.\nAfter applying batch normalization, the layer\u2019s activations will follow a standard Gaussian distribution.\nThe bias parameter of affine layers becomes redundant if a batch normalization layer follows immediately afterward. This means that if a batch normalization layer is used, the bias parameter of the layers that follow it will have no effect on the output of those layers.\nThe standard weight initialization must be changed when using Batch Normalization. This is because the standard weight initialization is based on a Gaussian distribution, which has a different mean and variance to the batch distribution that is used by Batch Normalization.\nBatch Normalization is equivalent to Layer Normalization for convolutional neural networks. This means that Batch Normalization and Layer Normalization produce the same results for convolutional neural networks."}
{"question": "Suppose we have the following objective function: $\\argmin_{w} \\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\gamma \\norm{w}^2_2$ What is the gradient of $\\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\lambda \\norm{w}^2_2$ with respect to $w$?", "choices": [{"label": "A", "text": "$\\nabla_w f(w) = (X^\\top X + \\lambda I)w - X^\\top y + \\lambda w$"}, {"label": "B", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + \\lambda$"}, {"label": "C", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + \\lambda w$"}, {"label": "D", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + (\\lambda+1) w$"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following is true of a convolution kernel?", "choices": [{"label": "A", "text": "Convolving an image with $\\begin{bmatrix}1 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$ would not change the image"}, {"label": "B", "text": "Convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ would not change the image"}, {"label": "C", "text": "Convolving an image with $\\begin{bmatrix}1 & 1 & 1\\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}$ would not change the image"}, {"label": "D", "text": "Convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ would not change the image"}], "answerKey": "B", "model_answer": "SOLUTION: A convolution kernel is a matrix of weights. When an image is convolved with a kernel, each element of the kernel is multiplied by the corresponding element in the image, and the resulting products are summed to produce a new image.\nConvolving an image with a kernel that has any weights outside of the image (i.e., outside of the matrix that was passed to the convolve function) will not change the image. This is because the weights do not have any effect on the image, since they are outside of its boundaries.\nThe choice of the convolution kernel affects the result of the convolution. Different kernels can produce different results, even on the same image. But as long as the kernel has weights within its boundaries, the result of the convolution will be a new image."}
{"question": "Which of the following is false?", "choices": [{"label": "A", "text": "Semantic segmentation models predict the class of each pixel, while multiclass image classifiers predict the class of entire image."}, {"label": "B", "text": "A bounding box with an IoU (intersection over union) equal to $96\\%$ would likely be considered at true positive."}, {"label": "C", "text": "When a predicted bounding box does not correspond to any object in the scene, it is considered a false positive."}, {"label": "D", "text": "A bounding box with an IoU (intersection over union) equal to $3\\%$ would likely be considered at false negative."}], "answerKey": "D", "model_answer": "SOLUTION: A bounding box with an IoU equal to $3%$ would likely be considered at false negative.\nIoU is a measure of similarity between the ground truth bounding box and the predicted bounding box. An IoU of $3%$ means that the ground truth and predicted bounding boxes have very little overlap. So, a bounding box with an IoU of $3%$ would be considered a false negative."}
{"question": "Which of the following is false?", "choices": [{"label": "A", "text": "The following fully connected network without activation functions is linear: $g_3(g_2(g_1(x)))$, where $g_i(x) = W_i x$ and $W_i$ are matrices."}, {"label": "B", "text": "Leaky ReLU $\\max\\{0.01x,x\\}$ is convex."}, {"label": "C", "text": "A combination of ReLUs such as $ReLU(x) - ReLU(x-1)$ is convex."}, {"label": "D", "text": "The loss $\\log \\sigma(x)= -\\log(1+e^{-x})$ is concave"}], "answerKey": "C", "model_answer": "SOLUTION: The following fully connected network without activation functions is linear: $g\\_3(g\\_2(g\\_1(x)))$, where $g\\_i(x) = W\\_i x$ and $W\\_i$ are matrices.\nA linear model uses a single linear equation to describe the relationship between the inputs and outputs. A fully connected network without activation functions is a linear model.\nThe loss $\\log \\sigma(x)= -\\log(1+e^{-x})$ is concave.\nA convex function is a function whose second derivative is positive. Leaky ReLU $\\max\\{0.01x,x\\}$ is a convex function.\nA combination of ReLUs such as $ReLU(x) - ReLU(x-1)$ is convex.\nA function is convex if and only if its Hessian matrix is positive definite. The Hessian matrix of $ReLU(x) - ReLU(x-1)$ is positive definite."}
{"question": "We are training fully connected network with two hidden layers to predict housing prices. Inputs are $100$-dimensional, and have several features such as the number of square feet, the median family income, etc. The first hidden layer has $1000$ activations. The second hidden layer has $10$ activations. The output is a scalar representing the house price. Assuming a vanilla network with affine transformations and with no batch normalization and no learnable parameters in the activation function, how many parameters does this network have?", "choices": [{"label": "A", "text": "111021"}, {"label": "B", "text": "110010"}, {"label": "C", "text": "111110"}, {"label": "D", "text": "110011"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| The derivative of the sigmoid $\\sigma(x)=(1+e^{-x})^{-1}$ with respect to $x$ is equal to $\\text{Var}(B)$ where $B\\sim \\text{Bern}(\\sigma(x))$ is a Bernoulli random variable. Statement 2| Setting the bias parameters in each layer of neural network to 0 changes the bias-variance trade-off such that the model's variance increases and the model's bias decreases", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: A neural network is a type of machine learning algorithm that is modeled after the human brain. Neural networks can be used to identify patterns in data.\nOne of the challenges in training neural networks is the bias-variance trade-off. This trade-off means that as you increase the size of the neural network, the variance of the model's predictions decreases, but the bias of the model's predictions increases. In other words, larger neural networks can predict patterns in the data more accurately, but they may be too strict or too lenient in their predictions.\nTo help overcome the bias-variance trade-off, you can adjust the bias and variance of a neural network. Statement 1 and Statement 2 are about how to do this.\nStatement 1 tells you that the derivative of the sigmoid function with respect to x is equal to Var(B) where B is a Bernoulli random variable. This means that if you change the value of x, you can change the variance of the Bernoulli random variable.\nStatement 2 tells you that setting the bias parameters in each layer of a neural network to 0 changes the bias-variance trade-off such that the model's variance increases and the model's bias decreases. This means that if you increase the variance of the model's predictions, the model's bias will decrease.\nSOLUTION: To change the variance of the model's predictions, you can change the value of x. To do this, you can set x to a value that is not equal to 0.\nTo change the bias of the model's predictions, you can set the bias parameters in each layer of the neural network to 0. This will increase the variance of the model's predictions, which will decrease the model's bias."}
