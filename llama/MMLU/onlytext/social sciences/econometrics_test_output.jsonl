{"question": "Which one of the following is the most appropriate definition of a 99% confidence interval?", "choices": [{"label": "A", "text": "99% of the time in repeated samples, the interval would contain the true value of the parameter"}, {"label": "B", "text": "99% of the time in repeated samples, the interval would contain the estimated value of the parameter"}, {"label": "C", "text": "99% of the time in repeated samples, the null hypothesis will be rejected"}, {"label": "D", "text": "99% of the time in repeated samples, the null hypothesis will not be rejected when it was false"}], "answerKey": "A", "model_answer": ""}
{"question": "What is the main difference between the Dickey Fuller (DF) and Phillips-Perron (PP) approaches to unit root testing?", "choices": [{"label": "A", "text": "ADF is a single equation approach to unit root testing while PP is a systems approach"}, {"label": "B", "text": "PP tests reverse the DF null and alternative hypotheses so that there is stationarity under the null hypothesis of the PP test"}, {"label": "C", "text": "The PP test incorporates an automatic correction for autocorrelated residuals in the test regression"}, {"label": "D", "text": "PP tests have good power in small samples whereas DF tests do not."}], "answerKey": "C", "model_answer": "LECTURE: In the context of these unit root tests, a unit root is a statistical term that indicates that the data do not follow a trend. A series has a unit root if the difference between the series and a trend is less than 1 for all values of the series.\nA stationary series has a unit root.\nA stationary series is a series that has a constant mean and a constant variance. It is a series that may have a trend but not a trend that changes over time.\nIf a series is stationary, it is not necessarily short-term.\nA series that is not stationary is called a nonstationary series.\nA nonstationary series has a unit root.\nA nonstationary series is a series that has a trend.\nIf a series is nonstationary, it is not necessarily long-term.\nSOLUTION: The main difference between the Dickey Fuller (DF) and Phillips-Perron (PP) approaches to unit root testing is that the PP test incorporates an automatic correction for autocorrelated residuals in the test regression.\nThe DF test involves differencing the series once. The null hypothesis of the DF test is that the series is nonstationary.\nThe PP test involves differencing the series multiple times. The null hypothesis of the PP test is that the series is stationary.\nThe PP test has an additional step: It checks for the presence of autocorrelated residuals in the test regression. Autocorrelated residuals are residuals that have a correlation structure similar to the correlation structure of the original series.\nIf the test finds autocorrelated residuals, it applies an algorithm to correct for them. This algorithm removes the autocorrelation from the residuals.\nThe PP test with this correction is called the PP test with the Prais-Winsten correction."}
{"question": "If there were a leverage effect in practice, what would be the shape of the news impact curve for as model that accounted for that leverage?", "choices": [{"label": "A", "text": "It would rise more quickly for negative disturbances than for positive ones of the same magnitude"}, {"label": "B", "text": "It would be symmetrical about zero"}, {"label": "C", "text": "It would rise less quickly for negative disturbances than for positive ones of the same magnitude"}, {"label": "D", "text": "It would be zero for all positive disturbances"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following statements is false concerning the linear probability model?", "choices": [{"label": "A", "text": "There is nothing in the model to ensure that the estimated probabilities lie between zero and one"}, {"label": "B", "text": "Even if the probabilities are truncated at zero and one, there will probably be many observations for which the probability is either exactly zero or exactly one"}, {"label": "C", "text": "The error terms will be heteroscedastic and not normally distributed"}, {"label": "D", "text": "The model is much harder to estimate than a standard regression model with a continuous dependent variable"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following statements concerning the regression population and sample is FALSE?", "choices": [{"label": "A", "text": "The population is the total collection of all items of interest"}, {"label": "B", "text": "The population can be infinite"}, {"label": "C", "text": "In theory, the sample could be larger than the population"}, {"label": "D", "text": "A random sample is one where each individual item from the population is equally likely to be drawn."}], "answerKey": "C", "model_answer": "LECTURE: A population is a group of people, animals, or things that you want to study. A sample is a group of people, animals, or things that are selected from a population.\nA sample is a random sample if each individual item from the population has an equal chance of being selected for the sample. This is called simple random sampling.\nSOLUTION: The population is the total collection of all items of interest.\nA population can be infinite.\nIn theory, the sample could be larger than the population.\nA random sample is one where each individual item from the population is equally likely to be drawn."}
{"question": "Which of the following statements is INCORRECT concerning a comparison of the Box-Pierce Q and the Ljung-Box Q* statistics for linear dependence in time series?", "choices": [{"label": "A", "text": "Asymptotically, the values of the two test statistics will be equal"}, {"label": "B", "text": "The Q test has better small-sample properties than the Q*"}, {"label": "C", "text": "The Q test is sometimes over-sized for small samples"}, {"label": "D", "text": "As the sample size tends towards infinity, both tests will show a tendency to always reject the null hypothesis of zero autocorrelation coefficients."}], "answerKey": "B", "model_answer": ""}
{"question": "A parsimonious model is one that", "choices": [{"label": "A", "text": "Includes too many variables"}, {"label": "B", "text": "Includes as few variables as possible to explain the data"}, {"label": "C", "text": "Is a well-specified model"}, {"label": "D", "text": "Is a mis-specified model"}], "answerKey": "A", "model_answer": "LECTURE: A parsimonious model is one that includes as few variables as possible to explain the data.\nA well-specified model is one for which the relationship among the variables is clear and the variables are measured appropriately.\nA mis-specified model is one in which the relationship among the variables is unclear or the variables are not being measured appropriately.\nSOLUTION: A parsimonious model is one that includes as few variables as possible to explain the data.\nThis model is parsimonious. It includes two variables, one for each part of the question."}
{"question": "Which of the following is NOT a feature of continuously compounded returns (i.e. log-returns)?", "choices": [{"label": "A", "text": "They can be interpreted as continuously compounded changes in the prices"}, {"label": "B", "text": "They can be added over time to give returns for longer time periods"}, {"label": "C", "text": "They can be added across a portfolio of assets to give portfolio returns"}, {"label": "D", "text": "They are usually fat-tailed"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following features of financial asset return time-series could be captured using a standard GARCH(1,1) model?\n\ni) Fat tails in the return distribution\n\n\nii) Leverage effects\n\n\niii) Volatility clustering\n\n\niv) Volatility affecting returns", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: Financial asset return time-series are often characterized by the following features:\nFat tails in the return distribution: The return time-series may have returns that are farther from the norm than would be expected from a normal distribution.\nLeverage effects: The return time-series may have a return that is affected by how leveraged the investment is.\nVolatility clustering: The return time-series may have periods of relative stability in the return distribution followed by periods of increased volatility.\nVolatility affecting returns: The return time-series may have returns that are affected by the volatility of the return distribution.\nA standard GARCH(1,1) model can capture the following features:\nVolatility affecting returns: A GARCH(1,1) model can capture the fact that returns are affected by the volatility of the return distribution."}
{"question": "Consider the estimation of a GARCH-M model. If the data employed were a time-series of daily corporate bond percentage returns, which of the following would you expect the value of the GARCH-in-mean parameter estimate to be?", "choices": [{"label": "A", "text": "Less than -1"}, {"label": "B", "text": "Between -1 and 0"}, {"label": "C", "text": "Between 0 and 1"}, {"label": "D", "text": "Bigger than 1"}], "answerKey": "C", "model_answer": "LECTURE: For a GARCH-M model, the GARCH-in-mean parameter estimate is the value of the long-term mean of the disturbances. The GARCH-in-mean parameter is denoted by \u03b4, and it can be positive or negative.\nIf \u03b4 is positive, then, in the long-term, the disturbances grow without bound.\nIf \u03b4 is negative, then, in the long-term, the disturbances converge to zero.\nThe GARCH-in-mean parameter estimate is less than -1, between -1 and 0, between 0 and 1, or bigger than 1.\nIf the GARCH-in-mean parameter estimate is less than -1, then the disturbances grow without bound in the long-term.\nIf the GARCH-in-mean parameter estimate is between -1 and 0, then the disturbances converge to zero in the long-term.\nIf the GARCH-in-mean parameter estimate is between 0 and 1, then the disturbances grow without bound in the long-term.\nIf the GARCH-in-mean parameter estimate is bigger than 1, then the disturbances converge to zero in the long-term."}
{"question": "Under which of the following situations would bootstrapping be preferred to pure simulation?\n\ni) If it is desired that the distributional properties of the data in the experiment\n\nare the same as those of some actual data\n\n\nii) If it is desired that the distributional properties of the data in the experiment\n\nare known exactly\n\n\niii) If the distributional properties of the actual data are unknown\n\n\niv) If the sample of actual data available is very small", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: In simulation, the experiment is designed to mimic the real world. The simulation model is a set of rules that tells the experiment how to behave.\nA farmer wants to calculate the average yield of a particular type of corn. She can design an experiment to grow multiple crops of corn and measure their yields. However, this approach takes a long time and is expensive.\nAn alternative is to use a simulation. The farmer can create a set of rules that describe how corn grows. She can use the rules to simulate the growth of multiple crops of corn. The simulation can estimate the average yield of a particular type of corn.\nSOLUTION: Bootstrapping is a technique for making predictions by analyzing a small sample of data.\nIf it is desired that the distributional properties of the data in the experiment are the same as those of some actual data, then bootstrapping would be preferred to pure simulation. Bootstrapping can use the actual data to create a set of rules that describe the distribution of the data. The rules can be used to make predictions about the population of data.\nIf the distributional properties of the actual data are unknown, then pure simulation would be preferred to bootstrapping. In this case, the simulation can be designed to match the distribution of the actual data.\nIf the sample of actual data available is very small, then bootstrapping would be preferred to pure simulation. Bootstrapping can use the limited data to create a set of rules that describe the distribution of the data. The rules can be used to make predictions about the population of data.\nPure simulation is preferred when bootstrapping is not possible or practical. For example, pure simulation is preferred when the experiment has multiple stages, and observing the experiment in one stage affects the results in another stage."}
{"question": "Which of the following may be consequences of one or more of the CLRM assumptions being violated?\n\ni) The coefficient estimates are not optimal\n\n\nii) The standard error estimates are not optimal\n\n\niii) The distributions assumed for the test statistics are inappropriate\n\n\niv) Conclusions regarding the strength of relationships between the dependent\n\nand independent variables may be invalid.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "LECTURE: The CLRM (Classical LeCTure: Measurements are written with both a number and a label. The label is included in parentheses after the number. The label tells you what the number means.\nWhen you are given a measurement, you need to figure out what the measurement means. You can use the label to help you.\nFor example, let's say you are given the number 76.\nThe label tells you that the number means \"favorite.\"\nSo, 76 is your favorite temperature.\nSOLUTION: To decide if the assumptions have been violated, you need to figure out what they mean.\nThe coefficient estimates are not optimal.\nThis assumption means that the numbers that were obtained from the data may not be the best numbers.\nThe standard error estimates are not optimal.\nThis assumption means that the spread of the data may not be the best measure of the spread of the population.\nThe distributions assumed for the test statistics are inappropriate.\nThis assumption means that the numbers may not be normally distributed.\nConclusions regarding the strength of relationships between the dependent and independent variables may be invalid.\nThis assumption means that it may be wrong to conclude that you have found a relationship between the variables."}
{"question": "Which of the following statements is true concerning forecasting in econometrics?", "choices": [{"label": "A", "text": "Forecasts can only be made for time-series data"}, {"label": "B", "text": "Mis-specified models are certain to produce inaccurate forecasts"}, {"label": "C", "text": "Structural forecasts are simpler to produce than those from time series models"}, {"label": "D", "text": "In-sample forecasting ability is a poor test of model adequacy"}], "answerKey": "D", "model_answer": "LECTURE: Forecasting is an important part of econometric analysis. It involves using historical data to create a model that can be used to predict future events.\nThere are many ways to perform a forecast. One way is to use a structural model, which uses economic theory to identify the factors that affect the variable you are interested in. For example, if you are interested in the relationship between the price of gasoline and the number of cars on the road, a structural model might use the fact that it is cheaper to drive a car than to take the bus to estimate that higher gasoline prices will lead to fewer cars on the road.\nAnother way to perform a forecast is to use a time-series model, which uses the historical data to identify patterns and trends. For example, a time-series model might estimate that the price of gasoline is higher in summer than in winter.\nBecause of the advantages of time-series models, most current forecasting research uses time-series methods. Time-series models are used to forecast changes in interest rates, stock prices, and exchange rates, as well as to forecast future values of economic variables.\nSOLUTION: The correct answer is D.\nIn-sample forecasting ability is a poor test of model adequacy.\nIn-sample forecasting ability does not necessarily indicate how well the model will forecast in the future. A model may have a high R-squared in-sample, but that does not guarantee that it will have a high R-squared out-of-sample.\nStructural forecasts are simpler to produce than those from time-series models.\nStructural forecasts do not require exogenous variables, or inputs that are not part of the model. So, structural forecasts are simpler to produce than time-series forecasts.\nMis-specified models are certain to produce inaccurate forecasts.\nA mis-specified model is not necessarily going to produce inaccurate forecasts. A mis-specified model may actually be able to accurately forecast the data it was fit to.\nForecasts can only be made for time-series data.\nTime-series data are the only data that can be used to make forecasts."}
{"question": "The pacf is necessary for distinguishing between", "choices": [{"label": "A", "text": "An AR and an MA model"}, {"label": "B", "text": "An AR and an ARMA model"}, {"label": "C", "text": "An MA and an ARMA model"}, {"label": "D", "text": "Different models from within the ARMA family"}], "answerKey": "B", "model_answer": "LECTURE: When comparing two models from within the ARMA family, you can use the pacf to determine which model is better. The pacf is necessary for distinguishing between an AR and an MA model.\nTo compare an AR and an MA model, look at the pacf of each. If the pacf of one model grows without bound, the other model is better.\nIf the pacf of one model has a spike at multimonotone breaks, the other model is better.\nIf the pacf of one model has a spike at every break, the other model is better.\nIf the pacf of one model is equal to the other model's pacf, the models are equivalent.\nIf the pacf of one model is less than the other model's pacf, the other model is better.\nSOLUTION: To distinguish between an AR and an ARMA model, look at the pacf of each. If the pacf of one model grows without bound, the other model is better."}
{"question": "Negative residual autocorrelation is indicated by which one of the following?", "choices": [{"label": "A", "text": "A cyclical pattern in the residuals"}, {"label": "B", "text": "An alternating pattern in the residuals"}, {"label": "C", "text": "A complete randomness in the residuals"}, {"label": "D", "text": "Residuals that are all close to zero"}], "answerKey": "B", "model_answer": "LECTURE: One way to check for autocorrelation in the residuals is to examine the pattern of the residuals.\nIf the absolute value of the residuals is plotted against the absolute value of the time variable, a negative residual autocorrelation indicates that the residuals decrease as the time variable increases. This pattern is called a \"ccyclical pattern\" in the residuals.\nA positive residual autocorrelation indicates that the residuals increase as the time variable increases. This pattern is called an \"alternating pattern\" in the residuals.\nComplete randomness in the residuals indicates that the residuals are not correlated with the time variable.\nIf the residuals are all close to zero, this indicates that there may be a problem with the model (such as forgetting to include a variable in the model).\nSOLUTION: To check for negative residual autocorrelation, look for a cyclical pattern in the residuals.\nThe residuals do not form a cyclical pattern."}
{"question": "Which of the following statements are true concerning a comparison between ARCH(q) and GARCH(1,1) models?\n\ni) The ARCH(q) model is likely to be the more parsimonious\n\n\nii) The ARCH(q) model is the more likely to violate non-negativity constraints\n\n\niii) The ARCH(q) model can allow for an infinite number of previous lags of squared\n\nreturns to affect the current conditional variance\n\n\niv) The GARCH(1,1) model will usually be sufficient to capture all of the dependence\n\nin the conditional variance", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "LECTURE: When comparing two models, such as ARCH(q) and GARCH(1,1), it is often useful to consider the following:\n1. Parsimony: A model is more parsimonious if it uses fewer parameters to fit the data. In this case, the ARCH(q) model is more parsimonious than the GARCH(1,1) model because the ARCH(q) model uses one parameter to describe the previous lags of squared returns, while the GARCH(1,1) model uses two parameters.\n2. Non-negativity constraints: The ARCH(q) model may violate non-negativity constraints. This occurs when one or more of the model's parameters is not positive. The GARCH(1,1) model does not violate non-negativity constraints.\n3. Number of previous lags of squared returns: The ARCH(q) model can allow for an infinite number of previous lags of squared returns to affect the current conditional variance. The GARCH(1,1) model can only allow for one previous lag of squared returns to affect the current conditional variance.\n4. Sufficiency: A model is sufficient if it can capture all of the dependence in the data. It is not possible to determine if a model is sufficient without comparing it to another model.\nSOLUTION: To determine if the GARCH(1,1) model will usually be sufficient to capture all of the dependence in the conditional variance, compare the number of parameters in the two models. The GARCH(1,1) model uses two parameters to describe the previous lags of squared returns. The ARCH(q) model uses one parameter. So, the GARCH(1,1) model is more parsimonious than the ARCH(q) model."}
{"question": "Which of the following statements are true concerning a triangular or recursive system?\n\ni) The parameters can be validly estimated using separate applications of OLS to\n\neach equation\n\n\nii) The independent variables may be correlated with the error terms in other\n\nequations\n\n\niii) An application of 2SLS would lead to unbiased but inefficient parameter estimates\n\n\niv) The independent variables may be correlated with the error terms in the equations\n\nin which they appear as independent variables", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
{"question": "Which one of the following statements best describes the algebraic representation of the fitted regression line?", "choices": [{"label": "A", "text": "\\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t + \\hat{u}_t"}, {"label": "B", "text": "\\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t"}, {"label": "C", "text": "\\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t + u_t"}, {"label": "D", "text": "y_t = \\hat{\\alpha} + \\hat{\\beta}x_t + \\hat{u}_t"}], "answerKey": "B", "model_answer": "LECTURE: The algebraic representation of the fitted regression line is y = \\alpha + \\beta x.\nThe model is written with symbols instead of specific numbers. This way, the model is easier to read and use.\nThe symbols \\alpha and \\beta represent the intercept and slope of the fitted regression line, respectively.\nThe symbol y represents the dependent variable, and the symbol x represents the independent variable.\nWhen you substitute the specific numbers from the model into the symbolic equation, you get the algebraic representation of the fitted regression line.\nThe other two models are not in the correct form.\nThe model \\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t + \\hat{u}_t has an intercept of \\hat{\\alpha} and a slope of \\hat{\\beta}.\nThe model \\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t has an intercept of \\hat{\\alpha} and a slope of \\hat{\\beta}.\nThe model y_t = \\hat{\\alpha} + \\beta x\\_t + \\hat{u}_t has an intercept of \\hat{\\alpha} and a slope of \\beta."}
{"question": "What are the dimensions of $\\hat{u}^t \\hat{u}?", "choices": [{"label": "A", "text": "T x k"}, {"label": "B", "text": "T x 1"}, {"label": "C", "text": "k x 1"}, {"label": "D", "text": "1 x 1"}], "answerKey": "D", "model_answer": "LECTURE: The dimensions of a vector are the number of values it contains.\nIf the vector has one value, it has dimension 1.\nIf the vector has two values, it has dimension 2.\n...\n...\nSOLUTION: The vector $\\hat{u}^t \\hat{u}$ has one value, so it has dimension 1."}
{"question": "The characteristic roots of the MA process\n\n$y_t = -3u_{t-1} + u_{t-2} + u_t$\n\nare", "choices": [{"label": "A", "text": "1 and 2"}, {"label": "B", "text": "1 and 0.5"}, {"label": "C", "text": "2 and -0.5"}, {"label": "D", "text": "1 and -3"}], "answerKey": "B", "model_answer": "LECTURE: The characteristic roots of a MA process are the values of the roots of its characteristic equation. The characteristic equation is the polynomial equation\n##\ufffd## = 0.\nThe roots of this equation determine the process's behavior.\nThe characteristic roots of a MA process are:\n1. The process is not mean-reverting, if the root is 1.\nA MA(1) process has a root of 1.\nA MA(2) process has a root of 1.\n2. The process is mean-reverting, if the root is not 1.\nA MA(1) process has a root of 0.\nA MA(2) process has a root of 0.5."}
{"question": "Which of the following is an equivalent expression for saying that the explanatory variable is \"non-stochastic\"?", "choices": [{"label": "A", "text": "The explanatory variable is partly random"}, {"label": "B", "text": "The explanatory variable is fixed in repeated samples"}, {"label": "C", "text": "The explanatory variable is correlated with the errors"}, {"label": "D", "text": "The explanatory variable always has a value of one"}], "answerKey": "B", "model_answer": "LECTURE: Sometimes, an explanatory variable is said to be \"non-stochastic\" or \"deterministic.\" This means that the value of the explanatory variable is fixed for each individual in the study.\nFor example, in a study about people's shoe sizes, the explanatory variable \"number of pairs of shoes owned\" is non-stochastic. The value of the explanatory variable is fixed for each person.\nIf an explanatory variable is non-stochastic, you can use it to predict each person's score on the dependent variable.\nOtherwise, if an explanatory variable is stochastic or random, you can use it to predict the range of scores on the dependent variable.\nSOLUTION: The correct answer is B.\nIf the explanatory variable is fixed in repeated samples, each sample of data has the same value for the explanatory variable. This means that the explanatory variable is non-stochastic."}
{"question": "Suppose that the Durbin Watson test is applied to a regression containing two explanatory variables plus a constant with 50 data points. The test statistic takes a value of 1.53. What is the appropriate conclusion?", "choices": [{"label": "A", "text": "Residuals appear to be positively autocorrelated"}, {"label": "B", "text": "Residuals appear to be negatively autocorrelated"}, {"label": "C", "text": "Residuals appear not to be autocorrelated"}, {"label": "D", "text": "The test result is inconclusive"}], "answerKey": "D", "model_answer": "LECTURE: The Durbin-Watson test is a test for autocorrelation. It measures the correlation of residuals with lower order terms. The test statistic is calculated as W, where the denominator is the sum of the squared residuals and the numerator is the sum of the squared lower order terms.\nIf the test statistic is less than 2, the Durbin-Watson test suggests the presence of positive autocorrelation. That is, the residuals have a linear relationship with the lower order terms.\nIf the test statistic is between 2 and 4, the test is inconclusive.\nIf the test statistic is greater than 4, the Durbin-Watson test suggests the presence of negative autocorrelation. That is, the residuals have a linear relationship with the higher order terms.\nSOLUTION: The test statistic of 1.53 is between 2 and 4, so the test is inconclusive. The test does not provide evidence of positive or negative autocorrelation."}
{"question": "If OLS is used in the presence of autocorrelation, which of the following will be likely consequences?\n\ni) Coefficient estimates may be misleading\n\n\nii) Hypothesis tests could reach the wrong conclusions\n\n\niii) Forecasts made from the model could be biased\n\n\niv) Standard errors may inappropriate", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "LECTURE: If a model is used in the presence of autocorrelation, the following consequences may occur:\nCoefficient estimates may be misleading.\nHypothesis tests could reach the wrong conclusions.\nForecasts made from the model could be biased.\nStandard errors may be inappropriate.\nIf only one of these consequences is present, then the first, second, third, or fourth choice, respectively, is the correct answer.\nSOLUTION: For each of the choices, consider whether the consequence is solely determined by the presence of autocorrelation.\nIf the consequence is solely determined by the presence of autocorrelation, then the choice is correct.\nCoefficient estimates may be misleading.\nHypothesis tests could reach the wrong conclusions.\nForecasts made from the model could be biased.\nThese consequences are solely determined by the presence of autocorrelation.\nStandard errors may be inappropriate.\nThis consequence is not solely determined by the presence of autocorrelation."}
{"question": "What will be the properties of the OLS estimator in the presence of multicollinearity?", "choices": [{"label": "A", "text": "It will be consistent, unbiased and efficient"}, {"label": "B", "text": "It will be consistent and unbiased but not efficient"}, {"label": "C", "text": "It will be consistent but not unbiased"}, {"label": "D", "text": "It will not be consistent"}], "answerKey": "A", "model_answer": ""}
{"question": "Which one of the following would NOT be a consequence of using non-stationary data in levels form?", "choices": [{"label": "A", "text": "The regression $R^2$ may be spuriously high"}, {"label": "B", "text": "Test statistics may not follow standard distributions"}, {"label": "C", "text": "Statistical inferences may be invalid"}, {"label": "D", "text": "Parameter estimates may be biased"}], "answerKey": "D", "model_answer": "LECTURE: When you use data in levels form, you observe the same data even if you move back and forth in time. For example, the unemployment rate in January 2008 and the unemployment rate in February 2008 are the same data.\nIf you use non-stationary data in levels form, you may get spurious results when trying to model the data. For example, a regression $R^2$ may be spuriously high, and parameter estimates may be biased.\nIf you use non-stationary data in first differences form, you will observe different data each time you move back in time. For example, the unemployment rate in January 2008 and the unemployment rate in February 2008 are different data.\nWhen data is first differenced, any trends or seasonality in the data will be removed. This can be helpful when you want to model the remaining patterns in the data.\nSOLUTION: Looking at non-stationary data in levels form can lead to spurious results. So, test statistics may not follow standard distributions, and statistical inferences may be invalid."}
{"question": "If a series, y, follows a random walk, what is the optimal one-step ahead forecast of y?", "choices": [{"label": "A", "text": "The current value of y"}, {"label": "B", "text": "Zero"}, {"label": "C", "text": "One"}, {"label": "D", "text": "The average value of y over the in-sample period"}], "answerKey": "A", "model_answer": ""}
{"question": "The order condition is", "choices": [{"label": "A", "text": "A necessary and sufficient condition for identification"}, {"label": "B", "text": "A necessary but not sufficient condition for identification"}, {"label": "C", "text": "A sufficient but not necessary condition for identification"}, {"label": "D", "text": "A condition that is nether necessary nor sufficient for identification"}], "answerKey": "B", "model_answer": "LECTURE: A necessary condition is a prerequisite for something to be true. If a necessary condition is met, then it is impossible for the something to be false.\nA sufficient condition is a prerequisite for something to be true. If a sufficient condition is met, then it is impossible for the something to be false.\nThe conditions of being a living thing and having lungs are a sufficient condition for being a mammal. If an organism is alive and has lungs, it is a mammal.\nA necessary but not sufficient condition is a prerequisite for something to be true. If a necessary condition is met, it is impossible for the something to be false. However, there may be other conditions that are also necessary.\nHaving a temperature of 98.6\u00b0F is a necessary condition for being human. But being over 70 feet tall is not a necessary condition for being a human.\nA condition that is neither necessary nor sufficient is not a condition for something to be true.\nBeing a green bug is a condition that is neither necessary nor sufficient for being a June bug.\nSOLUTION: The order condition is a necessary condition for identification. If the order of the numbers is changed, the result is a different fraction. So, the order condition is a necessary condition for a fraction to be a valid fraction.\nThe order condition is not a sufficient condition for identification. The fraction 1/2 is a valid fraction, but changing the order of the numbers changes the fraction to its opposite. So, the order condition is not a sufficient condition for a fraction to be a valid fraction."}
{"question": "If an estimator is said to have minimum variance, which of the following statements is NOT implied?", "choices": [{"label": "A", "text": "The probability that the estimate is a long way away from its true value is minimised"}, {"label": "B", "text": "The estimator is efficient"}, {"label": "C", "text": "Such an estimator would be termed \"best\""}, {"label": "D", "text": "Such an estimator will always be unbiased"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following are disadvantages of the Dickey-Fuller / Engle-Granger approach to testing for cointegration and modelling cointegrating relationships?\n\ni) Only one cointegrating relationship can be estimated\n\nii) Particularly for small samples. There is a high chance of the tests suggestingthat variables are not cointegrated when they are\n\niii) It is not possible to make inferences on the cointegrating regression\n\niv) The procedure forces the researcher to specify which is the dependent variable and which are the independent variables.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following statements is true concerning the population regression function (PRF) and sample regression function (SRF)?", "choices": [{"label": "A", "text": "The PRF is the estimated model"}, {"label": "B", "text": "The PRF is used to infer likely values of the SRF"}, {"label": "C", "text": "Whether the model is good can be determined by comparing the SRF and the PRF"}, {"label": "D", "text": "The PRF is a description of the process thought to be generating the data."}], "answerKey": "D", "model_answer": "LECTURE: A function is a rule that describes a relationship between an input and an output.\nIf one input has a value, the rule tells you the corresponding output.\nA function can be described by an equation, a graph, or both.\nSOLUTION: The population regression function (PRF) is a description of the process thought to be generating the data. The PRF is not an estimated model.\nThe sample regression function (SRF) is an estimated model of the PRF. The SRF is a close approximation of the PRF, but they are not equal.\nThe choice of which function to use depends on the situation. If you have the data from the entire population, then use the PRF. If you have data only from a sample of the population, then the SRF is a close approximation of the PRF."}
{"question": "Which one of the following is a disadvantage of the general to specific or \"LSE\" (\"Hendry\") approach to building econometric models, relative to the specific to general approach?", "choices": [{"label": "A", "text": "Some variables may be excluded at the first stage leading to coefficient biases"}, {"label": "B", "text": "The final model may lack theoretical interpretation"}, {"label": "C", "text": "The final model may be statistically inadequate"}, {"label": "D", "text": "If the initial model is mis-specified, all subsequent steps will be invalid."}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following statements are true concerning maximum likelihood (ML) estimation in the context of GARCH models?\n\ni) Maximum likelihood estimation selects the parameter values that maximise the\n\nprobability that we would have actually observed the values of the series y that we\n\nactually did.\n\n\nii) GARCH models can only be estimated by ML and not by OLS\n\n\niii) For estimation of a standard linear model (with no GARCH), the OLS and ML\n\nestimates for the slope and intercept parameters will be identical but the estimator\n\nfor the variance of the disturbances is slightly different\n\n\niv) Most computer packages use numerical procedures to estimate GARCH models\n\nrather than a set of analytical formulae", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "LECTURE: Maximum likelihood is a widely used method for estimating the parameters of statistical models. The method is based on the likelihood function, which is the probability of the data given the parameters. The likelihood function is transformed into a function of the parameters, and the parameters are estimated by finding the value of the transformed function that maximizes the likelihood.\nThe likelihood function is defined as the product of the probability distribution of the data and the probability distribution of the model. For the normal distribution, the probability distribution of the data is a normal distribution with mean \u03bc and variance \u03c32, and the probability distribution of the model is a normal distribution with mean \u03bc and a variance that is a function of the parameters \u03b8. Then the likelihood function is a normal distribution with mean \u03bc and a variance that is a function of \u03b8.\nThe likelihood function is transformed by taking the logarithm of the function. The logarithm of a product is the sum of the logarithms of the components. So, the logarithm of the likelihood function is the sum of the logarithm of the probability distribution of the data and the logarithm of the probability distribution of the model.\nFor the normal distribution, the logarithm of the likelihood function is a linear function of \u03b8. So, the maximum likelihood estimates of \u03b8 are the values of \u03b8 that make the logarithm of the likelihood function as large as possible.\nThe maximum likelihood estimates can be found by solving the equation that describes the logarithm of the likelihood function. This equation is called the likelihood equation."}
{"question": "Including relevant lagged values of the dependent variable on the right hand side of a regression equation could lead to which one of the following?", "choices": [{"label": "A", "text": "Biased but consistent coefficient estimates"}, {"label": "B", "text": "Biased and inconsistent coefficient estimates"}, {"label": "C", "text": "Unbiased but inconsistent coefficient estimates"}, {"label": "D", "text": "Unbiased and consistent but inefficient coefficient estimates."}], "answerKey": "A", "model_answer": "LECTURE: Regression analysis is a powerful tool for analyzing the relationships between variables. It is a way to measure how much one variable, the dependent variable, is associated with another variable, the independent variable.\nA regression equation is a formula that describes the relationship between the dependent variable and the independent variable. The formula is:\ndependent variable = independent variable + error\nThe error term represents the difference between the actual dependent variable and the predicted dependent variable.\nSOLUTION: Including relevant lagged values of the dependent variable on the right hand side of a regression equation could lead to biased but consistent coefficient estimates.\nLagged values are previous values of the dependent variable. When lagged values are included in a regression equation, the coefficient for the lagged values will be biased, but the coefficient for the independent variable will be unbiased."}
{"question": "Which one of the following factors is likely to lead to a relatively high degree of out-of-sample forecast accuracy?", "choices": [{"label": "A", "text": "A model that is based on financial theory"}, {"label": "B", "text": "A model that contains many variables"}, {"label": "C", "text": "A model whose dependent variable has recently exhibited a structural change"}, {"label": "D", "text": "A model that is entirely statistical in nature with no room for judgmental modification of forecasts"}], "answerKey": "A", "model_answer": "LECTURE: Out-of-sample forecast accuracy is a model's ability to make accurate predictions on data that the model has not seen during the model's construction.\nSOLUTION: A model that is based on financial theory is likely to lead to a relatively high degree of out-of-sample forecast accuracy. Financial theory provides a strong foundation for building empirical models.\nA model that contains many variables is likely to overshoot the underlying relationship of the variables to the dependent variable.\nA model whose dependent variable has recently exhibited a structural change is likely to require a significant overhaul of its structure.\nA model that is entirely statistical in nature with no room for judgmental modification of forecasts is likely to be too inflexible to accurately predict changing relationships."}
{"question": "Which of the following are plausible approaches to dealing with residual autocorrelation?\n\ni) Take logarithms of each of the variables\n\nii) Add lagged values of the variables to the regression equation\n\niii) Use dummy variables to remove outlying observations\n\niv) Try a model in first differenced form rather than in levels.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "LECTURE: In a simple linear regression, the equation of the line is given by y = b0 + b1x, where b1 is the slope of the line.\nWhen both x and y are continuous, the slope b1 measures how much y changes for a one-unit change in x.\nIf x is continuous and y is categorical, the slope b1 measures the difference in y between the highest and lowest categories of x.\nIf x is categorical and y is continuous, the slope b1 measures the difference in y for the category of x that has the lowest value.\nFor example, if x is the number of hours spent studying and y is the test score, the slope b1 measures how much y changes for a one-hour change in x.\nIf x is the number of hours spent studying and y is the number of hours watched on television, the slope b1 measures the difference in hours watched on television for the number of hours spent studying that has the lowest test score.\nSOLUTION: To deal with residual autocorrelation, which is a correlation between observations that are far apart, you can try the following approaches:\nTake logarithms of each of the variables: This can help to reduce the impact of outliers and make the model more parsimonious.\nAdd lagged values of the variables to the regression equation: This can help to mitigate autocorrelation.\nUse dummy variables to remove outlying observations: This can help to remove observations that are far out of line with the other observations.\nTry a model in first differenced form rather than in levels: This can help to reduce the impact of autocorrelation."}
{"question": "For an autoregressive process to be considered stationary", "choices": [{"label": "A", "text": "The roots of the characteristic equation must all lie inside the unit circle"}, {"label": "B", "text": "The roots of the characteristic equation must all lie on the unit circle"}, {"label": "C", "text": "The roots of the characteristic equation must all lie outside the unit circle"}, {"label": "D", "text": "The roots of the characteristic equation must all be less than one in absolute value"}], "answerKey": "C", "model_answer": "LECTURE: A time series is said to be stationary if its statistical properties do not change over time. Many time series properties are described by a set of parameters. These parameters are said to be stationary if they do not change over time.\nA stationary time series has the following properties:\nThe mean, median, and mode are equal.\nThe spread (variability) is constant.\nThe values of the statistical properties are not affected by when the data were observed.\nIf a time series is not stationary, it is said to be nonstationary.\nA nonstationary time series has the following properties:\nThe mean is not equal to the median.\nThe spread is not constant.\nThe values of the statistical properties are affected by when the data were observed.\nTo make a nonstationary time series stationary, you can apply a transform to the data. One common transform is to take the difference between each observation and the previous observation. This is called differencing.\nIf differencing a time series does not make it stationary, you may need to use a different transform.\nSOLUTION: An autoregressive process is stationary if its characteristic equation has all of its roots inside the unit circle. The characteristic equation is given by:\nwhere \u03bb is the root.\nThis equation has all of its roots inside the unit circle if all of its roots have absolute value less than 1.\nSo, the roots of the characteristic equation must all be less than one in absolute value for the process to be stationary."}
{"question": "Which of the following statements are true concerning information criteria?\n\n(i) Adjusted R-squared is an information criterion\n\n(ii) If the residual sum of squares falls when an additional term is added, the value of the information criterion will fall\n\n(iii) Akaike's information criterion always leads to model orders that are at least as large as those of Schwarz's information criterion\n\n(iv) Akaike's information criterion is consistent", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": ""}
{"question": "The \"within transform\" involves", "choices": [{"label": "A", "text": "Taking the average values of the variables"}, {"label": "B", "text": "Subtracting the mean of each entity away from each observation on that entity"}, {"label": "C", "text": "Estimating a panel data model using least squares dummy variables"}, {"label": "D", "text": "Using both time dummies and cross-sectional dummies in a fixed effects panel model"}], "answerKey": "B", "model_answer": ""}
{"question": "The purpose of \"augmenting\" the Dickey-Fuller test regression is to", "choices": [{"label": "A", "text": "Ensure that there is no heteroscedasticity in the test regression residuals."}, {"label": "B", "text": "Ensure that the test regression residuals are normally distributed"}, {"label": "C", "text": "Ensure that there is no autocorrelation in the test regression residuals"}, {"label": "D", "text": "Ensure that all of the non-stationarity is taken into account."}], "answerKey": "C", "model_answer": "LECTURE: One way to check for non-stationarity in a time series is to perform a unit root test, such as the Augmented Dickey-Fuller (ADF) test. The ADF test examines the difference between the series and its fitted trend.\nIf the test indicates that the series is non-stationary, you can take the series to be a random walk. A random walk is a time series with no predictable pattern.\nIf the test indicates that the series is stationary, you can take the series to be a time series with a predictable pattern. A stationary time series has a constant mean and a constant variance.\nThe ADF test is a statistical test. It uses the data to calculate a test statistic, which is then compared to a critical value. The critical value is based on the distribution of the test statistic when the null hypothesis is true.\nIf the test statistic is larger than the critical value, the null hypothesis is rejected. This means that there is evidence against the null hypothesis. In this case, you would fail to reject the null hypothesis if the test statistic is smaller than the critical value.\nSOLUTION: The purpose of \"augmenting\" the Dickey-Fuller test regression is to ensure that all of the non-stationarity is taken into account.\nThe unaugmented test uses the difference between the time series and a constant to calculate the test statistic. This constant is called a dummy variable or a constant term.\nThe augmented test uses the difference between the time series and its fitted trend to calculate the test statistic. The fitted trend is a polynomial term up to and including the first difference.\nThe augmented test accounts for both the level and the trend in the time series. The unaugmented test accounts for the level, but not the trend."}
{"question": "If a series, y, follows a random walk with drift b, what is the optimal one-step ahead forecast of the change in y?", "choices": [{"label": "A", "text": "The current value of y"}, {"label": "B", "text": "Zero"}, {"label": "C", "text": "One"}, {"label": "D", "text": "The average value of the change in y over the in-sample period"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following are plausible approaches to dealing with a model that exhibits heteroscedasticity?\n\ni) Take logarithms of each of the variables\n\nii) Use suitably modified standard errors\n\niii) Use a generalised least squares procedure\n\niv) Add lagged values of the variables to the regression equation.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: Heteroscedasticity occurs when the variance of the residuals is not constant. This means that the error terms in your regression model have different variances. When this happens, the standard errors and t-ratios of your regression coefficients will be incorrect.\nTo deal with heteroscedasticity, you can use one of the following approaches:\nUse suitably modified standard errors: This approach involves changing the way the standard errors are calculated to take into account the heteroscedasticity.\nUse a generalized least squares procedure: This approach involves regressing the dependent variable on the independent variable and a square of the independent variable. This will help to reduce the impact of the heteroscedasticity.\nThe first approach is the most conservative but is also the most straightforward. The second approach can be more powerful, but it is also more complex."}
{"question": "Which of the following statements are true concerning the standardised residuals (residuals divided by their respective conditional standard deviations) from an estimated GARCH model?\n\ni) They are assumed to be normally distributed\n\n\nii) Their squares will be related to their lagged squared values if the GARCH model is\n\nappropriate\n\n\niii) In practice, they are likely to have fat tails\n\n\niv) If the GARCH model is adequate, the standardised residuals and the raw residuals\n\nwill be identical", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: Normality, independence, and equal variance are important assumptions of many statistical tests. If an analysis assumes a certain distribution, independence, or equal variance, and these assumptions are violated, the results of the analysis may be inaccurate.\nA violation of the normality assumption may affect the results of a statistical test in the following ways:\nThe distribution of the data is not normal.\nThe data are normally distributed.\nThe shape of the distribution may affect the results of the test.\nA violation of the independence assumption may affect the results of a statistical test in the following ways:\nThe data are not independent.\nThe data are independent.\nThe dependence between the data may affect the results of the test.\nA violation of the equal variance assumption may affect the results of a statistical test in the following ways:\nThe data are not equally volatile.\nThe data are equally volatile.\nThe variance of the data may affect the results of the test.\nSOLUTION: The following statements are true concerning the standardised residuals from an estimated GARCH model:\nThey are assumed to be normally distributed.\nTheir squares will be related to their lagged squared values if the GARCH model is appropriate.\nIn practice, they are likely to have fat tails.\nIf the GARCH model is adequate, the standardised residuals and the raw residuals will be identical."}
{"question": "Which one of the following statements is true concerning VARs?", "choices": [{"label": "A", "text": "The coefficient estimates have intuitive theoretical interpretations"}, {"label": "B", "text": "The coefficient estimates usually have the same sign for all of the lags of a given variable in a given equation"}, {"label": "C", "text": "VARs often produce better forecasts than simultaneous equation structural models"}, {"label": "D", "text": "All of the components of a VAR must be stationary before it can be used for forecasting"}], "answerKey": "C", "model_answer": "LECTURE: A vector autoregression (VAR) is a model that shows how multiple variables change over time. A VAR can help you understand the relationships among multiple variables and can be used to make forecasts about these relationships.\nA VAR has the following components:\nequations, which describe how each variable changes.\nintercepts, which are the values of the variables when all of the lags are zero.\nlags, which are the number of times steps are moved ahead. For example, a lag of 2 means that the 3rd and 4th observations are used to calculate the 1st observation.\nA VAR is stationary when it has a constant mean and a constant conditional covariance across lags.\nA VAR is cointegrated when different types of nonstationarity cancel each other out over time.\nSOLUTION: The correct answer is D.\nA VAR must be cointegrated to be used for forecasting.\nAll of the components of a VAR must be stationary before it can be used for forecasting.\nThe coefficients in a VAR are not necessarily all positive or all negative.\nThe coefficients in a VAR do not have intuitive theoretical interpretations."}
{"question": "Which of the following statements is INCORRECT concerning the classical hypothesis testing framework?", "choices": [{"label": "A", "text": "If the null hypothesis is rejected, the alternative is accepted"}, {"label": "B", "text": "The null hypothesis is the statement being tested while the alternative encompasses the remaining outcomes of interest"}, {"label": "C", "text": "The test of significance and confidence interval approaches will always give the same conclusions"}, {"label": "D", "text": "Hypothesis tests are used to make inferences about the population parameters."}], "answerKey": "A", "model_answer": "LECTURE: The classical hypothesis testing framework is a set of steps used to make inferences about population parameters based on a sample.\nStep 1: Formulate a null hypothesis and an alternative hypothesis. The null hypothesis is usually a claim about the population parameter, and the alternative hypothesis is usually a claim about the population parameter that is opposite to the null hypothesis.\nStep 2: Set up the test of significance. The test of significance compares the sample evidence to the null hypothesis. The null hypothesis is rejected if the sample evidence is unlikely to have occurred by chance.\nStep 3: Calculate the confidence interval. The confidence interval is a range of values that is likely to include the true population parameter. The confidence level indicates the proportion of similar calculations that would produce a confidence interval that includes the true population parameter. For example, a 95% confidence level means that 95% of the calculations would produce a confidence interval that includes the true population parameter."}
{"question": "An ARMA(p,q) (p, q are integers bigger than zero) model will have", "choices": [{"label": "A", "text": "An acf and pacf that both decline geometrically"}, {"label": "B", "text": "An acf that declines geometrically and a pacf that is zero after p lags"}, {"label": "C", "text": "An acf that declines geometrically and a pacf that is zero after q lags"}, {"label": "D", "text": "An acf that is zero after p lags and a pacf that is zero after q lags"}], "answerKey": "A", "model_answer": "LECTURE: A time series is a sequence of data points, taken at successive time intervals. Many time series are not random variables, but instead represent a measurement made at each time interval.\nAn autoregressive moving average (ARMA) model is a statistical model that describes a time series. An ARMA model has two parts: a static part, which is an autoregressive (AR) model, and a dynamic part, which is a moving average (MA) model.\nThe static part of an ARMA model specifies that the time series is a linear combination of its own lags. The static part of an ARMA model is specified by two parameters: p, which is the number of autoregressive terms, and q, which is the number of moving average terms.\nThe dynamic part of an ARMA model specifies that the time series is a linear combination of its own lagged values and a white noise signal. The dynamic part of an ARMA model is specified by two parameters: p, which is the number of autoregressive terms, and q, which is the number of moving average terms.\nA time series is said to have an ARMA model of order (p, q) if it has a static part that is an AR model of order p and a dynamic part that is an MA model of order q.\nSOLUTION: A time series has an ARMA(p,q) model if it has an AR part and an MA part, where the AR part is of order p and the MA part is of order q.\nThe autocorrelation function (ACF) of a time series is the correlation of the time series with a lagged version of itself. The partial autocorrelation function (PACF) of a time series is the correlation of the time series with a lagged version of itself, after removing the effects of the earlier lags.\nIf a time series has an ARMA(p,q) model, then its ACF will decline geometrically, and its PACF will be zero after q lags.\nSo, the acf will decline geometrically and the pacf will be zero after q lags."}
{"question": "Suppose that the following regression is estimated using 27 quarterly observations:\n\n$y_t = \\beta_1 + \\beta_2 x_2 + \\beta_3 x_{3t} + u_t$\n\nWhat is the appropriate critical value for a 2-sided 5% size of test of $H_0: \\beta_3 = 1$?", "choices": [{"label": "A", "text": "1.64"}, {"label": "B", "text": "1.71"}, {"label": "C", "text": "2.06"}, {"label": "D", "text": "1.96"}], "answerKey": "C", "model_answer": "LECTURE: For a 2-sided test, the critical values are determined by whether the test is one-tailed or two-tailed.\nA one-tailed test has one critical value. The critical value is determined by the specified hypothesis.\nIf \u03b23 is the hypothesized value, the critical value is \u03b23.\nIf \u03b23 is not the hypothesized value, the critical value is the absolute value of \u03b23.\nA two-tailed test has two critical values. The critical values are determined by the specified hypothesis.\nIf \u03b23 is not equal to 1, the critical values are \u03b21 and \u03b22.\nIf \u03b23 is equal to 1, the critical values are 1 and \u03b22.\nSOLUTION: The test is two-tailed. The critical values are \u03b21 and \u03b22.\nThe appropriate critical value is 1.96."}
{"question": "Suppose that two researchers, using the same 3 variables and the same 250 observations on each variable, estimate a VAR. One estimates a VAR(6), while the other estimates a VAR(4). The determinants of the variance-covariance matrices of the residuals for each VAR are 0.0036 and 0.0049 respectively. What is the values of the test statistic for performing a test of whether the VAR(6) can be restricted to a VAR(4)?", "choices": [{"label": "A", "text": "77.07"}, {"label": "B", "text": "0.31"}, {"label": "C", "text": "0.33"}, {"label": "D", "text": "4.87"}], "answerKey": "A", "model_answer": "LECTURE: When estimating a vector error-correction model (VECM) or a vector autoregressive model (VAR), the residuals from the model will have a certain variance-covariance matrix. The determinants of this matrix are equal to the sum of the squared correlations.\nThe determinants of the variance-covariance matrices for the VAR(6) and VAR(4) models are 0.0036 and 0.0049, respectively. This means that the VAR(6) model has a slightly larger determinant than the VAR(4) model, and the two models are not equal.\nSOLUTION: To test whether the VAR(6) can be restricted to a VAR(4), you can use the following test statistic:\nThe test statistic has a t-distribution with 250-6=244 degrees of freedom. The values of the test statistic for both models are:\nFor the VAR(6) model, the test statistic is 77.07.\nFor the VAR(4) model, the test statistic is 0.31.\nSince the VAR(6) model has a larger test statistic, you would reject the null hypothesis that the VAR(6) model is equal to the VAR(4) model."}
{"question": "Which of the following is a DISADVANTAGE of using pure time-series models (relative to structural models)?", "choices": [{"label": "A", "text": "They are not theoretically motivated"}, {"label": "B", "text": "They cannot produce forecasts easily"}, {"label": "C", "text": "They cannot be used for very high frequency data"}, {"label": "D", "text": "It is difficult to determine the appropriate explanatory variables for use in pure time-series models"}], "answerKey": "A", "model_answer": "LECTURE: One way to evaluate the performance of an economic model is to compare its predictions to actual outcomes. For example, if a model predicts that the unemployment rate will be 6% next year, and the actual rate is 5%, the model's prediction is more accurate than the actual rate.\nHowever, comparing predictions to actual outcomes is not always possible, because the actual outcomes are not known until later. In this case, you can use alternative methods to evaluate a model.\nFor example, you can compare the predictions of different models to each other. If one model's predictions are more accurate than another model's predictions, the first model is to be preferred.\nAnother way to evaluate a model is to examine its underlying assumptions. If a model assumptions are more realistic than another model's assumptions, the first model is to be preferred."}
{"question": "Which of the following are alternative names for the dependent variable (usually denoted by y) in linear regression analysis?\n\n(i) The regressand\n\n(ii) The regressor\n\n(iii) The explained variable\n\n(iv) The explanatory variable", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: In linear regression analysis, the relationship between the dependent variable and the independent variable is studied. In this relationship, one variable is considered the dependent variable, or the variable you want to explain. The other variable is considered the independent variable, or the variable that can explain the dependent variable.\nWhen you fit a linear regression model, the dependent variable is usually denoted by y. The independent variable is usually denoted by x.\nSOLUTION: The dependent variable is the explained variable. The independent variable is the explanatory variable."}
{"question": "Which of the following are advantages of the VAR approach to modelling the relationship between variables relative to the estimation of full structural models?\n\ni) VARs receive strong motivation from financial and economic theory\n\n\nii) VARs in their reduced forms can be used easily to produce time-series forecasts\n\n\niii) VAR models are typically highly parsimonious\n\n\niv) OLS can be applied separately to each equation in a reduced form VAR", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "LECTURE: One of the advantages of the VAR approach to modeling the relationship between variables relative to the estimation of full structural models is that VAR models are typically highly parsimonious. This means that VAR models have fewer variables than do full structural models.\nBecause VAR models have fewer variables, they are simpler and can be estimated more quickly than full structural models. In addition, the reduced form of a VAR model can be used easily to produce time-series forecasts.\nHowever, there are also some disadvantages to the VAR approach. One disadvantage is that VAR models receive less motivation from financial and economic theory than do full structural models.\nAnother disadvantage is that VAR models may not be as flexible as full structural models. For example, VAR models assume that the variables have a linear relationship with each other. This may not be the case in practice.\nSOLUTION: To determine which of the choices is the most accurate, use the information in the passage to decide which of the advantages of the VAR approach are true.\nThe passage explains that one advantage of the VAR approach is that VAR models are typically highly parsimonious. This means that VAR models have fewer variables than do full structural models.\nThe passage also explains that one advantage of the VAR approach is that the reduced form of a VAR model can be used easily to produce time-series forecasts.\nThe other choices are not proven in the passage."}
{"question": "Which of the following statements is TRUE concerning the standard regression model?", "choices": [{"label": "A", "text": "y has a probability distribution"}, {"label": "B", "text": "x has a probability distribution"}, {"label": "C", "text": "The disturbance term is assumed to be correlated with x"}, {"label": "D", "text": "For an adequate model, the residual (u-hat) will be zero for all sample data points"}], "answerKey": "A", "model_answer": ""}
{"question": "Consider the following model for $y_t$:\n\n$y_t = \\mu + \\lambda t + u_t$\n\nWhich one of the following most accurately describes the process for $y_t$?", "choices": [{"label": "A", "text": "A unit root process"}, {"label": "B", "text": "A stationary process"}, {"label": "C", "text": "A deterministic trend process"}, {"label": "D", "text": "A random walk with drift"}], "answerKey": "C", "model_answer": "LECTURE: A stationary process is a process with a constant mean and a constant variance.\nA unit root process is a process with a mean that is not constant.\nA deterministic trend process is a process with a mean that is constantly changing.\nA random walk with drift is a process with a mean that is not zero and is constantly changing.\nSOLUTION: The model $y_t = \\mu + \\lambda t + u_t$ has a deterministic trend component, but not a random walk with drift. The coefficient $\\lambda t$ indicates that the mean of the process is constantly changing, but the mean is not randomly changing."}
{"question": "Which of the following is correct concerning logit and probit models?", "choices": [{"label": "A", "text": "They use a different method of transforming the model so that the probabilities lie between zero and one"}, {"label": "B", "text": "The logit model can result in too many observations falling at exactly zero or exactly one"}, {"label": "C", "text": "For the logit model, the marginal effect of a change in one of the explanatory variables is simply the estimate of the parameter attached to that variable, whereas this is not the case for the probit model"}, {"label": "D", "text": "The probit model is based on a cumulative logistic function"}], "answerKey": "A", "model_answer": ""}
{"question": "What is the most important disadvantage of the diagonal VECH approach to building multivariate GARCH models that is overcome by the BEKK formulation?", "choices": [{"label": "A", "text": "The diagonal VECH model is hard to interpret intuitively"}, {"label": "B", "text": "The diagonal VECH model contains too many parameters"}, {"label": "C", "text": "The diagonal VECH model does not ensure a positive-definite variance-covariance matrix"}, {"label": "D", "text": "The BEKK model reduces the dimensionality problem that arises when a number of series are modelled together."}], "answerKey": "C", "model_answer": "LECTURE: When building a multivariate GARCH model, one important consideration is the choice of the variance-covariance matrix. A diagonal matrix is often used, where each off-diagonal element is equal to zero. This is the VECH approach. However, this approach has some disadvantages.\nThe most important disadvantage of the diagonal VECH approach is that it does not ensure a positive-definite variance-covariance matrix. A positive-definite matrix has all positive eigenvalues, which is important for the statistical properties of the GARCH model.\nThe BEKK formulation overcomes the diagonal VECH disadvantage by using a block diagonal matrix, where each off-diagonal element is equal to zero. This approach ensures a positive-definite variance-covariance matrix and reduces the dimensionality problem that arises when a number of series are modelled together."}
{"question": "If a relevant variable is omitted from a regression equation, the consequences would be that:\n\ni) The standard errors would be biased\n\n\nii) If the excluded variable is uncorrelated with all of the included variables, all of\n\nthe slope coefficients will be inconsistent.\n\n\niii) If the excluded variable is uncorrelated with all of the included variables, the\n\nintercept coefficient will be inconsistent.\n\n\niv) If the excluded variable is uncorrelated with all of the included variables, all of\n\nthe slope and intercept coefficients will be consistent and unbiased but inefficient.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: If a relevant variable is omitted from a regression equation, the consequences are that the estimates of the slope and intercept coefficients will be biased.\nThe bias in the estimate of the slope coefficient will cause the predicted value of the dependent variable to be too high.\nThe bias in the estimate of the intercept coefficient will cause the predicted value of the dependent variable to be too low.\nIf all of the included variables are correlated with the omitted variable, the estimates of the slope and intercept coefficients will be inconsistent.\nThe inconsistency in the estimate of the slope coefficient will cause the predicted value of the dependent variable to be too high.\nThe inconsistency in the estimate of the intercept coefficient will cause the predicted value of the dependent variable to be too low.\nIf the omitted variable is a confounding variable, the estimates of the slope and intercept coefficients will be consistent and unbiased but inefficient.\nAn inefficient estimate of the slope coefficient will cause the predicted value of the dependent variable to be too high.\nAn inefficient estimate of the intercept coefficient will cause the predicted value of the dependent variable to be too low.\nIf the omitted variable is correlated with the included variables, the standard errors of the estimates of the slope and intercept coefficients will be biased.\nAn underestimate of the standard error will cause the confidence interval for the coefficient estimate to be too narrow.\nSOLUTION: If a relevant variable is omitted from a regression equation, the consequences are that the estimates of the slope and intercept coefficients will be biased.\nIf the excluded variable is uncorrelated with all of the included variables, the estimates of the slope and intercept coefficients will be consistent and unbiased but inefficient.\nIf the excluded variable is correlated with the included variables, the standard errors of the estimates of the slope and intercept coefficients will be biased."}
{"question": "Which of the following are alternative names for the independent variable (usually denoted by x) in linear regression analysis?\n\n(i) The regressor\n\n(ii) The regressand\n\n(iii) The causal variable\n\n(iv) The effect variable", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: In linear regression analysis, the independent variable is usually denoted by x. The following are alternative names for the independent variable in linear regression analysis:\nThe regressor: This is the variable that is \"pushed\" in linear regression.\nThe dependent variable: This is the variable that is \"pulled\" in linear regression.\nThe causal variable: This is the variable that is thought to cause changes in the dependent variable.\nThe effect variable: This is the variable that is thought to be affected by changes in the causal variable.\nSOLUTION: The correct choice is D."}
{"question": "Consider the OLS estimator for the standard error of the slope coefficient. Which of the following statement(s) is (are) true?\n\n(i) The standard error will be positively related to the residual variance\n\n(ii) The standard error will be negatively related to the dispersion of the observations on the explanatory variable about their mean value\n\n(iii) The standard error will be negatively related to the sample size\n\n(iv) The standard error gives a measure of the precision of the coefficient estimate.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "LECTURE: The standard error of the slope coefficient estimates the precision of the coefficient estimate. The standard error decreases with higher residual variance, lower dispersion of the observations about the mean value of the explanatory variable, and larger sample size.\nSOLUTION: The OLS estimator for the standard error of the slope coefficient is given by the formula:\nStandard error = \u03c3 / \u221an\nWhere \u03c3 is the standard deviation of the residuals and n is the sample size.\nThe standard error will be positively related to the residual variance and negatively related to the dispersion of the observations on the explanatory variable about their mean value.\nThe standard error will be negatively related to the sample size."}
{"question": "What is the meaning of the term \"heteroscedasticity\"?", "choices": [{"label": "A", "text": "The variance of the errors is not constant"}, {"label": "B", "text": "The variance of the dependent variable is not constant"}, {"label": "C", "text": "The errors are not linearly independent of one another"}, {"label": "D", "text": "The errors have non-zero mean"}], "answerKey": "A", "model_answer": "LECTURE: The mean of a set of numbers is the sum of the numbers divided by the number of numbers.\nThe variance of a set of numbers is the average of the squared differences from the mean.\nIf each number in a set of numbers is known, then the variance is calculated as follows:\nFirst, calculate the mean of the numbers. Then, for each number, calculate the difference from the mean. Square each of these differences. Then, add up all of the squared differences. Finally, divide the sum by the number of numbers.\nVariance = (1/N) \u2211(xi - mean)2\nIf one or more of the numbers in a set of numbers is unknown, then the variance is estimated as follows:\nFirst, calculate the mean of the numbers that are known. Then, for each number, calculate the difference from the mean. Square each of these differences. Then, add up all of the squared differences. Finally, divide the sum by the number of numbers that are known.\nVariance = (1/n) \u2211(xi - mean)2\nSOLUTION: The correct answer is A.\nThe variance of the errors is not constant.\nThe variance of the dependent variable is not constant."}
{"question": "If a Durbin Watson statistic takes a value close to zero, what will be the value of the first order autocorrelation coefficient?", "choices": [{"label": "A", "text": "Close to zero"}, {"label": "B", "text": "Close to plus one"}, {"label": "C", "text": "Close to minus one"}, {"label": "D", "text": "Close to either minus one or plus one"}], "answerKey": "C", "model_answer": ""}
{"question": "Under the null hypothesis of a Bera-Jarque test, the distribution has", "choices": [{"label": "A", "text": "Zero skewness and zero kurtosis"}, {"label": "B", "text": "Zero skewness and a kurtosis of three"}, {"label": "C", "text": "Skewness of one and zero kurtosis"}, {"label": "D", "text": "Skewness of one and kurtosis of three."}], "answerKey": "B", "model_answer": "LECTURE: The Bera-Jarque test is a version of the Jarque-Bera test for normality that has a simple correction for sample size. The null hypothesis of the test is that the population is normally distributed.\nIf the test statistic is less than the critical value, the null hypothesis is rejected. The data is considered to be normally distributed.\nIf the test statistic is greater than or equal to the critical value, the null hypothesis is not rejected. The data is considered to be normally distributed.\nThe test statistic is a function of the sample mean and the sample skewness and kurtosis. The critical value is a function of the sample size and the population's standard deviation and skewness and kurtosis.\nThe formulas for the test statistic and critical value are:\nThe test statistic:\nThe critical value:\nThe sample size is denoted by n. The population standard deviation is denoted by \u03c3. The population skewness is denoted by \u03b3. The population kurtosis is denoted by \u03b2.\nBoth the test statistic and the critical value are functions of the sample data. If the sample data are different from the population data, the test statistic and critical value will be different from their population values.\nSOLUTION: The correct answer is C.\nThe Bera-Jarque test assumes that the population is normally distributed. If the population has a skewness of one and a kurtosis of three, the null hypothesis of the Bera-Jarque test is that the distribution has a skewness of one and a kurtosis of three.\nThe other answer choices are not necessarily true. A distribution with zero skewness and zero kurtosis is a normal distribution. A distribution with skewness of one and kurtosis of three is a distribution that is not normal."}
{"question": "If an estimator is said to be consistent, it is implied that", "choices": [{"label": "A", "text": "On average, the estimated coefficient values will equal the true values"}, {"label": "B", "text": "The OLS estimator is unbiased and no other unbiased estimator has a smaller variance"}, {"label": "C", "text": "The estimates will converge upon the true values as the sample size increases"}, {"label": "D", "text": "The coefficient estimates will be as close to their true values as possible for small and large samples."}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following is a typical characteristic of financial asset return time-series?", "choices": [{"label": "A", "text": "Their distributions are thin-tailed"}, {"label": "B", "text": "They are not weakly stationary"}, {"label": "C", "text": "They are highly autocorrelated"}, {"label": "D", "text": "They have no trend"}], "answerKey": "D", "model_answer": "LECTURE: Financial asset return time-series are a series of returns, or rates of change in asset prices, over time. Financial assets are things that you buy and sell\u2014such as stocks and bonds.\nA financial asset return time-series is a set of returns that are ordered by the time at which they occur. For each asset, the return series starts with the first return at time t = 0 and continues for as many periods as the asset has been around.\nA financial asset can have different patterns in its return time-series. Some common patterns include:\nA trend, which is a persistent change in the average return.\nSeasonality, which is a pattern of returns that repeats about every 12 months.\nSOLUTION: A financial asset return time-series is not weakly stationary if it has a trend or a seasonal pattern.\nA financial asset return time-series has a trend if the average return is changing over time. For example, the return series for a stock may consist of a rising trend from the first few observations to the most recent ones.\nA financial asset return time-series is seasonal if the pattern of returns repeats about every 12 months. For example, a bond's return series may have a seasonal pattern of high returns in the spring and summer and low returns in the winter and fall.\nA financial asset return time-series is weakly stationary if it is mean-reverting. A series is mean-reverting if its mean keeps changing but returns to its long-term average. For example, a stock's return series may have a mean-reverting pattern, with returns that get smaller over time.\nA financial asset return time-series has no trend if its average return is not changing over time.\nA financial asset return time-series is thin-tailed if it has infrequent extreme returns. A return series with thin tails has only a few observations that fall outside the range of its typical returns.\nA financial asset return time-series is highly autocorrelated if its current return is strongly influenced by its past returns. A return series with high autocorrelation tells you much of its past behavior."}
{"question": "Which of the following assumptions are required to show the consistency, unbiasedness and efficiency of the OLS estimator?\n\ni) $E(u_t) = 0$\n\n\nii) $\\text{Var}(u_t) = \\sigma^2$\n\n\niii) $\\text{Cov}(u_t, u_{t-j}) = 0 \\forall j$\n\n\niv) $u_t \\sim N(0, \\sigma^2)$", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following is a disadvantage of the fixed effects approach to estimating a panel model?", "choices": [{"label": "A", "text": "The model is likely to be technical to estimate"}, {"label": "B", "text": "The approach may not be valid if the composite error term is correlated with one or more of the explanatory variables"}, {"label": "C", "text": "The number of parameters to estimate may be large, resulting in a loss of degrees of freedom"}, {"label": "D", "text": "The fixed effects approach can only capture cross-sectional heterogeneity and not temporal variation in the dependent variable."}], "answerKey": "C", "model_answer": "LECTURE: In a panel data model, each observation is a panel, or a set of data for a specific unit over time. Panel data models are used when you have information on multiple observations for the same unit.\nOne approach to modeling panel data is the fixed effects approach. With this approach, the model includes a fixed effect for each unit. The fixed effect is a constant term that is added to the model to account for differences between the units.\nThe fixed effects approach can only capture cross-sectional heterogeneity and not temporal variation in the dependent variable.\nCross-sectional heterogeneity refers to the differences between units that are observed at a specific point in time.\nTemporal variation in the dependent variable refers to the changes in the dependent variable that occur over time.\nSOLUTION: The fixed effects approach may not be valid if the composite error term is correlated with one or more of the explanatory variables. If the composite error term is correlated with one or more of the explanatory variables, the approach may not fully capture the variation in the dependent variable."}
{"question": "Consider an identical situation to that of question 21, except that now a 2-sided alternative is used. What would now be the appropriate conclusion?", "choices": [{"label": "A", "text": "H0 is rejected"}, {"label": "B", "text": "H0 is not rejected"}, {"label": "C", "text": "H1 is rejected"}, {"label": "D", "text": "There is insufficient information given in the question to reach a conclusion"}], "answerKey": "A", "model_answer": "LECTURE: In a hypothesis test, the conclusion is reached in one of two ways:\nH0 is rejected. This means that the evidence has convinced you that the hypothesis is not true. You would decide to do something different or not do something that you were going to do.\nH0 is not rejected. This means that the evidence is not strong enough to convince you that the hypothesis is not true. You will do something as planned.\nIf the test has insufficient information to reach a conclusion, you cannot say whether H0 is true or false.\nSOLUTION: The alternative homoscedastic test is used when the data are not equally spread out. This test is a two-sided test.\nThe conclusion is reached when the evidence is convincing. If the evidence is very convincing, the null hypothesis is rejected. If the evidence is not very convincing, the null hypothesis is not rejected.\nThere is insufficient information given in the question to reach a conclusion. You cannot say whether the null hypothesis is true or false."}
{"question": "The price of a house is best described as what type of number?", "choices": [{"label": "A", "text": "Discrete"}, {"label": "B", "text": "Cardinal"}, {"label": "C", "text": "Ordinal"}, {"label": "D", "text": "Nominal"}], "answerKey": "B", "model_answer": "LECTURE: Numbers can be classified by their properties.\nThe properties of numbers are:\nDiscrete: A discrete number is one that can be counted. The numbers we write with integers are discrete.\nCardinal: A cardinal number is one that can be placed in order by comparing the numbers. The numbers we write with real numbers are cardinal.\nOrdinal: An ordinal number is one that tells you the order of a set of things. The numbers we write with ordinal numbers are ordinal.\nNominal: A nominal number is one that has a meaning that is the same every year. The numbers we write with calendar numbers are nominal.\nSOLUTION: The price of a house is best described as a nominal number. The price of a house has a meaning that is the same every year."}
{"question": "If a Johansen \"trace\" test for a null hypothesis of 2 cointegrating vectors is applied to a system containing 4 variables is conducted, which eigenvalues would be used in the test?", "choices": [{"label": "A", "text": "All of them"}, {"label": "B", "text": "The largest 2"}, {"label": "C", "text": "The smallest 2"}, {"label": "D", "text": "The second largest"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following statements is true concerning variance decomposition analysis of VARs?\n\ni) Variance decompositions measure the impact of a unit shock to each of the variables on the VAR\n\nii) Variance decompositions can be thought of as measuring the proportion of the forecast error variance that is attributable to each variable\n\niii) The ordering of the variables is important for calculating impulse responses but not variance decompositions\n\niv) It is usual that most of the forecast error variance for a given variable is attributable to shocks to that variable", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": ""}
{"question": "Suppose that we have estimated a GARCH model for daily equity returns, and we are interested in producing a 10-day forecast of the volatility (measured by the standard deviation of returns) for use in a value at risk model. How could such a forecast most validly be calculated?", "choices": [{"label": "A", "text": "Produce 1, 2, 3, ..., 10 step ahead conditional variance forecasts and add them up"}, {"label": "B", "text": "Produce 1, 2, 3, ..., 10 step ahead conditional variance forecasts and add them up and take the square root"}, {"label": "C", "text": "Produce 1, 2, 3, ..., 10 step ahead conditional variance forecasts, take the square roots of each one and add them up"}, {"label": "D", "text": "Produce a 1-step ahead conditional variance forecast, take its square root and multiply it by the square root of 10"}], "answerKey": "B", "model_answer": ""}
{"question": "Suppose that the value of $R^2$ for an estimated regression model is exactly zero. Which of the following are true?\n\ni) All coefficient estimates on the slopes will be zero\n\nii) The fitted line will be horizontal with respect to all of the explanatory variables\n\niii) The regression line has not explained any of the variability of y about its mean value\n\niv) The intercept coefficient estimate must be zero.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
{"question": "A white noise process will have\n\n(i) A zero mean\n\n(ii) A constant variance\n\n(iii) Autocovariances that are constant\n\n(iv) Autocovariances that are zero except at lag zero", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following statements are true concerning the Box-Jenkins approach to diagnostic testing for ARMA models?\n\n(i) The tests will show whether the identified model is either too large or too small\n\n(ii) The tests involve checking the model residuals for autocorrelation, heteroscedasticity, and non-normality\n\n(iii) If the model suggested at the identification stage is appropriate, the acf and pacf for the residuals should show no additional structure\n\n(iv) If the model suggested at the identification stage is appropriate, the coefficients on the additional variables under the overfitting approach will be statistically insignificant", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "LECTURE: When diagnosing a model, you may want to use the Box-Jenkins approach to check whether the identified model is appropriate. The Box-Jenkins approach uses four diagnostic tests:\n1. The autocorrelation function (ACF) and partial autocorrelation function (PACF) of the residuals are checked for additional structure.\n2. The ACF and PACF of the residuals are checked for significant lag values.\n3. The residuals are checked for heteroscedasticity.\n4. The normality of the residuals is checked.\nIf any of the four tests indicate a problem, the model may need to be revised.\nSOLUTION: Look at each statement and decide if it is true.\n1. The tests will show whether the identified model is either too large or too small.\nThis statement is true. The ACF and PACF of the residuals can help you determine whether the identified model is either too large or too small.\n2. The tests involve checking the model residuals for autocorrelation, heteroscedasticity, and non-normality.\nThis statement is true. The ACF and PACF of the residuals can be used to check for autocorrelation and heteroscedasticity, and the normality of the residuals can be checked.\n3. If the model suggested at the identification stage is appropriate, the acf and pacf for the residuals should show no additional structure.\nThis statement is true. If the model is appropriate, the ACF and PACF of the residuals should not show any additional structure.\n4. If the model suggested at the identification stage is appropriate, the coefficients on the additional variables under the overfitting approach will be statistically insignificant.\nThis statement is true. If the model is appropriate, the coefficients on the additional variables under the overfitting approach will be statistically insignificant."}
{"question": "Which one of the following would be a plausible response to a finding of residual non-normality?", "choices": [{"label": "A", "text": "Use a logarithmic functional form instead of a linear one"}, {"label": "B", "text": "Add lags of the variables on the right hand side of the regression model"}, {"label": "C", "text": "Estimate the model in first differenced form"}, {"label": "D", "text": "Remove any large outliers from the data."}], "answerKey": "D", "model_answer": ""}
{"question": "The fixed effects panel model is also sometimes known as", "choices": [{"label": "A", "text": "A seemingly unrelated regression model"}, {"label": "B", "text": "The least squares dummy variables approach"}, {"label": "C", "text": "The random effects model"}, {"label": "D", "text": "Heteroscedasticity and autocorrelation consistent"}], "answerKey": "B", "model_answer": "LECTURE: Fixed effects panel data models are used when both variables in the analysis are observed over time for a panel of units. Many models are available to estimate the parameters of interest in these models.\nThe fixed effects panel model is also sometimes known as the random effects model. In this model, the fixed effects are estimated along with the parameters of interest. The fixed effects are used to compare the units with different values of the other variables in the model.\nThe fixed effects estimate the difference between units with different values of the unobserved coefficients. This difference is subtracted from the difference in the observed variables to estimate the parameters of interest.\nThe least squares dummy variables approach is a special case of the fixed effects panel model with only one fixed effect. In this case, the fixed effect is estimated along with the parameters of interest. The fixed effect is used to compare units with different values of the variable represented by the dummy variable.\nHeteroskedasticity and autocorrelation consistent is a property of some estimators in fixed effects panel data models. Heteroskedasticity refers to the lack of constant variance of the errors. Autocorrelation refers to the correlation of the errors with their own values.\nSOLUTION: The fixed effects panel model is also sometimes known as the random effects model. In this model, the fixed effects are estimated along with the parameters of interest. The fixed effects are used to compare units with different values of the other variables in the model.\nThe least squares dummy variables approach is a special case of the fixed effects panel model with only one fixed effect. In this case, the fixed effect is estimated along with the parameters of interest. The fixed effect is used to compare units with different values of the variable represented by the dummy variable."}
{"question": "Which of the following statements is TRUE concerning OLS estimation?", "choices": [{"label": "A", "text": "OLS minimises the sum of the vertical distances from the points to the line"}, {"label": "B", "text": "OLS minimises the sum of the squares of the vertical distances from the points to the line"}, {"label": "C", "text": "OLS minimises the sum of the horizontal distances from the points to the line"}, {"label": "D", "text": "OLS minimises the sum of the squares of the horizontal distances from the points to the line."}], "answerKey": "B", "model_answer": "LECTURE: One of the key features of a line is its slope, which determines how steep the line is. If the slope is positive, the line is steeper as you move to the right. If the slope is negative, the line is steeper as you move up.\nThink about what it means for a line to minimise the sum of the squares of the vertical distances from the points to the line. This is the same as saying that the line is perpendicular to the floor. So, the line will have a slope of 1.\nNow consider what it means for a line to minimise the sum of the horizontal distances from the points to the line. This is the same as saying that the line is parallel to the floor. So, the line will have a slope of 0."}
{"question": "If the standard tools for time-series analysis, such as estimation of the acf, pacf and spectral analysis, find no evidence of structure in the data, this implies that the data are which of the following?", "choices": [{"label": "A", "text": "Normally distributed"}, {"label": "B", "text": "Uncorrelated"}, {"label": "C", "text": "Independent"}, {"label": "D", "text": "Fat-tailed"}], "answerKey": "B", "model_answer": "LECTURE: Time-series data are data that are measured or observed over time. Many real-world data are observed over time, and they often exhibit the following features:\nThe data have a temporal pattern.\nThe data have a secular trend.\nThe data have seasonal patterns.\nThe data have irregular fluctuations.\nTime-series analysis is a set of statistical methods that can be used to analyze data with these features.\nThe standard tools for time-series analysis include the following:\nThe autocorrelation function (acf) is a measure of the correlation between a time series and its past values. The acf has a units of correlation and a units of time. The acf is zero for uncorrelated time series.\nThe partial autocorrelation function (pacf) is a measure of the correlation between a time series and its past values, after removing the effect of intermediate lags. The pacf has a units of correlation and a units of time. The pacf is zero for uncorrelated time series.\nSpectral analysis involves computing the power spectrum of a time series. The power spectrum is a plot of the amplitude of each frequency in the time series. The spectral analysis can help you identify the secular trend and the periodic patterns in the data.\nIf the acf, pacf, and spectral analysis all find no evidence of structure in the data, then the data are:\nUncorrelated.\nIndependent.\nFat-tailed."}
{"question": "If two variables, $x_t$ and $y_t$ are said to be cointegrated, which of the following statements are true?\n\ni) $x_t$ and $y_t$ must both be stationary\n\n\nii) Only one linear combination of $x_t$ and $y_t$ will be stationary\n\n\niii) The cointegrating equation for $x_t$ and $y_t$ describes the short-run relationship\n\nbetween the two series\n\n\niv) The residuals of a regression of $y_t$ on $x_t$ must be stationary", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "LECTURE: Two variables are said to be cointegrated if they can be expressed as the ratio of two stationary time series. Cointegration tells you that the two variables are integrated differently: one may be a short-run average, the other a long-run average.\nA variable is stationary if it is not trending and its mean is not changing over time. A stationary time series can be written in the form:\nxt=Xt\u2212dtN(0,\u03c32)\nwhere xt is the random variable, Xt is the mean of xt, d is the differencing operator, N(0,\u03c32) is a stationary normal distribution with mean 0 and variance \u03c32, and xt\u2212dt is the past value of xt.\nIf two variables are cointegrated, they can be written in the form:\ny = Xt\u2212dt/xt\nwhere y is a stationary time series.\nThe coefficients of a regression of y on x can be used to forecast y.\nSOLUTION: If two variables are cointegrated, only one linear combination of the two variables will be stationary. So, statement ii is true.\nThe cointegrating equation for x and y describes the short-run relationship between the two series. So, statement iii is true.\nThe residuals of a regression of y on x must be stationary. So, statement iv is true."}
{"question": "A dependent variable whose values are not observable outside a certain range but where the corresponding values of the independent variables are still available would be most accurately described as what kind of variable?", "choices": [{"label": "A", "text": "Censored"}, {"label": "B", "text": "Truncated"}, {"label": "C", "text": "Multinomial variable"}, {"label": "D", "text": "Discrete choice"}], "answerKey": "A", "model_answer": "LECTURE: A variable is said to be censored if its values are not observable beyond a certain range. Censored variables are caused by observing only a certain range of a variable's values. For example, a thermometer can measure a person's temperature, but the temperature cannot be measured if the person is dead. So, the variable temperature is censored at death.\nA variable is said to be truncated if its values are not observable below a certain range. Truncated variables are caused by observing values only from a certain range on. For example, if an income variable is truncated at $50,000, then an observer cannot observe an income less than $50,000.\nA variable is said to be discrete if it is made up of distinct values. A discrete variable can have missing values, or holes. For example, if a person's income is a discrete variable, then an observer cannot observe an income that is between two of the person's incomes.\nA variable is said to be multinomial if it is made up of distinct values that come in different levels. A multinomial variable is also called a categorical variable. For example, a person's income is a multinomial variable, because it has a set of possible values, called income levels.\nSOLUTION: The dependent variable is censored, because its values are not observable beyond a certain range. The corresponding values of the independent variables are still available, so the dependent variable is not truncated. The dependent variable is not discrete, because it has more than two values. The dependent variable is not multinomial, because it has only two possible values."}
{"question": "A Hausman test would be used for", "choices": [{"label": "A", "text": "Determining whether an equation that is part of a simultaneous system is identified"}, {"label": "B", "text": "Determining whether a simultaneous framework is needed for a particular variable"}, {"label": "C", "text": "Determining whether 2SLS or ILS is optimal"}, {"label": "D", "text": "Determining whether the structural form equations can be obtained via substitution from the reduced forms"}], "answerKey": "B", "model_answer": ""}
{"question": "Under the matrix notation for the classical linear regression model, $y = X \\beta + u$, what are the dimensions of $u$?", "choices": [{"label": "A", "text": "T x k"}, {"label": "B", "text": "T x 1"}, {"label": "C", "text": "k x 1"}, {"label": "D", "text": "1 x 1"}], "answerKey": "B", "model_answer": ""}
{"question": "How many parameters will be required to be estimated in total for all equations of a standard form, unrestricted, tri-variate VAR(4), ignoring the intercepts?", "choices": [{"label": "A", "text": "12"}, {"label": "B", "text": "4"}, {"label": "C", "text": "3"}, {"label": "D", "text": "36"}], "answerKey": "D", "model_answer": ""}
{"question": "A researcher tests for structural stability in the following regression model:\n\n$y_t = \\beta_1 + \\beta_2 x_{2t} + \\beta_3 x_{3t} + u_t$\n\nThe total sample of 200 observations is split exactly in half for the sub-sample regressions. Which would be the unrestricted residual sum of squares?", "choices": [{"label": "A", "text": "The RSS for the whole sample"}, {"label": "B", "text": "The RSS for the first sub-sample"}, {"label": "C", "text": "The RSS for the second sub-sample"}, {"label": "D", "text": "The sum of the RSS for the first and second sub-samples"}], "answerKey": "D", "model_answer": "LECTURE: The residual sum of squares is the difference between the total sum of squares and the sum of the square of the regression coefficients.\nRSS = total sum of squares - (a1^2 + a2^2 + a3^2)\nThe total sum of squares is the difference between the total sum of the dependent variable and the product of the independent variables and the regression coefficients.\ntotal sum of squares = total sum of the dependent variable - a1x1 - a2x2 - a3x3\nWhen there are multiple independent variables, the residual sum of squares can be separated into two parts: the part due to the first independent variable and the part due to the second independent variable.\nRSS = RSS for the first sub-sample + RSS for the second sub-sample\nRSS for the first sub-sample = total sum of squares for the first sub-sample - a1^2x1 - a2^2x2 - a3^2x3\nRSS for the second sub-sample = total sum of squares for the second sub-sample - a1^2x1 - a2^2x2 - a3^2x3"}
{"question": "Suppose that we are interested in testing the null hypothesis that a GARCH(2,2) model can be restricted to a process with a constant conditional variance using the likelihood ratio test approach. Which of the following statements are true?", "choices": [{"label": "A", "text": "The test statistic will follow a chi-squared distribution with 2 degrees of freedom under the null hypothesis"}, {"label": "B", "text": "The value of the log-likelihood function will almost always be bigger for the restricted model than for the unrestricted model"}, {"label": "C", "text": "If the relevant values of the log-likelihood functions are -112.3 and -118.4, the value of the test statistic is 12.2"}, {"label": "D", "text": "The likelihood ratio test compares the slopes of the log-likelihood function at the maximum and at the restricted parameter value."}], "answerKey": "C", "model_answer": "LECTURE: The likelihood ratio test is a modified version of the F-test. The null hypothesis for the likelihood ratio test is that the restricted model is true. If the test is statistically significant, then the null hypothesis is rejected in favor of the alternative hypothesis, which is that the restricted model is false.\nThe likelihood ratio test statistic is given by:\nwhere \u03bb is the value of the log-likelihood function at the restricted parameter value.\nIf the null hypothesis is rejected, then the value of the test statistic is greater than \u03bb.\nThe test statistic follows a chi-squared distribution with 1 degree of freedom.\nSOLUTION: Under the null hypothesis, the test statistic will follow a chi-squared distribution with 2 degrees of freedom.\nThe value of the log-likelihood function will almost always be bigger for the restricted model than for the unrestricted model.\nThe likelihood ratio test compares the slopes of the log-likelihood function at the maximum and at the restricted parameter value."}
{"question": "Which one of the following is NOT a plausible remedy for near multicollinearity?", "choices": [{"label": "A", "text": "Use principal components analysis"}, {"label": "B", "text": "Drop one of the collinear variables"}, {"label": "C", "text": "Use a longer run of data"}, {"label": "D", "text": "Take logarithms of each of the variables"}], "answerKey": "D", "model_answer": ""}
{"question": "Consider the following AR(2) process:\n\nyt = 1.5 yt-1 - 0.5 yt-2 + ut\n\nThis is a", "choices": [{"label": "A", "text": "Stationary process"}, {"label": "B", "text": "Unit root process"}, {"label": "C", "text": "Explosive process"}, {"label": "D", "text": "Stationary and unit root process"}], "answerKey": "B", "model_answer": "stationary process is a stochastic process with constant mean and variance.\nA unit root process is a stochastic process with a non-constant mean.\nAn explosive process is a stochastic process with a mean that grows without limits.\nA stationary and unit root process is a stochastic process with a mean that grows without limits and a non-constant mean."}
{"question": "Which of the following could be used as a test for autocorrelation up to third order?", "choices": [{"label": "A", "text": "The Durbin Watson test"}, {"label": "B", "text": "White's test"}, {"label": "C", "text": "The RESET test"}, {"label": "D", "text": "The Breusch-Godfrey test"}], "answerKey": "D", "model_answer": "LECTURE: One way to check for autocorrelation is to use a test for heteroscedasticity. Heteroscedasticity occurs when the unexplained part of the variance of the error term is not constant. This can lead to unexpected results when fitting a regression model.\nOne test for heteroscedasticity is the Breusch-Pagan test. This test compares the observed variance to the variance that would be expected if the variables were not correlated. If the observed variance is less than the expected variance, then there is evidence of heteroscedasticity.\nThe Breusch-Pagan test can be modified to test for autocorrelation up to third order. One way to do this is to use White's test. White's test is a modification of the Breusch-Pagan test that can detect autocorrelation up to a certain order.\nThe RESET test is another test for heteroscedasticity that can also detect autocorrelation up to second order.\nThe Durbin Watson test is a test for autocorrelation in the error term of a regression model. This test is based on the correlation between the error term and the dependent variable.\nThe Breusch-Godfrey test is another test for heteroscedasticity that can also detect autocorrelation in the error term of a regression model.\nSOLUTION: To test for autocorrelation up to third order, use White's test.\nThe other tests can detect autocorrelation up to a certain order, but they are not tests for autocorrelation up to third order."}
{"question": "The residual from a standard regression model is defined as", "choices": [{"label": "A", "text": "The difference between the actual value, y, and the mean, y-bar"}, {"label": "B", "text": "The difference between the fitted value, y-hat, and the mean, y-bar"}, {"label": "C", "text": "The difference between the actual value, y, and the fitted value, y-hat"}, {"label": "D", "text": "The square of the difference between the fitted value, y-hat, and the mean, y-bar"}], "answerKey": "C", "model_answer": ""}
{"question": "If OLS is applied separately to each equation that is part of a simultaneous system, the resulting estimates will be", "choices": [{"label": "A", "text": "Unbiased and consistent"}, {"label": "B", "text": "Biased but consistent"}, {"label": "C", "text": "Biased and inconsistent"}, {"label": "D", "text": "It is impossible to apply OLS to equations that are part of a simultaneous system"}], "answerKey": "C", "model_answer": ""}
{"question": "Which one of the following is NOT an example of mis-specification of functional form?", "choices": [{"label": "A", "text": "Using a linear specification when y scales as a function of the squares of x"}, {"label": "B", "text": "Using a linear specification when a double-logarithmic model would be more appropriate"}, {"label": "C", "text": "Modelling y as a function of x when in fact it scales as a function of 1/x"}, {"label": "D", "text": "Excluding a relevant variable from a linear regression model"}], "answerKey": "D", "model_answer": "LECTURE: In an attempt to identify the correct functional form for a model, it can be useful to try multiple specifications and compare the goodness of fit. For example, you may want to try a linear, a quadratic, or a logarithmic specification before deciding that a higher-order term is needed.\nMis-specification of functional form can occur when a model is specified with the wrong type of higher-order term. For example, a quadratic specification is used when a linear specification is more appropriate, or a logarithmic specification is used when a linear specification is more appropriate."}
{"question": "Suppose that we wished to evaluate the factors that affected the probability that an investor would choose an equity fund rather than a bond fund or a cash investment. Which class of model would be most appropriate?", "choices": [{"label": "A", "text": "A logit model"}, {"label": "B", "text": "A multinomial logit"}, {"label": "C", "text": "A tobit model"}, {"label": "D", "text": "An ordered logit model"}], "answerKey": "B", "model_answer": "LECTURE: A discrete choice model is a quantitative model that evaluates how the characteristics of a set of alternatives affect the choices made by an agent. In an economic setting, the agent is often a consumer, and the choices are often concerning the purchase of a goods or service.\nDiscrete choice models are used to analyze a wide range of data, including data from surveys and data on choices made among products.\nA logit model is a special case of a discrete choice model. It is used when there are two possible outcomes for an agent to choose between. The logit model is defined as follows:\nmaximize \u03c6(b0 + b1X1 + b2X2 + ... + bkXk)\nsubject to 0 = \u03c6(b0 + b1X1 + b2X2 + ... + bkXk + \u03b5)\nwhere \u03c6 is the logit function, \u03b5 is an error term, and X1, X2, ..., Xk are the variables that describe the alternatives.\nThe logit function is defined to be the inverse of the cumulative distribution function of a standard normal variable. This function has an inverse that is also a cumulative distribution function.\nThe logit function is \u03c6(z) = 1/2(1 + \u03c3(z)), where \u03c3(z) is the standard normal cumulative distribution function.\nUsing the logit function, we can write the objective function as:\nmaximize 1/2(1 + \u03c3(b0 + b1X1 + b2X2 + ... + bkXk))\nThe logit model is identified by the parameters b0, b1, b2, ..., bk.\nA multinomial logit model is a special case of a discrete choice model. It is used when an agent has to choose among three or more possible outcomes. The multinomial logit model is defined as follows:\nmaximize \u03c6(b0, b1, b2, ..., bk)\nsubject to 0 = \u03c6(b0, b1, b2, ..., bk + \u03b5)\nand 0 = b0 + b1 + b2 + ... + bk + \u03b5.\nThe multinormal logit model is identified by the parameters b0, b1, b2, ..., bk.\nAn ordered logit model is a special case of a discrete choice model. It is used when the alternatives have a natural ordering, such as \"very poor,\" \"poor,\" \"fair,\" \"good,\" and \"very good.\" The ordered logit model is defined as follows:\nmaximize \u03c6(b0 + b1X1 + b2X2 + ... + bkXk)\nsubject to 0 = \u03c6(b0 + b1X1 + b2X2 + ... + bkXk + \u03b5)\nand X1 \u2264 X2 \u2264 ... \u2264 Xk.\nThe ordered logit model is identified by the parameters b0, b1, b2, ..., bk.\nA tobit model is a special case of a mixed logit model. It is used when there are at least three possible outcomes for an agent to choose between. The tobit model is defined as follows:\nmaximize \u03c6(b0 + b1X1 + b2X2 + ... + bkXk + \u03b5)\nsubject to 0 = \u03c6(b0 + b1X1 + b2X2 + ... + bkXk + \u03b5) and X1 \u2264 X2 \u2264 ... \u2264 Xk.\nThe tobit model is identified by the parameters b0, b1, b2, ..., bk."}
{"question": "Which of the following statements will be true if the number of replications used in a Monte Carlo study is small?\n\ni) The statistic of interest may be estimated imprecisely\n\n\nii) The results may be affected by unrepresentative combinations of random draws\n\n\niii) The standard errors on the estimated quantities may be unacceptably large\n\n\niv) Variance reduction techniques can be used to reduce the standard errors", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following is a disadvantage of the random effects approach to estimating a panel model?", "choices": [{"label": "A", "text": "The approach may not be valid if the composite error term is correlated with one or more of the explanatory variables"}, {"label": "B", "text": "The number of parameters to estimate may be large, resulting in a loss of degrees of freedom"}, {"label": "C", "text": "The random effects approach can only capture cross-sectional heterogeneity and not temporal variation in the dependent variable."}, {"label": "D", "text": "All of (a) to (c) are potential disadvantages of the random effects approach."}], "answerKey": "A", "model_answer": "LECTURE: Panel data are data that include information on both cross-section and timeSeries dimensions. Panel data are collected by observing each individual or entity in a population at multiple points in time. Many social science and economic databases are organized as panel data.\nThe basic model for a panel data set is the fixed effects model, which estimates a separate fixed effect for each individual or entity in the data set. This model ignores the time dimension of the data and simply accounts for any remaining differences between individuals or entities.\nThe random effects model extends the fixed effects model by adding a random effect for each individual or entity. The random effect represents the unobservable differences between individuals or entities that are not captured by the other variables in the model. This model accounts for both within- and between-individuals variations.\nThe fixed effects model is often used when the time dimension of the data is not important. For example, if you are interested in comparing individuals or entities at the same point in time, the fixed effects model may be a good choice.\nThe random effects model is often used when the time dimension of the data is important. For example, if you are interested in comparing how individuals or entities change over time, the random effects model may be a good choice.\nSOLUTION: The random effects approach may not be valid if the composite error term is correlated with one or more of the explanatory variables. This could happen if the explanatory variables are not excluded in the estimation of the error term.\nThe number of parameters to estimate may be large, resulting in a loss of degrees of freedom. This disadvantage is not specific to the random effects approach.\nThe random effects approach can only capture cross-sectional heterogeneity and not temporal variation in the dependent variable. This disadvantage is specific to the random effects approach."}
{"question": "Which of the following could result in autocorrelated residuals?\n\ni) Slowness of response of the dependent variable to changes in the values of the independent variables\n\nii) Over-reactions of the dependent variable to changes in the independent variables\n\niii) Omission of relevant explanatory variables that are autocorrelated\n\niv) Outliers in the data", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: Autocorrelation is a type of correlation that occurs within a time series. It can occur when a time series is correlated with its own past or future values.\nConsider a time series Y that is correlated with its own past values. This correlation can cause the following problems:\n1. The regression of Y on Y itself can produce a spurious relationship, which can lead to incorrect conclusions.\n2. The omission of relevant explanatory variables that are autocorrelated can lead to incorrect conclusions.\n3. The presence of autocorrelated explanatory variables can lead to incorrect conclusions.\nSuppose you are investigating the relationship between Y and an explanatory variable X. Y is autocorrelated. You can correct for this problem in one of the following ways:\n1. Omit the autocorrelated variable X.\n2. Use a lagged value of X instead of the original value.\n3. Use a different variable Z that is not autocorrelated with Y."}
{"question": "Which of the following statements are true concerning the acf and pacf?\n\n(i) The acf and pacf are often hard to interpret in practice\n\n(ii) The acf and pacf can be difficult to calculate for some data sets\n\n(iii) Information criteria represent an alternative approach to model order determination\n\n(iv) If applied correctly, the acf and pacf will always deliver unique model selections", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following conditions are necessary for a series to be classifiable as a weakly stationary process?\n\n(i) It must have a constant mean\n\n(ii) It must have a constant variance\n\n(iii) It must have constant autocovariances for given lags\n\n(iv) It must have a constant probability distribution", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: A sequence is stationary if its statistical properties change at a constant rate. That is, if the parameters of the distribution change at a constant rate as the sample size changes.\nA wide-sense stationary (WSS) process is a process that is stationary.\nA weakly stationary process is a process that is not wide-sense stationary, but has a constant mean and a constant variance.\nA strongly stationary process is a process that is not wide-sense stationary and has a constant mean, a constant variance, and a constant autocovariance for a constant lag.\nIf a process is not wide-sense stationary and does not have a constant mean, a constant variance, and a constant autocovariance for a constant lag, then it is not stationary.\nSOLUTION: A process is weakly stationary if it has a constant mean and a constant variance. It is also weakly stationary if it has a constant probability distribution.\nSo, a process is weakly stationary if it has a constant mean, a constant variance, and a constant probability distribution."}
{"question": "Consider the following equation and determine the class of model that it best represents\n\n$y_{it} = \\alpha + \\beta_{it} + \\mu_i + \\nu_{it}$", "choices": [{"label": "A", "text": "An entity fixed effects model"}, {"label": "B", "text": "A time fixed effects model"}, {"label": "C", "text": "A random effects model"}, {"label": "D", "text": "A pure time series model"}], "answerKey": "A", "model_answer": "LECTURE: When designing a model for a social science research question, you need to decide what type of model to use. Each type of model represents a different set of equations.\nA random effects model accounts for random assignment of units to groups. This type of model is used when groups are assigned based on random events.\nAn entity fixed effects model includes fixed effects for entities. This type of model is used when groups are defined by entities that have fixed traits.\nA time fixed effects model includes fixed effects for time periods. This type of model is used when different time periods have fixed traits.\nA pure time series model includes only time series variables. This type of model is used when all the variables in the model are measured at a single point in time.\nSOLUTION: The equation includes both entity fixed effects and time fixed effects. So, a time fixed effects model is the best model to use."}
{"question": "Note that statistical tables are not necessary to answer this question. For a sample of 1000 observations, the Dickey-Fuller test statistic values are", "choices": [{"label": "A", "text": "More negative than (i.e. bigger in absolute value than) those in the left hand tail of a normal distribution"}, {"label": "B", "text": "Less negative than (i.e. smaller in absolute value than) those in the left hand tail of a normal distribution"}, {"label": "C", "text": "Obtained from an analytical formula for the density of the Dickey-Fuller distribution"}, {"label": "D", "text": "More negative (i.e. bigger in absolute value) for a 10% size of test than a 5% test."}], "answerKey": "A", "model_answer": ""}
{"question": "Suppose that a hypothesis test is conducted using a 5% significance level. Which of the following statements are correct?\n\n(i) The significance level is equal to the size of the test\n\n(ii) The significance level is equal to the power of the test\n\n(iii) 2.5% of the total distribution will be in each tail rejection region for a 2-sided test\n\n(iv) 5% of the total distribution will be in each tail rejection region for a 2-sided test.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: A hypothesis test is conducted on a population parameter using a 5% significance level.\nThe test is a 2-sided test.\nThe power of the test is 0.80.\nThe size of the test is 5%."}
{"question": "Which one of the following criticisms of the Dickey-Fuller/Engle-Granger approach to dealing with cointegrated variables is overcome by the Engle-Yoo (EY) procedure?", "choices": [{"label": "A", "text": "In the context of small samples, Dickey Fuller tests are prone to conclude that there is a unit root in a series when there is not"}, {"label": "B", "text": "The Engle-Granger (EG) approach can only detect up to one cointegrating relationship even though there could be more than one"}, {"label": "C", "text": "The variables are treated asymmetrically in the cointegrating tests"}, {"label": "D", "text": "It is not possible to perform tests about the cointegrating relationship"}], "answerKey": "D", "model_answer": ""}
{"question": "Consider a series that follows an MA(1) with zero mean and a moving average coefficient of 0.4. What is the value of the autocovariance at lag 1?", "choices": [{"label": "A", "text": "0.4"}, {"label": "B", "text": "1"}, {"label": "C", "text": "0.34"}, {"label": "D", "text": "It is not possible to determine the value of the autocovariances without knowing the disturbance variance."}], "answerKey": "D", "model_answer": "LECTURE: The autocovariance function is used to describe the relationship between a time series and its own lagged version. The autocovariance at lag 1 is the covariance between the time series values at time 1 and time 0.\nThe autocovariance function of an MA(q) series is given by:\nCov(Xt, Xt-q) = Cov(Xt, Xt-q) = \u03c32"}
{"question": "Which of the following estimation techniques are available for the estimation of over-identified systems of simultaneous equations?\n\ni) OLS\n\nii) ILS\n\niii) 2SLS\n\niv) IV", "choices": [{"label": "A", "text": "(iii) only"}, {"label": "B", "text": "(iii) and (iv) only"}, {"label": "C", "text": "(ii), (iii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii) and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: For an over-identified system of simultaneous equations, there are more equations than observations. This means that there are multiple ways to satisfy the simultaneous equations. In this case, there is no unique solution for the parameters of the model.\nSOLUTION: An over-identified system of simultaneous equations can be estimated using IV, 2SLS, or ILS techniques.\nThe OLS technique will not work because there is an intercept term in the model. The intercept is a constant term in the equation that does not use any of the endogenous variables. Since there are more equations than observations, there are multiple values that the intercept term can take. This means that the OLS estimate of the intercept will be poorly determined."}
{"question": "Which one of the following statements best describes a Type II error?", "choices": [{"label": "A", "text": "It is the probability of incorrectly rejecting the null hypothesis"}, {"label": "B", "text": "It is equivalent to the power of the test"}, {"label": "C", "text": "It is equivalent to the size of the test"}, {"label": "D", "text": "It is the probability of failing to reject a null hypothesis that was wrong"}], "answerKey": "D", "model_answer": ""}
{"question": "Which one of the following would be the most appropriate as a 95% (two-sided) confidence interval for the intercept term of the model given in question 21?", "choices": [{"label": "A", "text": "(-4.79,2.19)"}, {"label": "B", "text": "(-4.16,4.16)"}, {"label": "C", "text": "(-1.98,1.98)"}, {"label": "D", "text": "(-5.46,2.86)"}], "answerKey": "D", "model_answer": "LECTURE: A confidence interval is a range of values that is likely to contain the true population parameter. For example, a 95% confidence interval for the population mean is a range that contains the mean 95% of the time.\nTo calculate a confidence interval, use the following formula:\nCI = x \u00b1 z*\u03c3"}
{"question": "Which of the following are characteristics of a stationary process?\n\ni) It crosses its mean value frequently\n\n\nii) It has constant mean and variance\n\n\niii) It contains no trend component\n\n\niv) It will be stationary in first difference form", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "LECTURE: A process is stationary if its statistical properties do not change over time.\nA process is nonstationary if its statistical properties change over time.\nBoth stationary and nonstationary processes can be first difference, second difference, or infinity difference.\nA first difference process has a trend but no seasonal components.\nA second difference process has a trend and seasonal components, but no calendar components.\nAn infinity difference process has a trend, seasonal components, and calendar components.\nSOLUTION: A process will be stationary in first difference form if and only if it is a first difference process. A first difference process has a trend but no seasonal components.\nSo, a stationary process must have a constant mean and variance. It cannot cross its mean value frequently."}
{"question": "Consider again the VAR model of equation 16. Which of the following conditions must hold for it to be said that there is bi-directional feedback?", "choices": [{"label": "A", "text": "The b and d coefficients significant and the a and c coefficients insignificant"}, {"label": "B", "text": "The a and c coefficients significant and the b and d coefficients insignificant"}, {"label": "C", "text": "The a and c coefficients significant"}, {"label": "D", "text": "The b and d coefficients significant"}], "answerKey": "D", "model_answer": ""}
{"question": "Consider the following sample autocorrelation estimates obtained using 250 data points:\n\n1) Lag 1 2 3\n\n2) Coefficient 0.2 -0.15 -0.1\n\n3) Assuming that the coefficients are approximately normally distributed, which of the coefficients are statistically significant at the 5% level?", "choices": [{"label": "A", "text": "1 only"}, {"label": "B", "text": "1 and 2 only"}, {"label": "C", "text": "1, 2 and 3 only"}, {"label": "D", "text": "It is not possible to determine the statistical significance since no standard errors have been given"}], "answerKey": "B", "model_answer": "LECTURE: For a set of autocorrelation coefficients to be statistically significant, each coefficient should have a small standard error. The standard error measures how much the coefficient is likely to differ from its true value.\nA coefficient is statistically significant at a 5% level of significance if its standard error is less than 0.05.\nIf the standard error is greater than 0.05, the coefficient is not statistically significant.\nIt is not possible to determine the statistical significance since no standard errors have been given.\nSOLUTION: Look at the coefficient values and decide if they are statistically significant at the 5% level.\nThe coefficient for lag 1 is 0.2.\nThe coefficient for lag 2 is -0.15.\nThe coefficient for lag 3 is -0.1.\nAll of the coefficients are statistically significant at the 5% level."}
{"question": "Which one of the following is examined by looking at a goodness of fit statistic?", "choices": [{"label": "A", "text": "How well the population regression function fits the data"}, {"label": "B", "text": "How well the sample regression function fits the population regression function"}, {"label": "C", "text": "How well the sample regression function fits the data"}, {"label": "D", "text": "How well the population regression function fits the sample regression function."}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following statements are correct concerning the use of antithetic variates as part of a Monte Carlo experiment?\n\ni) Antithetic variates work by reducing the number of replications required to cover the whole probability space\n\nii) Antithetic variates involve employing a similar variable to that used in the simulation, but whose properties are known analytically\n\niii) Antithetic variates involve using the negative of each of the random draws and repeating the experiment using those values as the draws\n\niv) Antithetic variates involve taking one over each of the random draws and repeating the experiment using those values as the draws", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "Monte Carlo experiment uses random draws to conduct a statistical simulation. The value of a statistical experiment is the set of possible outcomes. The probability of each outcome is the long-run frequency of obtaining that outcome.\nA simulation uses random draws to obtain values for the variables of the experiment. The outcome of the experiment is the vector of values obtained for each variable.\nThe probability of the outcome is the probability that each value was obtained. This probability is called the probability distribution of the outcome.\nSOLUTION: Antithetic variates work by reducing the number of replications required to cover the whole probability space.\nTo use antithetic variates, you employ a similar variable to that used in the simulation, but whose properties are known analytically. For example, if you are simulating a random variable X, you can use the variable X* = -X.\nThen, instead of using the original random variable in the simulation, you use the antithetic variable. This reduces the variance of the estimation of the expected value of the original variable."}
{"question": "Which one of the following statements is true concerning alternative forecast accuracy measures?", "choices": [{"label": "A", "text": "Mean squared error is usually highly correlated with trading rule profitability"}, {"label": "B", "text": "Mean absolute error provides a quadratic loss function"}, {"label": "C", "text": "Mean absolute percentage error is a useful measure for evaluating asset return forecasts"}, {"label": "D", "text": "Mean squared error penalises large forecast errors disproportionately more than small forecast errors"}], "answerKey": "D", "model_answer": "LECTURE: One way to evaluate forecast accuracy is to compare forecast errors to a measure of the size of the forecast. For example, if forecast errors are small and the size of the forecast is small, then the forecast is accurate.\nMean absolute error is a measure of the size of the forecast. It is the average of the absolute values of the forecast errors.\nMean absolute percentage error is a measure of the size of the forecast. It is the average of the absolute values of the forecast errors expressed as a percentage of the size of the forecast.\nMean squared error is a measure of how disproportionate forecast errors are. A forecast error of $100 is worse than a forecast error of $10."}
{"question": "Which of the following criticisms of standard (\"plain vanilla\") GARCH models can be overcome by EGARCH models?\n\ni) Estimated coefficient values from GARCH models may be negative\n\nii) GARCH models cannot account for leverage effects\n\niii) The responsiveness of future volatility to positive and negative shocks is symmetric under a GARCH formulation\n\niv) GARCH models cannot allow for a feedback from the volatility to the returns", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: Financial economists have developed a large number of models to describe the behavior of financial assets. One important class of these models is the class of volatility models, which attempt to explain the dynamics of the volatility of returns. Volatility is a fundamental aspect of the returns on financial assets. For many assets, the volatility of returns is an important determinant of the asset's value. Investors often demand a premium for holding assets with high volatility.\nOne popular volatility model is the GARCH model, which stands for Generalized ARCH model. A GARCH model defines a specific form for the volatility of returns as a function of the past volatility and the past returns. The GARCH formulation allows for the volatility of returns to respond to the returns themselves.\nThere are several criticisms of the standard GARCH model, however. One criticism is that the estimated coefficient values from GARCH models may be negative. This criticism can be overcome by using the EGARCH model, which stands for Error Correction ARCH model. The EGARCH model is a modification of the GARCH model that includes a term that can correct for the negative values of the estimated coefficient.\nAnother criticism of the standard GARCH model is that it cannot account for leverage effects. LeCTURE: Financial assets often have a higher volatility than the underlying assets that they represent. This phenomenon is called leverage effects. Some GARCH models can account for leCTURE: Financial assets often have a higher volatility than the underlying assets that they represent. This phenomenon is called leverage effects. Some GARCH models can account for leverage effects, but the standard GARCH model does not.\nA third criticism of the GARCH model is that the responsiveness of future volatility to positive and negative shocks is symmetric under the GARCH formulation. This symmetry may not hold in some cases. Some economists have proposed models that depart from the GARCH formulation to address this criticism. One such model is the EGARCH model.\nSOLUTION: The correct answer is D. The first, second, and third criticisms of standard GARCH models can be addressed by using EGARCH models."}
{"question": "Suppose that 100 separate firms were tested to determine how many of them \"beat the market\" using a Jensen-type regression, and it is found that 3 fund managers significantly do so. Does this suggest prima facie evidence for stock market inefficiency?", "choices": [{"label": "A", "text": "Yes"}, {"label": "B", "text": "No"}, {"label": "C", "text": "In order to answer this question, you would need to test every fund manager trading in that market"}, {"label": "D", "text": "There is insufficient information given in the question to draw a conclusion about market efficiency."}], "answerKey": "B", "model_answer": "LECTURE: Market efficiency is a hot topic among investors and economists. Efficient and inefficient markets have different implications for investors.\nAn efficient market is a market in which the prices of securities accurately reflect their intrinsic values. In an efficient market, it is not possible to consistently beat the market through analysis or ordinary investment techniques.\nAn inefficient market is a market in which prices do not accurately reflect intrinsic values. In an inefficient market, some investors have an advantage: they can consistently buy undervalued securities and sell overvalued securities.\nSOLUTION: The fact that three fund managers beat the market does not necessarily suggest prima facie evidence for stock market inefficiency. This is because beating the market is not impossible in an efficient market.\nFor example, if three fund managers consistently underestimate their risk, they may be more likely to buy stocks that perform well. They may be able to beat the market by doing this.\nHowever, if 100 fund managers were tested, and only three beat the market, this suggests that it may be difficult to consistently beat the market. This is because most investors do not beat the market.\nThis evidence is not sufficient to conclude whether the market is efficient."}
{"question": "Which of the following are advantages of the use of panel data over pure cross-sectional or pure time-series modelling?\n\n(i) The use of panel data can increase the number of degrees of freedom and therefore the power of tests\n\n(ii) The use of panel data allows the average value of the dependent variable to vary either cross-sectionally or over time or both\n\n(iii) The use of panel data enables the researcher allows the estimated relationship between the independent and dependent variables to vary either cross-sectionally or over time or both", "choices": [{"label": "A", "text": "(i) only"}, {"label": "B", "text": "(i) and (ii) only"}, {"label": "C", "text": "(ii) only"}, {"label": "D", "text": "(i), (ii), and (iii)"}], "answerKey": "B", "model_answer": "LECTURE: Panel data are made up of data on multiple units, such as individuals or companies, over time. Panel data have information on both cross-sectional and time-series dimensions of the data. This section discusses some of the advantages of using panel data over pure cross-sectional or pure time-series data.\nCompare panel data to pure cross-sectional data. In pure cross-sectional data, the units are observed at a single point in time. The data have information on the values of the dependent variable and the values of the independent variables, but the units are not observed over time.\nCompare panel data to pure time-series data. In pure time-series data, the units are observed at multiple points in time. The data have information on the changes in the values of the dependent variable and the independent variables over time.\nAdvantages of using panel data over pure cross-sectional or pure time-series data:\nMore flexible. Panel data allow the researcher to estimate a variety of models, including models that do not assume constant independent variables.\nIncreased number of degrees of freedom. The increase in degrees of freedom can lead to higher statistical power.\nMore information. Panel data provide information on both cross-sectional and time-series dimensions of the data. This additional information can be used to obtain more accurate estimates of the relationships between the independent and dependent variables."}
{"question": "If the Engle-Granger test is applied to the residuals of a potentially cointegrating regression, what would be the interpretation of the null hypothesis?", "choices": [{"label": "A", "text": "The variables are cointegrated"}, {"label": "B", "text": "The variables are not cointegrated"}, {"label": "C", "text": "Both variables are stationary"}, {"label": "D", "text": "Both variables are non-stationary"}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following statements are true concerning the autocorrelation function (acf) and partial autocorrelation function (pacf)?\n\ni) The acf and pacf will always be identical at lag one whatever the model\n\nii) The pacf for an MA(q) model will in general be non-zero beyond lag q\n\niii) The pacf for an AR(p) model will be zero beyond lag p\n\niv) The acf and pacf will be the same at lag two for an MA(1) model", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: The autocorrelation function (ACF) and partial autocorrelation function (PACF) are used to identify the order of a stationary time series model. The ACF shows the correlation between the time series and its own lags, while the PACF shows the correlation of the time series with an intermittent lag.\nThe ACF and PACF are related to the model by the following formulas:\nACF(h) = Corr(Yt, Yt-h)\nPACF(h) = Corr(Yt, Yt-h | Yt-1, ..., Yt-p)\nwhere Yt is the time series value at time t, Yt-h is the time series value at time t-h, and Corr() is the correlation coefficient.\nSOLUTION: The first statement is true. The ACF and PACF are identical at lag one for any stationary time series.\nThe third statement is true. The PACF for an AR(p) model is zero beyond lag p.\nThe second statement is false. The pacf for an MA(q) model can be non-zero beyond lag q.\nThe fourth statement is true. The ACF and PACF are the same at lag two for an MA(1) model."}
