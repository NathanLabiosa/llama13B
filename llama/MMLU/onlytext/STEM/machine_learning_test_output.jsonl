{"question": "Statement 1| Linear regression estimator has the smallest variance among all unbiased estimators. Statement 2| The coefficients \u03b1 assigned to the classifiers assembled by AdaBoost are always non-negative.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": ""}
{"question": "Statement 1| RoBERTa pretrains on a corpus that is approximate 10x larger than the corpus BERT pretrained on. Statement 2| ResNeXts in 2018 usually used tanh activation functions.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: When you are writing, it is important to ensure that your statements are true. A statement is true if it accurately describes the topic.\nA statement is false if it describes the topic inaccurately.\nSOLUTION: Look at each statement separately.\nStatement 1 is true. RoBERTa was pretrained on a corpus that is 10 times larger than the corpus that BERT was pretrained on.\nStatement 2 is false. ResNeXts did not usually use tanh activation functions."}
{"question": "Statement 1| Support vector machines, like logistic regression models, give a probability distribution over the possible labels given an input example. Statement 2| We would expect the support vectors to remain the same in general as we move from a linear kernel to higher order polynomial kernels.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: In a classification algorithm, data is divided into two or more classes. The job of a classifier is to take an input and put it into one of the classes.\nA naive Bayes classifier uses probability to decide which class a input belongs to. The classifier assumes that the features of the input have a probability distribution. The classifier calculates the probability of the input for each class, and the class with the highest probability is chosen.\nA support vector classifier is a different type of classifier. It finds a hyperplane in the high-dimensional space of the features that maximally separates the two classes. This hyperplane is called a decision boundary. The classifier then classifies an input by determining which side of the decision boundary the input lies.\nSOLUTION: The first statement is true. A support vector machine gives a probability distribution over the possible labels for an input.\nThe second statement is false. The support vectors do not remain the same when a linear kernel is replaced with a higher order polynomial kernel. The decision boundary moves when a higher order polynomial kernel is used."}
{"question": "A machine learning problem involves four attributes plus a class. The attributes have 3, 2, 2, and 2 possible values each. The class has 3 possible values. How many maximum possible different examples are there?", "choices": [{"label": "A", "text": "12"}, {"label": "B", "text": "24"}, {"label": "C", "text": "48"}, {"label": "D", "text": "72"}], "answerKey": "D", "model_answer": "LECTURE: The number of possible different examples a machine learning problem can have depends on the number of values each attribute can have.\nIf an attribute has n possible values, then the number of possible different examples is equal to the number of values for that attribute. For example, if an attribute has only 2 possible values, then the number of possible different examples is 2.\nIf each attribute has m possible values, then the number of possible different examples is equal to the number of values for each attribute. For example, if each attribute has 3 possible values, then the number of possible different examples is 3^m.\nSOLUTION: There are 3 possible values for the class, and each attribute has 3, 2, 2, and 2 possible values, respectively. So, the number of possible different examples is 3^5 = 24."}
{"question": "As of 2020, which architecture is best for classifying high-resolution images?", "choices": [{"label": "A", "text": "convolutional networks"}, {"label": "B", "text": "graph networks"}, {"label": "C", "text": "fully connected networks"}, {"label": "D", "text": "RBF networks"}], "answerKey": "A", "model_answer": "LECTURE: Deep learning is a subfield of machine learning that is inspired by the structure and function of the brain's neural networks. Deep learning models can automatically learn a hierarchy of features from raw data.\nA deep learning model is made up of multiple layers. Each layer processes the output from the previous layer.\nFor example, an image is processed by a series of layers in a deep learning model for image classification. The first layers identify simple features, such as edges. The subsequent layers combine those features to form more complex ones, such as the shape of an object."}
{"question": "Statement 1| The log-likelihood of the data will always increase through successive iterations of the expectation maximation algorithm. Statement 2| One disadvantage of Q-learning is that it can only be used when the learner has prior knowledge of how its actions affect its environment.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: The expectation maximization algorithm is an iterative algorithm that is used to estimate the parameters of a statistical model. The algorithm has two main stages: the expectation stage and the maximization stage.\nIn the expectation stage, the algorithm uses the current parameter estimate to calculate the expected value of the missing data. This expected value is then used to calculate the new parameter estimate in the maximization stage.\nThe algorithm repeats the expectation and maximization stages until the expected value of the missing data conincides with the observed data.\nSOLUTION: The first statement is true. The log-likelihood of the data will increase through successive iterations of the expectation maximation algorithm.\nThe second statement is false. One disadvantage of Q-learning is that it can be used when the learner has prior knowledge of how its actions affect its environment."}
{"question": "Let us say that we have computed the gradient of our cost function and stored it in a vector g. What is the cost of one gradient descent update given the gradient?", "choices": [{"label": "A", "text": "O(D)"}, {"label": "B", "text": "O(N)"}, {"label": "C", "text": "O(ND)"}, {"label": "D", "text": "O(ND^2)"}], "answerKey": "A", "model_answer": "LECTURE: The gradient descent algorithm is used to find the local minimum of a cost function. It does this by adjusting the values of the variables based on the negative of the gradient.\nThe gradient tells you the rate of change of the cost function. A value of zero on the gradient indicates a local minimum.\nIf the gradient is negative, the cost function is decreasing. If the gradient is positive, the cost function is increasing.\nSOLUTION: The gradient descent update has two parts: evaluating the gradient and updating the variables.\nThe cost of evaluating the gradient is O(ND). To evaluate the gradient, you need to call the cost function, which takes ND inputs.\nThe cost of updating the variables is O(ND). To update the variables, you multiplying each gradient by a fixed vector and add the results. This takes D multiplies and N adds.\nSo, the cost of one gradient descent update is O(ND)."}
{"question": "Statement 1| For a continuous random variable x and its probability distribution function p(x), it holds that 0 \u2264 p(x) \u2264 1 for all x. Statement 2| Decision tree is learned by minimizing information gain.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: A probability distribution function is a function that describes how a random variable is distributed.\nFor a continuous random variable x and its probability distribution function p(x), it holds that 0 \u2264 p(x) \u2264 1 for all x.\nSOLUTION: The first statement is true. For a continuous random variable x and its probability distribution function p(x), it holds that 0 \u2264 p(x) \u2264 1 for all x.\nThe probability of a continuous variable x is always between 0 and 1. For example, the probability of a die roll is between 0 and 1.\nThe second statement is false. A decision tree is learned by minimizing the impurity or error of the nodes, not information gain."}
{"question": "Consider the Bayesian network given below. How many independent parameters are needed for this Bayesian Network H -> U <- P <- W?", "choices": [{"label": "A", "text": "2"}, {"label": "B", "text": "4"}, {"label": "C", "text": "8"}, {"label": "D", "text": "16"}], "answerKey": "C", "model_answer": "LECTURE: A Bayesian network is a directed acyclic graph (DAG) in which each node represents a random variable. The nodes are connected by edges, which represent the dependencies between the random variables.\nA Bayesian network has the following components:\nNodes: Each node in the graph represents a random variable. A node may represent a single variable or a set of variables.\nEdges: Each edge in the graph represents a dependency between two random variables. A dependency occurs when the value of one random variable affects the value of another random variable.\nA Bayesian network has the following properties:\nFinite: A Bayesian network has a finite number of nodes and edges.\nDirected acyclic: A Bayesian network is directed acyclic, which means that there are no edges between nodes. This property makes it possible to use the network to compute the posteriori probabilities of each node.\nBayesian: A Bayesian network is a Bayesian network, which means that the probabilities used in the network are subject to uncertainty. These probabilities are represented by probabilities from a prior distribution."}
{"question": "As the number of training examples goes to infinity, your model trained on that data will have:", "choices": [{"label": "A", "text": "Lower variance"}, {"label": "B", "text": "Higher variance"}, {"label": "C", "text": "Same variance"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": "LECTURE: The bias-variance tradeoff is a fundamental problem in the theory of supervised learning. Bias refers to how well the model fits the training data. Variance refers to how well the model generalizes to new data. A model with a high bias has a strong dependence on the training data and tends to overfit the data. A model with a high variance has a weak dependence on the training data and tends to underfit the data.\nSOLUTION: As the number of training examples goes to infinity, the model trained on that data will have the same variance. A model with a finite number of parameters will have lower bias, but higher variance. As the number of parameters goes to infinity, the model will have lower bias, but the same variance."}
{"question": "Statement 1| The set of all rectangles in the 2D plane (which includes non axisaligned rectangles) can shatter a set of 5 points. Statement 2| The VC-dimension of k-Nearest Neighbour classifier when k = 1 is infinite.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: A set of points shatters a set of points if the distance between every point in the first set and every point in the second set is at least a certain positive number. The quantity is called the shattering ratio.\nSOLUTION: For each statement, decide whether it is true or false.\nS o l u t i o n: Statement 1 is true. The set of all rectangles in the 2D plane (which includes non axis-aligned rectangles) can shatter the set of 5 points. To see this, note that the set of all rectangles in the 2D plane includes the set of 5 points, so the shattering ratio is at least 1.\nStatement 2 is false. The VC-dimension of a k-Nearest Neighbour classifier when k = 1 is finite. For example, the set of all points in the 2D plane shatters the set of 5 points, but the VC-dimension is 5."}
{"question": "_ refers to a model that can neither model the training data nor generalize to new data.", "choices": [{"label": "A", "text": "good fitting"}, {"label": "B", "text": "overfitting"}, {"label": "C", "text": "underfitting"}, {"label": "D", "text": "all of the above"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| The F1 score can be especially useful for datasets with class high imbalance. Statement 2| The area under the ROC curve is one of the main metrics used to assess anomaly detectors.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: When comparing claims, make sure to consider the following:\nTwo claims have the same effect.\nThe first claim is about the F1 score. It can be especially useful for datasets with class imbalance. Class imbalance occurs when there are many more normal examples than anomalous examples. The F1 score is a measure of a binary classification algorithm's ability to correctly classify examples.\nThe second claim is about the ROC curve. The area under the ROC curve is one of the main metrics used to assess anomaly detectors. Anomaly detectors try to identify examples that are not normal. The ROC curve is a graph that shows the performance of an anomaly detector. To read the curve, imagine that the x-axis is a threshold. If a point is above the curve, the anomaly detector identifies the point as an anomaly. If a point is below the curve, the anomaly detector identifies the point as normal.\nSOLUTION: The first claim is true. The second claim is false.\nThe F1 score is not a metric used to assess anomaly detectors."}
{"question": "Statement 1| The back-propagation algorithm learns a globally optimal neural network with hidden layers. Statement 2| The VC dimension of a line should be at most 2, since I can find at least one case of 3 points that cannot be shattered by any line.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: A function is a special kind of relation where each input is associated with exactly one output. A function is said to be one-to-one, or injective, if each input is associated with a unique output.\nThink about the function f(x) = 3x. This function is not one-to-one because the input 3 is associated with the output 6. This is called a duplicate value.\nA function is said to be onto, or surjective, if each output is associated with at least one input.\nThink about the function f(x) = 1/x. This function is onto because the output 1 is associated with the input 1/1 = 1. But the output 1 is also associated with the input 0.25.\nA function is said to be a function if it is both one-to-one and onto.\nThink about the function f(x) = x^2. This function is one-to-one because each input is associated with a unique output. For example, the input 2 is associated with the output 2^2 = 4, but the input 3 is associated with the output 3^2 = 9.\nThis function is also onto because all outputs are associated with at least one input. For example, the output 4 is associated with the input 4^2 = 16, and the output 9 is associated with the input 3^2 = 9.\nSo, the function f(x) = x^2 is a function.\nSOLUTION: The first statement is false. The back-propagation algorithm does not guarantee a globally optimal neural network. A globally optimal neural network is one in which the output is the same as the output of any other neural network.\nThe second statement is false. The VC dimension of a line is 1."}
{"question": "High entropy means that the partitions in classification are", "choices": [{"label": "A", "text": "pure"}, {"label": "B", "text": "not pure"}, {"label": "C", "text": "useful"}, {"label": "D", "text": "useless"}], "answerKey": "B", "model_answer": "LECTURE: In chemistry, entropy is a measure of how much a substance has \"spread out.\" When the particles in a substance are spread out, the entropy of the substance increases.\nA substance that is pure is made of a single type of matter. The entropy of a pure substance is zero.\nA substance that is not pure is made of two or more different types of matter. The entropy of a substance that is not pure is not zero.\nA substance that is useful is one that can be used to do work. A substance that is not useful is one that cannot be used to do work.\nSOLUTION: High entropy does not mean that the partitions in classification are useful. A substance that is not pure is made of two or more different types of matter. But the entropy of a substance that is not pure is not zero. So, a substance that is not pure is not useful."}
{"question": "Statement 1| Layer Normalization is used in the original ResNet paper, not Batch Normalization. Statement 2| DCGANs use self-attention to stabilize training.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": ""}
{"question": "In building a linear regression model for a particular data set, you observe the coefficient of one of the features having a relatively high negative value. This suggests that", "choices": [{"label": "A", "text": "This feature has a strong effect on the model (should be retained)"}, {"label": "B", "text": "This feature does not have a strong effect on the model (should be ignored)"}, {"label": "C", "text": "It is not possible to comment on the importance of this feature without additional information"}, {"label": "D", "text": "Nothing can be determined."}], "answerKey": "C", "model_answer": ""}
{"question": "For a neural network, which one of these structural assumptions is the one that most affects the trade-off between underfitting (i.e. a high bias model) and overfitting (i.e. a high variance model):", "choices": [{"label": "A", "text": "The number of hidden nodes"}, {"label": "B", "text": "The learning rate"}, {"label": "C", "text": "The initial choice of weights"}, {"label": "D", "text": "The use of a constant-term unit input"}], "answerKey": "A", "model_answer": "LECTURE: A neural network is a model that is designed to recognize patterns.\nA neural network has many layers. The input layer is the first layer. The output layer is the last layer. The layers in the middle are called hidden layers.\nA neural network can have a large number of hidden layers. Each hidden layer has a large number of hidden nodes.\nEach hidden node is connected to each node in the adjacent layers. When a hidden node is activated, it applies an activation function to the weighted sum of its connections. The activation function is a function such as the sigmoid function or the tanh function.\nThe weighted sum is the sum of the products of the weights and the node's input. The weights are variables that determine the strength of the connections between nodes.\nSOLUTION: The use of a constant-term unit input most affects the trade-off between underfitting and overfitting.\nThe use of a constant-term unit input is a structural assumption of a neural network. It specifies that one or more of the unit inputs in the input layer is a constant value."}
{"question": "For polynomial regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "The polynomial degree"}, {"label": "B", "text": "Whether we learn the weights by matrix inversion or gradient descent"}, {"label": "C", "text": "The assumed variance of the Gaussian noise"}, {"label": "D", "text": "The use of a constant-term unit input"}], "answerKey": "A", "model_answer": "LECTURE: For polynomial regression, there are several structural assumptions that affect the trade-off between underfitting and overfitting.\nThe polynomial degree is the number of terms in the polynomial equation. The higher the degree, the more complex the equation is, and the more data is needed to solve for the weights. This relationship is shown in the figure below.\nAs the degree of the polynomial increases, the number of weights that must be adjusted to match the data increases. More weight adjustments are required because the polynomial function is more complex and can better approximate a wide range of functions.\nHowever, using a higher degree polynomial also increases the risk of overfitting. Overfitting occurs when a model is too complex and begins to follow the noise in the data. This makes the model more sensitive to the data it was trained on, but less able to make accurate predictions on new data.\nSOLUTION: The assumed variance of the Gaussian noise affects the trade-off between underfitting and overfitting. The variance is a measure of how spread out the data is. If the variance is too low, the model will underfit. The model will underfit because the model will not have enough weights to match the data.\nIf the variance is too high, the model will overfit. The model will overfit because the model will have too many weights to match the data.\nThe use of a constant-term unit input affects the trade-off between underfitting and overfitting. A constant-term unit input is a scalar value that is added to the output of the polynomial function. This additional value does not vary with the input x.\nThe choice of whether to use matrix inversion or gradient descent to learn the weights affects the trade-off between underfitting and overfitting. Matrix inversion can be less computationally demanding, but it may also be more prone to overfitting. Gradient descent is more computationally demanding, but it may be less prone to overfitting."}
{"question": "Statement 1| As of 2020, some models attain greater than 98% accuracy on CIFAR-10. Statement 2| The original ResNets were not optimized with the Adam optimizer.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "The K-means algorithm:", "choices": [{"label": "A", "text": "Requires the dimension of the feature space to be no bigger than the number of samples"}, {"label": "B", "text": "Has the smallest value of the objective function when K = 1"}, {"label": "C", "text": "Minimizes the within class variance for a given number of clusters"}, {"label": "D", "text": "Converges to the global optimum if and only if the initial means are chosen as some of the samples themselves"}], "answerKey": "C", "model_answer": "LECTURE: K-means is a simple, fast, and effective clustering technique that is widely used in data mining. The K-means algorithm works as follows:\n1. Choose initial means randomly.\n2. Assign each point to the nearest mean.\n3. Update the means: the new center of a cluster is the average of all the points in the cluster.\n4. Repeat steps 2 and 3 until the means no longer change."}
{"question": "Statement 1| VGGNets have convolutional kernels of smaller width and height than AlexNet's first-layer kernels. Statement 2| Data-dependent weight initialization procedures were introduced before Batch Normalization.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: When comparing two propositions, you can use either the true, false dilemma or the false, true dilemma.\nIf one proposition is true and the other is false, then the first proposition is true, but the second is false.\nIf one proposition is false and the other is true, then the first proposition is false, but the second is true.\nSOLUTION: The first statement is true. The second statement is false."}
{"question": "What is the rank of the following matrix? A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]", "choices": [{"label": "A", "text": "0"}, {"label": "B", "text": "1"}, {"label": "C", "text": "2"}, {"label": "D", "text": "3"}], "answerKey": "B", "model_answer": "LECTURE: A matrix is a rectangular array of numbers. Matrices can have multiple rows and columns.\nThe rank of a matrix is the number of rows and columns that are not pivot rows and pivot columns.\nIf a matrix has a rank of 0, then the matrix is singular and not invertible.\nIf a matrix has a rank of 1, then the matrix is invertible.\nIf a matrix has a rank of greater than 1, then the matrix is invertible.\nSOLUTION: To find the rank of the matrix A, look at the matrix and consider whether any of the rows or columns are pivot rows or pivot columns.\nSince all the rows and columns of the matrix are identical, the rank of the matrix is 0."}
{"question": "Statement 1| Density estimation (using say, the kernel density estimator) can be used to perform classification. Statement 2| The correspondence between logistic regression and Gaussian Naive Bayes (with identity class covariances) means that there is a one-to-one correspondence between the parameters of the two classifiers.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: Density estimation is the process of estimating the probability density function of a random variable. Density estimation can be used for classification, even though it is not a classification algorithm. To see this, consider the following steps:\n1. Use a density estimator, such as the kernel density estimator, to estimate the probability density function of a random variable.\n2. Use the estimated probability density function to determine a class label. For example, you can use the estimated probability density function to determine whether a point is above a certain threshold.\nSOLUTION: Step 1 is true. Density estimation can be used for classification.\nStep 2 is false. The correspondence between logistic regression and Gaussian Naive Bayes (with identity class covariances) is as follows:"}
{"question": "Suppose we would like to perform clustering on spatial data such as the geometrical locations of houses. We wish to produce clusters of many different sizes and shapes. Which of the following methods is the most appropriate?", "choices": [{"label": "A", "text": "Decision Trees"}, {"label": "B", "text": "Density-based clustering"}, {"label": "C", "text": "Model-based clustering"}, {"label": "D", "text": "K-means clustering"}], "answerKey": "B", "model_answer": "LECTURE: Clustering is the process of grouping data into clusters. In clustering, data points are assigned to clusters, and the clusters are grouped together based on their similarities.\nThere are many ways to cluster data. The method you choose will depend on the type of data you have and the questions you want to answer.\nDensity-based clustering: These algorithms search for dense areas of data. Data points within acluster have a high density, and data points outside the cluster have a low density.Density-based clustering does not require you to specify the number of clusters in advance.\nModel-based clustering: These algorithms create clusters based on a model of the data. Themodel represents the clusters and the data between the clusters. You can use model-basedclustering to identify clusters of different sizes.\nHierarchical clustering: These algorithms create a hierarchy of clusters. You can choose to stop the clustering process at any point to get a desired number of clusters.\nModel-based clustering is the most appropriate method for clustering spatial data. It creates a model of the data and identifies the clusters based on the model. This makes it possible to have clusters of many different sizes and shapes."}
{"question": "Statement 1| In AdaBoost weights of the misclassified examples go up by the same multiplicative factor. Statement 2| In AdaBoost, weighted training error e_t of the tth weak classifier on training data with weights D_t tends to increase as a function of t.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: In AdaBoost, the weighted training error e_t of the tth weak classifier on training data with weights D_t tends to increase as a function of t.\nThis means that the misclassified examples get more attention as the number of classifiers in AdaBoost increases. The training error of each classifier is a weighted sum of the errors on the misclassified examples. The weights are equal for all misclassified examples."}
{"question": "MLE estimates are often undesirable because", "choices": [{"label": "A", "text": "they are biased"}, {"label": "B", "text": "they have high variance"}, {"label": "C", "text": "they are not consistent estimators"}, {"label": "D", "text": "None of the above"}], "answerKey": "B", "model_answer": "LECTURE: MLE is a statistic that estimates the parameters of a probability distribution. To find the MLE, you try to find the value of a parameter that makes the likelihood function as large as possible. The likelihood function is a function of the data and the parameter.\nThe maximum likelihood estimate is an unbiased estimator. That is, the MLE has an expected value that is equal to the true value of the parameter.\nHowever, the MLE is not always the best estimator. The MLE can have a high variance, which means it can be far from the true value. In that case, the MLE is said to be a poor estimator.\nThere are several ways in which the MLE can be a poor estimator:\nThe variance of the MLE is too high. This can happen when the data are not informative.\nThe MLE is not a consistent estimator. This means that as the data get larger, the MLE gets worse.\nThe MLE is biased. This means that the expected value of the MLE is not equal to the true value of the parameter.\nSOLUTION: MLE estimates are often undesirable because they are not consistent estimators. A consistent estimator is an estimator whose expected value is equal to the true value of the parameter as the amount of data grows.\nThe MLE is not a consistent estimator for the Cauchy distribution. This means that as the data get larger, the MLE gets worse."}
{"question": "Computational complexity of Gradient descent is,", "choices": [{"label": "A", "text": "linear in D"}, {"label": "B", "text": "linear in N"}, {"label": "C", "text": "polynomial in D"}, {"label": "D", "text": "dependent on the number of iterations"}], "answerKey": "C", "model_answer": "LECTURE: In the context of big O notation, the time complexity of an algorithm is represented in terms of the number of operations that it takes. For example, the time complexity of an algorithm is denoted by O(f(n)), which indicates that the operation count is linear in n.\nBig O notation hides details of an algorithm's implementation. Two algorithms may have the same time complexity in Big O notation, even though their implementations are different.\nFor example, the following two algorithms have the same time complexity in Big O notation:\nAlgorithm A: for i from 1 to n, do some operation.\nAlgorithm B: for each element in a list, do some operation.\nBoth algorithms have a time complexity of O(n).\nSOLUTION: The computational complexity of Gradient descent is linear in D.\nThe gradient descent algorithm has a time complexity of O(D), which indicates that the operation count is linear in the size of the dataset D."}
{"question": "Averaging the output of multiple decision trees helps _.", "choices": [{"label": "A", "text": "Increase bias"}, {"label": "B", "text": "Decrease bias"}, {"label": "C", "text": "Increase variance"}, {"label": "D", "text": "Decrease variance"}], "answerKey": "D", "model_answer": "LECTURE: When you average the output of multiple decision trees, you are creating a model that is based on a set of decisions. The performance of this model is determined by both its bias and its variance.\nBias is a measure of how much the model's predictions deviate from the true values. A decision tree model with a high bias will make too many errors on the training data.\nVariance is a measure of how much the model's predictions deviate from each other. A decision tree model with a high variance will make different errors on different training data.\nSOLUTION: Averaging the output of multiple decision trees helps decrease variance. Each decision tree is a different model, so each tree has a different output. By taking the average of these outputs, you create a new model that is less prone to errors. The new model has lower variance."}
{"question": "The model obtained by applying linear regression on the identified subset of features may differ from the model obtained at the end of the process of identifying the subset during", "choices": [{"label": "A", "text": "Best-subset selection"}, {"label": "B", "text": "Forward stepwise selection"}, {"label": "C", "text": "Forward stage wise selection"}, {"label": "D", "text": "All of the above"}], "answerKey": "C", "model_answer": "LECTURE: In the process of feature selection, you can use forward stage wise selection to stepwise reduce the number of features during the model building process. This approach is similar to forward stepwise selection, but it doesn't make assumptions about the linearity of the model or the distribution of the data."}
{"question": "Neural networks:", "choices": [{"label": "A", "text": "Optimize a convex objective function"}, {"label": "B", "text": "Can only be trained with stochastic gradient descent"}, {"label": "C", "text": "Can use a mix of different activation functions"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": "LECTURE: A neural network is a composition of functions that process inputs to produce outputs. A neural network is a function of the form:\nf(x1, x2, ..., xn) = g(h(x1, x2, ..., xn))\nHere, x1, x2, ..., xn are the inputs, and g and h are functions that are each composed of one or more neurons.\nA neuron is a function that processes n inputs and has an output between 0 and 1. A neuron's output is computed as follows:\noutput = 0.5 \u00d7 (sum of weights) + 0.5\nThe inputs to a neuron are typically connected to the outputs of other neurons, and the weights are real numbers that determine the strength of these connections.\nSOLUTION: A neural network is a function of the form:\nf(x1, x2, ..., xn) = g(h(x1, x2, ..., xn))\nHere, g and h are functions that are each composed of one or more neurons.\nA neuron is a function that processes n inputs and has an output between 0 and 1.\nA neural network can use a mix of different activation functions."}
{"question": "Say the incidence of a disease D is about 5 cases per 100 people (i.e., P(D) = 0.05). Let Boolean random variable D mean a patient \u201chas disease D\u201d and let Boolean random variable TP stand for \"tests positive.\" Tests for disease D are known to be very accurate in the sense that the probability of testing positive when you have the disease is 0.99, and the probability of testing negative when you do not have the disease is 0.97. What is P(TP), the prior probability of testing positive.", "choices": [{"label": "A", "text": "0.0368"}, {"label": "B", "text": "0.473"}, {"label": "C", "text": "0.078"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| After mapped into feature space Q through a radial basis kernel function, 1-NN using unweighted Euclidean distance may be able to achieve better classification performance than in original space (though we can\u2019t guarantee this). Statement 2| The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SVM.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: The VC dimension of a model is a measure of its capacity to fit a set of training data. The VC dimension of a model is smaller than the VC dimension of a simpler model if the simpler model can also fit the set of training data.\nThe VC dimension of a Perceptron is 1. A Perceptron is a linear model that has one free parameter.\nThe VC dimension of a simple linear SVM is 2. A simple linear SVM is a linear model that has two free parameters.\nSo, the first statement is true. The second statement is false."}
{"question": "The disadvantage of Grid search is", "choices": [{"label": "A", "text": "It can not be applied to non-differentiable functions."}, {"label": "B", "text": "It can not be applied to non-continuous functions."}, {"label": "C", "text": "It is hard to implement."}, {"label": "D", "text": "It runs reasonably slow for multiple linear regression."}], "answerKey": "D", "model_answer": "LECTURE: In machine learning, optimization is the process of finding the values of the model parameters that minimize the error. In other words, optimization finds the values of the parameters that make the model as accurate as possible.\nMany algorithms can be used for optimization. Some algorithms are used for optimization problems that are easy to solve. Other algorithms are used for optimization problems that are hard to solve. Grid search is an example of an algorithm that is used for optimization problems that are hard to solve."}
{"question": "Predicting the amount of rainfall in a region based on various cues is a ______ problem.", "choices": [{"label": "A", "text": "Supervised learning"}, {"label": "B", "text": "Unsupervised learning"}, {"label": "C", "text": "Clustering"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": "LECTURE: Some problems can be solved by dividing the data into groups, or clusters. These are called clustering problems.\nA clustering problem is a type of unsupervised learning problem. Unlike supervised learning problems, clustering problems do not have a specific correct answer.\nSOLUTION: To predict the amount of rainfall in a region based on various cues, you can use a clustering algorithm. These algorithms can automatically group the data into clusters."}
{"question": "Which of the following sentence is FALSE regarding regression?", "choices": [{"label": "A", "text": "It relates inputs to outputs."}, {"label": "B", "text": "It is used for prediction."}, {"label": "C", "text": "It may be used for interpretation."}, {"label": "D", "text": "It discovers causal relationships"}], "answerKey": "D", "model_answer": ""}
{"question": "Which one of the following is the main reason for pruning a Decision Tree?", "choices": [{"label": "A", "text": "To save computing time during testing"}, {"label": "B", "text": "To save space for storing the Decision Tree"}, {"label": "C", "text": "To make the training set error smaller"}, {"label": "D", "text": "To avoid overfitting the training set"}], "answerKey": "D", "model_answer": ""}
{"question": "Statement 1| The kernel density estimator is equivalent to performing kernel regression with the value Yi = 1/n at each point Xi in the original data set. Statement 2| The depth of a learned decision tree can be larger than the number of training examples used to create the tree.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: The depth of a decision tree is the number of branches that come out of a single internal node. The maximum depth of a decision tree is the number of nodes in the tree.\nA learned decision tree is grown to its maximum depth.\nThe tree is not grown to its maximum depth."}
{"question": "Suppose your model is overfitting. Which of the following is NOT a valid way to try and reduce the overfitting?", "choices": [{"label": "A", "text": "Increase the amount of training data."}, {"label": "B", "text": "Improve the optimisation algorithm being used for error minimisation."}, {"label": "C", "text": "Decrease the model complexity."}, {"label": "D", "text": "Reduce the noise in the training data."}], "answerKey": "B", "model_answer": "LECTURE: In general, there are four main ways to try and reduce overfitting in a model:\n1. Decrease the model complexity: The more complex a model is, the more likely it is to overfit. Decreasing the model complexity may help to reduce overfitting.\n2. Increase the amount of training data: Adding more data to the training set may help the model to better learn the patterns in the data and reduce overfitting.\n3. Reduce the noise in the training data: Other things being equal, the more data that is affected by noise, the more difficult it is to train a model. Reducing the noise in the training data may help to reduce overfitting.\n4. Improve the optimisation algorithm: Different optimisation algorithms have different ways of finding the minimum error. Some optimisation algorithms are more likely to overfit than others. For example, stochastic gradient descent is more likely to overfit than batch gradient descent. Improving the optimisation algorithm may help to reduce overfitting.\nSOLUTION: Decrease the model complexity is a way to reduce overfitting that does not involve collecting more training data, reducing the noise in the training data, or improving the optimisation algorithm. So, decreasing the model complexity is a valid way to try and reduce overfitting."}
{"question": "Statement 1| The softmax function is commonly used in mutliclass logistic regression. Statement 2| The temperature of a nonuniform softmax distribution affects its entropy.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: In multiclass logistic regression, the softmax function is commonly used to find the probabilities of each class. The softmax function takes as input the output of a logistic regression model for a single class and transforms it into a set of probabilities for each class.\nThe temperature of a nonuniform softmax distribution affects its entropy.\nEntropy is a measure of the amount of uncertainty in a set of probabilities. The entropy of a uniform softmax distribution is zero, which means that the probabilities are completely certain. The entropy of a nonuniform softmax distribution is greater than zero, which means that the probabilities are more uncertain.\nSOLUTION: The first statement is true. The softmax function is used in multiclass logistic regression. This function takes the output of a logistic regression model for a single class and transforms it into a set of probabilities for each class.\nThe second statement is false. The temperature of a uniform softmax distribution affects its entropy. A uniform softmax distribution is a distribution where each probability is equal. The entropy of a uniform softmax distribution is zero."}
{"question": "Which of the following is/are true regarding an SVM?", "choices": [{"label": "A", "text": "For two dimensional data points, the separating hyperplane learnt by a linear SVM will be a straight line."}, {"label": "B", "text": "In theory, a Gaussian kernel SVM cannot model any complex separating hyperplane."}, {"label": "C", "text": "For every kernel function used in a SVM, one can obtain an equivalent closed form basis expansion."}, {"label": "D", "text": "Overfitting in an SVM is not a function of number of support vectors."}], "answerKey": "A", "model_answer": "LECTURE: A support vector machine (SVM) is a binary classifier. It defines a decision boundary by finding the best boundary between two classes.\nThe boundary is found by taking a vote among the training examples. For each example, the SVM votes for the class to which the example is closest.\nThe SVM finds the boundary by maximizing the margin, which is the distance between the boundary and the closest examples.\nIf the distance is too small, the SVM has not found a good boundary. The SVM can be made more flexible by using a different kernel function.\nA kernel function takes one or more inputs and maps them to a new space. In the new space, the SVM can find a better decision boundary.\nFor example, the line chart shows the distance between the boundary and the closest examples. The distance is measured by the blue line. The purpose of the SVM is to find the best boundary, which is the line that separates the two classes.\nThe SVM uses the gray line to find the best boundary. The gray line is the margin.\nSOLUTION: For two dimensional data points, the separating hyperplane learnt by a linear SVM will be a straight line.\nA linear SVM uses a straight line to separate the two classes. The line is the separating hyperplane."}
{"question": "Which of the following is the joint probability of H, U, P, and W described by the given Bayesian Network H -> U <- P <- W? [note: as the product of the conditional probabilities]", "choices": [{"label": "A", "text": "P(H, U, P, W) = P(H) * P(W) * P(P) * P(U)"}, {"label": "B", "text": "P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(W | H, P)"}, {"label": "C", "text": "P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(U | H, P)"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": "LECTURE: A network is a set of nodes and a set of links that connect the nodes. Nodes represent objects, and links represent relationships between objects.\nA Bayesian network is a type of network that represents objects and relationships between objects using probabilities. In a Bayesian network, each node represents an object, and each link represents a relationship between objects. The relationships are represented by conditional probabilities, which are calculated as P(A|B), or P(A conditioned on B).\nThese conditional probabilities describe the probability of object A, given that object B has occurred. For example, if B represents the event that it is raining, and A represents the event that a tree is wet, then the conditional probability P(A|B) represents the probability that a tree is wet, given that it is raining.\nSOLUTION: To find the joint probability of H, U, P, and W, use the following formula:\nP(H, U, P, W) = P(H) * P(W) * P(P | W) * P(U | H, P)\nFirst, calculate the probability of P given W. The conditional probability P(P | W) is the probability of a sunny day, given that it is sunny. This probability is 1.0.\nThen, calculate the probability of U given H and P. The conditional probability P(U | H, P) is the probability of a hot day, given that it is sunny and hot. This probability is also 1.0.\nSo, the joint probability of H, U, P, and W is P(H) * P(W) * P(P | W) * P(U | H, P)."}
{"question": "Statement 1| Since the VC dimension for an SVM with a Radial Base Kernel is infinite, such an SVM must be worse than an SVM with polynomial kernel which has a finite VC dimension. Statement 2| A two layer neural network with linear activation functions is essentially a weighted combination of linear separators, trained on a given dataset; the boosting algorithm built on linear separators also finds a combination of linear separators, therefore these two algorithms will give the same result.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| The ID3 algorithm is guaranteed to find the optimal decision tree. Statement 2| Consider a continuous probability distribution with density f() that is nonzero everywhere. The probability of a value x is equal to f(x).", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: In a decision tree, every decision is made by choosing a critical point. A critical point is a value of a feature that is either an absolute boundary or a relative boundary.\nAn absolute boundary is a value that is unique across all possible values of a feature. For example, in the problem of classifying cars by their weight and horsepower, the absolute boundary of 1.5 is a unique value: no car can weigh 1.5 tons.\nA relative boundary is a value that is a boundary for a range of values of a feature. For example, in the same car classification problem, the relative boundary of 30 is a boundary for the range of horsepower values. For a car with more than 30 horsepower, the horsepower value is no longer associated with cars with 6 or 8 cylinders.\nA decision tree is built by choosing a critical point and splitting the data into two branches. One branch is the set of data with values that are less than or equal to the critical point. The other branch is the set of data with values that are greater than the critical point.\nThe process is repeated for each branch until all the data is in one of the branches. This branch is the output of the decision tree.\nSOLUTION: The first statement is true. The ID3 algorithm is one of the simplest and most popular algorithms for finding a decision tree. It is guaranteed to find a decision tree that is optimal for binary classification problems.\nA binary classification problem is a classification problem with two possible classifications.\nThe second statement is false. For a continuous probability distribution, the probability of a value is never greater than the value of the probability density function at that point. So, the probability of a value is equal to the density function at that point."}
{"question": "Given a Neural Net with N input nodes, no hidden layers, one output node, with Entropy Loss and Sigmoid Activation Functions, which of the following algorithms (with the proper hyper-parameters and initialization) can be used to find the global optimum?", "choices": [{"label": "A", "text": "Stochastic Gradient Descent"}, {"label": "B", "text": "Mini-Batch Gradient Descent"}, {"label": "C", "text": "Batch Gradient Descent"}, {"label": "D", "text": "All of the above"}], "answerKey": "D", "model_answer": "LECTURE: Neural nets are composed of layers of interconnected nodes. Each node is a simple computer that performs a mathematical operation on its inputs. The nodes in a neural net can have different types, or activations, such as the Sigmoid or ReLU activations.\nAn entropy loss is a measure of the randomness or uncertainty in a set of values. This quantity is zero when the values are perfectly ordered, and it is infinite when the values are equally likely.\nSOLUTION: To find the global optimum for a Neural Net, use Mini-Batch Gradient Descent.\nMini-Batch Gradient Descent is a variation of the standard Batch Gradient Descent algorithm. Instead of using the entire training set to find the gradient of the loss function with respect to the weights, Mini-Batch Gradient Descent uses a random subset of the training set. This subset is called a mini-batch.\nBy using mini-batches, Mini-Batch Gradient Descent is faster than Batch Gradient Descent. It also has a slightly more robust root-finding: Mini-Batch Gradient Descent may be able to escape shallow local minima that Batch Gradient Descent gets stuck in.\nWhen using Mini-Batch Gradient Descent, be sure to choose a reasonable batch size. A larger batch size leads to a faster convergence, but a smaller batch size can lead to a more robust optimization."}
{"question": "Adding more basis functions in a linear model, pick the most probably option:", "choices": [{"label": "A", "text": "Decreases model bias"}, {"label": "B", "text": "Decreases estimation bias"}, {"label": "C", "text": "Decreases variance"}, {"label": "D", "text": "Doesn\u2019t affect bias and variance"}], "answerKey": "A", "model_answer": ""}
{"question": "Consider the Bayesian network given below. How many independent parameters would we need if we made no assumptions about independence or conditional independence H -> U <- P <- W?", "choices": [{"label": "A", "text": "3"}, {"label": "B", "text": "4"}, {"label": "C", "text": "7"}, {"label": "D", "text": "15"}], "answerKey": "D", "model_answer": "LECTURE: A network is a set of nodes connected by edges. In a Bayesian network, each node represents a random variable, and each edge from one node to another represents a statistical dependency between the variables.\nThe edges in a Bayesian network are labeled with a direction, which indicates the order of the variables. The direction from a variable to another variable means that the second variable helps to predict the first variable.\nFor example, consider a Bayesian network with nodes for the months of the year and the number of days each month that it rains. There are edges labeled \"January,\" \"February,\" and so on, and the directions of these edges indicate that the month helps to predict the number of rain days. There is also an edge labeled \"January \u21c4 February,\" which indicates that February helps to predict January.\nThe direction of an edge can also be indicated by a bidirectional arrow. Such an arrow indicates that there is a bidirectional relationship between the variables. For example, the edges in a Bayesian network that represents the relationship between a father and his adult children should have bidirectional arrows, to represent the relationship between a father and his children.\nSOLUTION: To determine the number of independent parameters in a Bayesian network, look at the edges in the network and count the number of independent edges. An edge is independent if the conditions for independence listed below are met.\nThe nodes at the ends of the edge are conditionally independent, given any other nodes in the network.\nThe edges at one end of the edge are independent, given any nodes or edges in the network.\nThe edges at both ends of the edge are independent, given any nodes or edges in the network.\nIf a edge is independent, then the nodes it connects are independent parameters.\nApplying these conditions to the given network, we see that H and W are independent, since they are not connected by any edges. U and P are also independent, since the edge from U to P is independent. So, we only need 3 independent parameters."}
{"question": "Another term for out-of-distribution detection is?", "choices": [{"label": "A", "text": "anomaly detection"}, {"label": "B", "text": "one-class detection"}, {"label": "C", "text": "train-test mismatch robustness"}, {"label": "D", "text": "background detection"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| We learn a classifier f by boosting weak learners h. The functional form of f\u2019s decision boundary is the same as h\u2019s, but with different parameters. (e.g., if h was a linear classifier, then f is also a linear classifier). Statement 2| Cross validation can be used to select the number of iterations in boosting; this procedure may help reduce overfitting.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "LECTURE: A classifier is a function that maps an input to an output. For example, a classifier can be a function that tells you whether an image contains a cat or a dog.\nA weak learner is a classifier that is not too accurate. This might seem strange, but the idea is that a weak learner is easier to improve by combining it with other classifiers.\nGiven a set of weak learners, you can combine them to form a stronger learner by using the following process:\n1. For each weak learner, use it to make a prediction on the training data.\n2. For each prediction, use the actual class label to calculate a error value.\n3. Use the error values to calculate a new set of parameters for the weak learner.\n4. Use the new parameters to create a new, stronger learner.\nThis process is called boosting."}
{"question": "Statement 1| Highway networks were introduced after ResNets and eschew max pooling in favor of convolutions. Statement 2| DenseNets usually cost more memory than ResNets.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": ""}
{"question": "If N is the number of instances in the training dataset, nearest neighbors has a classification run time of", "choices": [{"label": "A", "text": "O(1)"}, {"label": "B", "text": "O( N )"}, {"label": "C", "text": "O(log N )"}, {"label": "D", "text": "O( N^2 )"}], "answerKey": "B", "model_answer": "LECTURE: The big O notation is a way to describe the limiting behavior of a function as the argument gets larger. The function f(n) is O(g(n)) if and only if there are constants c and n0 such that f(n) \u2264 cg(n) for all n \u2265 n0. In this case, the function g(n) is called the dominant term of f(n).\nFor example, if n is large, then 2n is O(n).\nSOLUTION: To decide whether the classification run time is O(1), O(log N), or O(N), decide which term is the dominant term.\nIf the classification run time is O(1), then the run time is constant, regardless of the size of the training dataset. This is possible if the function has no variables or if the function has a constant variable.\nIf the classification run time is O(log N), then the run time increases much slower than linearly with the size of the training dataset. This can happen if the function contains a single logarithm.\nIf the classification run time is O(N), then the run time increases linearly with the size of the training dataset. This can happen if the function has a variable that is part of an O(N) function.\nIf the classification run time is O(N^2), then the run time increases faster than linearly with the size of the training dataset. This can happen if the function contains a single N^2 term or if the function contains a variable that is part of an O(N^2) function."}
{"question": "Statement 1| The original ResNets and Transformers are feedforward neural networks. Statement 2| The original Transformers use self-attention, but the original ResNet does not.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| RELUs are not monotonic, but sigmoids are monotonic. Statement 2| Neural networks trained with gradient descent with high probability converge to the global optimum.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "LECTURE: Neural networks are made of layers of artificial neurons. An artificial neuron is a simple computing unit that receives some input values, performs a simple computation, and then passes the result to the next layer.\nA sigmoid is a monotonic function. A monotonic function is a function for which the slope never changes. For example, if f(x) is a monotonic function, then f(x) \u2264 f(y) for all x \u2264 y.\nThe output of a sigmoid function is in the range [0, 1]. To use a sigmoid function as a activation function (a function that turns the input of an artificial neuron on or off), you can use the formula:\nf(x) = 1 / (1 + e^(-x))\nA rectified linear unit (RELU) is a type of activation function. A rectified linear unit returns 0 for negative input values and the input value for non-negative input values.\nSOLUTION: You can use the following steps to decide whether the statements are true or false:\nStep 1: Think about each statement.\nA sigmoid is a monotonic function. A monotonic function is a function for which the slope never changes. For example, if f(x) is a monotonic function, then f(x) \u2264 f(y) for all x \u2264 y.\nA sigmoid is not monotonic. A sigmoid is a curve.\nSo, Statement 1 is false.\nA rectified linear unit (RELU) is a monotonic function. A monotonic function is a function for which the slope never changes. For example, if f(x) is a monotonic function, then f(x) \u2264 f(y) for all x \u2264 y.\nA rectified linear unit (RELU) is not monotonic. A rectified linear unit returns 0 for negative input values and the input value for non-negative input values.\nSo, Statement 2 is false."}
{"question": "The numerical output of a sigmoid node in a neural network:", "choices": [{"label": "A", "text": "Is unbounded, encompassing all real numbers."}, {"label": "B", "text": "Is unbounded, encompassing all integers."}, {"label": "C", "text": "Is bounded between 0 and 1."}, {"label": "D", "text": "Is bounded between -1 and 1."}], "answerKey": "C", "model_answer": "LECTURE: Neural networks are made up of layers of nodes. Each node performs a simple calculation. The output of each node is connected to the input of each node in the next layer.\nA sigmoid node is one type of node. A sigmoid node performs a calculation to produce a value that is between 0 and 1.\nSOLUTION: A sigmoid node has the following output:\noutput = 1 / (1 + exp(-a(input - b)))\nThe output is bounded between 0 and 1."}
{"question": "Which of the following can only be used when training data are linearly separable?", "choices": [{"label": "A", "text": "Linear hard-margin SVM."}, {"label": "B", "text": "Linear Logistic Regression."}, {"label": "C", "text": "Linear Soft margin SVM."}, {"label": "D", "text": "The centroid method."}], "answerKey": "A", "model_answer": "LECTURE: In a linear classification problem, the data are linearly separable if it is possible to draw a straight line that separates the data into categories. One class is on one side of the line and the other class is on the other side.\nThe centroid method is one way to classify data that are linearly separable. To use the centroid method, follow these steps:\nStep 1: Compute the centroid of each class. The centroid is the average of all the data points in a class.\nStep 2: Find the line that passes through the centroid of each class. This line is the decision boundary.\nStep 3: Classify each data point by determining which side of the decision boundary it is on.\nThe centroid method is a linear classification algorithm. It can only be used when the data are linearly separable.\nA linear hard-margin SVM is a type of support vector machine. It can also use a linear classification algorithm when the data are linearly separable. A linear hard-margin SVM finds the line that separates the data. This line is called the decision boundary. The line must pass through the centroid of each class.\nA linear soft-margin SVM is another type of support vector machine. It can also use a linear classification algorithm when the data are linearly separable. A linear soft-margin SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-margin SOLUTION: SOLUTION: A linear soft-"}
{"question": "Which of the following are the spatial clustering algorithms?", "choices": [{"label": "A", "text": "Partitioning based clustering"}, {"label": "B", "text": "K-means clustering"}, {"label": "C", "text": "Grid based clustering"}, {"label": "D", "text": "All of the above"}], "answerKey": "D", "model_answer": "LECTURE: In cluster analysis, different clustering algorithms are used to determine the best way to group data points into clusters. Some algorithms are partitioning-based, which means that the data is split into multiple clusters. Other algorithms are hierarchical, which means that the data is grouped into a series of clusters, with each cluster being part of a larger cluster.\nSOLUTION: The best way to group data points into clusters is with the k-means clustering algorithm. This algorithm is partitioning-based.\nK-means clustering works as follows:\n1. Randomly choose k data points to be the initial centroids of the clusters.\n2. Assign each data point to the centroid closest to it.\n3. For each centroid, calculate the new centroid as the average of all the data points assigned to it.\n4. Repeat steps 2 and 3 until the centroids no longer change.\nThe k-means clustering algorithm is used to determine the optimal number of clusters. This is done by testing different values of k and selecting the value that results in the smallest total within-cluster sum of squares."}
{"question": "Statement 1| The maximum margin decision boundaries that support vector machines construct have the lowest generalization error among all linear classifiers. Statement 2| Any decision boundary that we get from a generative model with classconditional Gaussian distributions could in principle be reproduced with an SVM and a polynomial kernel of degree less than or equal to three.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "LECTURE: For two claims, the following criteria must be met for both claims to be true:\nBoth claims must be supported by evidence.\nBoth claims must be true for the given topic.\nSOLUTION: Look for evidence that supports each claim.\nThe maximum margin decision boundaries that support vector machines construct have the lowest generalization error among all linear classifiers.\nThis claim is true.\nAny decision boundary that we get from a generative model with classconditional Gaussian distributions could in principle be reproduced with an SVM and a polynomial kernel of degree less than or equal to three.\nThis claim is false."}
{"question": "Statement 1| L2 regularization of linear models tends to make models more sparse than L1 regularization. Statement 2| Residual connections can be found in ResNets and Transformers.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": ""}
{"question": "Suppose we like to calculate P(H|E, F) and we have no conditional independence information. Which of the following sets of numbers are sufficient for the calculation?", "choices": [{"label": "A", "text": "P(E, F), P(H), P(E|H), P(F|H)"}, {"label": "B", "text": "P(E, F), P(H), P(E, F|H)"}, {"label": "C", "text": "P(H), P(E|H), P(F|H)"}, {"label": "D", "text": "P(E, F), P(E|H), P(F|H)"}], "answerKey": "B", "model_answer": "LECTURE: If two events are independent, then probability is a linear function of the probability of the individual events. That is, if E and F are independent, then P(E and F) = P(E) P(F).\nIf two events are not independent, then probability is not a linear function of the probability of the individual events. In general, to calculate P(E and F), you need to use the fact that P(E and F) = P(E) P(F|E).\nSo, if you have no conditional independence information, P(E, F), P(E|H), P(F|H), and P(H) are not sufficient to calculate P(H|E, F)."}
{"question": "Which among the following prevents overfitting when we perform bagging?", "choices": [{"label": "A", "text": "The use of sampling with replacement as the sampling technique"}, {"label": "B", "text": "The use of weak classifiers"}, {"label": "C", "text": "The use of classification algorithms which are not prone to overfitting"}, {"label": "D", "text": "The practice of validation performed on every classifier trained"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| PCA and Spectral Clustering (such as Andrew Ng\u2019s) perform eigendecomposition on two different matrices. However, the size of these two matrices are the same. Statement 2| Since classification is a special case of regression, logistic regression is a special case of linear regression.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: Eigendecomposition is a computationally expensive process that involves calculating the eigenvalues and eigenvectors of a matrix. The size of the matrix and its spectrum determine the difficulty of the eigendecomposition process.\nSOLUTION: PCA and spectral clustering both perform eigendecomposition on the same size matrix. So, they are similar in this way.\nHowever, logistic regression is a special case of linear regression. This means that logistic regression has a different formula than linear regression, but they are built on the same basic idea.\nSo, statement 1 is true.\nStatement 2 is false."}
{"question": "Statement 1| The Stanford Sentiment Treebank contained movie reviews, not book reviews. Statement 2| The Penn Treebank has been used for language modeling.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: When you are considering two statements, you can use either statement as a basis for your decision. If one statement supports a claim that the other statement opposes, then you have a contradiction. You can then conclude that at least one of the statements is false.\nIf one statement supports a claim that the other statement does not address, then you do not have a contradiction. You can then choose to accept either statement.\nSOLUTION: The first statement states that the Stanford Sentiment Treebank contained movie reviews, not book reviews. The second statement states that the Penn Treebank has been used for language modeling.\nThese two statements do not conflict with each other. The Stanford Sentiment Treebank could contain movie reviews or book reviews, and the Penn Treebank could be used for language modeling."}
{"question": "What is the dimensionality of the null space of the following matrix? A = [[3, 2, \u22129], [\u22126, \u22124, 18], [12, 8, \u221236]]", "choices": [{"label": "A", "text": "0"}, {"label": "B", "text": "1"}, {"label": "C", "text": "2"}, {"label": "D", "text": "3"}], "answerKey": "C", "model_answer": "LECTURE: The null space of a matrix is the set of all vector solutions to the system of linear equations represented by the matrix. The null space of a matrix A is the set of all vectors that satisfy the system of linear equations represented by A.\nThe null space is a subspace of the set of all vectors. If the null space has dimension k, then it can be expressed as the direct sum of a k-dimensional subspace and a (n - k)-dimensional subspace, where n is the number of columns in A.\nThe null space is empty if and only if every vector is a solution to the system of linear equations represented by A. This is equivalent to saying that A is invertible.\nSOLUTION: To find the dimensionality of the null space of A, look for the columns of A that can be multiplied by a scalar to produce a zero vector.\nThere are two ways to do this. One way is to look for multiple columns of A that have a dot product of zero with each other. Since A is a 3x3 matrix, the dot product of two columns is given by the dot product of the matrices.\nFor example, the dot product of the second and third columns is given by the following matrix:"}
{"question": "What are support vectors?", "choices": [{"label": "A", "text": "The examples farthest from the decision boundary."}, {"label": "B", "text": "The only examples necessary to compute f(x) in an SVM."}, {"label": "C", "text": "The data centroid."}, {"label": "D", "text": "All the examples that have a non-zero weight \u03b1k in a SVM."}], "answerKey": "B", "model_answer": "LECTURE: In an SVM, the data is divided into two classes. The decision boundary is a line that separates the two classes.\nA point in the feature space is called a support vector if it is on the decision boundary or if it can be moved to the decision boundary by a small amount.\nThe weight \u03b1k is associated with each support vector. The weight tells you how important the support vector is in finding the decision boundary.\nGiven the question: 'What are support vectors?', the choices:"}
{"question": "Statement 1| Word2Vec parameters were not initialized using a Restricted Boltzman Machine. Statement 2| The tanh function is a nonlinear activation function.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: Many neural network architectures use word embeddings, which are large, continuous vectors of numbers that are assigned to each word in a language. When word embeddings are used to represent words in a language, each word can be represented by a vector.\nWord2Vec is an algorithm that is used to train word embeddings. You can use the Word2Vec algorithm to train word embeddings by using a large corpus, or collection, of text. The algorithm uses the corpus to calculate the vectors for each word.\nThe Word2Vec algorithm has several default parameters. One of the parameters is called the 'minimum count'. This parameter is the smallest number of times a word must appear in the corpus in order to be included in the word embeddings.\nSOLUTION: Statement 1 is true. The Word2Vec algorithm has a default value for the minimum count. The default value is 5. So, if the Word2Vec parameters were not initialized using a Restricted Boltzman Machine, the minimum count is 5.\nStatement 2 is true. The tanh function is a nonlinear activation function. The tanh function maps its input to a value between -1 and 1. Nonlinear activation functions can help a neural network model make decisions that are more complex than simple binary decisions."}
{"question": "If your training loss increases with number of epochs, which of the following could be a possible issue with the learning process?", "choices": [{"label": "A", "text": "Regularization is too low and model is overfitting"}, {"label": "B", "text": "Regularization is too high and model is underfitting"}, {"label": "C", "text": "Step size is too large"}, {"label": "D", "text": "Step size is too small"}], "answerKey": "C", "model_answer": ""}
{"question": "Say the incidence of a disease D is about 5 cases per 100 people (i.e., P(D) = 0.05). Let Boolean random variable D mean a patient \u201chas disease D\u201d and let Boolean random variable TP stand for \"tests positive.\" Tests for disease D are known to be very accurate in the sense that the probability of testing positive when you have the disease is 0.99, and the probability of testing negative when you do not have the disease is 0.97. What is P(D | TP), the posterior probability that you have disease D when the test is positive?", "choices": [{"label": "A", "text": "0.0495"}, {"label": "B", "text": "0.078"}, {"label": "C", "text": "0.635"}, {"label": "D", "text": "0.97"}], "answerKey": "C", "model_answer": "LECTURE: Posterior probability is the probability of a hypothesis after taking into account some evidence. The posterior probability of having a disease D after testing positive is 0.99. This means that after the very accurate test, it is 99% certain that you have the disease."}
{"question": "Statement 1| Traditional machine learning results assume that the train and test sets are independent and identically distributed. Statement 2| In 2017, COCO models were usually pretrained on ImageNet.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: Traditional machine learning models are trained on a separate set of data called the training set. The model learns from the training set and is tested on a separate set of data called the test set.\nThere are several important assumptions behind this approach:\nThe train and test sets are independent. This means that the test set is drawn from the same distribution as the training set.\nThe train and test sets have the same distribution. This means that the data in the test set looks the same as the data in the training set.\nThese assumptions help make it possible to use the test set to evaluate the model's performance. If the model performs well on the test set, it is likely to perform well in real-world situations.\nSOLUTION: The first statement is true. The traditional machine learning model makes the independence and identical distribution assumptions.\nThe second statement is true. In 2017, a common approach to pretraining COCO models was to use ImageNet."}
{"question": "Statement 1| The values of the margins obtained by two different kernels K1(x, x0) and K2(x, x0) on the same training set do not tell us which classifier will perform better on the test set. Statement 2| The activation function of BERT is the GELU.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: The values of the margins obtained by two different kernels K1(x, x0) and K2(x, x0) on the same training set do not tell you which classifier will perform better on the test set.\nWhy? Margins are computed on the training set, which has the same data that the classifiers were trained on. The classifiers were trained to maximize their margin on the training set, so the classifiers will look the same to a margin function.\nSOLUTION: The activation function of BERT is the GELU.\nThe GELU is a smooth, piece-wise linear function that is often used as a substitute for the rectified linear unit (ReLU) activation function. The ReLU is the most commonly used activation function in deep learning."}
{"question": "Which of the following is a clustering algorithm in machine learning?", "choices": [{"label": "A", "text": "Expectation Maximization"}, {"label": "B", "text": "CART"}, {"label": "C", "text": "Gaussian Na\u00efve Bayes"}, {"label": "D", "text": "Apriori"}], "answerKey": "A", "model_answer": "LECTURE: Machine learning algorithms can be grouped into three broad categories: supervised learning, unsupervised learning, and reinforcement learning.\nA supervised learning algorithm is trained on a labeled dataset. The algorithm tries to learn the function that maps an input to an output.\nAn unsupervised learning algorithm is trained on an unlabeled dataset. The algorithm tries to find patterns in the data.\nA reinforcement learning algorithm is trained on a sequence of reward-unrelated, error-related, or reward-related events. The algorithm tries to learn the best action to take in a given state.\nSOLUTION: Expectation Maximization is a clustering algorithm. It is used to find the clusters of data points in a dataset.\nExpectation Maximization is an iterative algorithm. It has two steps: the expectation step and the maximization step. In the expectation step, each data point is assigned to a cluster. In the maximization step, the cluster assignments are reviewed and changed as needed.\nThe other algorithms are not clustering algorithms.\nCART is a classification algorithm. It is used to find the class to which a data point belongs.\nGaussian Na\u00efve Bayes is a classification algorithm. It is used to find the class to which a data point belongs.\nApriori is a classification algorithm. It is used to find the most important items in a dataset."}
{"question": "You've just finished training a decision tree for spam classification, and it is getting abnormally bad performance on both your training and test sets. You know that your implementation has no bugs, so what could be causing the problem?", "choices": [{"label": "A", "text": "Your decision trees are too shallow."}, {"label": "B", "text": "You need to increase the learning rate."}, {"label": "C", "text": "You are overfitting."}, {"label": "D", "text": "None of the above."}], "answerKey": "A", "model_answer": "LECTURE: In the decision tree setup, the maximum depth of the tree is determined by the max_depth parameter. If the tree grows too deep, it will overshoot the best split and start to overfit the training data.\nLooking for the deepest tree.\nYou can use the max_depth parameter to limit the size of a tree. The default value is 50.\nIf the decision tree is too shallow, it will not learn the underlying structure of the data.\nThe data is yielding more complex structure than the tree is.\nYou can use the min_samples_split parameter to require that a split in a decision tree have at least a certain number of samples. The default value is 2.\nFinally, the learning rate of a decision tree is controlled by the learning_rate parameter. A higher learning rate will cause a tree to grow faster.\nSOLUTION: Too many branches.\nDecision trees can become too complex when they have too many branches. This is called overfitting.\nAn overfitted decision tree has grown too deep or has too many nodes. It is likely to start practicing at the training data and will do poorly on new, unseen data.\nYou can try to reduce the size of the tree by increasing the max_depth parameter.\nAlternatively, you can try to reduce the complexity of the tree by reducing the number of nodes. You can do this by decreasing the min_samples_split parameter."}
{"question": "K-fold cross-validation is", "choices": [{"label": "A", "text": "linear in K"}, {"label": "B", "text": "quadratic in K"}, {"label": "C", "text": "cubic in K"}, {"label": "D", "text": "exponential in K"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| Industrial-scale neural networks are normally trained on CPUs, not GPUs. Statement 2| The ResNet-50 model has over 1 billion parameters.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: When you are considering two statements, you can use the following table to determine whether each statement is true or false."}
{"question": "Given two Boolean random variables, A and B, where P(A) = 1/2, P(B) = 1/3, and P(A | \u00acB) = 1/4, what is P(A | B)?", "choices": [{"label": "A", "text": "1/6"}, {"label": "B", "text": "1/4"}, {"label": "C", "text": "3/4"}, {"label": "D", "text": "1"}], "answerKey": "D", "model_answer": "LECTURE: Two Boolean random variables, A and B, are functions that take on the values true and false.\nThe probability that A is true is 1/2, and the probability that B is true is 1/3.\nSOLUTION: The probability that A is true given that B is true is 1/4.\nThe probability that A is true given that B is false is 1/2.\nSo, the probability that A is true given B is 1/4."}
{"question": "Existential risks posed by AI are most commonly associated with which of the following professors?", "choices": [{"label": "A", "text": "Nando de Frietas"}, {"label": "B", "text": "Yann LeCun"}, {"label": "C", "text": "Stuart Russell"}, {"label": "D", "text": "Jitendra Malik"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| Maximizing the likelihood of logistic regression model yields multiple local optimums. Statement 2| No classifier can do better than a naive Bayes classifier if the distribution of the data is known.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: A logistic regression model is a statistical model that is used to predict the probability that an instance will have a certain classification. The model is called logistic because it uses a logistic function, also known as the sigmoid function, to transform the output of the model. The logistic function is a function that takes a real number as input and outputs a number between 0 and 1.\nThe logistic function is defined as follows:\nf(x) = 1 / (1 + e^(-x))\nIn the context of logistic regression, the input to the logistic function is a linear combination of the features used to predict the classification. The output of the logistic function is the probability that an instance has the classification.\nA naive Bayes classifier is a probabilistic classifier that assumes that the features are independent of each other. This assumption makes the model very fast to train and use, but it may not be accurate in all cases.\nA logistic regression model does not make the assumption that the features are independent of each other. This can make the model more accurate, but it also makes the model more complex to train and use.\nSOLUTION: The first statement is true. A logistic regression model can have multiple local optimums. A local optimum is a solution that is not the absolute best, but it is good enough. A logistic regression model has a local optimum whenever the function cannot be improved by making changes to the data.\nA logistic function is a concave function. A concave function is a function that is bowl-shaped. When the input to a logistic function is increased, the output of the function decreases. But the output never goes down to zero. As a result, the logistic function has a local optimum for every value of the input.\nThe second statement is false. A naive Bayes classifier is not necessarily the best classifier when the distribution of the data is known. A naive Bayes classifier assumes that the features are independent of each other. This assumption may not hold in many real-world datasets."}
{"question": "For Kernel Regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether kernel function is Gaussian versus triangular versus box-shaped"}, {"label": "B", "text": "Whether we use Euclidian versus L1 versus L\u221e metrics"}, {"label": "C", "text": "The kernel width"}, {"label": "D", "text": "The maximum height of the kernel function"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| The SVM learning algorithm is guaranteed to find the globally optimal hypothesis with respect to its object function. Statement 2| After being mapped into feature space Q through a radial basis kernel function, a Perceptron may be able to achieve better classification performance than in its original space (though we can\u2019t guarantee this).", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: The SVM learning algorithm is a method for finding the best boundary between two classes. It does this by finding a hyperplane in a high-dimensional space that separates the two classes. This hyperplane is called the optimal hyperplane.\nTo find the optimal hyperplane, SVM uses a technique called Lagrange multipliers. This technique involves adding a term to the optimization problem that encourages the hyperplane to go through a specific point. This point is called the center point.\nBy adding the center point to the optimization problem, SVM can ensure that the optimal hyperplane is closest to the center point among all possible hyperplanes. This property is called the C-supporting lemma.\nGiven the statement:\nThe SVM learning algorithm is guaranteed to find the globally optimal hypothesis with respect to its object function.\nThis statement is true.\nBy the C-supporting lemma, the optimal hyperplane is the best boundary for the two classes. So, SVM finds the globally optimal hypothesis.\nAfter being mapped into feature space Q through a radial basis kernel function, a Perceptron may be able to achieve better classification performance than in its original space (though we can\u2019t guarantee this).\nThis statement is false.\nIt is impossible to prove that a Perceptron will achieve better performance in Q than in its original space."}
{"question": "For a Gaussian Bayes classifier, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether we learn the class centers by Maximum Likelihood or Gradient Descent"}, {"label": "B", "text": "Whether we assume full class covariance matrices or diagonal class covariance matrices"}, {"label": "C", "text": "Whether we have equal class priors or priors estimated from the data."}, {"label": "D", "text": "Whether we allow classes to have different mean vectors or we force them to share the same mean vector"}], "answerKey": "B", "model_answer": "LECTURE: A Gaussian Bayes classifier assumes that the features are independently and identically distributed (i.i.d.) and that the features and class labels are normally distributed. The classifier uses a Bayes rule to calculate the probabilities of each class given the features.\nThe formula for the prior probability of a class is:\nP(Cj) = N(0, Vj)\nThe formula for the likelihood of a class is:\nL(Cj | x) = exp(\u2212(1/2)\u2009xT\u2009Vj\u22121\u2009x)\nThe classifier uses the Bayes rule to calculate the posterior probability of each class given the features:\nP(Cj | x) = P(Cj)\u2009L(Cj | x)\nThe classifier then chooses the class with the highest posterior probability as the predicted class.\nThe trade-off between underfitting and overfitting depends on the choice of the class centers (Cj).\nSuppose the data has K different classes.\nIf the class centers are equal, then the classifier is forced to share the same mean vector across all classes. This can lead to underfitting, because the classifier does not take into account the class-specific differences.\nIf the class centers are different, then the classifier is forced to use different mean vectors across the classes. This can lead to overfitting, because the classifier will fit the training data exactly but may not generalize well to new data."}
{"question": "Statement 1| Overfitting is more likely when the set of training data is small. Statement 2| Overfitting is more likely when the hypothesis space is small.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "LECTURE: In machine learning, a model is trained on a set of data in order to make predictions. Overfitting happens when a model is too complex and fits the training data too closely. This can cause the model to make poor predictions on new data that it has not seen before.\nA model overfits the training data when it is too complex for the amount of training data available. This can happen when the model has too many parameters or is too flexible.\nSOLUTION: The first statement is true. Overfitting is more likely when the set of training data is small. When the set of training data is small, a model has to make many assumptions to fit the data well. This can lead to overfitting.\nThe second statement is false. Overfitting is not more likely when the hypothesis space is small. The hypothesis space is the set of all possible predictions that a model can make. A smaller hypothesis space has fewer predictions to choose from, but this does not necessarily mean that the model will overfit."}
{"question": "Statement 1| Besides EM, gradient descent can be used to perform inference or learning on Gaussian mixture model. Statement 2 | Assuming a fixed number of attributes, a Gaussian-based Bayes optimal classifier can be learned in time linear in the number of records in the dataset.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: In machine learning, there are two main methods for finding a classifier: generic and algorithm-specific.\nA generic method is used when a classification algorithm is not specified. In this case, you can use any algorithm, as long as it is reasonable.\nAn algorithm-specific method is used when a specific classification algorithm is supposed to be used. In this case, you need to find a classifier using only that algorithm.\nSOLUTION: The first statement is true. Gradient descent is an algorithm that can be used to find the minimum of a function. This is what is done when finding a Gaussian-based Bayes optimal classifier.\nThe second statement is false. Even though gradient descent can be used to find a Gaussian-based Bayes optimal classifier, it is not the only method that can be used. An observer looking at the first statement might think that there is no other way to perform inference or learning on a Gaussian mixture model except by using gradient descent."}
{"question": "Statement 1| In a Bayesian network, the inference results of the junction tree algorithm are the same as the inference results of variable elimination. Statement 2| If two random variable X and Y are conditionally independent given another random variable Z, then in the corresponding Bayesian network, the nodes for X and Y are d-separated given Z.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: In a Bayesian network, the inference results of the junction tree algorithm are the same as the inference results of variable elimination.\nThe junction tree algorithm and variable elimination are two methods for determining the posterior probability of a set in a Bayesian network. The junction tree algorithm is based on the structure of the network, while variable elimination is based on the probability equation for a conditional probability.\nThe statements are true. The junction tree algorithm and variable elimination are two ways to calculate the same thing: the posterior probability of a set in a Bayesian network.\nIf two random variable X and Y are conditionally independent given another random variable Z, then in the corresponding Bayesian network, the nodes for X and Y are d-separated given Z.\nThis statement is true. If two random variables are conditionally independent, they have no variable in common that can affect both. So, the nodes for those random variables are d-separated.\nSOLUTION: Each statement is true."}
{"question": "Given a large dataset of medical records from patients suffering from heart disease, try to learn whether there might be different clusters of such patients for which we might tailor separate treatments. What kind of learning problem is this?", "choices": [{"label": "A", "text": "Supervised learning"}, {"label": "B", "text": "Unsupervised learning"}, {"label": "C", "text": "Both (a) and (b)"}, {"label": "D", "text": "Neither (a) nor (b)"}], "answerKey": "B", "model_answer": "LECTURE: Supervised learning is used when you have labeled data. This is data that includes both a set of inputs and a set of desired outputs. The goal of supervised learning is to build a model that can accurately predict the outputs for new inputs.\nFor example, consider a dataset of labeled animal images. The dataset includes images of animals and information about which animal each image represents. This dataset is labeled because the information about which animal each image represents is part of the dataset.\nA model that is trained on this dataset can use its patterns and rules to predict the labels for new animal images.\nUnsolved learning is used when you have unlabeled data. This is data that includes a set of inputs, but no desired outputs. The goal of unsupervised learning is to discover structure in the data, such as groups of similar inputs.\nFor example, consider a dataset of animal images. This dataset is unlabeled because it includes no information about which animal each image represents.\nA model that is trained on this dataset can use its patterns and rules to identify groups of similar animal images.\nSOLUTION: This is an unsupervised learning problem. There are no labeled data sets, and so the data must be used to discover structure in the data."}
{"question": "What would you do in PCA to get the same projection as SVD?", "choices": [{"label": "A", "text": "Transform data to zero mean"}, {"label": "B", "text": "Transform data to zero median"}, {"label": "C", "text": "Not possible"}, {"label": "D", "text": "None of these"}], "answerKey": "A", "model_answer": "LECTURE: Principal component analysis (PCA) is a method for dimensionality reduction. It transforms a large set of variables into a smaller set of variables, called principal components. The principal components are ordered by their importance.\nThe first principal component is the one that explains the most variation in the data. The second principal component explains the most variation among the remaining data points after the first principal component has been removed. This process is called variance thresholding.\nIf one principal component explains less than a certain amount of variation, it is removed. This certain amount is called the variance threshold.\nBy enough thresholds, the complete data set is reconstructed.\nThe principal components are calculated by performing an eigenvalue decomposition of the covariance matrix of the data.\nThe covariance matrix is a matrix of pairwise covariances. Its eigenvectors are the principal components. The eigenvalues indicate how much variance is explained by each principal component."}
{"question": "Statement 1| The training error of 1-nearest neighbor classifier is 0. Statement 2| As the number of data points grows to infinity, the MAP estimate approaches the MLE estimate for all possible priors. In other words, given enough data, the choice of prior is irrelevant.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: A classifier is a function that maps an input to an output. The output is called the class of the input. A 1-nearest neighbor classifier classifies an input by choosing the class of its 1-nearest neighbor. The 1-nearest neighbor of an input is the data point in the training set that is closest to the input.\nThe training error of a classifier is the error it makes on the training set. The generalization error of a classifier is the error it makes on new, unseen data.\nSOLUTION: The first statement is true. The training error of a 1-nearest neighbor classifier is 0. This classifier chooses the class of its 1-nearest neighbor. The 1-nearest neighbor of any input is the input itself. So, the classifier classifies the input by assigning it its own class.\nThe second statement is false. The MAP estimate is the Maximum a Posteriori estimate. The MAP estimate is an estimate of the parameters of a probabilistic model. The MLE estimate is the Maximum Likelihood estimate. The MLE estimate is an estimate of the parameters of a probabilistic model.\nFor any given prior, the MAP estimate and the MLE estimate are the same. But the MAP estimate is based on the prior. The MLE estimate is based on the data. As the number of data points grows to infinity, the MLE estimate approaches the maximum likelihood estimate for all possible priors. But the MAP estimate does not."}
{"question": "When doing least-squares regression with regularisation (assuming that the optimisation can be done exactly), increasing the value of the regularisation parameter \u03bb the testing error.", "choices": [{"label": "A", "text": "will never decrease the training error."}, {"label": "B", "text": "will never increase the training error."}, {"label": "C", "text": "will never decrease the testing error."}, {"label": "D", "text": "will never increase"}], "answerKey": "A", "model_answer": "LECTURE: When do least-squares regression with regularization, the regularization parameter \u03bb controls the trade-off between the training error and the testing error.\nThe training error is the error that occurs on the training data. The testing error is the error that occurs on the testing data.\nSOLUTION: Increasing the value of the regularization parameter \u03bb will decrease the training error and increase the testing error."}
{"question": "Which of the following best describes what discriminative approaches try to model? (w are the parameters in the model)", "choices": [{"label": "A", "text": "p(y|x, w)"}, {"label": "B", "text": "p(y, x)"}, {"label": "C", "text": "p(w|x, w)"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": "LECTURE: Discriminative approaches try to model the probability of a class."}
{"question": "Statement 1| CIFAR-10 classification performance for convolution neural networks can exceed 95%. Statement 2| Ensembles of neural networks do not improve classification accuracy since the representations they learn are highly correlated.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: Statements 1 and 2 are false.\nEnsembles of neural networks do improve classification accuracy, and the representations they learn are not highly correlated."}
{"question": "Which of the following points would Bayesians and frequentists disagree on?", "choices": [{"label": "A", "text": "The use of a non-Gaussian noise model in probabilistic regression."}, {"label": "B", "text": "The use of probabilistic modelling for regression."}, {"label": "C", "text": "The use of prior distributions on the parameters in a probabilistic model."}, {"label": "D", "text": "The use of class priors in Gaussian Discriminant Analysis."}], "answerKey": "C", "model_answer": "LECTURE: Bayesian and frequentist approaches to statistical modeling are two common ways to use probability in data analysis.\nBayesian methods begin with a prior belief about the parameters of a model and update this belief as evidence is gathered from the data. This approach is particularly useful when the researcher has some prior knowledge about the world, or when the parameters of the model are complex.\nFrequentist methods do not use prior knowledge about the parameters. Instead, they describe how often the parameters would need to take certain values, given the data. This approach is often used when developing a model from scratch.\nSOLUTION: Bayesian and frequentist statisticians would disagree about the use of class priors in Gaussian Discriminant Analysis.\nClass priors are informative prior distributions on the classes. They represent the conditional probability of the class labels, given the observed data.\nFrequentist statisticians would not use class priors, because frequentist methods do not update the prior distribution as data are observed.\nBayesian statisticians would use class priors, because Bayesian methods update the prior distribution with the data."}
{"question": "Statement 1| The BLEU metric uses precision, while the ROGUE metric uses recall. Statement 2| Hidden markov models were frequently used to model English sentences.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| ImageNet has images of various resolutions. Statement 2| Caltech-101 has more images than ImageNet.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: It is important to read and understand all parts of a statement before deciding if it is true.\nIf one part of a statement is true, but the other part is false, the entire statement is false.\nIf each part of a statement is true, the statement is true.\nSOLUTION: Each part of the first statement is true, so the statement is true.\nThe ImageNet database has images of various resolutions.\nCaltech-101 has more images than ImageNet.\nThe second statement is also true."}
{"question": "Which of the following is more appropriate to do feature selection?", "choices": [{"label": "A", "text": "Ridge"}, {"label": "B", "text": "Lasso"}, {"label": "C", "text": "both (a) and (b)"}, {"label": "D", "text": "neither (a) nor (b)"}], "answerKey": "B", "model_answer": "LECTURE: In order to select relevant features for a model, you can use techniques such as Ridge and Lasso.\nRidge is a technique that helps to prevent overfitting by adding a regularization term to the cost function. This regularization term has the effect of reducing the weights of the features. Ridge can be used to handle multicollinearity, which is a common problem in large-scale feature sets.\nLasso is a technique that uses a regularization term to produce a set of sparse features. A sparse feature set is one in which some features have been eliminated. Lasso can be used to reduce the number of features and to improve the performance of a model.\nSOLUTION: Ridge is more appropriate for feature selection. Ridge and Lasso are similar in that they both use regularization to produce a set of sparse features. However, Ridge is more forgiving about multicollinearity, which is a common problem in large-scale feature sets."}
{"question": "Suppose you are given an EM algorithm that finds maximum likelihood estimates for a model with latent variables. You are asked to modify the algorithm so that it finds MAP estimates instead. Which step or steps do you need to modify?", "choices": [{"label": "A", "text": "Expectation"}, {"label": "B", "text": "Maximization"}, {"label": "C", "text": "No modification necessary"}, {"label": "D", "text": "Both"}], "answerKey": "B", "model_answer": ""}
{"question": "For a Gaussian Bayes classifier, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether we learn the class centers by Maximum Likelihood or Gradient Descent"}, {"label": "B", "text": "Whether we assume full class covariance matrices or diagonal class covariance matrices"}, {"label": "C", "text": "Whether we have equal class priors or priors estimated from the data"}, {"label": "D", "text": "Whether we allow classes to have different mean vectors or we force them to share the same mean vector"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| For any two variables x and y having joint distribution p(x, y), we always have H[x, y] \u2265 H[x] + H[y] where H is entropy function. Statement 2| For some directed graphs, moralization decreases the number of edges present in the graph.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: For two variables x and y, the joint distribution p(x, y) has the following properties:\n1. H[p(x, y)] \u2264 H[p(x)] + H[p(y)].\nThis is because the joint distribution p(x, y) can be broken down into the product of the marginal distributions p(x) and p(y).\n2. H[p(x, y)] = H[p(x)] + H[p(y)].\nThis is true if and only if there is some value in the range of p(x) and p(y) for which the marginal distribution is the same for both p(x) and p(y).\nSOLUTION: For any two variables x and y having joint distribution p(x, y), we always have H[x, y] \u2265 H[x] + H[y].\nThis is true because H[x, y] represents the entropy of the distribution for both x and y, and H[x] and H[y] represent the entropy for x and y, respectively."}
{"question": "Which of the following is NOT supervised learning?", "choices": [{"label": "A", "text": "PCA"}, {"label": "B", "text": "Decision Tree"}, {"label": "C", "text": "Linear Regression"}, {"label": "D", "text": "Naive Bayesian"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| A neural network's convergence depends on the learning rate. Statement 2| Dropout multiplies randomly chosen activation values by zero.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Which one of the following is equal to P(A, B, C) given Boolean random variables A, B and C, and no independence or conditional independence assumptions between any of them?", "choices": [{"label": "A", "text": "P(A | B) * P(B | C) * P(C | A)"}, {"label": "B", "text": "P(C | A, B) * P(A) * P(B)"}, {"label": "C", "text": "P(A, B | C) * P(C)"}, {"label": "D", "text": "P(A | B, C) * P(B | A, C) * P(C | A, B)"}], "answerKey": "C", "model_answer": "LECTURE: The rules for probability require that the probabilities of all events must be between 0 and 1. If the probabilities are not between 0 and 1, the calculations involving those probabilities are undefined.\nIf one event is entirely within the other event, the probability of the smaller event is equal to the probability of the larger event.\nFor example, if A is entirely within B, then P(A) = P(A | B).\nIf A and B are entirely within C, then P(A | B) = P(A, B | C).\nSOLUTION: Use the fact that P(A, B, C) = P(A | B, C) * P(B | A, C) * P(C | A, B).\nThis equation is based on the fact that the probability of all events happening is equal to the product of the probabilities of each event happening."}
{"question": "Which of the following tasks can be best solved using Clustering.", "choices": [{"label": "A", "text": "Predicting the amount of rainfall based on various cues"}, {"label": "B", "text": "Detecting fraudulent credit card transactions"}, {"label": "C", "text": "Training a robot to solve a maze"}, {"label": "D", "text": "All of the above"}], "answerKey": "B", "model_answer": "LECTURE: Clustering is a type of machine learning that involves grouping data into subsets. In clustering, the program finds patterns in the data and groups data points that are similar to each other.\nSOLUTION: This task involves grouping data into subsets.\nPredicting the amount of rainfall based on various cues can be best solved using Clustering. The program can group data points that are similar in terms of rainfall amounts.\nDetecting fraudulent credit card transactions requires identifying patterns in the data.\nTraining a robot to solve a maze involves finding a pattern in the data and grouping data points that are similar to each other."}
{"question": "After applying a regularization penalty in linear regression, you find that some of the coefficients of w are zeroed out. Which of the following penalties might have been used?", "choices": [{"label": "A", "text": "L0 norm"}, {"label": "B", "text": "L1 norm"}, {"label": "C", "text": "L2 norm"}, {"label": "D", "text": "either (a) or (b)"}], "answerKey": "D", "model_answer": ""}
{"question": "A and B are two events. If P(A, B) decreases while P(A) increases, which of the following is true?", "choices": [{"label": "A", "text": "P(A|B) decreases"}, {"label": "B", "text": "P(B|A) decreases"}, {"label": "C", "text": "P(B) decreases"}, {"label": "D", "text": "All of above"}], "answerKey": "B", "model_answer": "LECTURE: If P(A, B) decreases, then either P(A|B) decreases or P(B|A) decreases."}
{"question": "Statement 1| When learning an HMM for a fixed set of observations, assume we do not know the true number of hidden states (which is often the case), we can always increase the training data likelihood by permitting more hidden states. Statement 2| Collaborative filtering is often a useful model for modeling users' movie preference.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: When learning an HMM, you have to choose the number of hidden states. You can try different numbers and see if the model's performance improves.\nSOLUTION: The first statement is true. When learning an HMM for a fixed set of observations, you can always increase the training data likelihood by permitting more hidden states.\nThe second statement is true. Collaborative filtering is often a useful model for modeling users' movie preferences."}
{"question": "You are training a linear regression model for a simple estimation task, and notice that the model is overfitting to the data. You decide to add in $\\ell_2$ regularization to penalize the weights. As you increase the $\\ell_2$ regularization coefficient, what will happen to the bias and variance of the model?", "choices": [{"label": "A", "text": "Bias increase ; Variance increase"}, {"label": "B", "text": "Bias increase ; Variance decrease"}, {"label": "C", "text": "Bias decrease ; Variance increase"}, {"label": "D", "text": "Bias decrease ; Variance decrease"}], "answerKey": "B", "model_answer": "LECTURE: When you have a model that is performing well but you suspect that it is overfitting to the data, you can add regularization to the model to reduce the overfitting. One form of regularization that can be used in a linear regression model is $\\ell_2$ regularization, which adds a term to the objective function that is proportional to the square of the weight vector.\nThe effect of adding regularization to a linear regression model is to \"balance\" the importance of the model fitting the data and having small weights. As the magnitude of the weights becomes smaller, the model's capacity to overfit the data is reduced.\nSOLUTION: As you increase the magnitude of the $\\ell_2$ regularization coefficient, the magnitude of the weights becomes smaller. Therefore, the bias of the model decreases as the magnitude of the $\\ell_2$ regularization coefficient increases.\nThe variance of the model also decreases as the magnitude of the $\\ell_2$ regularization coefficient increases. This is because the regularization term acts to penalize large weights, which are then avoided in the optimization process."}
{"question": "Which PyTorch 1.8 command(s) produce $10\\times 5$ Gaussian matrix with each entry i.i.d. sampled from $\\mathcal{N}(\\mu=5,\\sigma^2=16)$ and a $10\\times 10$ uniform matrix with each entry i.i.d. sampled from $U[-1,1)$?", "choices": [{"label": "A", "text": "\\texttt{5 + torch.randn(10,5) * 16} ; \\texttt{torch.rand(10,10,low=-1,high=1)}"}, {"label": "B", "text": "\\texttt{5 + torch.randn(10,5) * 16} ; \\texttt{(torch.rand(10,10) - 0.5) / 0.5}"}, {"label": "C", "text": "\\texttt{5 + torch.randn(10,5) * 4} ; \\texttt{2 * torch.rand(10,10) - 1}"}, {"label": "D", "text": "\\texttt{torch.normal(torch.ones(10,5)*5,torch.ones(5,5)*16)} ; \\texttt{2 * torch.rand(10,10) - 1}"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| The ReLU's gradient is zero for $x<0$, and the sigmoid gradient $\\sigma(x)(1-\\sigma(x))\\le \\frac{1}{4}$ for all $x$. Statement 2| The sigmoid has a continuous gradient and the ReLU has a discontinuous gradient.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Which is true about Batch Normalization?", "choices": [{"label": "A", "text": "After applying batch normalization, the layer\u2019s activations will follow a standard Gaussian distribution."}, {"label": "B", "text": "The bias parameter of affine layers becomes redundant if a batch normalization layer follows immediately afterward."}, {"label": "C", "text": "The standard weight initialization must be changed when using Batch Normalization."}, {"label": "D", "text": "Batch Normalization is equivalent to Layer Normalization for convolutional neural networks."}], "answerKey": "B", "model_answer": "LECTURE: Batch Normalization is a technique for improving the training of deep neural networks. It is used to accelerate training and improve the generalization of deep networks by normalizing the activations of the layers.\nBatch Normalization works by applying a combination of normalization and interpolation to the activations of each layer. The result is that the activations are transformed to have a smaller variance.\nThere are several ways to do normalization. One way is to apply the following transformation to each element of the activation:\nx \u2192 x\u25aa\u200a=x\u2212\u03bc\u03c3x \u2192 x\u25aa\u200a=x\u2212\u03bc\u03c3where x\u25aa is the normalized activation, x is the original activation, and \u03bc and \u03c3 are the mean and standard deviation of the activations, respectively.\nAnother way is to apply the following transformation to each element of the activation:\nx \u2192 x\u25a9 =\u03c3x+\u03bcx \u2192 x\u25a9 =\u03c3x+\u03bcwhere x\u25a9 is the normalized activation, x is the original activation, and \u03bc and \u03c3 are the mean and standard deviation of the activations, respectively.\nThe choice of which method to use is determined by the presence of a bias parameter in the layer. The first method is used if the layer has a bias parameter, and the second method is used if the layer does not have a bias parameter.\nThe interpolation is applied to the normalized activation to transform it back to the original activation range. The interpolation is defined as:\nx\u25aa\u2192x\u25ab=mx\u25aa+bx\u25aa\u2192x\u25ab=mx\u25aa+bwhere m and b are the slope and y-intercept of the line that passes through the point (\u03bc, \u03c3) and the origin, and x\u25aa and x\u25ab are the original and normalized activations, respectively.\nWhen a Batch Normalization layer is used, the activations of the layer are first normalized and then interpolated to transform them back to the original activation range.\nThe standard weight initialization must be changed when using Batch Normalization. With Batch Normalization, the weights are not initialized with zeros. Instead, the weights are initialized to the mean value of the normalized activations."}
{"question": "Suppose we have the following objective function: $\\argmin_{w} \\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\gamma \\norm{w}^2_2$ What is the gradient of $\\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\lambda \\norm{w}^2_2$ with respect to $w$?", "choices": [{"label": "A", "text": "$\\nabla_w f(w) = (X^\\top X + \\lambda I)w - X^\\top y + \\lambda w$"}, {"label": "B", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + \\lambda$"}, {"label": "C", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + \\lambda w$"}, {"label": "D", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + (\\lambda+1) w$"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following is true of a convolution kernel?", "choices": [{"label": "A", "text": "Convolving an image with $\\begin{bmatrix}1 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$ would not change the image"}, {"label": "B", "text": "Convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ would not change the image"}, {"label": "C", "text": "Convolving an image with $\\begin{bmatrix}1 & 1 & 1\\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}$ would not change the image"}, {"label": "D", "text": "Convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ would not change the image"}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following is false?", "choices": [{"label": "A", "text": "Semantic segmentation models predict the class of each pixel, while multiclass image classifiers predict the class of entire image."}, {"label": "B", "text": "A bounding box with an IoU (intersection over union) equal to $96\\%$ would likely be considered at true positive."}, {"label": "C", "text": "When a predicted bounding box does not correspond to any object in the scene, it is considered a false positive."}, {"label": "D", "text": "A bounding box with an IoU (intersection over union) equal to $3\\%$ would likely be considered at false negative."}], "answerKey": "D", "model_answer": "Semantic segmentation models predict the class of each pixel, while multiclass image classifiers predict the class of the entire image."}
{"question": "Which of the following is false?", "choices": [{"label": "A", "text": "The following fully connected network without activation functions is linear: $g_3(g_2(g_1(x)))$, where $g_i(x) = W_i x$ and $W_i$ are matrices."}, {"label": "B", "text": "Leaky ReLU $\\max\\{0.01x,x\\}$ is convex."}, {"label": "C", "text": "A combination of ReLUs such as $ReLU(x) - ReLU(x-1)$ is convex."}, {"label": "D", "text": "The loss $\\log \\sigma(x)= -\\log(1+e^{-x})$ is concave"}], "answerKey": "C", "model_answer": ""}
{"question": "We are training fully connected network with two hidden layers to predict housing prices. Inputs are $100$-dimensional, and have several features such as the number of square feet, the median family income, etc. The first hidden layer has $1000$ activations. The second hidden layer has $10$ activations. The output is a scalar representing the house price. Assuming a vanilla network with affine transformations and with no batch normalization and no learnable parameters in the activation function, how many parameters does this network have?", "choices": [{"label": "A", "text": "111021"}, {"label": "B", "text": "110010"}, {"label": "C", "text": "111110"}, {"label": "D", "text": "110011"}], "answerKey": "A", "model_answer": "LECTURE: Neurons in a fully connected network with two hidden layers have two sets of parameters: the weights and the biases.\nEach neuron in the first hidden layer has 1000 weights and 10 biases.\nEach neuron in the second hidden layer has 10 weights and 1 bias.\nEach neuron in the output layer has 1 weight and 1 bias.\nSo, each neuron in the network has 1013 parameters.\nThere are 1000 neurons in the first hidden layer, 10 neurons in the second hidden layer, and 1 neuron in the output layer. So, the network has a total of 1000 \u00d7 1013 + 10 \u00d7 111 + 1 \u00d7 1 = 111021 parameters."}
{"question": "Statement 1| The derivative of the sigmoid $\\sigma(x)=(1+e^{-x})^{-1}$ with respect to $x$ is equal to $\\text{Var}(B)$ where $B\\sim \\text{Bern}(\\sigma(x))$ is a Bernoulli random variable. Statement 2| Setting the bias parameters in each layer of neural network to 0 changes the bias-variance trade-off such that the model's variance increases and the model's bias decreases", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: The bias-variance trade-off is a fundamental challenge in the design of machine learning algorithms. A model with high bias is overly simplified and has a high variance, which means its performance is highly sensitive to the training data. A model with high variance is overly complex and has a high bias, which means it is sensitive to noise in the training data."}
