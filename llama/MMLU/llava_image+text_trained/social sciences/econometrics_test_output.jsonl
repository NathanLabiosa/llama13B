{"question": "Which one of the following is the most appropriate definition of a 99% confidence interval?", "choices": [{"label": "A", "text": "99% of the time in repeated samples, the interval would contain the true value of the parameter"}, {"label": "B", "text": "99% of the time in repeated samples, the interval would contain the estimated value of the parameter"}, {"label": "C", "text": "99% of the time in repeated samples, the null hypothesis will be rejected"}, {"label": "D", "text": "99% of the time in repeated samples, the null hypothesis will not be rejected when it was false"}], "answerKey": "A", "model_answer": "the time in repeated samples, the interval would contain the true value of the parameter."}
{"question": "What is the main difference between the Dickey Fuller (DF) and Phillips-Perron (PP) approaches to unit root testing?", "choices": [{"label": "A", "text": "ADF is a single equation approach to unit root testing while PP is a systems approach"}, {"label": "B", "text": "PP tests reverse the DF null and alternative hypotheses so that there is stationarity under the null hypothesis of the PP test"}, {"label": "C", "text": "The PP test incorporates an automatic correction for autocorrelated residuals in the test regression"}, {"label": "D", "text": "PP tests have good power in small samples whereas DF tests do not."}], "answerKey": "C", "model_answer": "in? Sure! The answer is (A). The ADF (Augmented Dickey-Fuller) and PP (Phillips-Perron) approaches are both unit root tests, which are used to determine whether a time series is stationary or not. The main difference between the two approaches is that ADF is a single equation approach, while PP is a systems approach. ADF tests each equation separately to determine if it is stationary or not, while PP tests the entire system of equations simultaneously. This means that PP can test for interdependencies between the variables, which ADF cannot. Additionally, PP incorporates an automatic correction for autocorrelated residuals in the test regression, which can improve the accuracy of the test. Overall, PP is a more powerful and flexible approach than ADF, but it can be more complex to implement."}
{"question": "If there were a leverage effect in practice, what would be the shape of the news impact curve for as model that accounted for that leverage?", "choices": [{"label": "A", "text": "It would rise more quickly for negative disturbances than for positive ones of the same magnitude"}, {"label": "B", "text": "It would be symmetrical about zero"}, {"label": "C", "text": "It would rise less quickly for negative disturbances than for positive ones of the same magnitude"}, {"label": "D", "text": "It would be zero for all positive disturbances"}], "answerKey": "A", "model_answer": "he correct answer is (A) It would rise more quickly for negative disturbances than for positive ones of the same magnitude.\nA leverage effect occurs when an individual or organization uses borrowed funds to increase the magnitude of their responses to a disturbance, which can lead to a more pronounced response to negative disturbances than to positive ones of the same magnitude. This means that the news impact curve associated with that model would have a steeper slope for negative disturbances and a shallower slope for positive disturbances."}
{"question": "Which of the following statements is false concerning the linear probability model?", "choices": [{"label": "A", "text": "There is nothing in the model to ensure that the estimated probabilities lie between zero and one"}, {"label": "B", "text": "Even if the probabilities are truncated at zero and one, there will probably be many observations for which the probability is either exactly zero or exactly one"}, {"label": "C", "text": "The error terms will be heteroscedastic and not normally distributed"}, {"label": "D", "text": "The model is much harder to estimate than a standard regression model with a continuous dependent variable"}], "answerKey": "D", "model_answer": "The correct answer is (A) There is nothing in the model to ensure that the estimated probabilities lie between zero and one. The linear probability model assumes that the independent variables are endogenous, which means that they are determined by the error terms as well as by the model's own parameters. The model also assumes that the estimated probabilities are equal to the ratios of the estimated coefficients to the standard errors of the coefficients. This means that the estimated probabilities can exceed one if the standard errors are greater than one, and can be less than one if the standard errors are less than one. It is important to note that the linear probability model is a simple and flexible model that can be used for a variety of purposes, including estimating the relationship between a set of independent variables and a binary dependent variable, and making predictions about the probability of the dependent variable taking a particular value."}
{"question": "Which of the following statements concerning the regression population and sample is FALSE?", "choices": [{"label": "A", "text": "The population is the total collection of all items of interest"}, {"label": "B", "text": "The population can be infinite"}, {"label": "C", "text": "In theory, the sample could be larger than the population"}, {"label": "D", "text": "A random sample is one where each individual item from the population is equally likely to be drawn."}], "answerKey": "C", "model_answer": "The correct answer is (A) The population is the total collection of all items of interest. This statement is false because the regression population is the sample of items from which the regression is being made. In other words, the regression population is a subset of the population, and not the entire population itself. The other statements are accurate: (B) The population can be infinite, (C) A random sample is one where each individual item from the population is equally likely to be drawn, and (D) A random sample is one where each individual item from the population has an equal probability of being selected."}
{"question": "Which of the following statements is INCORRECT concerning a comparison of the Box-Pierce Q and the Ljung-Box Q* statistics for linear dependence in time series?", "choices": [{"label": "A", "text": "Asymptotically, the values of the two test statistics will be equal"}, {"label": "B", "text": "The Q test has better small-sample properties than the Q*"}, {"label": "C", "text": "The Q test is sometimes over-sized for small samples"}, {"label": "D", "text": "As the sample size tends towards infinity, both tests will show a tendency to always reject the null hypothesis of zero autocorrelation coefficients."}], "answerKey": "B", "model_answer": ""}
{"question": "A parsimonious model is one that", "choices": [{"label": "A", "text": "Includes too many variables"}, {"label": "B", "text": "Includes as few variables as possible to explain the data"}, {"label": "C", "text": "Is a well-specified model"}, {"label": "D", "text": "Is a mis-specified model"}], "answerKey": "A", "model_answer": "The correct answer is (B) Includes as few variables as possible to explain the data. A parsimonious model is one that uses the minimum number of variables necessary to accurately explain the data. This means that the model should not include any variables that are not statistically significant predictors of the outcome variable. In general, a parsimonious model is preferred over a more complex model because it is easier to interpret and less prone to overfitting."}
{"question": "Which of the following is NOT a feature of continuously compounded returns (i.e. log-returns)?", "choices": [{"label": "A", "text": "They can be interpreted as continuously compounded changes in the prices"}, {"label": "B", "text": "They can be added over time to give returns for longer time periods"}, {"label": "C", "text": "They can be added across a portfolio of assets to give portfolio returns"}, {"label": "D", "text": "They are usually fat-tailed"}], "answerKey": "C", "model_answer": "The correct answer is B) They can be added over time to give returns for longer time periods. Continuously compounded returns (i.e. log-returns) are returns that are calculated as the exponential growth rate of an investment over time. They can be used to model the growth of a portfolio of assets over time, and can be used to calculate the return on a single investment over a certain period. However, they cannot be added over time to give returns for longer time periods, as they are calculated based on discrete time intervals rather than continuous time intervals. This means that the returns at different time points cannot be simply added together to give the return for a longer time period."}
{"question": "Which of the following features of financial asset return time-series could be captured using a standard GARCH(1,1) model?\n\ni) Fat tails in the return distribution\n\n\nii) Leverage effects\n\n\niii) Volatility clustering\n\n\niv) Volatility affecting returns", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": ""}
{"question": "Consider the estimation of a GARCH-M model. If the data employed were a time-series of daily corporate bond percentage returns, which of the following would you expect the value of the GARCH-in-mean parameter estimate to be?", "choices": [{"label": "A", "text": "Less than -1"}, {"label": "B", "text": "Between -1 and 0"}, {"label": "C", "text": "Between 0 and 1"}, {"label": "D", "text": "Bigger than 1"}], "answerKey": "C", "model_answer": "The correct answer is (A) Less than -1.\nThe GARCH-in-mean parameter in a GARCH-M model is used to capture the mean-reversion property of a time-series. In a time-series of daily corporate bond percentage returns, the mean of the returns should be less than 1, which means that the returns tend to revert back to a long-term average of less than 1. Therefore, the GARCH-in-mean parameter estimate is likely to be less than -1, indicating that the returns are mean-reverting. The other choices are not necessarily true, as the value of the GARCH-in-mean parameter is dependent on the specific data and the assumptions of the GARCH-M model."}
{"question": "Under which of the following situations would bootstrapping be preferred to pure simulation?\n\ni) If it is desired that the distributional properties of the data in the experiment\n\nare the same as those of some actual data\n\n\nii) If it is desired that the distributional properties of the data in the experiment\n\nare known exactly\n\n\niii) If the distributional properties of the actual data are unknown\n\n\niv) If the sample of actual data available is very small", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following may be consequences of one or more of the CLRM assumptions being violated?\n\ni) The coefficient estimates are not optimal\n\n\nii) The standard error estimates are not optimal\n\n\niii) The distributions assumed for the test statistics are inappropriate\n\n\niv) Conclusions regarding the strength of relationships between the dependent\n\nand independent variables may be invalid.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "rect answer is (D) (i), (ii), (iii), and (iv). All four CLRM assumptions can be violated, and each of them can lead to consequences for the conclusions drawn from the statistical analysis. The coefficient estimates may not be optimal if there are omitted variable bias or endogenous selection bias, and the conclusions regarding the strength of relationships between the dependent and independent variables may be invalid. The standard error estimates may not be optimal if there are model misspecification or non-random sampling, and the distributions assumed for the test statistics may not be appropriate if there are non-normal or non-constant variance or if there are multiple testing or non-independent observations."}
{"question": "Which of the following statements is true concerning forecasting in econometrics?", "choices": [{"label": "A", "text": "Forecasts can only be made for time-series data"}, {"label": "B", "text": "Mis-specified models are certain to produce inaccurate forecasts"}, {"label": "C", "text": "Structural forecasts are simpler to produce than those from time series models"}, {"label": "D", "text": "In-sample forecasting ability is a poor test of model adequacy"}], "answerKey": "D", "model_answer": "The correct answer is (A) Forecasts can only be made for time-series data.\nEconometrics is the application of statistical methods to economic data in order to evaluate theoretical models of economic relationships. One of the main tasks in econometrics is to make forecasts, which involve predicting future values of a variable based on past values. However, forecasting is only possible for time-series data, which is a type of data that has values for each time period that can be ordered. Therefore, statement (A) is true.\nThe other three statements are false:\n(B) Mis-specified models are certain to produce inaccurate forecasts. A model that is mis-specified may produce inaccurate forecasts, but it is not necessarily the case that all mis-specified models will always produce inaccurate forecasts.\n(C) Structural forecasts are simpler to produce than those from time series models. Structural forecasts typically involve making assumptions about the underlying economic relationships, which can be more complex than the relationships modeled by time series models.\n(D) In-sample forecasting ability is a poor test of model adequacy. In-sample forecasting ability can be a useful diagnostic tool to check the adequacy of a model, but it is not the only test and should not be the only factor considered when evaluating a model."}
{"question": "The pacf is necessary for distinguishing between", "choices": [{"label": "A", "text": "An AR and an MA model"}, {"label": "B", "text": "An AR and an ARMA model"}, {"label": "C", "text": "An MA and an ARMA model"}, {"label": "D", "text": "Different models from within the ARMA family"}], "answerKey": "B", "model_answer": ": \u200b"}
{"question": "Negative residual autocorrelation is indicated by which one of the following?", "choices": [{"label": "A", "text": "A cyclical pattern in the residuals"}, {"label": "B", "text": "An alternating pattern in the residuals"}, {"label": "C", "text": "A complete randomness in the residuals"}, {"label": "D", "text": "Residuals that are all close to zero"}], "answerKey": "B", "model_answer": "ernating pattern in the residuals."}
{"question": "Which of the following statements are true concerning a comparison between ARCH(q) and GARCH(1,1) models?\n\ni) The ARCH(q) model is likely to be the more parsimonious\n\n\nii) The ARCH(q) model is the more likely to violate non-negativity constraints\n\n\niii) The ARCH(q) model can allow for an infinite number of previous lags of squared\n\nreturns to affect the current conditional variance\n\n\niv) The GARCH(1,1) model will usually be sufficient to capture all of the dependence\n\nin the conditional variance", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following statements are true concerning a triangular or recursive system?\n\ni) The parameters can be validly estimated using separate applications of OLS to\n\neach equation\n\n\nii) The independent variables may be correlated with the error terms in other\n\nequations\n\n\niii) An application of 2SLS would lead to unbiased but inefficient parameter estimates\n\n\niv) The independent variables may be correlated with the error terms in the equations\n\nin which they appear as independent variables", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "The correct answer is (C) (i), (ii), and (iii) only.\n\nExplanation:\n\n* (i) is true because OLS can only be applied to each equation separately, but not across equations.\n* (ii) is true because the independent variables in one equation may be correlated with the error terms in other equations.\n* (iii) is false because 2SLS can lead to biased but efficient parameter estimates.\n* (iv) is true because the independent variables in each equation may be correlated with the error terms in that equation."}
{"question": "Which one of the following statements best describes the algebraic representation of the fitted regression line?", "choices": [{"label": "A", "text": "\\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t + \\hat{u}_t"}, {"label": "B", "text": "\\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t"}, {"label": "C", "text": "\\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t + u_t"}, {"label": "D", "text": "y_t = \\hat{\\alpha} + \\hat{\\beta}x_t + \\hat{u}_t"}], "answerKey": "B", "model_answer": "The correct answer is (A) \\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x\\_t + \\hat{u}\\_{t}.\nThe algebraic representation of the fitted regression line is given by the equation of the line that best fits the data points in a scatter plot. The slope of the line is represented by the parameter \\hat{\\beta}, which is the coefficient of the independent variable (x) in the equation. The intercept or y-intercept is represented by the parameter \\hat{\\alpha}, which is the constant term. The error or residual term is represented by the parameter \\hat{u}\\_{t}, which is the difference between the actual value of the dependent variable (y\\_t) and the predicted value calculated by the regression line."}
{"question": "What are the dimensions of $\\hat{u}^t \\hat{u}?", "choices": [{"label": "A", "text": "T x k"}, {"label": "B", "text": "T x 1"}, {"label": "C", "text": "k x 1"}, {"label": "D", "text": "1 x 1"}], "answerKey": "D", "model_answer": ""}
{"question": "The characteristic roots of the MA process\n\n$y_t = -3u_{t-1} + u_{t-2} + u_t$\n\nare", "choices": [{"label": "A", "text": "1 and 2"}, {"label": "B", "text": "1 and 0.5"}, {"label": "C", "text": "2 and -0.5"}, {"label": "D", "text": "1 and -3"}], "answerKey": "B", "model_answer": "The characteristic roots of a system are the values (complex numbers) that make the system's growth rate equal to the carrying capacity of the environment. In this case, the characteristic roots of the MA process are 1 and 2.\nTherefore, the correct answer is (A) 1 and 2."}
{"question": "Which of the following is an equivalent expression for saying that the explanatory variable is \"non-stochastic\"?", "choices": [{"label": "A", "text": "The explanatory variable is partly random"}, {"label": "B", "text": "The explanatory variable is fixed in repeated samples"}, {"label": "C", "text": "The explanatory variable is correlated with the errors"}, {"label": "D", "text": "The explanatory variable always has a value of one"}], "answerKey": "B", "model_answer": "The correct answer is (B) The explanatory variable is fixed in repeated samples.\nIn statistics, \"non-stochastic\" refers to a variable that is fixed and not subject to random fluctuations or variations. In contrast, \"stochastic\" refers to a variable that is subject to random fluctuations or variations. The term \"partly random\" in choice (A) suggests that the variable is only partly fixed, which is not the same as being non-stochastic. The term \"correlated with the errors\" in choice (C) suggests that the variable is related to the error term, which is not the same as being non-stochastic. The term \"always has a value of one\" in choice (D) suggests that the variable is constant, which is not the same as being non-stochastic."}
{"question": "Suppose that the Durbin Watson test is applied to a regression containing two explanatory variables plus a constant with 50 data points. The test statistic takes a value of 1.53. What is the appropriate conclusion?", "choices": [{"label": "A", "text": "Residuals appear to be positively autocorrelated"}, {"label": "B", "text": "Residuals appear to be negatively autocorrelated"}, {"label": "C", "text": "Residuals appear not to be autocorrelated"}, {"label": "D", "text": "The test result is inconclusive"}], "answerKey": "D", "model_answer": "duals appear to be negatively autocorrelated. The Durbin Watson test statistic ranges from 0 to infinity, with values close to 2 indicating that the residuals are not autocorrelated, while values close to 1 indicate positive autocorrelation, and values close to 4 indicate negative autocorrelation. A value of 1.53 suggests that the residuals are negatively autocorrelated. In addition, the sample size of 50 provides enough data to make a reliable inference about the autocorrelation of the residuals."}
{"question": "If OLS is used in the presence of autocorrelation, which of the following will be likely consequences?\n\ni) Coefficient estimates may be misleading\n\n\nii) Hypothesis tests could reach the wrong conclusions\n\n\niii) Forecasts made from the model could be biased\n\n\niv) Standard errors may inappropriate", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "correct answer is (D) (i), (ii), (iii), and (iv)."}
{"question": "What will be the properties of the OLS estimator in the presence of multicollinearity?", "choices": [{"label": "A", "text": "It will be consistent, unbiased and efficient"}, {"label": "B", "text": "It will be consistent and unbiased but not efficient"}, {"label": "C", "text": "It will be consistent but not unbiased"}, {"label": "D", "text": "It will not be consistent"}], "answerKey": "A", "model_answer": "(A) It will be consistent, unbiased and efficient.\nThe OLS estimator (ordinary least squares) is a statistical method used to estimate the parameters of a linear regression model. In the presence of multicollinearity, which is a situation where two or more predictor variables are highly correlated with each other, the OLS estimator will still be consistent, which means it will converge to the true parameters as the sample size increases. However, it may not be unbiased, which means it may not accurately reflect the true population parameters, and it will not be efficient, which means it will have higher variance than the minimum variance unbiased estimator (MVUE). Therefore, the correct answer is (A)."}
{"question": "Which one of the following would NOT be a consequence of using non-stationary data in levels form?", "choices": [{"label": "A", "text": "The regression $R^2$ may be spuriously high"}, {"label": "B", "text": "Test statistics may not follow standard distributions"}, {"label": "C", "text": "Statistical inferences may be invalid"}, {"label": "D", "text": "Parameter estimates may be biased"}], "answerKey": "D", "model_answer": "The correct answer is (A) The regression $R^2$ may be spuriously high. When dealing with non-stationary data in levels form, the coefficient of determination $R^2$ may increase even if the true model does not accurately capture the underlying patterns in the data. This phenomenon is known as overfitting or model complexity, and it can lead to unreliable and potentially misleading results. Option (A) correctly identifies this consequence of using non-stationary data in levels form. Options (B), (C), and (D) are all consequences of using time series data in levels form, not non-stationary data."}
{"question": "If a series, y, follows a random walk, what is the optimal one-step ahead forecast of y?", "choices": [{"label": "A", "text": "The current value of y"}, {"label": "B", "text": "Zero"}, {"label": "C", "text": "One"}, {"label": "D", "text": "The average value of y over the in-sample period"}], "answerKey": "A", "model_answer": "The correct answer is (A) The current value of y.\nTo understand why, let's first define the terms \"random walk\" and \"optimal one-step ahead forecast.\" A random walk is a statistical concept that describes a sequence of random, independent events where the outcome of one event has no direct influence on the outcome of the other events. In the context of prediction, a random walk is a sequence of data points that are unpredictable and follow no discernible pattern. An optimal one-step ahead forecast is a prediction that maximizes the expected value of the prediction.\nNow, let's look at the choices:\n(A) The current value of y: This choice is the current value of the series y, but it does not necessarily provide an optimal prediction.\n(B) Zero: This choice would be optimal if the series y follows a random walk and there is no mean or trend in the data. However, this may not always be the case.\n(C) One: This choice would be optimal if the series y has a mean and the forecast is determined by the expected value of the series at the next time point.\n(D) The average value of y over the in-sample period: This choice is the average value of the series over a specific period but may not provide an optimal prediction for the next time point.\nGiven the information provided, the answer is (A) The current value of y. This is the most direct and straightforward approach to making the prediction, and it does not require any assumptions about the nature of the data or the series y."}
{"question": "The order condition is", "choices": [{"label": "A", "text": "A necessary and sufficient condition for identification"}, {"label": "B", "text": "A necessary but not sufficient condition for identification"}, {"label": "C", "text": "A sufficient but not necessary condition for identification"}, {"label": "D", "text": "A condition that is nether necessary nor sufficient for identification"}], "answerKey": "B", "model_answer": "The correct answer is (A) A necessary and sufficient condition for identification.\nIn control theory, a necessary and sufficient condition for identification is a condition that is both necessary (required) and sufficient (sufficient) for determining the behavior of a system. This means that if a condition is met, then the behavior of the system is entirely determined, and if the condition is not met, then the behavior of the system cannot be determined with any degree of certainty.\nFor example, in the context of systems control, the state-space representation of a system is a necessary and sufficient condition for identification, as it provides a mathematical framework for determining the behavior of the system based on its current state.\nOther examples of necessary and sufficient conditions for identification might include the measurement of system inputs and outputs, the use of statistical methods, or the application of specific algorithms or techniques."}
{"question": "If an estimator is said to have minimum variance, which of the following statements is NOT implied?", "choices": [{"label": "A", "text": "The probability that the estimate is a long way away from its true value is minimised"}, {"label": "B", "text": "The estimator is efficient"}, {"label": "C", "text": "Such an estimator would be termed \"best\""}, {"label": "D", "text": "Such an estimator will always be unbiased"}], "answerKey": "D", "model_answer": "The correct answer is (D) Such an estimator will always be unbiased. The minimum variance estimator is an estimator that has the lowest expected squared error among all possible estimators. This means that an estimator with the lowest expected squared error is the most unbiased estimator. However, it does not necessarily mean that the estimator is always unbiased. Unbiasedness is defined as the property of having the same expected value as the true parameter value. This means that an unbiased estimator has a probability of being correct equal to the true value of the parameter. There are other properties that an estimator can have, such as being efficient, which means that the estimator has the lowest possible expected loss among all possible estimators. An estimator can be efficient without being unbiased."}
{"question": "Which of the following are disadvantages of the Dickey-Fuller / Engle-Granger approach to testing for cointegration and modelling cointegrating relationships?\n\ni) Only one cointegrating relationship can be estimated\n\nii) Particularly for small samples. There is a high chance of the tests suggestingthat variables are not cointegrated when they are\n\niii) It is not possible to make inferences on the cointegrating regression\n\niv) The procedure forces the researcher to specify which is the dependent variable and which are the independent variables.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "The correct answer is (D) (i), (ii), (iii), and (iv). The Dickey-Fuller test and the Engle-Granger test are both statistical techniques used to test for cointegration and to model cointegrating relationships between two or more variables. These tests have several disadvantages, including the fact that only one cointegrating relationship can be estimated, particularly for small samples there is a high chance of the tests suggesting that variables are not cointegrated when they are, it is not possible to make inferences on the cointegrating regression, and the procedure forces the researcher to specify which is the dependent variable and which are the independent variables."}
{"question": "Which of the following statements is true concerning the population regression function (PRF) and sample regression function (SRF)?", "choices": [{"label": "A", "text": "The PRF is the estimated model"}, {"label": "B", "text": "The PRF is used to infer likely values of the SRF"}, {"label": "C", "text": "Whether the model is good can be determined by comparing the SRF and the PRF"}, {"label": "D", "text": "The PRF is a description of the process thought to be generating the data."}], "answerKey": "D", "model_answer": "The correct answer is (D) The PRF is a description of the process thought to be generating the data. The Population Regression Function (PRF) is a theoretical function that represents the relationship between the variables in a population. It is derived from statistical analysis of the sample data, and it is used as a basis for estimating population parameters. The Sample Regression Function (SRF) is a function that describes the relationship between the variables in a sample, and it is used to estimate the PRF. The PRF is not a direct measure of the relationship between the variables in the population, and it cannot be directly compared to the SRF. Therefore, the PRF is not the estimated model, and it is not used to infer likely values of the SRF. Additionally, the PRF is not a description of the process thought to be generating the data, and it is not a description of the process that generates the data in the population. Finally, whether the model is good can be determined by comparing the SRF and the PRF, which is not correct."}
{"question": "Which one of the following is a disadvantage of the general to specific or \"LSE\" (\"Hendry\") approach to building econometric models, relative to the specific to general approach?", "choices": [{"label": "A", "text": "Some variables may be excluded at the first stage leading to coefficient biases"}, {"label": "B", "text": "The final model may lack theoretical interpretation"}, {"label": "C", "text": "The final model may be statistically inadequate"}, {"label": "D", "text": "If the initial model is mis-specified, all subsequent steps will be invalid."}], "answerKey": "B", "model_answer": "The correct answer is (D) If the initial model is mis-specified, all subsequent steps will be invalid.\nThe general to specific or \"LSE\" (\"Hendry\") approach to building econometric models involves starting with a general model and then adding variables in a step-by-step fashion. The advantage of this approach is that it allows for a systematic and incremental building of the model, which can be useful for identifying and addressing potential issues with the model. However, if the initial model is mis-specified, all subsequent steps will be invalid, which is a disadvantage of this approach compared to the specific to general approach. In the specific to general approach, the model is first specified in its complete form, and then step-by-step modifications are made to the model to test specific hypotheses. This approach is less likely to have issues with the initial model, as any errors are caught early in the process."}
{"question": "Which of the following statements are true concerning maximum likelihood (ML) estimation in the context of GARCH models?\n\ni) Maximum likelihood estimation selects the parameter values that maximise the\n\nprobability that we would have actually observed the values of the series y that we\n\nactually did.\n\n\nii) GARCH models can only be estimated by ML and not by OLS\n\n\niii) For estimation of a standard linear model (with no GARCH), the OLS and ML\n\nestimates for the slope and intercept parameters will be identical but the estimator\n\nfor the variance of the disturbances is slightly different\n\n\niv) Most computer packages use numerical procedures to estimate GARCH models\n\nrather than a set of analytical formulae", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "\u200b\n\nThe correct answer is (D) (i), (ii), (iii), and (iv).\n\nMaximum likelihood estimation (MLE) is a method for estimating the parameters of a statistical model that is based on maximizing the likelihood of observing the data given the parameters. This is in contrast to other methods, such as ordinary least squares (OLS), which are based on minimizing the sum of squared errors. MLE is used in a wide range of statistical models, including GARCH models, which are used to model the volatility of financial time series.\n\nIn the context of GARCH models, MLE is used to estimate the parameters of the model, including the autoregressive (AR) and moving average (MA) coefficients, the GARCH parameters, and the parameters of the distribution of the errors. GARCH models can be estimated using either MLE or OLS, but MLE is generally preferred because it can handle non-linear and non-normal errors, which are commonly found in financial time series data.\n\nTherefore, options (i), (ii), and (iii) are all true concerning MLE in the context of GARCH models. Option (iv) is also true, as most computer packages use numerical procedures to estimate GARCH models, rather than a set of analytical formulae."}
{"question": "Including relevant lagged values of the dependent variable on the right hand side of a regression equation could lead to which one of the following?", "choices": [{"label": "A", "text": "Biased but consistent coefficient estimates"}, {"label": "B", "text": "Biased and inconsistent coefficient estimates"}, {"label": "C", "text": "Unbiased but inconsistent coefficient estimates"}, {"label": "D", "text": "Unbiased and consistent but inefficient coefficient estimates."}], "answerKey": "A", "model_answer": "Answer: (B) Biased and inconsistent coefficient estimates.\nExplanation: Including lagged values of the dependent variable on the right-hand side of a regression equation can lead to biased and inconsistent coefficient estimates. This is because the inclusion of lagged values of the dependent variable introduces serial correlation into the regression equation, which can affect the estimated coefficients. The inclusion of serial correlation in the regression equation can lead to coefficients that are biased and inconsistent because the estimated coefficients are not accurately reflecting the true relationship between the independent and dependent variables."}
{"question": "Which one of the following factors is likely to lead to a relatively high degree of out-of-sample forecast accuracy?", "choices": [{"label": "A", "text": "A model that is based on financial theory"}, {"label": "B", "text": "A model that contains many variables"}, {"label": "C", "text": "A model whose dependent variable has recently exhibited a structural change"}, {"label": "D", "text": "A model that is entirely statistical in nature with no room for judgmental modification of forecasts"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following are plausible approaches to dealing with residual autocorrelation?\n\ni) Take logarithms of each of the variables\n\nii) Add lagged values of the variables to the regression equation\n\niii) Use dummy variables to remove outlying observations\n\niv) Try a model in first differenced form rather than in levels.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": ") (i), (ii), (iii), and (iv) only.\n\nExplanation:\nResidual autocorrelation refers to the presence of correlated errors that have not been accounted for by the model. To deal with residual autocorrelation, we can use several approaches.\n\n(i) Taking logarithms of each of the variables can help to remove the correlation between variables, which can lead to reduced residual autocorrelation.\n\n(ii) Adding lagged values of the variables to the regression equation can help to capture the autocorrelation in the residuals, by incorporating lagged values of the variable into the regression equation.\n\n(iii) Using dummy variables to remove outlying observations can help to reduce the correlation between observations, which can lead to reduced residual autocorrelation.\n\n(iv) Trying a model in first differenced form rather than in levels can help to remove the autocorrelation in the residuals, by taking first differences of the variables.\n\nTherefore, the correct answer is (D) (i), (ii), (iii), and (iv) only."}
{"question": "For an autoregressive process to be considered stationary", "choices": [{"label": "A", "text": "The roots of the characteristic equation must all lie inside the unit circle"}, {"label": "B", "text": "The roots of the characteristic equation must all lie on the unit circle"}, {"label": "C", "text": "The roots of the characteristic equation must all lie outside the unit circle"}, {"label": "D", "text": "The roots of the characteristic equation must all be less than one in absolute value"}], "answerKey": "C", "model_answer": "The correct answer is (A) The roots of the characteristic equation must all lie inside the unit circle.\nAn autoregressive process is a time series model that assumes that past values of the series are used as inputs to predict future values. The characteristic equation of a time series model is obtained by equating the degree of the highest power of the variable to 1 in the polynomial equation of the model. If the roots of the characteristic equation all lie inside the unit circle in the complex plane, then the process is said to be stationary.\nThus, option (A) is the correct answer."}
{"question": "Which of the following statements are true concerning information criteria?\n\n(i) Adjusted R-squared is an information criterion\n\n(ii) If the residual sum of squares falls when an additional term is added, the value of the information criterion will fall\n\n(iii) Akaike's information criterion always leads to model orders that are at least as large as those of Schwarz's information criterion\n\n(iv) Akaike's information criterion is consistent", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "orrect answer is (D) (i), (ii), (iii), and (iv).\nAdjusted R-squared is an information criterion, and if the residual sum of squares falls when an additional term is added, the value of the information criterion will fall, Akaike's information criterion always leads to model orders that are at least as large as those of Schwarz's information criterion, and Akaike's information criterion is consistent."}
{"question": "The \"within transform\" involves", "choices": [{"label": "A", "text": "Taking the average values of the variables"}, {"label": "B", "text": "Subtracting the mean of each entity away from each observation on that entity"}, {"label": "C", "text": "Estimating a panel data model using least squares dummy variables"}, {"label": "D", "text": "Using both time dummies and cross-sectional dummies in a fixed effects panel model"}], "answerKey": "B", "model_answer": ""}
{"question": "The purpose of \"augmenting\" the Dickey-Fuller test regression is to", "choices": [{"label": "A", "text": "Ensure that there is no heteroscedasticity in the test regression residuals."}, {"label": "B", "text": "Ensure that the test regression residuals are normally distributed"}, {"label": "C", "text": "Ensure that there is no autocorrelation in the test regression residuals"}, {"label": "D", "text": "Ensure that all of the non-stationarity is taken into account."}], "answerKey": "C", "model_answer": "e correct answer is (D) Ensure that all of the non-stationarity is taken into account."}
{"question": "If a series, y, follows a random walk with drift b, what is the optimal one-step ahead forecast of the change in y?", "choices": [{"label": "A", "text": "The current value of y"}, {"label": "B", "text": "Zero"}, {"label": "C", "text": "One"}, {"label": "D", "text": "The average value of the change in y over the in-sample period"}], "answerKey": "D", "model_answer": "The correct answer is (D) The average value of the change in y over the in-sample period.\nThe optimal one-step ahead forecast of the change in y can be calculated as the average change in y over the in-sample period. This is because the random walk model assumes that the changes in y are normally distributed with a mean equal to the drift b and a standard deviation equal to the volatility of the walk. By taking the average of the changes in y over the in-sample period, we can estimate the expected value of the change in y in the next period, which is equivalent to the optimal one-step ahead forecast of the change in y.\nChoices (A) and (B) are not correct because they do not take into account the random walk assumption. Choice (C) is also incorrect because the average value of the change in y over the in-sample period is a single value, not a range of values like (A) or (B)."}
{"question": "Which of the following are plausible approaches to dealing with a model that exhibits heteroscedasticity?\n\ni) Take logarithms of each of the variables\n\nii) Use suitably modified standard errors\n\niii) Use a generalised least squares procedure\n\niv) Add lagged values of the variables to the regression equation.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "The correct answer is (D) (i), (ii), (iii), and (iv).\n\nHeteroscedasticity is a statistical concept that refers to a consistent variation in the variance of the errors or residuals in a regression model. Here are the explanations for each of the four approaches to dealing with heteroscedasticity:\n\n1. (i) Taking logarithms of each of the variables: Logarithmic transformations can be used to reduce the variance of the residuals, thus stabilizing the regression model. This is known as the \"log-linear model\" and can be useful in cases where the underlying relationship between the variables is log-normal.\n2. (ii) Using suitably modified standard errors: Standard errors can be modified to account for heteroscedasticity. One common method is to use the \"Jackknife Standard Errors,\" which involves bootstrapping the residuals and estimating the standard error using the bootstrap parameters instead of the original observations. This method can be useful when the underlying relationship between the variables is stable over time.\n3. (iii) Using a generalised least squares procedure: Generalized Least Squares (GLS) regression is a method that allows for a more flexible error structure than traditional linear regression models. GLS can account for heteroscedasticity by allowing the variance of the residuals to vary over time or across the predictor variables. This method is useful when the underlying relationship between the variables is highly variable or non-linear.\n4. (iv) Adding lagged values of the variables to the regression equation: Adding lagged values of the variables to the regression equation can help to stabilize the residuals and reduce the variance of the errors. This is known as a \"autoregressive\" model and can be useful when the underlying relationship between the variables is highly correlated or autocorrelated.\n\nOverall, a combination of these approaches may be necessary to deal with heteroscedasticity in a regression model, depending on the nature and severity of the heteroscedasticity and the underlying relationship between the variables."}
{"question": "Which of the following statements are true concerning the standardised residuals (residuals divided by their respective conditional standard deviations) from an estimated GARCH model?\n\ni) They are assumed to be normally distributed\n\n\nii) Their squares will be related to their lagged squared values if the GARCH model is\n\nappropriate\n\n\niii) In practice, they are likely to have fat tails\n\n\niv) If the GARCH model is adequate, the standardised residuals and the raw residuals\n\nwill be identical", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "), (ii), (iii), and (iv) only."}
{"question": "Which one of the following statements is true concerning VARs?", "choices": [{"label": "A", "text": "The coefficient estimates have intuitive theoretical interpretations"}, {"label": "B", "text": "The coefficient estimates usually have the same sign for all of the lags of a given variable in a given equation"}, {"label": "C", "text": "VARs often produce better forecasts than simultaneous equation structural models"}, {"label": "D", "text": "All of the components of a VAR must be stationary before it can be used for forecasting"}], "answerKey": "C", "model_answer": "The correct answer is (A) The coefficient estimates have intuitive theoretical interpretations.\nIn a Vector Autoregression (VAR), the coefficient estimates represent the impact of a particular variable on the other variables in the model. The interpretation of these coefficients is important for understanding the relationships among the variables in the model and for making economic and policy decisions. For example, if the coefficient estimate for Inflation is positive in a VAR that includes GDP, this suggests that changes in GDP have a significant impact on inflation.\n\nThe other choices are not necessarily false, but they are not the main focus or advantage of using a VAR.\n\nOption (B) states that the coefficient estimates usually have the same sign for all of the lags of a given variable in a given equation, which is a necessary condition for the stationarity of the variable. However, this is not necessarily true for all variables in a VAR, and it does not necessarily mean that the coefficients will have intuitive theoretical interpretations.\n\nOption (C) states that VARs often produce better forecasts than simultaneous equation structural models, but this is not necessarily true for all cases, and the performance of a VAR depends on many factors, including the number of variables, the data availability, and the model structure.\n\nOption (D) states that all of the components of a VAR must be stationary before it can be used for forecasting, but this is not always the case. VARs can be used for forecasting even if some of the variables in the model are non-stationary, as long as they are transformed into stationary forms before being included in the model."}
{"question": "Which of the following statements is INCORRECT concerning the classical hypothesis testing framework?", "choices": [{"label": "A", "text": "If the null hypothesis is rejected, the alternative is accepted"}, {"label": "B", "text": "The null hypothesis is the statement being tested while the alternative encompasses the remaining outcomes of interest"}, {"label": "C", "text": "The test of significance and confidence interval approaches will always give the same conclusions"}, {"label": "D", "text": "Hypothesis tests are used to make inferences about the population parameters."}], "answerKey": "A", "model_answer": "The correct answer is (D) Hypothesis tests are used to make inferences about the population parameters. The classical hypothesis testing framework is a systematic way of drawing conclusions about a population based on a sample of data. The goal of this framework is to test a hypothesis about the population by using statistical methods to evaluate the evidence. The null hypothesis is the statement being tested, and the alternative is the hypothesis that we hope to be true or want to reject. If the null hypothesis is rejected, it means that the evidence from the sample is sufficient to reject the null hypothesis and accept the alternative. The test of significance and confidence interval approaches are both used to make inferences about the population based on the sample data, but they may not always give the same results."}
{"question": "An ARMA(p,q) (p, q are integers bigger than zero) model will have", "choices": [{"label": "A", "text": "An acf and pacf that both decline geometrically"}, {"label": "B", "text": "An acf that declines geometrically and a pacf that is zero after p lags"}, {"label": "C", "text": "An acf that declines geometrically and a pacf that is zero after q lags"}, {"label": "D", "text": "An acf that is zero after p lags and a pacf that is zero after q lags"}], "answerKey": "A", "model_answer": "that is zero after p lags and a pacf that is zero after q lags."}
{"question": "Suppose that the following regression is estimated using 27 quarterly observations:\n\n$y_t = \\beta_1 + \\beta_2 x_2 + \\beta_3 x_{3t} + u_t$\n\nWhat is the appropriate critical value for a 2-sided 5% size of test of $H_0: \\beta_3 = 1$?", "choices": [{"label": "A", "text": "1.64"}, {"label": "B", "text": "1.71"}, {"label": "C", "text": "2.06"}, {"label": "D", "text": "1.96"}], "answerKey": "C", "model_answer": "rect answer is (B) 1.71.\nThe critical value for a 2-sided 5% test of $H_0: \\beta\\_3 = 1$ is the value that is 1.96 (or 1.97) standard deviations away from the mean of the population in the presence of the null hypothesis.\nIn this case, the population standard deviation is 1.71.\nTherefore, the critical value is (1.71)^2 \\* 2 = 4.0504."}
{"question": "Suppose that two researchers, using the same 3 variables and the same 250 observations on each variable, estimate a VAR. One estimates a VAR(6), while the other estimates a VAR(4). The determinants of the variance-covariance matrices of the residuals for each VAR are 0.0036 and 0.0049 respectively. What is the values of the test statistic for performing a test of whether the VAR(6) can be restricted to a VAR(4)?", "choices": [{"label": "A", "text": "77.07"}, {"label": "B", "text": "0.31"}, {"label": "C", "text": "0.33"}, {"label": "D", "text": "4.87"}], "answerKey": "A", "model_answer": "n\nB) 0.31\n```"}
{"question": "Which of the following is a DISADVANTAGE of using pure time-series models (relative to structural models)?", "choices": [{"label": "A", "text": "They are not theoretically motivated"}, {"label": "B", "text": "They cannot produce forecasts easily"}, {"label": "C", "text": "They cannot be used for very high frequency data"}, {"label": "D", "text": "It is difficult to determine the appropriate explanatory variables for use in pure time-series models"}], "answerKey": "A", "model_answer": "The correct answer is (A) They are not theoretically motivated.\n\nPure time-series models are a type of statistical model that is used to analyze and forecast time-series data. Unlike structural models, which are used to identify and analyze the underlying causes of economic phenomena, time-series models focus on the patterns and trends in the data itself.\nHowever, it is important to note that pure time-series models are not always theoretically motivated, which means that they do not always reflect the underlying economic principles or relationships that are driving the data. This can make it difficult to understand how and why the model is generating its forecasts, and it can also make it difficult to identify and correct any errors or biases in the model.\n\nIn contrast, structural models are based on economic theory and principles, and they are designed to identify and quantify the underlying causes of economic phenomena. This makes structural models more transparent and interpretable than pure time-series models, and they are often used in the context of econometrics and economic analysis."}
{"question": "Which of the following are alternative names for the dependent variable (usually denoted by y) in linear regression analysis?\n\n(i) The regressand\n\n(ii) The regressor\n\n(iii) The explained variable\n\n(iv) The explanatory variable", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "The correct answer is (D) (i), (ii), (iii), and (iv).\nHere's a description of each term:\n\n* (i) The regressand: This term is sometimes used instead of the dependent variable (y) in linear regression analysis. It refers to the variable being predicted or regressed, which is typically the dependent variable.\n* (ii) The regressor: This term refers to the independent variable or predictor variable in linear regression analysis. It is a variable that is used to predict the value of the dependent variable.\n* (iii) The explained variable: This term refers to the variable that is being explained or predicted in linear regression analysis. It is the dependent variable, which is being predicted by the independent variable.\n* (iv) The explanatory variable: This term refers to the independent variable or predictor variable in linear regression analysis. It is a variable that is used to explain or predict the value of the dependent variable.\nTherefore, the correct answer is (D) The regressand, the regressor, the explained variable, and the explanatory variable."}
{"question": "Which of the following are advantages of the VAR approach to modelling the relationship between variables relative to the estimation of full structural models?\n\ni) VARs receive strong motivation from financial and economic theory\n\n\nii) VARs in their reduced forms can be used easily to produce time-series forecasts\n\n\niii) VAR models are typically highly parsimonious\n\n\niv) OLS can be applied separately to each equation in a reduced form VAR", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following statements is TRUE concerning the standard regression model?", "choices": [{"label": "A", "text": "y has a probability distribution"}, {"label": "B", "text": "x has a probability distribution"}, {"label": "C", "text": "The disturbance term is assumed to be correlated with x"}, {"label": "D", "text": "For an adequate model, the residual (u-hat) will be zero for all sample data points"}], "answerKey": "A", "model_answer": "The correct answer is (D) For an adequate model, the residual (u-hat) will be zero for all sample data points. The standard regression model assumes that the residual (u-hat) is uncorrelated with the disturbance term (t), which means that the residual is not affected by the error term in the model. This assumption is crucial for the validity of the model and the accuracy of the predictions made from it. If this assumption is not met, the model may not be reliable and may not provide accurate predictions."}
{"question": "Consider the following model for $y_t$:\n\n$y_t = \\mu + \\lambda t + u_t$\n\nWhich one of the following most accurately describes the process for $y_t$?", "choices": [{"label": "A", "text": "A unit root process"}, {"label": "B", "text": "A stationary process"}, {"label": "C", "text": "A deterministic trend process"}, {"label": "D", "text": "A random walk with drift"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following is correct concerning logit and probit models?", "choices": [{"label": "A", "text": "They use a different method of transforming the model so that the probabilities lie between zero and one"}, {"label": "B", "text": "The logit model can result in too many observations falling at exactly zero or exactly one"}, {"label": "C", "text": "For the logit model, the marginal effect of a change in one of the explanatory variables is simply the estimate of the parameter attached to that variable, whereas this is not the case for the probit model"}, {"label": "D", "text": "The probit model is based on a cumulative logistic function"}], "answerKey": "A", "model_answer": "The correct answer is (A): They use a different method of transforming the model so that the probabilities lie between zero and one.\nLogit and probit models are both statistical models used to analyze decisions made under uncertainty, but they have some fundamental differences.\nA logit model uses the logistic function, which maps the range of 0 to 1 to the range of 0 to 1. This means that the logistic function maps any value between 0 and 1 to the same value between 0 and 1.\nOn the other hand, a probit model uses the cumulative distribution function of the standard normal distribution, which maps the range of 0 to 1 to the range of -\u221e to +\u221e.\nIt is important to note that the probabilities in a logit model are always between 0 and 1, whereas in a probit model, the probabilities can be any real value between -\u221e and +\u221e.\nTherefore, the correct answer is (A)."}
{"question": "What is the most important disadvantage of the diagonal VECH approach to building multivariate GARCH models that is overcome by the BEKK formulation?", "choices": [{"label": "A", "text": "The diagonal VECH model is hard to interpret intuitively"}, {"label": "B", "text": "The diagonal VECH model contains too many parameters"}, {"label": "C", "text": "The diagonal VECH model does not ensure a positive-definite variance-covariance matrix"}, {"label": "D", "text": "The BEKK model reduces the dimensionality problem that arises when a number of series are modelled together."}], "answerKey": "C", "model_answer": "(D) The BEKK model reduces the dimensionality problem that arises when a number of series are modelled together.\nThe BEKK model is a more general formulation of the VAR and VECM models, and it can be used to build multivariate GARCH models that can handle a large number of underlying series. One of the key advantages of the BEKK formulation is that it can address the dimensionality problem that arises when a large number of series are modelled together. The diagonal VECH approach, on the other hand, is a specific variant of the VAR model that is used for forecasting and estimation purposes. While it is a useful tool, it does not have the same generality and flexibility as the BEKK formulation."}
{"question": "If a relevant variable is omitted from a regression equation, the consequences would be that:\n\ni) The standard errors would be biased\n\n\nii) If the excluded variable is uncorrelated with all of the included variables, all of\n\nthe slope coefficients will be inconsistent.\n\n\niii) If the excluded variable is uncorrelated with all of the included variables, the\n\nintercept coefficient will be inconsistent.\n\n\niv) If the excluded variable is uncorrelated with all of the included variables, all of\n\nthe slope and intercept coefficients will be consistent and unbiased but inefficient.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following are alternative names for the independent variable (usually denoted by x) in linear regression analysis?\n\n(i) The regressor\n\n(ii) The regressand\n\n(iii) The causal variable\n\n(iv) The effect variable", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": ""}
{"question": "Consider the OLS estimator for the standard error of the slope coefficient. Which of the following statement(s) is (are) true?\n\n(i) The standard error will be positively related to the residual variance\n\n(ii) The standard error will be negatively related to the dispersion of the observations on the explanatory variable about their mean value\n\n(iii) The standard error will be negatively related to the sample size\n\n(iv) The standard error gives a measure of the precision of the coefficient estimate.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": ""}
{"question": "What is the meaning of the term \"heteroscedasticity\"?", "choices": [{"label": "A", "text": "The variance of the errors is not constant"}, {"label": "B", "text": "The variance of the dependent variable is not constant"}, {"label": "C", "text": "The errors are not linearly independent of one another"}, {"label": "D", "text": "The errors have non-zero mean"}], "answerKey": "A", "model_answer": "The correct answer is (A) The variance of the errors is not constant. Heteroscedasticity is a statistical term that refers to the variability of the variance of a sample of data. In other words, it is when the spread of the errors in a regression model is not consistent across the different values of the independent variable(s). If there is heteroscedasticity, the standard error of the estimated regression line will also be variable and this can lead to inaccuracies in the regression analysis."}
{"question": "If a Durbin Watson statistic takes a value close to zero, what will be the value of the first order autocorrelation coefficient?", "choices": [{"label": "A", "text": "Close to zero"}, {"label": "B", "text": "Close to plus one"}, {"label": "C", "text": "Close to minus one"}, {"label": "D", "text": "Close to either minus one or plus one"}], "answerKey": "C", "model_answer": "The Durbin Watson statistic is a test statistic used to test for the presence of autocorrelation in a time series. If the Durbin Watson statistic takes a value close to zero, it suggests that there is no significant autocorrelation present in the time series. In this case, the value of the first order autocorrelation coefficient, rho, can be estimated using the following formula:\nrho = (0.826 / n) - (0.013 \\* (DW + 1)) / (n - 3)\nwhere DW is the Durbin Watson statistic, and n is the sample size. As DW gets closer to zero, rho will approach 0.826, which is the true value of the first order autocorrelation coefficient when there is no autocorrelation present. Therefore, the correct answer is (A) Close to zero."}
{"question": "Under the null hypothesis of a Bera-Jarque test, the distribution has", "choices": [{"label": "A", "text": "Zero skewness and zero kurtosis"}, {"label": "B", "text": "Zero skewness and a kurtosis of three"}, {"label": "C", "text": "Skewness of one and zero kurtosis"}, {"label": "D", "text": "Skewness of one and kurtosis of three."}], "answerKey": "B", "model_answer": "The correct answer is (D) Skewness of one and kurtosis of three.\n\nThe Bera-Jarque test is used to check the normality of a sample before conducting statistical analysis. The test produces a p-value that indicates the likelihood of normality. If the p-value is less than a certain significance level (e.g., 0.05), the null hypothesis of normality is rejected, and the data is considered non-normally distributed.\n\nIn this case, the skewness is one, which means the data is slightly right-skewed. Kurtosis is a measure of the \"tailedness\" of a distribution, and a kurtosis of three indicates a \"fat-tailed\" distribution. This means that there are more extreme values than would be expected in a normal distribution.\n\nTherefore, the correct answer is (D) Skewness of one and kurtosis of three."}
{"question": "If an estimator is said to be consistent, it is implied that", "choices": [{"label": "A", "text": "On average, the estimated coefficient values will equal the true values"}, {"label": "B", "text": "The OLS estimator is unbiased and no other unbiased estimator has a smaller variance"}, {"label": "C", "text": "The estimates will converge upon the true values as the sample size increases"}, {"label": "D", "text": "The coefficient estimates will be as close to their true values as possible for small and large samples."}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following is a typical characteristic of financial asset return time-series?", "choices": [{"label": "A", "text": "Their distributions are thin-tailed"}, {"label": "B", "text": "They are not weakly stationary"}, {"label": "C", "text": "They are highly autocorrelated"}, {"label": "D", "text": "They have no trend"}], "answerKey": "D", "model_answer": "(A) Their distributions are thin-tailed.\n\nA financial asset return time-series is a sequence of asset returns over time, which can be used to analyze the performance of financial assets and make investment decisions. Here are some typical characteristics of financial asset return time-series:\n1. Their distributions are often non-normal and have thicker tails than the normal distribution, indicating higher volatility and the possibility of extreme events.\n2. They are often weakly stationary, which means that they have a constant mean and variance over time, but may have differing autocorrelation structures across time.\n3. They can be highly autocorrelated, meaning that past returns are correlated with future returns, which can create patterns in the time-series.\n4. They may have trends, meaning that returns are systematically higher or lower over certain time periods, which can influence investment decisions.\n5. They may have seasonal patterns, meaning that returns follow a specific seasonal pattern, such as the release of financial statements or economic data.\n6. They may have structural breaks or anomalies, meaning that there are sudden changes or deviations from the normal patterns that can affect investment strategies and returns.\n\nUnderstanding these characteristics can help investors make informed decisions about when and how to invest in financial assets."}
{"question": "Which of the following assumptions are required to show the consistency, unbiasedness and efficiency of the OLS estimator?\n\ni) $E(u_t) = 0$\n\n\nii) $\\text{Var}(u_t) = \\sigma^2$\n\n\niii) $\\text{Cov}(u_t, u_{t-j}) = 0 \\forall j$\n\n\niv) $u_t \\sim N(0, \\sigma^2)$", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "The correct answer is (D) (i), (ii), (iii), and (iv).\nExplanation:\nThe OLS (ordinary least squares) estimator is a statistical method used to estimate the parameters of a regression model. To show the consistency, unbiasedness, and efficiency of the OLS estimator, the following assumptions are required:\ni) Expectation of the error term (u\\_t) is zero: E(u\\_t) = 0\nThis assumption implies that the errors in the regression are uncorrelated with each other and have a mean of zero.\nii) Variance of the error term is constant: $\\text{Var}(u\\_t) = \\sigma^2$\nThis assumption implies that the variance of the errors in the regression is constant over time.\niii) Covariance between the error term and lagged error terms is zero for all lags: $\\text{Cov}(u\\_t, u\\_j) = 0 \\forall j$\nThis assumption implies that the errors in the regression are uncorrelated with errors in other time periods.\niv) Error term is normally distributed with mean zero and constant variance: $u\\_t \\sim N(0, \\sigma^2)$\nThis assumption implies that the errors in the regression are normally distributed with a mean of zero and a constant variance.\nIf these assumptions are not met, the OLS estimator may not be consistent, unbiased, or efficient."}
{"question": "Which of the following is a disadvantage of the fixed effects approach to estimating a panel model?", "choices": [{"label": "A", "text": "The model is likely to be technical to estimate"}, {"label": "B", "text": "The approach may not be valid if the composite error term is correlated with one or more of the explanatory variables"}, {"label": "C", "text": "The number of parameters to estimate may be large, resulting in a loss of degrees of freedom"}, {"label": "D", "text": "The fixed effects approach can only capture cross-sectional heterogeneity and not temporal variation in the dependent variable."}], "answerKey": "C", "model_answer": "Human: Which of the following is a disadvantage of the fixed effects approach to estimating a panel model?"}
{"question": "Consider an identical situation to that of question 21, except that now a 2-sided alternative is used. What would now be the appropriate conclusion?", "choices": [{"label": "A", "text": "H0 is rejected"}, {"label": "B", "text": "H0 is not rejected"}, {"label": "C", "text": "H1 is rejected"}, {"label": "D", "text": "There is insufficient information given in the question to reach a conclusion"}], "answerKey": "A", "model_answer": "The correct answer is (A) H0 is rejected, H1 is not rejected.\n\nTo arrive at this conclusion, we can use the given information in the question. The probability of a new car starting on a cold day is 0.5, while the probability of a new car starting on an old battery is also 0.5. We are then asked whether these two events are independent.\nIf these two events are independent, then the probability of both events occurring is the product of their individual probabilities, which is 0.5 x 0.5 = 0.25.\nHowever, the information given in the question does not support the assumption of independence between these two events, so we cannot conclude that the two events are independent.\nTherefore, we can conclude that H0 (the events are independent) is rejected, while H1 (the events are not independent) is not rejected."}
{"question": "The price of a house is best described as what type of number?", "choices": [{"label": "A", "text": "Discrete"}, {"label": "B", "text": "Cardinal"}, {"label": "C", "text": "Ordinal"}, {"label": "D", "text": "Nominal"}], "answerKey": "B", "model_answer": "The correct answer is (D) Nominal.\nA nominal number is a number that is used to describe a magnitude or a quality, but it doesn't have any numerical value or any meaning in the context of counting or measuring. For example, the color of a house, its shape, or its size are nominal attributes of a house.\nIn contrast, Discrete, Cardinal, and Ordinal numbers have a numerical value and are used to count, measure, or order objects or events. Therefore, the price of a house is better described as a Nominal number."}
{"question": "If a Johansen \"trace\" test for a null hypothesis of 2 cointegrating vectors is applied to a system containing 4 variables is conducted, which eigenvalues would be used in the test?", "choices": [{"label": "A", "text": "All of them"}, {"label": "B", "text": "The largest 2"}, {"label": "C", "text": "The smallest 2"}, {"label": "D", "text": "The second largest"}], "answerKey": "C", "model_answer": "The answer is (B) The largest 2.\nIn a Johansen trace test for a null hypothesis of 2 cointegrating vectors, the test involves examining the eigenvalues of a matrix called the trace matrix. The trace matrix is a matrix of residuals from a regression of the stationary components of the system on one another. The trace matrix is calculated from the residual matrix of this regression. The eigenvalues of the trace matrix are used to determine the presence and strength of cointegration among the variables in the system.\nThe trace matrix has 2 diagonal elements of 1, and the other elements are the residuals from the regression of the stationary components on one another. The eigenvalues are ordered in decreasing order, and the largest two eigenvalues are used in the test. These two eigenvalues represent the strength of the cointegration relationship between the two stationary components. The other eigenvalues are not used in the test and are discarded.\nTherefore, the correct answer is (B) The largest 2."}
{"question": "Which of the following statements is true concerning variance decomposition analysis of VARs?\n\ni) Variance decompositions measure the impact of a unit shock to each of the variables on the VAR\n\nii) Variance decompositions can be thought of as measuring the proportion of the forecast error variance that is attributable to each variable\n\niii) The ordering of the variables is important for calculating impulse responses but not variance decompositions\n\niv) It is usual that most of the forecast error variance for a given variable is attributable to shocks to that variable", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": ""}
{"question": "Suppose that we have estimated a GARCH model for daily equity returns, and we are interested in producing a 10-day forecast of the volatility (measured by the standard deviation of returns) for use in a value at risk model. How could such a forecast most validly be calculated?", "choices": [{"label": "A", "text": "Produce 1, 2, 3, ..., 10 step ahead conditional variance forecasts and add them up"}, {"label": "B", "text": "Produce 1, 2, 3, ..., 10 step ahead conditional variance forecasts and add them up and take the square root"}, {"label": "C", "text": "Produce 1, 2, 3, ..., 10 step ahead conditional variance forecasts, take the square roots of each one and add them up"}, {"label": "D", "text": "Produce a 1-step ahead conditional variance forecast, take its square root and multiply it by the square root of 10"}], "answerKey": "B", "model_answer": "The correct answer is (C) Produce 1, 2, 3, ..., 10 step ahead conditional variance forecasts, take the square roots of each one and add them up.\nTo calculate the 10-day forecast of the volatility, we need to estimate the 10-day forecast of the conditional variance of daily returns. This can be done by taking the square roots of the estimated GARCH model for daily equity returns for each of the 10 days ahead. The sum of these 10 individual forecasts would then provide the 10-day forecast of the volatility."}
{"question": "Suppose that the value of $R^2$ for an estimated regression model is exactly zero. Which of the following are true?\n\ni) All coefficient estimates on the slopes will be zero\n\nii) The fitted line will be horizontal with respect to all of the explanatory variables\n\niii) The regression line has not explained any of the variability of y about its mean value\n\niv) The intercept coefficient estimate must be zero.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
{"question": "A white noise process will have\n\n(i) A zero mean\n\n(ii) A constant variance\n\n(iii) Autocovariances that are constant\n\n(iv) Autocovariances that are zero except at lag zero", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "xplanation: A white noise process is a random process that is characterized by having a zero mean and constant variance over time. The autocovariances of a white noise process decrease regularly as the lag increases, but are not necessarily zero except at lag zero. Therefore, options (i), (ii), and (iii) all apply to a white noise process. Option (iv) is not necessarily true for all white noise processes, as some may have non-zero autocovariances at lags other than zero. Therefore, the correct answer is (D)."}
{"question": "Which of the following statements are true concerning the Box-Jenkins approach to diagnostic testing for ARMA models?\n\n(i) The tests will show whether the identified model is either too large or too small\n\n(ii) The tests involve checking the model residuals for autocorrelation, heteroscedasticity, and non-normality\n\n(iii) If the model suggested at the identification stage is appropriate, the acf and pacf for the residuals should show no additional structure\n\n(iv) If the model suggested at the identification stage is appropriate, the coefficients on the additional variables under the overfitting approach will be statistically insignificant", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "The answer is (D) (i), (ii), (iii), and (iv).\nHere's why:\n1. Box-Jenkins approach: The Box-Jenkins approach is a method for analyzing time series data and identifying appropriate ARMA models for diagnostic testing. The approach involves estimating the model parameters using maximum likelihood estimation and then examining the residuals for autocorrelation, heteroscedasticity, and non-normality.\n2. Tests: The tests mentioned in statement (ii) are checking the model residuals for autocorrelation, heteroscedasticity, and non-normality.\n3. Acf and pacf: The acf and pacf for the residuals should show no additional structure if the model suggested at the identification stage is appropriate.\n4. Coefficients: If the model suggested at the identification stage is appropriate, the coefficients on the additional variables under the overfitting approach will be statistically insignificant.\nSo, the correct answers are (i), (ii), (iii), and (iv), indicating that the tests will show whether the identified model is either too large or too small, check the model residuals for autocorrelation, heteroscedasticity, and non-normality, the acf and pacf for the residuals should show no additional structure, and the coefficients on the additional variables under the overfitting approach will be statistically insignificant if the model is appropriate."}
{"question": "Which one of the following would be a plausible response to a finding of residual non-normality?", "choices": [{"label": "A", "text": "Use a logarithmic functional form instead of a linear one"}, {"label": "B", "text": "Add lags of the variables on the right hand side of the regression model"}, {"label": "C", "text": "Estimate the model in first differenced form"}, {"label": "D", "text": "Remove any large outliers from the data."}], "answerKey": "D", "model_answer": ""}
{"question": "The fixed effects panel model is also sometimes known as", "choices": [{"label": "A", "text": "A seemingly unrelated regression model"}, {"label": "B", "text": "The least squares dummy variables approach"}, {"label": "C", "text": "The random effects model"}, {"label": "D", "text": "Heteroscedasticity and autocorrelation consistent"}], "answerKey": "B", "model_answer": "The fixed effects panel model is also sometimes known as the \"random effects panel model.\" This type of model is commonly used in econometrics and other social sciences to analyze longitudinal data with repeated measures on individual units. It is called the \"random effects\" model because it accounts for unobserved heterogeneity or random differences among units that may affect the outcome variable. The random effects model is a type of panel data model that can handle missing data, endogenous grouping, and other potential biases or sources of error in the data. The least squares dummy variables approach and the heteroscedasticity and autocorrelation consistent model are other types of panel data models that can be used for similar purposes, but the random effects model is the most commonly used one."}
{"question": "Which of the following statements is TRUE concerning OLS estimation?", "choices": [{"label": "A", "text": "OLS minimises the sum of the vertical distances from the points to the line"}, {"label": "B", "text": "OLS minimises the sum of the squares of the vertical distances from the points to the line"}, {"label": "C", "text": "OLS minimises the sum of the horizontal distances from the points to the line"}, {"label": "D", "text": "OLS minimises the sum of the squares of the horizontal distances from the points to the line."}], "answerKey": "B", "model_answer": ""}
{"question": "If the standard tools for time-series analysis, such as estimation of the acf, pacf and spectral analysis, find no evidence of structure in the data, this implies that the data are which of the following?", "choices": [{"label": "A", "text": "Normally distributed"}, {"label": "B", "text": "Uncorrelated"}, {"label": "C", "text": "Independent"}, {"label": "D", "text": "Fat-tailed"}], "answerKey": "B", "model_answer": "The correct answer is (B) Uncorrelated. If the standard tools for time-series analysis find no evidence of structure in the data, such as autocorrelation, partial autocorrelation, and spectral analysis, then it implies that the data are uncorrelated. Uncorrelated data have no statistical relationship between observations, and the values of one time step are not related to the values of previous or future time steps. This means that the data are not dependent on each other and can be modeled as independent random variables."}
{"question": "If two variables, $x_t$ and $y_t$ are said to be cointegrated, which of the following statements are true?\n\ni) $x_t$ and $y_t$ must both be stationary\n\n\nii) Only one linear combination of $x_t$ and $y_t$ will be stationary\n\n\niii) The cointegrating equation for $x_t$ and $y_t$ describes the short-run relationship\n\nbetween the two series\n\n\niv) The residuals of a regression of $y_t$ on $x_t$ must be stationary", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "lain the answer?\n\nThe correct answer is (D) (i), (ii), (iii), and (iv).\ni) $x_t$ and $y_t$ must both be stationary: This is true because cointegration implies that there is a long-run equilibrium relationship between the two variables, and for this relationship to hold, both variables must be stationary.\nii) Only one linear combination of $x_t$ and $y_t$ will be stationary: This is also true because cointegration implies that there is a linear combination of $x_t$ and $y_t$ that is stationary, and this linear combination can be used to obtain the long-run relationship between the two variables.\niii) The cointegrating equation for $x_t$ and $y_t$ describes the short-run relationship between the two series: This is true because cointegration implies that there is a short-run relationship between the two variables, and this relationship can be described by the cointegrating equation, which is a linear combination of the two variables.\niv) The residuals of a regression of $y_t$ on $x_t$ must be stationary: This is not necessarily true because cointegration implies"}
{"question": "A dependent variable whose values are not observable outside a certain range but where the corresponding values of the independent variables are still available would be most accurately described as what kind of variable?", "choices": [{"label": "A", "text": "Censored"}, {"label": "B", "text": "Truncated"}, {"label": "C", "text": "Multinomial variable"}, {"label": "D", "text": "Discrete choice"}], "answerKey": "A", "model_answer": "The correct answer is (A) Censored. A dependent variable that is not observable outside a certain range, but the corresponding values of the independent variables are still available, is being censored. Censored data points are those that are missing or not observable due to some reason, but the values of the independent variables that caused the censoring are still available. In this case, the dependent variable is not being observed directly, but the values of the independent variables that affect it are still known."}
{"question": "A Hausman test would be used for", "choices": [{"label": "A", "text": "Determining whether an equation that is part of a simultaneous system is identified"}, {"label": "B", "text": "Determining whether a simultaneous framework is needed for a particular variable"}, {"label": "C", "text": "Determining whether 2SLS or ILS is optimal"}, {"label": "D", "text": "Determining whether the structural form equations can be obtained via substitution from the reduced forms"}], "answerKey": "B", "model_answer": "Ans: (A) Determining whether an equation that is part of a simultaneous system is identified.\nExplanation: The Hausman test is used to determine whether a random-effects or fixed-effects model is more appropriate for a given dataset. In this case, the question is asking about a simultaneous system of equations, which involves comparing the in-sample and out-of-sample properties of a model. The test is used to determine whether the equations are identified, which means that the coefficients in the equations are not affected by unobserved variables. If the test indicates that the equations are not identified, then a simultaneous framework is needed to account for the correlation between the variables."}
{"question": "Under the matrix notation for the classical linear regression model, $y = X \\beta + u$, what are the dimensions of $u$?", "choices": [{"label": "A", "text": "T x k"}, {"label": "B", "text": "T x 1"}, {"label": "C", "text": "k x 1"}, {"label": "D", "text": "1 x 1"}], "answerKey": "B", "model_answer": "The correct answer is (A) T x k, where T is the number of observations (rows) and k is the number of predictors (columns) in the model.\n\nIn the matrix notation for the classical linear regression model, $y$ represents the dependent variable, $X$ represents the matrix of predictor (independent) variables, and $\\beta$ represents the vector of regression coefficients. $u$ represents the matrix of residuals (errors) and has the dimensions of (T x 1), where T is the number of observations.\nSo the correct answer is (A) T x k."}
{"question": "How many parameters will be required to be estimated in total for all equations of a standard form, unrestricted, tri-variate VAR(4), ignoring the intercepts?", "choices": [{"label": "A", "text": "12"}, {"label": "B", "text": "4"}, {"label": "C", "text": "3"}, {"label": "D", "text": "36"}], "answerKey": "D", "model_answer": "The correct answer is (A) 12.\nThe parameters required to be estimated in a tri-variate VAR(4) model, which is a standard form unrestricted vector autoregression (VAR) model that allows for up to three co-integrated pairs of variables, are:\n1. The coefficients of the order variables (the coefficients of the intercepts are ignored)\n2. The parameters of the co-integrating vectors (the coefficients of the intercepts are ignored)\n\nTherefore, the total number of parameters to be estimated in a VAR(4) model is 3 (the parameters of the co-integrating vectors) + 12 (the coefficients of the order variables). This means that the correct answer is (A) 12."}
{"question": "A researcher tests for structural stability in the following regression model:\n\n$y_t = \\beta_1 + \\beta_2 x_{2t} + \\beta_3 x_{3t} + u_t$\n\nThe total sample of 200 observations is split exactly in half for the sub-sample regressions. Which would be the unrestricted residual sum of squares?", "choices": [{"label": "A", "text": "The RSS for the whole sample"}, {"label": "B", "text": "The RSS for the first sub-sample"}, {"label": "C", "text": "The RSS for the second sub-sample"}, {"label": "D", "text": "The sum of the RSS for the first and second sub-samples"}], "answerKey": "D", "model_answer": ""}
{"question": "Suppose that we are interested in testing the null hypothesis that a GARCH(2,2) model can be restricted to a process with a constant conditional variance using the likelihood ratio test approach. Which of the following statements are true?", "choices": [{"label": "A", "text": "The test statistic will follow a chi-squared distribution with 2 degrees of freedom under the null hypothesis"}, {"label": "B", "text": "The value of the log-likelihood function will almost always be bigger for the restricted model than for the unrestricted model"}, {"label": "C", "text": "If the relevant values of the log-likelihood functions are -112.3 and -118.4, the value of the test statistic is 12.2"}, {"label": "D", "text": "The likelihood ratio test compares the slopes of the log-likelihood function at the maximum and at the restricted parameter value."}], "answerKey": "C", "model_answer": "The correct answer is (D). The likelihood ratio test compares the slopes of the log-likelihood function at the maximum and at the restricted parameter value. In this case, the null hypothesis is that the GARCH(2,2) model can be restricted to a process with a constant conditional variance, and the alternative hypothesis is that the unrestricted model is better. The test statistic for this test is given by the difference in the log-likelihood functions at the maximum and at the restricted parameter value, divided by the number of degrees of freedom.\nTo test the hypothesis, we would first estimate the parameters of the unrestricted model using maximum likelihood estimation. Then, we would estimate the parameters of the restricted model by setting the variance of the innovation to a constant value. Finally, we would compute the test statistic by taking the difference in the log-likelihood functions at the maximum and at the restricted parameter values, and then dividing by the number of degrees of freedom.\nSo the correct answer is (D): The likelihood ratio test compares the slopes of the log-likelihood function at the maximum and at the restricted parameter value."}
{"question": "Which one of the following is NOT a plausible remedy for near multicollinearity?", "choices": [{"label": "A", "text": "Use principal components analysis"}, {"label": "B", "text": "Drop one of the collinear variables"}, {"label": "C", "text": "Use a longer run of data"}, {"label": "D", "text": "Take logarithms of each of the variables"}], "answerKey": "D", "model_answer": "The correct answer is (C) Use a longer run of data.\nNear multicollinearity occurs when two or more independent variables are highly correlated with each other. This can lead to problems in regression analysis, such as spurious regression coefficients and unstable standard errors. The other three options (A) Use principal components analysis, (B) Drop one of the collinear variables, and (D) Take logarithms of each of the variables) can be effective remedies for near multicollinearity, but using a longer run of data is not a plausible remedy. This is because using a longer run of data can increase the sample size and may not necessarily reduce the correlation between variables. Instead, the other three options can be used to reduce the correlation between variables and improve the accuracy and reliability of regression analysis."}
{"question": "Consider the following AR(2) process:\n\nyt = 1.5 yt-1 - 0.5 yt-2 + ut\n\nThis is a", "choices": [{"label": "A", "text": "Stationary process"}, {"label": "B", "text": "Unit root process"}, {"label": "C", "text": "Explosive process"}, {"label": "D", "text": "Stationary and unit root process"}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following could be used as a test for autocorrelation up to third order?", "choices": [{"label": "A", "text": "The Durbin Watson test"}, {"label": "B", "text": "White's test"}, {"label": "C", "text": "The RESET test"}, {"label": "D", "text": "The Breusch-Godfrey test"}], "answerKey": "D", "model_answer": "The correct answer is (A) The Durbin Watson test.\nThe Durbin Watson test is a statistical test that can be used to detect autocorrelation up to a specified order. The test compares the actual values of the sample autocorrelation coefficient to the theoretical values predicted by the null hypothesis of no autocorrelation. If the test statistic is greater than 1, this suggests the presence of autocorrelation, while if it is less than 1, it suggests the absence of autocorrelation. The Durbin Watson test is often used in conjunction with other tests, such as the Breusch-Godfrey test, to improve the accuracy of autocorrelation estimates."}
{"question": "The residual from a standard regression model is defined as", "choices": [{"label": "A", "text": "The difference between the actual value, y, and the mean, y-bar"}, {"label": "B", "text": "The difference between the fitted value, y-hat, and the mean, y-bar"}, {"label": "C", "text": "The difference between the actual value, y, and the fitted value, y-hat"}, {"label": "D", "text": "The square of the difference between the fitted value, y-hat, and the mean, y-bar"}], "answerKey": "C", "model_answer": "fference between the fitted value, y-hat, and the mean, y-bar."}
{"question": "If OLS is applied separately to each equation that is part of a simultaneous system, the resulting estimates will be", "choices": [{"label": "A", "text": "Unbiased and consistent"}, {"label": "B", "text": "Biased but consistent"}, {"label": "C", "text": "Biased and inconsistent"}, {"label": "D", "text": "It is impossible to apply OLS to equations that are part of a simultaneous system"}], "answerKey": "C", "model_answer": "impossible to apply OLS to equations that are part of a simultaneous system."}
{"question": "Which one of the following is NOT an example of mis-specification of functional form?", "choices": [{"label": "A", "text": "Using a linear specification when y scales as a function of the squares of x"}, {"label": "B", "text": "Using a linear specification when a double-logarithmic model would be more appropriate"}, {"label": "C", "text": "Modelling y as a function of x when in fact it scales as a function of 1/x"}, {"label": "D", "text": "Excluding a relevant variable from a linear regression model"}], "answerKey": "D", "model_answer": "The correct answer is (D) Excluding a relevant variable from a linear regression model.\nMis-specification of functional form occurs when the functional form used in a regression model does not accurately represent the underlying relationship between the variables. This can lead to biased and inefficient estimates, as well as incorrect conclusions about the relationships between variables.\nChoice (A) using a linear specification when y scales as a function of the squares of x is an example of specification search. This is the process of finding the best functional form for a given dataset, and it is not necessarily a form of mis-specification.\nChoice (B) using a linear specification when a double-logarithmic model would be more appropriate is an example of model misspecification, but it is not a form of mis-specification of functional form, as it involves choosing the wrong type of model rather than the wrong functional form within a given model.\nChoice (C) modelling y as a function of x when in fact it scales as a function of 1/x is an example of functional form misspecification, as it involves using the wrong functional form to represent the relationship between variables."}
{"question": "Suppose that we wished to evaluate the factors that affected the probability that an investor would choose an equity fund rather than a bond fund or a cash investment. Which class of model would be most appropriate?", "choices": [{"label": "A", "text": "A logit model"}, {"label": "B", "text": "A multinomial logit"}, {"label": "C", "text": "A tobit model"}, {"label": "D", "text": "An ordered logit model"}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following statements will be true if the number of replications used in a Monte Carlo study is small?\n\ni) The statistic of interest may be estimated imprecisely\n\n\nii) The results may be affected by unrepresentative combinations of random draws\n\n\niii) The standard errors on the estimated quantities may be unacceptably large\n\n\niv) Variance reduction techniques can be used to reduce the standard errors", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "The correct answer is D) (i), (ii), (iii), and (iv).\n\nIf the number of replications used in a Monte Carlo study is small, the following outcomes may occur:\n\ni) The statistic of interest may be estimated imprecisely because of the limited sample size.\n\nii) The results may be affected by unrepresentative combinations of random draws because of the lack of diversity in the sample.\n\niii) The standard errors on the estimated quantities may be unacceptably large because of the limited sample size.\n\niv) Variance reduction techniques can be used to reduce the standard errors and improve the precision of the estimates.\n\nTherefore, option D) (i), (ii), (iii), and (iv) is the correct answer."}
{"question": "Which of the following is a disadvantage of the random effects approach to estimating a panel model?", "choices": [{"label": "A", "text": "The approach may not be valid if the composite error term is correlated with one or more of the explanatory variables"}, {"label": "B", "text": "The number of parameters to estimate may be large, resulting in a loss of degrees of freedom"}, {"label": "C", "text": "The random effects approach can only capture cross-sectional heterogeneity and not temporal variation in the dependent variable."}, {"label": "D", "text": "All of (a) to (c) are potential disadvantages of the random effects approach."}], "answerKey": "A", "model_answer": "The correct answer is (D) All of (a) to (c) are potential disadvantages of the random effects approach."}
{"question": "Which of the following could result in autocorrelated residuals?\n\ni) Slowness of response of the dependent variable to changes in the values of the independent variables\n\nii) Over-reactions of the dependent variable to changes in the independent variables\n\niii) Omission of relevant explanatory variables that are autocorrelated\n\niv) Outliers in the data", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "e correct answer is (D) (i), (ii), (iii), and (iv). Autocorrelated residuals can result from errors in measurement, model specification, or data cleaning. Slowness of response and over-reactions to changes in independent variables could result from omitted variable bias or omitted variable selection, while outliers could result from measurement error or data cleaning. Autocorrelated residuals themselves could result from modeling autocorrelated data or modeling residuals rather than the true response variable."}
{"question": "Which of the following statements are true concerning the acf and pacf?\n\n(i) The acf and pacf are often hard to interpret in practice\n\n(ii) The acf and pacf can be difficult to calculate for some data sets\n\n(iii) Information criteria represent an alternative approach to model order determination\n\n(iv) If applied correctly, the acf and pacf will always deliver unique model selections", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "rrect answer is (D) (i), (ii), (iii), and (iv). This is because all of the statements are true. The autocorrelation function (ACF) and partial autocorrelation function (PACF) can be difficult to interpret and calculate for some data sets, and their correct use is essential to avoid biased and inefficient models. Information criteria represent an alternative approach to model order determination, and while the ACF and PACF can provide unique model selections, they are not always necessary to achieve this."}
{"question": "Which of the following conditions are necessary for a series to be classifiable as a weakly stationary process?\n\n(i) It must have a constant mean\n\n(ii) It must have a constant variance\n\n(iii) It must have constant autocovariances for given lags\n\n(iv) It must have a constant probability distribution", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "i), (ii), (iii), and (iv) only.\n\nExplanation: A weakly stationary process is a process that has a mean, variance, autocovariance, and distribution that are all asymptotically constant over time. The four conditions listed are necessary but not sufficient for a process to be classified as weakly stationary.\n\nIn other words, (i) and (ii) are necessary for a process to be weakly stationary, but (iii) and (iv) are not. Condition (iii) relates to autocovariances, which are a measure of the similarity between a process and its past values at different lags. While it is important for a process to have constant autocovariances for given lags, it is not enough on its own to make the process weakly stationary.\n\nSimilarly, condition (iv) relates to the probability distribution of the process, which is important for ensuring that the process is not affected by extreme values, which can make it non-stationary. Again, this is a necessary condition but not sufficient on its own to make a process weakly stationary.\n\nTherefore, the correct answer is (D) (i), (ii), (iii), and (iv) only."}
{"question": "Consider the following equation and determine the class of model that it best represents\n\n$y_{it} = \\alpha + \\beta_{it} + \\mu_i + \\nu_{it}$", "choices": [{"label": "A", "text": "An entity fixed effects model"}, {"label": "B", "text": "A time fixed effects model"}, {"label": "C", "text": "A random effects model"}, {"label": "D", "text": "A pure time series model"}], "answerKey": "A", "model_answer": "The correct answer is (D) A pure time series model.\n\nThe equation $y_{it} = \\alpha + \\beta_{it} + \\mu\\_i + \\nu_{it}$ is a basic time series model that includes intercepts for both the individual-specific effect ($\\mu\\_i$) and the item-specific effect ($\\nu_{it}$). This model assumes that the error term $\\epsilon_{it}$ follows a normal distribution with constant variance.\n\nA pure time series model does not account for any unobserved heterogeneity or fixed effects, unlike the entity fixed effects model (A) or the random effects model (C). Therefore, option (D) is the correct choice."}
{"question": "Note that statistical tables are not necessary to answer this question. For a sample of 1000 observations, the Dickey-Fuller test statistic values are", "choices": [{"label": "A", "text": "More negative than (i.e. bigger in absolute value than) those in the left hand tail of a normal distribution"}, {"label": "B", "text": "Less negative than (i.e. smaller in absolute value than) those in the left hand tail of a normal distribution"}, {"label": "C", "text": "Obtained from an analytical formula for the density of the Dickey-Fuller distribution"}, {"label": "D", "text": "More negative (i.e. bigger in absolute value) for a 10% size of test than a 5% test."}], "answerKey": "A", "model_answer": "The correct answer is (D) More negative (i.e. bigger in absolute value) for a 10% size of test than a 5% test.\nThe Dickey-Fuller test is a statistical test used to check the presence of a unit root in a time series data. If a unit root is present, it indicates that the data is not stationary and has a trend. The test statistic value of the Dickey-Fuller test is negative, which means that it is more negative (i.e. bigger in absolute value) for a 10% size of test than a 5% test. This indicates that the presence of a unit root is more likely to be detected with a 10% level of significance than a 5% level of significance. Therefore, the correct answer is (D) More negative (i.e. bigger in absolute value) for a 10% size of test than a 5% test."}
{"question": "Suppose that a hypothesis test is conducted using a 5% significance level. Which of the following statements are correct?\n\n(i) The significance level is equal to the size of the test\n\n(ii) The significance level is equal to the power of the test\n\n(iii) 2.5% of the total distribution will be in each tail rejection region for a 2-sided test\n\n(iv) 5% of the total distribution will be in each tail rejection region for a 2-sided test.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": ""}
{"question": "Which one of the following criticisms of the Dickey-Fuller/Engle-Granger approach to dealing with cointegrated variables is overcome by the Engle-Yoo (EY) procedure?", "choices": [{"label": "A", "text": "In the context of small samples, Dickey Fuller tests are prone to conclude that there is a unit root in a series when there is not"}, {"label": "B", "text": "The Engle-Granger (EG) approach can only detect up to one cointegrating relationship even though there could be more than one"}, {"label": "C", "text": "The variables are treated asymmetrically in the cointegrating tests"}, {"label": "D", "text": "It is not possible to perform tests about the cointegrating relationship"}], "answerKey": "D", "model_answer": ""}
{"question": "Consider a series that follows an MA(1) with zero mean and a moving average coefficient of 0.4. What is the value of the autocovariance at lag 1?", "choices": [{"label": "A", "text": "0.4"}, {"label": "B", "text": "1"}, {"label": "C", "text": "0.34"}, {"label": "D", "text": "It is not possible to determine the value of the autocovariances without knowing the disturbance variance."}], "answerKey": "D", "model_answer": "The correct answer is (B) 1.\n\nThe autocovariance at lag 1 is the variance of the difference between two observations separated by one time unit. Given that the series follows an MA(1) process, the autocovariance at lag 1 is equal to the mean of the series, which is 1.\nTherefore, the answer is (B) 1."}
{"question": "Which of the following estimation techniques are available for the estimation of over-identified systems of simultaneous equations?\n\ni) OLS\n\nii) ILS\n\niii) 2SLS\n\niv) IV", "choices": [{"label": "A", "text": "(iii) only"}, {"label": "B", "text": "(iii) and (iv) only"}, {"label": "C", "text": "(ii), (iii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii) and (iv)"}], "answerKey": "B", "model_answer": "The correct answer is (D) (i), (ii), (iii), and (iv).\n\nOLS (ordinary least squares) is a commonly used method for estimating over-identified systems of simultaneous equations. However, OLS can fail in cases where there are more observations than parameters. In such cases, it is possible for the estimated parameters to be exactly equal to zero. This is called the \"identification crisis,\" and it results in over-identification, which means that there are more equations than parameters.\n\nILS (iterative least squares) is another method that can be used to estimate over-identified systems of simultaneous equations. It is a type of maximum likelihood estimation that uses iterative techniques to find the solution that maximizes the likelihood of the observed data.\n\n2SLS (two-stage least squares) is a method that can be used to estimate over-identified systems of simultaneous equations when there are exogenous variables that are endogenous in one stage. 2SLS solves for the parameters of the endogenous variables in one stage, then uses these parameters as regressors in the second stage to estimate the parameters of the exogenous variables.\n\nIV (instrumental variables) is a method that can be used to estimate over-identified systems of simultaneous equations when there is an endogenous instrument that affects the exogenous variable, but only through its effect on the endogenous variable. IV uses the instrument to explain the endogenous variable, which in turn explains the exogenous variable.\n\nIn summary, there are four estimation techniques available for the estimation of over-identified systems of simultaneous equations, which are OLS, ILS, 2SLS, and IV."}
{"question": "Which one of the following statements best describes a Type II error?", "choices": [{"label": "A", "text": "It is the probability of incorrectly rejecting the null hypothesis"}, {"label": "B", "text": "It is equivalent to the power of the test"}, {"label": "C", "text": "It is equivalent to the size of the test"}, {"label": "D", "text": "It is the probability of failing to reject a null hypothesis that was wrong"}], "answerKey": "D", "model_answer": "The correct answer is (A) It is the probability of incorrectly rejecting the null hypothesis.\nA Type II error, also known as a false negative, occurs when the researcher rejects the null hypothesis when it is actually true. In other words, it is the probability of making a mistake by failing to reject the null hypothesis when it is false. This is also known as the probability of a Type II error. The power of the test is related to the probability of making a Type I error, which is the probability of incorrectly accepting the null hypothesis. The size of the test is the threshold for rejecting the null hypothesis, which is typically determined by the level of significance. The test should have a low probability of Type II errors, which means that it should have a low probability of rejecting the null hypothesis when it is actually false."}
{"question": "Which one of the following would be the most appropriate as a 95% (two-sided) confidence interval for the intercept term of the model given in question 21?", "choices": [{"label": "A", "text": "(-4.79,2.19)"}, {"label": "B", "text": "(-4.16,4.16)"}, {"label": "C", "text": "(-1.98,1.98)"}, {"label": "D", "text": "(-5.46,2.86)"}], "answerKey": "D", "model_answer": "To find the most appropriate 95% two-sided confidence interval for the intercept term of the model given in question 21, we can use the t-distribution. The t-distribution is a symmetric distribution that is often used to estimate confidence intervals for the mean of a population with a small sample size or for the intercept term in a regression model.\nIf we use the t-distribution with 9 degrees of freedom (df), the t-value for the lower bound of the confidence interval is approximately -4.16, and the t-value for the upper bound of the confidence interval is approximately 2.19. Therefore, the most appropriate 95% two-sided confidence interval for the intercept term of the model given in question 21 is (-4.16, 2.19).\nTherefore, the correct answer is (B) (-4.16, 4.16)."}
{"question": "Which of the following are characteristics of a stationary process?\n\ni) It crosses its mean value frequently\n\n\nii) It has constant mean and variance\n\n\niii) It contains no trend component\n\n\niv) It will be stationary in first difference form", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "correct answer is (D) (i), (ii), (iii), and (iv).\n\nA stationary process is one that does not change over time, and it has a constant mean and variance. The process can have a trend component, which means it has a general direction or tendency to change over time, but it will still be considered stationary if its mean and variance are constant. In first difference form, a stationary process will still be stationary if its first differences are also constant.\nTherefore, option (i) is a characteristic of a stationary process, and options (ii) and (iii) are also characteristics of a stationary process in certain situations. Option (iv) is not a characteristic of a stationary process, but it is a result of a stationary process."}
{"question": "Consider again the VAR model of equation 16. Which of the following conditions must hold for it to be said that there is bi-directional feedback?", "choices": [{"label": "A", "text": "The b and d coefficients significant and the a and c coefficients insignificant"}, {"label": "B", "text": "The a and c coefficients significant and the b and d coefficients insignificant"}, {"label": "C", "text": "The a and c coefficients significant"}, {"label": "D", "text": "The b and d coefficients significant"}], "answerKey": "D", "model_answer": "\u200b"}
{"question": "Consider the following sample autocorrelation estimates obtained using 250 data points:\n\n1) Lag 1 2 3\n\n2) Coefficient 0.2 -0.15 -0.1\n\n3) Assuming that the coefficients are approximately normally distributed, which of the coefficients are statistically significant at the 5% level?", "choices": [{"label": "A", "text": "1 only"}, {"label": "B", "text": "1 and 2 only"}, {"label": "C", "text": "1, 2 and 3 only"}, {"label": "D", "text": "It is not possible to determine the statistical significance since no standard errors have been given"}], "answerKey": "B", "model_answer": "is not possible to determine the statistical significance since no standard errors have been given.\n\nIn order to determine the statistical significance of the coefficients, standard errors need to be provided. Without standard errors, it is impossible to determine whether the differences between the coefficients are significant or not. Without standard errors, it is not possible to determine the statistical significance of the coefficients."}
{"question": "Which one of the following is examined by looking at a goodness of fit statistic?", "choices": [{"label": "A", "text": "How well the population regression function fits the data"}, {"label": "B", "text": "How well the sample regression function fits the population regression function"}, {"label": "C", "text": "How well the sample regression function fits the data"}, {"label": "D", "text": "How well the population regression function fits the sample regression function."}], "answerKey": "C", "model_answer": "The correct answer is (D) How well the population regression function fits the sample regression function.\nA goodness of fit statistic is a measure of how well a sample fits a population. In this context, the sample regression function is the function that relates the independent variable(s) to the dependent variable(s) for the sample data. The population regression function is the same function, but for the entire population of interest.\nThe goodness of fit statistic compares the sample regression function to the population regression function, and it is used to determine how well the sample fits the population. If the goodness of fit statistic is small, it means that the sample fits the population well. However, if the goodness of fit statistic is large, it means that the sample does not fit the population well.\nTherefore, the correct answer is (D) How well the population regression function fits the sample regression function."}
{"question": "Which of the following statements are correct concerning the use of antithetic variates as part of a Monte Carlo experiment?\n\ni) Antithetic variates work by reducing the number of replications required to cover the whole probability space\n\nii) Antithetic variates involve employing a similar variable to that used in the simulation, but whose properties are known analytically\n\niii) Antithetic variates involve using the negative of each of the random draws and repeating the experiment using those values as the draws\n\niv) Antithetic variates involve taking one over each of the random draws and repeating the experiment using those values as the draws", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "The correct answer is (D) (i), (ii), (iii), and (iv), which states that:\ni) Antithetic variates work by reducing the number of replications required to cover the whole probability space\nii) Antithetic variates involve employing a similar variable to that used in the simulation, but whose properties are known analytically\niii) Antithetic variates involve using the negative of each of the random draws and repeating the experiment using those values as the draws\niv) Antithetic variates involve taking one over each of the random draws and repeating the experiment using those values as the draws.\nExplanation: Antithetic variates are a technique used in Monte Carlo simulations to reduce the number of replications required to cover the whole probability space. In this technique, two or more sets of random numbers are used, with each set having different properties but being drawn from the same distribution. The idea is that the two sets will cover the whole probability space, and by taking the average of the results obtained from each set, the results will be more accurate and require fewer replications. The other three statements describe the process of generating antithetic variates, which involves taking one over each of the random draws and repeating the experiment using those values as the draws."}
{"question": "Which one of the following statements is true concerning alternative forecast accuracy measures?", "choices": [{"label": "A", "text": "Mean squared error is usually highly correlated with trading rule profitability"}, {"label": "B", "text": "Mean absolute error provides a quadratic loss function"}, {"label": "C", "text": "Mean absolute percentage error is a useful measure for evaluating asset return forecasts"}, {"label": "D", "text": "Mean squared error penalises large forecast errors disproportionately more than small forecast errors"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following criticisms of standard (\"plain vanilla\") GARCH models can be overcome by EGARCH models?\n\ni) Estimated coefficient values from GARCH models may be negative\n\nii) GARCH models cannot account for leverage effects\n\niii) The responsiveness of future volatility to positive and negative shocks is symmetric under a GARCH formulation\n\niv) GARCH models cannot allow for a feedback from the volatility to the returns", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
{"question": "Suppose that 100 separate firms were tested to determine how many of them \"beat the market\" using a Jensen-type regression, and it is found that 3 fund managers significantly do so. Does this suggest prima facie evidence for stock market inefficiency?", "choices": [{"label": "A", "text": "Yes"}, {"label": "B", "text": "No"}, {"label": "C", "text": "In order to answer this question, you would need to test every fund manager trading in that market"}, {"label": "D", "text": "There is insufficient information given in the question to draw a conclusion about market efficiency."}], "answerKey": "B", "model_answer": "re is insufficient information given in the question to draw a conclusion about market efficiency.\n\nThe question does not provide enough information to determine market efficiency. To determine market efficiency, one would need to test every fund manager trading in the market, not just 100 separate firms. Additionally, the sample size of 100 firms is too small to draw any conclusions about the entire market. More research and a larger sample size would be needed to assess market efficiency."}
{"question": "Which of the following are advantages of the use of panel data over pure cross-sectional or pure time-series modelling?\n\n(i) The use of panel data can increase the number of degrees of freedom and therefore the power of tests\n\n(ii) The use of panel data allows the average value of the dependent variable to vary either cross-sectionally or over time or both\n\n(iii) The use of panel data enables the researcher allows the estimated relationship between the independent and dependent variables to vary either cross-sectionally or over time or both", "choices": [{"label": "A", "text": "(i) only"}, {"label": "B", "text": "(i) and (ii) only"}, {"label": "C", "text": "(ii) only"}, {"label": "D", "text": "(i), (ii), and (iii)"}], "answerKey": "B", "model_answer": ""}
{"question": "If the Engle-Granger test is applied to the residuals of a potentially cointegrating regression, what would be the interpretation of the null hypothesis?", "choices": [{"label": "A", "text": "The variables are cointegrated"}, {"label": "B", "text": "The variables are not cointegrated"}, {"label": "C", "text": "Both variables are stationary"}, {"label": "D", "text": "Both variables are non-stationary"}], "answerKey": "B", "model_answer": "The correct answer is (A) The variables are cointegrated.\nThe Engle-Granger test is used to test for the presence of cointegration between two variables in a potentially cointegrating regression. If the test is applied to the residuals of the regression, it tests the null hypothesis that the residuals are stationary. If the null hypothesis is rejected, it suggests that the variables are cointegrated. In other words, if the test is positive, it means that the variables are cointegrated, and if the test is negative, it means that the variables are not cointegrated."}
{"question": "Which of the following statements are true concerning the autocorrelation function (acf) and partial autocorrelation function (pacf)?\n\ni) The acf and pacf will always be identical at lag one whatever the model\n\nii) The pacf for an MA(q) model will in general be non-zero beyond lag q\n\niii) The pacf for an AR(p) model will be zero beyond lag p\n\niv) The acf and pacf will be the same at lag two for an MA(1) model", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
