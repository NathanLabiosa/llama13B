{"question": "Which one of the following is the most appropriate definition of a 99% confidence interval?", "choices": [{"label": "A", "text": "99% of the time in repeated samples, the interval would contain the true value of the parameter"}, {"label": "B", "text": "99% of the time in repeated samples, the interval would contain the estimated value of the parameter"}, {"label": "C", "text": "99% of the time in repeated samples, the null hypothesis will be rejected"}, {"label": "D", "text": "99% of the time in repeated samples, the null hypothesis will not be rejected when it was false"}], "answerKey": "A", "model_answer": ""}
{"question": "What is the main difference between the Dickey Fuller (DF) and Phillips-Perron (PP) approaches to unit root testing?", "choices": [{"label": "A", "text": "ADF is a single equation approach to unit root testing while PP is a systems approach"}, {"label": "B", "text": "PP tests reverse the DF null and alternative hypotheses so that there is stationarity under the null hypothesis of the PP test"}, {"label": "C", "text": "The PP test incorporates an automatic correction for autocorrelated residuals in the test regression"}, {"label": "D", "text": "PP tests have good power in small samples whereas DF tests do not."}], "answerKey": "C", "model_answer": ""}
{"question": "If there were a leverage effect in practice, what would be the shape of the news impact curve for as model that accounted for that leverage?", "choices": [{"label": "A", "text": "It would rise more quickly for negative disturbances than for positive ones of the same magnitude"}, {"label": "B", "text": "It would be symmetrical about zero"}, {"label": "C", "text": "It would rise less quickly for negative disturbances than for positive ones of the same magnitude"}, {"label": "D", "text": "It would be zero for all positive disturbances"}], "answerKey": "A", "model_answer": "LECTURE: In an economy, the news impact curve describes the effect of unexpected changes in the news on the economy's output. Good stories have a positive effect, and bad stories have a negative effect. The shape of the news impact curve determines the effect of positive and negative stories.\nThe news impact curve is a theoretical concept, and its shape is a parameter of the model. The shape of the news impact curve determines the effect of positive and negative stories.\nA leverage effect would make the news impact curve rise more quickly for negative disturbances than for positive ones of the same magnitude. This means that the economy would be more sensitive to bad news than to good news.\nA leverage effect would make the news impact curve more asymmetric, with a more positive slope above the equilibrium level of output than below.\nA leverage effect would not necessarily make the news impact curve zero for all positive disturbances. For example, the news impact curve could have a very low positive slope above the equilibrium level of output."}
{"question": "Which of the following statements is false concerning the linear probability model?", "choices": [{"label": "A", "text": "There is nothing in the model to ensure that the estimated probabilities lie between zero and one"}, {"label": "B", "text": "Even if the probabilities are truncated at zero and one, there will probably be many observations for which the probability is either exactly zero or exactly one"}, {"label": "C", "text": "The error terms will be heteroscedastic and not normally distributed"}, {"label": "D", "text": "The model is much harder to estimate than a standard regression model with a continuous dependent variable"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following statements concerning the regression population and sample is FALSE?", "choices": [{"label": "A", "text": "The population is the total collection of all items of interest"}, {"label": "B", "text": "The population can be infinite"}, {"label": "C", "text": "In theory, the sample could be larger than the population"}, {"label": "D", "text": "A random sample is one where each individual item from the population is equally likely to be drawn."}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following statements is INCORRECT concerning a comparison of the Box-Pierce Q and the Ljung-Box Q* statistics for linear dependence in time series?", "choices": [{"label": "A", "text": "Asymptotically, the values of the two test statistics will be equal"}, {"label": "B", "text": "The Q test has better small-sample properties than the Q*"}, {"label": "C", "text": "The Q test is sometimes over-sized for small samples"}, {"label": "D", "text": "As the sample size tends towards infinity, both tests will show a tendency to always reject the null hypothesis of zero autocorrelation coefficients."}], "answerKey": "B", "model_answer": ""}
{"question": "A parsimonious model is one that", "choices": [{"label": "A", "text": "Includes too many variables"}, {"label": "B", "text": "Includes as few variables as possible to explain the data"}, {"label": "C", "text": "Is a well-specified model"}, {"label": "D", "text": "Is a mis-specified model"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following is NOT a feature of continuously compounded returns (i.e. log-returns)?", "choices": [{"label": "A", "text": "They can be interpreted as continuously compounded changes in the prices"}, {"label": "B", "text": "They can be added over time to give returns for longer time periods"}, {"label": "C", "text": "They can be added across a portfolio of assets to give portfolio returns"}, {"label": "D", "text": "They are usually fat-tailed"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following features of financial asset return time-series could be captured using a standard GARCH(1,1) model?\n\ni) Fat tails in the return distribution\n\n\nii) Leverage effects\n\n\niii) Volatility clustering\n\n\niv) Volatility affecting returns", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: Financial assets have time-series returns, or patterns of change over time. Many financial time-series models have been developed to describe these returns.\nOne approach is to use a Gaussian, or normal, model. In a Gaussian model, the returns follow a Gaussian distribution, which is a bell-shaped curve.\nA more flexible approach is to use a GARCH model. A GARCH model defines the return series as a combination of short-term and long-term movements. The short-term movements are modeled as a random walk, which is a series of random changes. The long-term movements are modeled with an ARCH model, which is a model of the conditional variance of the series.\nThe volatility of a financial asset's return series is an important feature of the time-series. Volatility clustering means that the volatility tends to persist. In other words, if the return series is volatile on a particular day, then it is likely to be volatile the next day.\nResearch has shown that leCTURE: Financial assets have time-series returns, or patterns of change over time. Many financial time-series models have been developed to describe these returns.\nOne approach is to use a Gaussian, or normal, model. In a Gaussian model, the returns follow a Gaussian distribution, which is a bell-shaped curve.\nA more flexible approach is to use a GARCH model. A GARCH model defines the return series as a combination of short-term and long-term movements. The short-term movements are modeled as a random walk, which is a series of random changes. The long-term movements are modeled with an ARCH model, which is a model of the conditional variance of the series.\nThe volatility of a financial asset's return series is an important feature of the time-series. Volatility clustering means that the volatility tends to persist. In other words, if the return series is volatile on a particular day, then it is likely to be volatile the next day.\nResearch has shown that leverage effects are important in some financial assets. These effects suggest that the returns to the asset are higher in times of higher volatility.\nMany financial time-series models can capture the following features of a financial asset's return time-series:\n* Volatility clustering\n* Volatility affecting returns\n* Leverage effects\nHowever, these models cannot capture the following features:\n* Fat tails in the return distribution\n*"}
{"question": "Consider the estimation of a GARCH-M model. If the data employed were a time-series of daily corporate bond percentage returns, which of the following would you expect the value of the GARCH-in-mean parameter estimate to be?", "choices": [{"label": "A", "text": "Less than -1"}, {"label": "B", "text": "Between -1 and 0"}, {"label": "C", "text": "Between 0 and 1"}, {"label": "D", "text": "Bigger than 1"}], "answerKey": "C", "model_answer": ""}
{"question": "Under which of the following situations would bootstrapping be preferred to pure simulation?\n\ni) If it is desired that the distributional properties of the data in the experiment\n\nare the same as those of some actual data\n\n\nii) If it is desired that the distributional properties of the data in the experiment\n\nare known exactly\n\n\niii) If the distributional properties of the actual data are unknown\n\n\niv) If the sample of actual data available is very small", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following may be consequences of one or more of the CLRM assumptions being violated?\n\ni) The coefficient estimates are not optimal\n\n\nii) The standard error estimates are not optimal\n\n\niii) The distributions assumed for the test statistics are inappropriate\n\n\niv) Conclusions regarding the strength of relationships between the dependent\n\nand independent variables may be invalid.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following statements is true concerning forecasting in econometrics?", "choices": [{"label": "A", "text": "Forecasts can only be made for time-series data"}, {"label": "B", "text": "Mis-specified models are certain to produce inaccurate forecasts"}, {"label": "C", "text": "Structural forecasts are simpler to produce than those from time series models"}, {"label": "D", "text": "In-sample forecasting ability is a poor test of model adequacy"}], "answerKey": "D", "model_answer": ""}
{"question": "The pacf is necessary for distinguishing between", "choices": [{"label": "A", "text": "An AR and an MA model"}, {"label": "B", "text": "An AR and an ARMA model"}, {"label": "C", "text": "An MA and an ARMA model"}, {"label": "D", "text": "Different models from within the ARMA family"}], "answerKey": "B", "model_answer": "LECTURE: The acronym ARMA stands for Autoregressive Moving Average. An ARMA model is a statistical model that describes a process, such as a time series.\nThe parameters of an ARMA model are the coefficients of the autoregressive and moving average terms. The autoregressive term is of the form a_1, a_2, ..., a_p, where each a_i is a coefficient. The moving average term is of the form b_1, b_2, ..., b_q, where each b_i is a coefficient.\nThe model is used to make predictions by using past values of the process. For example, to make a prediction for t, the model uses the past values of the process at times 1 to t-1.\nThe autoregressive term measures the effect of the past values on the prediction. A coefficient of a_i that is not equal to zero indicates that a past value has an effect on the prediction. For example, a_1 is the coefficient for the effect of the past value at time t-1.\nThe moving average term measures the effect of the past errors on the prediction. A coefficient of b_i that is not equal to zero indicates that a past error has an effect on the prediction. For example, b_1 is the coefficient for the effect of the past error at time t-1.\nSOLUTION: The pacf is necessary for distinguishing between an AR and an MA model. The pacf of an AR model has a constant slope, while the pacf of an MA model has no constant slope.\nSo, for different models from within the ARMA family, the pacf can help you distinguish between an AR and an MA model."}
{"question": "Negative residual autocorrelation is indicated by which one of the following?", "choices": [{"label": "A", "text": "A cyclical pattern in the residuals"}, {"label": "B", "text": "An alternating pattern in the residuals"}, {"label": "C", "text": "A complete randomness in the residuals"}, {"label": "D", "text": "Residuals that are all close to zero"}], "answerKey": "B", "model_answer": "LECTURE: In a time series, autocorrelation occurs when the value of a variable at one time is correlated with its value at an earlier time. For example, the temperature today is correlated with the temperature yesterday.\nAutocorrelation can be negative as well as positive. A negative autocorrelation indicates that the variable tended to be lower in the past when it was lower in the recent past. An alternative way to say this is that negative autocorrelation indicates that the variable tends to revert to its recent past.\nA complete randomness in the residuals suggests that there is no pattern of autocorrelation. If the residuals are completely random, there is no tendency for the variable to revert to its recent past.\nA cyclical pattern in the residuals suggests that there is a pattern of autocorrelation. If the residuals exhibit a cyclical pattern, there is a tendency for the variable to revert to its recent past.\nAn alternating pattern in the residuals suggests that there is a pattern of autocorrelation. If the residuals alternate between above and below zero, there is a tendency for the variable to revert to its recent past.\nResiduals that are all close to zero indicate that there is no pattern of autocorrelation. If the residuals are all close to zero, there is no tendency for the variable to revert to its recent past.\nSOLUTION: To determine if negative residual autocorrelation is indicated, look for a pattern of negative autocorrelation in the residuals.\nSome of the residuals are above zero, and some are below zero. This pattern is not indicative of negative residual autocorrelation.\nResiduals that are all close to zero would indicate negative residual autocorrelation. No residuals are close to zero, so negative residual autocorrelation is not indicated."}
{"question": "Which of the following statements are true concerning a comparison between ARCH(q) and GARCH(1,1) models?\n\ni) The ARCH(q) model is likely to be the more parsimonious\n\n\nii) The ARCH(q) model is the more likely to violate non-negativity constraints\n\n\niii) The ARCH(q) model can allow for an infinite number of previous lags of squared\n\nreturns to affect the current conditional variance\n\n\niv) The GARCH(1,1) model will usually be sufficient to capture all of the dependence\n\nin the conditional variance", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following statements are true concerning a triangular or recursive system?\n\ni) The parameters can be validly estimated using separate applications of OLS to\n\neach equation\n\n\nii) The independent variables may be correlated with the error terms in other\n\nequations\n\n\niii) An application of 2SLS would lead to unbiased but inefficient parameter estimates\n\n\niv) The independent variables may be correlated with the error terms in the equations\n\nin which they appear as independent variables", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: A triangular system is a system of three equations. A recursive system is a system where one or more of the equations depend on the error terms from other equations.\nAn application of OLS to each equation in a triangular system will generally produce unbiased parameter estimates. However, the estimates will be inefficient, because the estimates of the parameters in each equation will be correlated.\nTo achieve efficient estimates, you can use a method called instrumental variables. One way to do this is by applying two-stage least squares (2SLS) to a recursive system.\n2SLS involves first regressing the error terms from the top equation on the independent variables and the error terms from the bottom equation. Then, regress the dependent variable in the top equation on the variables from the regression in the first step.\nThe parameters in the top equation will be biased, but efficient, because they will no longer be correlated with the error terms in the bottom equation.\nAn application of OLS to each equation in a triangular system will produce correlated parameter estimates. These estimates will be biased, and their variability will be overestimated."}
{"question": "Which one of the following statements best describes the algebraic representation of the fitted regression line?", "choices": [{"label": "A", "text": "\\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t + \\hat{u}_t"}, {"label": "B", "text": "\\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t"}, {"label": "C", "text": "\\hat{y}_t = \\hat{\\alpha} + \\hat{\\beta}x_t + u_t"}, {"label": "D", "text": "y_t = \\hat{\\alpha} + \\hat{\\beta}x_t + \\hat{u}_t"}], "answerKey": "B", "model_answer": ""}
{"question": "What are the dimensions of $\\hat{u}^t \\hat{u}?", "choices": [{"label": "A", "text": "T x k"}, {"label": "B", "text": "T x 1"}, {"label": "C", "text": "k x 1"}, {"label": "D", "text": "1 x 1"}], "answerKey": "D", "model_answer": ""}
{"question": "The characteristic roots of the MA process\n\n$y_t = -3u_{t-1} + u_{t-2} + u_t$\n\nare", "choices": [{"label": "A", "text": "1 and 2"}, {"label": "B", "text": "1 and 0.5"}, {"label": "C", "text": "2 and -0.5"}, {"label": "D", "text": "1 and -3"}], "answerKey": "B", "model_answer": "LECTURE: The characteristic roots of a difference equation have a profound effect on the behavior of the equation.\nIf all the characteristic roots are outside the unit circle, the equation will have a unique equilibrium.\nIf at least one characteristic root is inside the unit circle, the equation may not have a unique equilibrium.\nThe position of the equilibrium is determined by the root that is closest to the unit circle.\nIf this root is between -1 and 1, the equilibrium is inside the unit circle and is a root of the equation.\nIf this root is outside -1 and 1, the equilibrium is outside the unit circle.\n\nSOLUTION: The characteristic roots are 1 and 0.5.\nBoth roots are inside the unit circle. So, the equation may not have a unique equilibrium."}
{"question": "Which of the following is an equivalent expression for saying that the explanatory variable is \"non-stochastic\"?", "choices": [{"label": "A", "text": "The explanatory variable is partly random"}, {"label": "B", "text": "The explanatory variable is fixed in repeated samples"}, {"label": "C", "text": "The explanatory variable is correlated with the errors"}, {"label": "D", "text": "The explanatory variable always has a value of one"}], "answerKey": "B", "model_answer": ""}
{"question": "Suppose that the Durbin Watson test is applied to a regression containing two explanatory variables plus a constant with 50 data points. The test statistic takes a value of 1.53. What is the appropriate conclusion?", "choices": [{"label": "A", "text": "Residuals appear to be positively autocorrelated"}, {"label": "B", "text": "Residuals appear to be negatively autocorrelated"}, {"label": "C", "text": "Residuals appear not to be autocorrelated"}, {"label": "D", "text": "The test result is inconclusive"}], "answerKey": "D", "model_answer": ""}
{"question": "If OLS is used in the presence of autocorrelation, which of the following will be likely consequences?\n\ni) Coefficient estimates may be misleading\n\n\nii) Hypothesis tests could reach the wrong conclusions\n\n\niii) Forecasts made from the model could be biased\n\n\niv) Standard errors may inappropriate", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": ""}
{"question": "What will be the properties of the OLS estimator in the presence of multicollinearity?", "choices": [{"label": "A", "text": "It will be consistent, unbiased and efficient"}, {"label": "B", "text": "It will be consistent and unbiased but not efficient"}, {"label": "C", "text": "It will be consistent but not unbiased"}, {"label": "D", "text": "It will not be consistent"}], "answerKey": "A", "model_answer": "LECTURE: Linear regression is a method of estimating the relationship between a dependent variable and one or more independent variables. It is based on the concept of linearity, which means that the relationship between the variables is assumed to be a straight line.\nThe output of a linear regression is a table that displays the coefficients of the independent variables. The coefficient for each independent variable is estimated from the sample data. The coefficient tells you how much the dependent variable changes for a one-unit change in the independent variable.\nA constant, in addition to the independent variables, can be included in the linear regression. The constant is not estimated from the sample data; instead, it is assumed to be known. The constant is used to assign a value of the dependent variable for the first unit of the independent variable.\nThe properties of the OLS estimator are as follows:\nWhen there is no multicollinearity, the OLS estimator is efficient, which means that it is consistent and unbiased. Efficiency means that the estimator requires the least amount of information to achieve a certain level of accuracy.\nWhen there is multicollinearity, the OLS estimator is consistent and unbiased, but not efficient. In other words, the estimator does not require the least amount of information to achieve a certain level of accuracy, but it does not have a significant bias.\nWhen there is multicollinearity, the OLS estimator is not efficient. This means that the estimator requires more information to achieve a certain level of accuracy than does some other estimator. In addition, the estimator has a significant bias.\nWhen there is multicollinearity, the OLS estimator is consistent but not unbiased. This means that the estimator does not have a significant bias, but it requires the least amount of information to achieve a certain level of accuracy."}
{"question": "Which one of the following would NOT be a consequence of using non-stationary data in levels form?", "choices": [{"label": "A", "text": "The regression $R^2$ may be spuriously high"}, {"label": "B", "text": "Test statistics may not follow standard distributions"}, {"label": "C", "text": "Statistical inferences may be invalid"}, {"label": "D", "text": "Parameter estimates may be biased"}], "answerKey": "D", "model_answer": ""}
{"question": "If a series, y, follows a random walk, what is the optimal one-step ahead forecast of y?", "choices": [{"label": "A", "text": "The current value of y"}, {"label": "B", "text": "Zero"}, {"label": "C", "text": "One"}, {"label": "D", "text": "The average value of y over the in-sample period"}], "answerKey": "A", "model_answer": ""}
{"question": "The order condition is", "choices": [{"label": "A", "text": "A necessary and sufficient condition for identification"}, {"label": "B", "text": "A necessary but not sufficient condition for identification"}, {"label": "C", "text": "A sufficient but not necessary condition for identification"}, {"label": "D", "text": "A condition that is nether necessary nor sufficient for identification"}], "answerKey": "B", "model_answer": ""}
{"question": "If an estimator is said to have minimum variance, which of the following statements is NOT implied?", "choices": [{"label": "A", "text": "The probability that the estimate is a long way away from its true value is minimised"}, {"label": "B", "text": "The estimator is efficient"}, {"label": "C", "text": "Such an estimator would be termed \"best\""}, {"label": "D", "text": "Such an estimator will always be unbiased"}], "answerKey": "D", "model_answer": "LECTURE: An estimator is said to have minimum variance if it minimises the expected value of the squared difference between the estimator and the true value.\nThe expected value of a sum of random variables is a measure of the center of the distribution of the sum. It is a number, not a random variable. For a sum of random variables, the expected value is calculated as the sum of the expected values of the individual random variables.\nThe expected value of a random variable is a measure of the center of the distribution of the random variable. It is a number, not a random variable. For a random variable, the expected value is calculated as the average of the possible values of the random variable.\nIf the expected value of the squared difference between an estimator and the true value is minimised, then the estimator is unbiased. This means that the expected value of the estimator is equal to the expected value of the true value.\nIf the expected value of the squared difference between an estimator and the true value is minimised, the estimator is efficient. This means that the estimator is the best possible estimator, in the sense that it has the minimum variance.\nA Minimax estimator is an efficient estimator. A Minimax estimator is an estimator that minimises the expected value of the squared difference between the estimator and the true value.\nSOLUTION: The question asks which of the following statements is NOT implied when an estimator is said to have minimum variance.\nAn estimator is efficient. This is implied.\n Such an estimator would be termed \"best\". This is implied.\nSuch an estimator will always be unbiased. This is implied.\nThe probability that the estimate is a long way away from its true value is minimised. This is not implied. An estimator with minimum variance is not necessarily unbiased."}
{"question": "Which of the following are disadvantages of the Dickey-Fuller / Engle-Granger approach to testing for cointegration and modelling cointegrating relationships?\n\ni) Only one cointegrating relationship can be estimated\n\nii) Particularly for small samples. There is a high chance of the tests suggestingthat variables are not cointegrated when they are\n\niii) It is not possible to make inferences on the cointegrating regression\n\niv) The procedure forces the researcher to specify which is the dependent variable and which are the independent variables.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following statements is true concerning the population regression function (PRF) and sample regression function (SRF)?", "choices": [{"label": "A", "text": "The PRF is the estimated model"}, {"label": "B", "text": "The PRF is used to infer likely values of the SRF"}, {"label": "C", "text": "Whether the model is good can be determined by comparing the SRF and the PRF"}, {"label": "D", "text": "The PRF is a description of the process thought to be generating the data."}], "answerKey": "D", "model_answer": ""}
{"question": "Which one of the following is a disadvantage of the general to specific or \"LSE\" (\"Hendry\") approach to building econometric models, relative to the specific to general approach?", "choices": [{"label": "A", "text": "Some variables may be excluded at the first stage leading to coefficient biases"}, {"label": "B", "text": "The final model may lack theoretical interpretation"}, {"label": "C", "text": "The final model may be statistically inadequate"}, {"label": "D", "text": "If the initial model is mis-specified, all subsequent steps will be invalid."}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following statements are true concerning maximum likelihood (ML) estimation in the context of GARCH models?\n\ni) Maximum likelihood estimation selects the parameter values that maximise the\n\nprobability that we would have actually observed the values of the series y that we\n\nactually did.\n\n\nii) GARCH models can only be estimated by ML and not by OLS\n\n\niii) For estimation of a standard linear model (with no GARCH), the OLS and ML\n\nestimates for the slope and intercept parameters will be identical but the estimator\n\nfor the variance of the disturbances is slightly different\n\n\niv) Most computer packages use numerical procedures to estimate GARCH models\n\nrather than a set of analytical formulae", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": ""}
{"question": "Including relevant lagged values of the dependent variable on the right hand side of a regression equation could lead to which one of the following?", "choices": [{"label": "A", "text": "Biased but consistent coefficient estimates"}, {"label": "B", "text": "Biased and inconsistent coefficient estimates"}, {"label": "C", "text": "Unbiased but inconsistent coefficient estimates"}, {"label": "D", "text": "Unbiased and consistent but inefficient coefficient estimates."}], "answerKey": "A", "model_answer": ""}
{"question": "Which one of the following factors is likely to lead to a relatively high degree of out-of-sample forecast accuracy?", "choices": [{"label": "A", "text": "A model that is based on financial theory"}, {"label": "B", "text": "A model that contains many variables"}, {"label": "C", "text": "A model whose dependent variable has recently exhibited a structural change"}, {"label": "D", "text": "A model that is entirely statistical in nature with no room for judgmental modification of forecasts"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following are plausible approaches to dealing with residual autocorrelation?\n\ni) Take logarithms of each of the variables\n\nii) Add lagged values of the variables to the regression equation\n\niii) Use dummy variables to remove outlying observations\n\niv) Try a model in first differenced form rather than in levels.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "LECTURE: Residual autocorrelation is the correlation between a variable and its own lags. That is, if one variable is correlated with its own past values, then those values will be correlated with each other.\nOne possible approach to dealing with residual autocorrelation is to use different methods of differencing to change the time pattern of the variable. For example, taking the logarithm of a variable can help to remove the autocorrelation of the variable.\nAnother approach is to use a different type of model. For example, instead of using a regression model, which is used with lagged values, you might try a different type of model that is not used with lagged values.\nAdding dummy variables is another approach to dealing with autocorrelation. Dummy variables are variables that are normally distributed with expected value of zero. They can be used to replace correlated variables in a regression.\nFirst differencing is a type of differencing that changes the time pattern of a variable. First differencing is used when the time pattern of a variable is not stationary. Stationary variables have a time pattern that does not change over time."}
{"question": "For an autoregressive process to be considered stationary", "choices": [{"label": "A", "text": "The roots of the characteristic equation must all lie inside the unit circle"}, {"label": "B", "text": "The roots of the characteristic equation must all lie on the unit circle"}, {"label": "C", "text": "The roots of the characteristic equation must all lie outside the unit circle"}, {"label": "D", "text": "The roots of the characteristic equation must all be less than one in absolute value"}], "answerKey": "C", "model_answer": "LECTURE: A stationary process is one in which the statistical properties do not change over time. For example, the mean, variance, and correlation of a stationary process are all constant.\nAn autoregressive process is a stochastic process that is completely described by a set of coefficients. The general form of an autoregressive process is:\nY(k) = a + b1*Y(k-1) + b2*Y(k-2) + ... + bn*Y(k-n)\nwhere Y is the output of the process, and a, b1, b2, ..., bn are the coefficients.\nThe roots of the characteristic equation play a key role in determining the stationary properties of a process. For an autoregressive process to be considered stationary, the roots of the characteristic equation must all lie inside the unit circle.\nSOLUTION: The unit circle is the set of all points in the complex plane with magnitude 1. It is shown in the graph below.\nPoints inside the unit circle are called simple. Points on the unit circle are called singular. Points outside the unit circle are called complex.\nThe roots of the characteristic equation must all be less than one in absolute value for the process to be stationary. This is shown in the graph below."}
{"question": "Which of the following statements are true concerning information criteria?\n\n(i) Adjusted R-squared is an information criterion\n\n(ii) If the residual sum of squares falls when an additional term is added, the value of the information criterion will fall\n\n(iii) Akaike's information criterion always leads to model orders that are at least as large as those of Schwarz's information criterion\n\n(iv) Akaike's information criterion is consistent", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": ""}
{"question": "The \"within transform\" involves", "choices": [{"label": "A", "text": "Taking the average values of the variables"}, {"label": "B", "text": "Subtracting the mean of each entity away from each observation on that entity"}, {"label": "C", "text": "Estimating a panel data model using least squares dummy variables"}, {"label": "D", "text": "Using both time dummies and cross-sectional dummies in a fixed effects panel model"}], "answerKey": "B", "model_answer": "LECTURE: Fixed effects modeling is a method for analyzing panel data. Panel data is a type of data that includes information about the same units over multiple time periods. In order to analyze panel data, researchers need to use models that take into account both the fixed effects of units and the time effects of time periods.\nThere are several ways to do fixed effects modeling. One way is to include both time dummies and cross-sectional dummies in the model. Time dummies are for categories of time periods, and cross-sectional dummies are for categories of units.\nFor example, consider a panel data set with two time periods and three units. The first time period has two categories, and the second time period has three categories. There are two time dummies, and three cross-sectional dummies.\nThe first time dummy is for the first time period. The second time dummy is for the second time period. The third cross-sectional dummy is for the first unit. The fourth cross-sectional dummy is for the second unit. The fifth cross-sectional dummy is for the third unit.\nThe model includes both the time dummies and the cross-sectional dummies. The time dummies indicate which time period an observation is in, and the cross-sectional dummies indicate which unit an observation is for.\nThe assistant can use the data set to estimate the model. The estimated model will have coefficients for the time dummies and the cross-sectional dummies.\nFor example, the estimated model might show that the value of the variable increases by 1 in the second time period as compared to the first time period, but is lower for the third unit as compared to the first unit.\nSOLUTION: The within transform involves using both time dummies and cross-sectional dummies in a fixed effects panel model. This is a method for analyzing panel data.\nThe within transform uses the fixed effects of the model to estimate the effects of the time dummies and the cross-sectional dummies. The within estimates show what happens on average to observations that are similar with respect to the fixed effects.\nFor example, the within estimate for the effect of the second time dummy is an average of the difference between the second time period and the first time period, holding the fixed effects of the units constant.\nThe within estimates do not necessarily represent what happens on average to all observations. They represent what happens on average to observations that are similar with respect to the fixed effects."}
{"question": "The purpose of \"augmenting\" the Dickey-Fuller test regression is to", "choices": [{"label": "A", "text": "Ensure that there is no heteroscedasticity in the test regression residuals."}, {"label": "B", "text": "Ensure that the test regression residuals are normally distributed"}, {"label": "C", "text": "Ensure that there is no autocorrelation in the test regression residuals"}, {"label": "D", "text": "Ensure that all of the non-stationarity is taken into account."}], "answerKey": "C", "model_answer": "LECTURE: In a unit on practical business applications of time series analysis, you learned about the ARIMA model. The ARIMA model is a time series model that uses three components to describe the pattern of a time series:\nThe autoregressive (A) component describes the dependence of the current observation on the previous observations.\nThe moving average (MA) component describes the dependence of the current observation on the error term of the previous observation.\nThe integrated (I) component describes the dependence of the current observation on the error term of the previous observations.\nTogether, these three components form the ARIMA model.\nYou also learned that a time series is a sequence of observations that are ordered in time. A time series is a stationary time series if the statistical properties of the observations do not change over time. A time series is a non-stationary time series if the statistical properties change over time.\nA first-order differencing is a technique that can be used to remove the trend and the seasonality from a non-stationary time series. This technique can be used to transform a non-stationary time series into a stationary time series.\nA unit on practical business applications of time series analysis also covers the topic of testing for autocorrelation in a time series. A time series is autocorrelated if the observations are dependent on the previous observations. A test for autocorrelation can be used to determine if a time series is autocorrelated.\nSOLUTION: The augmented Dickey-Fuller test is a test for non-stationarity. The test statistic for the augmented Dickey-Fuller test is based on the residuals from a regression of the time series on an ARIMA model. The residuals from a regression of the time series on an ARIMA model are the differences between the actual observations and the observations predicted by the ARIMA model.\nThe purpose of \"augmenting\" the Dickey-Fuller test regression is to ensure that all of the non-stationarity is taken into account. The residuals from a regression of the time series on an ARIMA model include the non-stationary pattern of the time series. Including the non-stationary pattern of the time series in the test for non-stationarity ensures that all of the non-stationarity is taken into account."}
{"question": "If a series, y, follows a random walk with drift b, what is the optimal one-step ahead forecast of the change in y?", "choices": [{"label": "A", "text": "The current value of y"}, {"label": "B", "text": "Zero"}, {"label": "C", "text": "One"}, {"label": "D", "text": "The average value of the change in y over the in-sample period"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following are plausible approaches to dealing with a model that exhibits heteroscedasticity?\n\ni) Take logarithms of each of the variables\n\nii) Use suitably modified standard errors\n\niii) Use a generalised least squares procedure\n\niv) Add lagged values of the variables to the regression equation.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: Heteroscedasticity means that the uncertainty of the error term is constant. This is not a problem for the validity of the regression results, but it does mean that the estimate of the fixed effect is no longer the coefficient on the dependent variable. Instead, you can obtain a consistent estimate of the fixed effect by including a squared term for each independent variable in the regression. The square of each independent variable will give you one additional coefficient. In this case, the additional coefficient is the variance of the error. This variance is a function of the independent variables, so you can include it in the regression by feeding in the squared terms.\nIf you have a lot of independent variables, you may not be able to include all of the squared terms. In this case, you can use a method called generalized least squares. This method replaces the squared terms with the sum of the squared terms up to a certain degree.\nThe modified standard errors produced by most statistical software take into account the fact that the uncertainty of the error term is no longer constant. They are still valid when you include squared terms for the independent variables.\nLogarithms of each of the variables can be used to deal with heteroscedasticity. This is because the variance of the error is proportional to the inverse of the average of the independent variables. So, if you take the logarithm of each variable, the variance of the error will be proportional to the average of the logged variables. This will eliminate the heteroscedasticity.\nSOLUTION: To deal with heteroscedasticity, you can use suitably modified standard errors or a generalized least squares procedure.\nTaking logarithms of each of the variables will eliminate the heteroscedasticity. However, this approach can make it difficult to interpret the results, and it may not be the most appropriate way to deal with heteroscedasticity.\nAdding lagged values of the variables to the regression equation can help deal with heteroscedasticity. This is because the lagged values of the variables are highly correlated with the original variables. This correlation will help eliminate the heteroscedasticity."}
{"question": "Which of the following statements are true concerning the standardised residuals (residuals divided by their respective conditional standard deviations) from an estimated GARCH model?\n\ni) They are assumed to be normally distributed\n\n\nii) Their squares will be related to their lagged squared values if the GARCH model is\n\nappropriate\n\n\niii) In practice, they are likely to have fat tails\n\n\niv) If the GARCH model is adequate, the standardised residuals and the raw residuals\n\nwill be identical", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: In the context of a GARCH model, residuals are the differences between the observed returns and the returns expected from the model. The standardised residuals are the residuals divided by their respective conditional standard deviations.\nThe standardised residuals from an estimated GARCH model have the following properties:\nThey are assumed to be normally distributed.\nTheir squares will be related to their lagged squared values if the GARCH model is appropriate.\nIn practice, they are likely to have fat tails.\nIf the GARCH model is adequate, the standardised residuals and the raw residuals will be identical.\nThe standardised residuals are useful in situations where the residuals are not normally distributed or where they have different conditional standard deviations. In such cases, the standardised residuals can provide a more accurate measure of the errors in the model."}
{"question": "Which one of the following statements is true concerning VARs?", "choices": [{"label": "A", "text": "The coefficient estimates have intuitive theoretical interpretations"}, {"label": "B", "text": "The coefficient estimates usually have the same sign for all of the lags of a given variable in a given equation"}, {"label": "C", "text": "VARs often produce better forecasts than simultaneous equation structural models"}, {"label": "D", "text": "All of the components of a VAR must be stationary before it can be used for forecasting"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following statements is INCORRECT concerning the classical hypothesis testing framework?", "choices": [{"label": "A", "text": "If the null hypothesis is rejected, the alternative is accepted"}, {"label": "B", "text": "The null hypothesis is the statement being tested while the alternative encompasses the remaining outcomes of interest"}, {"label": "C", "text": "The test of significance and confidence interval approaches will always give the same conclusions"}, {"label": "D", "text": "Hypothesis tests are used to make inferences about the population parameters."}], "answerKey": "A", "model_answer": ""}
{"question": "An ARMA(p,q) (p, q are integers bigger than zero) model will have", "choices": [{"label": "A", "text": "An acf and pacf that both decline geometrically"}, {"label": "B", "text": "An acf that declines geometrically and a pacf that is zero after p lags"}, {"label": "C", "text": "An acf that declines geometrically and a pacf that is zero after q lags"}, {"label": "D", "text": "An acf that is zero after p lags and a pacf that is zero after q lags"}], "answerKey": "A", "model_answer": "LECTURE: A stationary time series is one where the statistical properties of the series are constant over time. Autocorrelation and partial autocorrelation are measures of the dependence of a series on its own past values.\nA series is said to be an ARMA(p,q) process if it is both autoregressive of order p and moving-average of order q. That is, the current value of the series depends on p previous values and q lags.\nThe acf and pacf are functions of the time lag. They tell you about the dependence of the series on its own past values. The acf declines geometrically as the time lag increases. This means that the series becomes less correlated with its past values as the difference between the current value and its past values increases. The pacf is zero after q lags. This means that the series is not correlated with its past values after q lags.\nSOLUTION: An ARMA(p,q) model will have an acf that declines geometrically and a pacf that is zero after q lags. This is the decline geomtrically and zero after lags. This is the decline geometrically and zero after lags. This is the decline geometrically and zero after lags. This is the decline geometrically and zero after lags. This is the decline geometrically and zero after lags. This is the decline geometrically and zero after lags. This is the decline geometrically and zero after lags. This is the decline geometrically and zero after lags."}
{"question": "Suppose that the following regression is estimated using 27 quarterly observations:\n\n$y_t = \\beta_1 + \\beta_2 x_2 + \\beta_3 x_{3t} + u_t$\n\nWhat is the appropriate critical value for a 2-sided 5% size of test of $H_0: \\beta_3 = 1$?", "choices": [{"label": "A", "text": "1.64"}, {"label": "B", "text": "1.71"}, {"label": "C", "text": "2.06"}, {"label": "D", "text": "1.96"}], "answerKey": "C", "model_answer": ""}
{"question": "Suppose that two researchers, using the same 3 variables and the same 250 observations on each variable, estimate a VAR. One estimates a VAR(6), while the other estimates a VAR(4). The determinants of the variance-covariance matrices of the residuals for each VAR are 0.0036 and 0.0049 respectively. What is the values of the test statistic for performing a test of whether the VAR(6) can be restricted to a VAR(4)?", "choices": [{"label": "A", "text": "77.07"}, {"label": "B", "text": "0.31"}, {"label": "C", "text": "0.33"}, {"label": "D", "text": "4.87"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following is a DISADVANTAGE of using pure time-series models (relative to structural models)?", "choices": [{"label": "A", "text": "They are not theoretically motivated"}, {"label": "B", "text": "They cannot produce forecasts easily"}, {"label": "C", "text": "They cannot be used for very high frequency data"}, {"label": "D", "text": "It is difficult to determine the appropriate explanatory variables for use in pure time-series models"}], "answerKey": "A", "model_answer": "LECTURE: Time-series models are statistical models that are used to analyze data that is collected over time.\nA pure time-series model is a statistical model that uses only the time-series data as predictors. Pure time-series models assume that the relationships between the predictors and the outcome are constant over time.\nA structural model is a statistical model that includes information about the relationships between the predictors and the outcome. Structural models can use time-series data as predictors, but they can also include other types of data, such as data on the population as a whole.\nSome of the disadvantages of using pure time-series models are:\nThey are not theoretically motivated. Pure time-series models do not necessarily have well-understood economic interpretations.\nThey cannot produce forecasts easily. Pure time-series models are not designed for making forecasts.\nThey cannot be used for very high frequency data. Pure time-series models may not be able to effectively model data that is collected at very high frequencies.\nIt is difficult to determine the appropriate explanatory variables for use in pure time-series models. When using a pure time-series model, it is difficult to determine which variables to include as predictors."}
{"question": "Which of the following are alternative names for the dependent variable (usually denoted by y) in linear regression analysis?\n\n(i) The regressand\n\n(ii) The regressor\n\n(iii) The explained variable\n\n(iv) The explanatory variable", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: In linear regression analysis, the dependent variable is usually denoted by y. It is called the dependent variable because its value depends on the value of the independent variable. The independent variable is usually denoted by x. It is called the independent variable because its value does not depend on the value of the dependent variable.\nThe value of the dependent variable can be explained by the value of the independent variable. This relationship is called a linear function.\nThe dependent variable can be broken down into two parts: the explained variable and the error. The explained variable is the part of the dependent variable that can be predicted by the independent variable. The error is the part that cannot be predicted.\nThe independent variable can be broken down into two parts: the explanatory variable and the constant. The explanatory variable is the part of the independent variable that can be predicted by the dependent variable. The constant is the part that cannot be predicted.\nSOLUTION: The dependent variable is typically denoted by y. It is the explained variable.\nThe regressand is another name for the dependent variable.\nThe regressor is another name for the independent variable.\nThe explained variable is the part of the dependent variable that can be predicted by the independent variable.\nThe explanatory variable is another name for the independent variable."}
{"question": "Which of the following are advantages of the VAR approach to modelling the relationship between variables relative to the estimation of full structural models?\n\ni) VARs receive strong motivation from financial and economic theory\n\n\nii) VARs in their reduced forms can be used easily to produce time-series forecasts\n\n\niii) VAR models are typically highly parsimonious\n\n\niv) OLS can be applied separately to each equation in a reduced form VAR", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following statements is TRUE concerning the standard regression model?", "choices": [{"label": "A", "text": "y has a probability distribution"}, {"label": "B", "text": "x has a probability distribution"}, {"label": "C", "text": "The disturbance term is assumed to be correlated with x"}, {"label": "D", "text": "For an adequate model, the residual (u-hat) will be zero for all sample data points"}], "answerKey": "A", "model_answer": ""}
{"question": "Consider the following model for $y_t$:\n\n$y_t = \\mu + \\lambda t + u_t$\n\nWhich one of the following most accurately describes the process for $y_t$?", "choices": [{"label": "A", "text": "A unit root process"}, {"label": "B", "text": "A stationary process"}, {"label": "C", "text": "A deterministic trend process"}, {"label": "D", "text": "A random walk with drift"}], "answerKey": "C", "model_answer": "LECTURE: A stationary process is a statistical process that does not change over time. A unit root process is a statistical process that changes over time.\nA random walk is a mathematical model of a random process. A random walk with drift is a random walk in which the change in the process is not zero.\nA deterministic trend process is a statistical process that includes a trend, or a long-term change in the process.\nSOLUTION: The model yt=\u03bc+\u03bbt+ut describes a deterministic trend process. A deterministic trend process includes a trend, or a long-term change in the process. The trend in the model yt is the term \u03bbt."}
{"question": "Which of the following is correct concerning logit and probit models?", "choices": [{"label": "A", "text": "They use a different method of transforming the model so that the probabilities lie between zero and one"}, {"label": "B", "text": "The logit model can result in too many observations falling at exactly zero or exactly one"}, {"label": "C", "text": "For the logit model, the marginal effect of a change in one of the explanatory variables is simply the estimate of the parameter attached to that variable, whereas this is not the case for the probit model"}, {"label": "D", "text": "The probit model is based on a cumulative logistic function"}], "answerKey": "A", "model_answer": ""}
{"question": "What is the most important disadvantage of the diagonal VECH approach to building multivariate GARCH models that is overcome by the BEKK formulation?", "choices": [{"label": "A", "text": "The diagonal VECH model is hard to interpret intuitively"}, {"label": "B", "text": "The diagonal VECH model contains too many parameters"}, {"label": "C", "text": "The diagonal VECH model does not ensure a positive-definite variance-covariance matrix"}, {"label": "D", "text": "The BEKK model reduces the dimensionality problem that arises when a number of series are modelled together."}], "answerKey": "C", "model_answer": "A GARCH model is a multivariate model that contains a variance-covariance matrix. The diagonal VECH model is a multivariate GARCH model that has recently proven to be popular. However, the diagonal VECH model does not ensure a positive-definite variance-covariance matrix. This means that the diagonal VECH model can be used to model only specific types of portfolios.\nThe BEKK formulation, unlike the diagonal VECH approach, ensures a positive-definite variance-covariance matrix. This is the most important disadvantage of the diagonal VECH approach that is overcome by the BEKK formulation."}
{"question": "If a relevant variable is omitted from a regression equation, the consequences would be that:\n\ni) The standard errors would be biased\n\n\nii) If the excluded variable is uncorrelated with all of the included variables, all of\n\nthe slope coefficients will be inconsistent.\n\n\niii) If the excluded variable is uncorrelated with all of the included variables, the\n\nintercept coefficient will be inconsistent.\n\n\niv) If the excluded variable is uncorrelated with all of the included variables, all of\n\nthe slope and intercept coefficients will be consistent and unbiased but inefficient.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: Omitting a relevant variable from a regression equation can lead to bias in the estimated coefficients.\nIf an excluded variable is correlated with one or more of the included variables, the slope coefficients will be biased.\nIf an excluded variable is uncorrelated with all of the included variables, the intercept coefficient will be inconsistent.\nIf an excluded variable is uncorrelated with all of the included variables, the slope coefficients will be inconsistent.\nIf an excluded variable is uncorrelated with all of the included variables, the intercept and all slope coefficients will be consistent and unbiased but inefficient.\nSOLUTION: If the excluded variable is uncorrelated with all of the included variables, the intercept coefficient will be inconsistent.\nSo, the consequences of omitting a relevant variable from a regression equation are that the intercept coefficient will be inconsistent."}
{"question": "Which of the following are alternative names for the independent variable (usually denoted by x) in linear regression analysis?\n\n(i) The regressor\n\n(ii) The regressand\n\n(iii) The causal variable\n\n(iv) The effect variable", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": ""}
{"question": "Consider the OLS estimator for the standard error of the slope coefficient. Which of the following statement(s) is (are) true?\n\n(i) The standard error will be positively related to the residual variance\n\n(ii) The standard error will be negatively related to the dispersion of the observations on the explanatory variable about their mean value\n\n(iii) The standard error will be negatively related to the sample size\n\n(iv) The standard error gives a measure of the precision of the coefficient estimate.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": ""}
{"question": "What is the meaning of the term \"heteroscedasticity\"?", "choices": [{"label": "A", "text": "The variance of the errors is not constant"}, {"label": "B", "text": "The variance of the dependent variable is not constant"}, {"label": "C", "text": "The errors are not linearly independent of one another"}, {"label": "D", "text": "The errors have non-zero mean"}], "answerKey": "A", "model_answer": "LECTURE: In a simple linear regression, the dependent variable is assumed to be normally distributed and to have a constant variance. These two assumptions are important for the model's validity.\nThe variance of the dependent variable is constant. This means that the spread of the dependent variable is the same throughout the sample. If the variance is not constant, the model is not valid.\nThe errors are not linearly independent of one another. Linear independence is a property of sets of numbers. If a set of numbers is linearly independent, it is possible to write it as a linear combination of numbers in the set. If a set of errors is not linearly independent, the model is not valid.\nThe errors have a zero mean. This assumption is strange at first glance, but it is important for the model's validity. The mean of the errors is the value around which the errors tend to concentrate. If the mean is zero, the errors tend to concentrate around zero. This makes it possible to write the model as y = b0 + b1x.\nThe errors are not normally distributed. If the errors are not normally distributed, the model is not valid.\nSOLUTION: Heteroscedasticity means that the variance of the dependent variable is not constant. So, the variance of the dependent variable is not constant."}
{"question": "If a Durbin Watson statistic takes a value close to zero, what will be the value of the first order autocorrelation coefficient?", "choices": [{"label": "A", "text": "Close to zero"}, {"label": "B", "text": "Close to plus one"}, {"label": "C", "text": "Close to minus one"}, {"label": "D", "text": "Close to either minus one or plus one"}], "answerKey": "C", "model_answer": ""}
{"question": "Under the null hypothesis of a Bera-Jarque test, the distribution has", "choices": [{"label": "A", "text": "Zero skewness and zero kurtosis"}, {"label": "B", "text": "Zero skewness and a kurtosis of three"}, {"label": "C", "text": "Skewness of one and zero kurtosis"}, {"label": "D", "text": "Skewness of one and kurtosis of three."}], "answerKey": "B", "model_answer": "LECTURE: Measures of skewness and kurtosis can be calculated from the sample data.\nSkewness is a measure of the asymmetry of a distribution. A skewed distribution has a long tail in one direction. A normal distribution has a skewness of zero.\nSkewness can be calculated using the formula:\nSkewness = 3(mean - median) / standard deviation\nKurtosis is a measure of the peakedness of a distribution. A distribution with a higher kurtosis has a more peaked distribution. A normal distribution has a kurtosis of zero.\nKurtosis can be calculated using the formula:\nKurtosis = (mean - median) / standard deviation\nThe Bera-Jarque test is a goodness-of-fit test for the normal distribution. The null hypothesis of the test is that the distribution is normal.\nThe Bera-Jarque test assumes that the sample data are normally distributed. If the sample data are not normally distributed, the Bera-Jarque test may not be appropriate.\nIf the Bera-Jarque test rejects the null hypothesis, it does not necessarily mean that the sample data come from a non-normal distribution. The Bera-Jarque test is a strong test for normality. Even small deviations from normality can result in a test statistic that is far enough from the critical value to reject the null hypothesis. In such cases, other tests for normality may be more appropriate.\nIf the Bera-Jarque test fails to reject the null hypothesis, it does not necessarily mean that the sample data come from a normal distribution. The Bera-Jarque test is a moderate test for normality. Even severe deviations from normality may not result in a test statistic that is far enough from the critical value to reject the null hypothesis. In such cases, other tests for normality may be more appropriate.\nSOLUTION: The null hypothesis of a Bera-Jarque test is that the distribution has zero skewness and zero kurtosis. The sample data do not necessarily have zero skewness and zero kurtosis. So, the null hypothesis may not be true.\nThe alternative hypothesis of a Bera-Jarque test is that the distribution has nonzero skewness and/or kurtosis. The sample data have skewness one and kurtosis three. So, the alternative hypothesis is true."}
{"question": "If an estimator is said to be consistent, it is implied that", "choices": [{"label": "A", "text": "On average, the estimated coefficient values will equal the true values"}, {"label": "B", "text": "The OLS estimator is unbiased and no other unbiased estimator has a smaller variance"}, {"label": "C", "text": "The estimates will converge upon the true values as the sample size increases"}, {"label": "D", "text": "The coefficient estimates will be as close to their true values as possible for small and large samples."}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following is a typical characteristic of financial asset return time-series?", "choices": [{"label": "A", "text": "Their distributions are thin-tailed"}, {"label": "B", "text": "They are not weakly stationary"}, {"label": "C", "text": "They are highly autocorrelated"}, {"label": "D", "text": "They have no trend"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following assumptions are required to show the consistency, unbiasedness and efficiency of the OLS estimator?\n\ni) $E(u_t) = 0$\n\n\nii) $\\text{Var}(u_t) = \\sigma^2$\n\n\niii) $\\text{Cov}(u_t, u_{t-j}) = 0 \\forall j$\n\n\niv) $u_t \\sim N(0, \\sigma^2)$", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following is a disadvantage of the fixed effects approach to estimating a panel model?", "choices": [{"label": "A", "text": "The model is likely to be technical to estimate"}, {"label": "B", "text": "The approach may not be valid if the composite error term is correlated with one or more of the explanatory variables"}, {"label": "C", "text": "The number of parameters to estimate may be large, resulting in a loss of degrees of freedom"}, {"label": "D", "text": "The fixed effects approach can only capture cross-sectional heterogeneity and not temporal variation in the dependent variable."}], "answerKey": "C", "model_answer": ""}
{"question": "Consider an identical situation to that of question 21, except that now a 2-sided alternative is used. What would now be the appropriate conclusion?", "choices": [{"label": "A", "text": "H0 is rejected"}, {"label": "B", "text": "H0 is not rejected"}, {"label": "C", "text": "H1 is rejected"}, {"label": "D", "text": "There is insufficient information given in the question to reach a conclusion"}], "answerKey": "A", "model_answer": ""}
{"question": "The price of a house is best described as what type of number?", "choices": [{"label": "A", "text": "Discrete"}, {"label": "B", "text": "Cardinal"}, {"label": "C", "text": "Ordinal"}, {"label": "D", "text": "Nominal"}], "answerKey": "B", "model_answer": "LECTURE: Numbers are written with both a number and a unit. The unit comes after the number. The unit shows what the number means.\nDiscrete numbers are sums of integers.\nCardinal numbers are sums of units.\nOrdinal numbers show the order of things.\nNominal numbers describe names of things.\nSOLUTION: A house can be sold for $300,000, or it can be sold for $300,000 more. The number 300,000 is a discrete number.\nThe price of a house is nominal. It describes a name of a thing."}
{"question": "If a Johansen \"trace\" test for a null hypothesis of 2 cointegrating vectors is applied to a system containing 4 variables is conducted, which eigenvalues would be used in the test?", "choices": [{"label": "A", "text": "All of them"}, {"label": "B", "text": "The largest 2"}, {"label": "C", "text": "The smallest 2"}, {"label": "D", "text": "The second largest"}], "answerKey": "C", "model_answer": "LECTURE: In a Johansen test for cointegration, the trace statistic is used to determine the number of cointegrating relationships in the system. The trace statistic considers all of the eigenvalues.\nThe largest eigenvalue indicates the number of cointegrating relationships. For example, if the largest eigenvalue is 1, then there is one cointegrating relationship in the system. If the largest eigenvalue is greater than 1, then there are multiple cointegrating relationships.\nThe other eigenvalues do not affect the determination of the number of cointegrating relationships."}
{"question": "Which of the following statements is true concerning variance decomposition analysis of VARs?\n\ni) Variance decompositions measure the impact of a unit shock to each of the variables on the VAR\n\nii) Variance decompositions can be thought of as measuring the proportion of the forecast error variance that is attributable to each variable\n\niii) The ordering of the variables is important for calculating impulse responses but not variance decompositions\n\niv) It is usual that most of the forecast error variance for a given variable is attributable to shocks to that variable", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": ""}
{"question": "Suppose that we have estimated a GARCH model for daily equity returns, and we are interested in producing a 10-day forecast of the volatility (measured by the standard deviation of returns) for use in a value at risk model. How could such a forecast most validly be calculated?", "choices": [{"label": "A", "text": "Produce 1, 2, 3, ..., 10 step ahead conditional variance forecasts and add them up"}, {"label": "B", "text": "Produce 1, 2, 3, ..., 10 step ahead conditional variance forecasts and add them up and take the square root"}, {"label": "C", "text": "Produce 1, 2, 3, ..., 10 step ahead conditional variance forecasts, take the square roots of each one and add them up"}, {"label": "D", "text": "Produce a 1-step ahead conditional variance forecast, take its square root and multiply it by the square root of 10"}], "answerKey": "B", "model_answer": ""}
{"question": "Suppose that the value of $R^2$ for an estimated regression model is exactly zero. Which of the following are true?\n\ni) All coefficient estimates on the slopes will be zero\n\nii) The fitted line will be horizontal with respect to all of the explanatory variables\n\niii) The regression line has not explained any of the variability of y about its mean value\n\niv) The intercept coefficient estimate must be zero.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: The value of $R^2$ for an estimated regression model is exactly zero. This means that the regression line has not explained any of the variability of y about its mean value.\nSo, the intercept coefficient estimate must be zero, and all coefficient estimates on the slopes will be zero.\nSince the intercept is zero, the regression line will be horizontal with respect to all of the explanatory variables.\nAnd since all coefficient estimates on the slopes are zero, the regression line will not go through any of the points."}
{"question": "A white noise process will have\n\n(i) A zero mean\n\n(ii) A constant variance\n\n(iii) Autocovariances that are constant\n\n(iv) Autocovariances that are zero except at lag zero", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": "LECTURE: Autocovariance is a measure of how two values change together. For example, the autocovariance of a white noise process at lags 0 and 1 is given by:\nThe autocovariance is zero except at lag 0, which indicates that the values are not correlated at different points in time.\nA constant variance indicates that the values in the process are constant over time. This means that the variance of a white noise process is constant.\nA zero mean indicates that the values in the process are on average constant over time. This means that the mean of a white noise process is zero.\nSOLUTION: A white noise process has a zero mean, which means that the values in the process are on average constant over time.\nA white noise process also has autocovariances that are zero except at lag zero, which indicates that the values are not correlated at different points in time.\nSo, the choices are incorrect."}
{"question": "Which of the following statements are true concerning the Box-Jenkins approach to diagnostic testing for ARMA models?\n\n(i) The tests will show whether the identified model is either too large or too small\n\n(ii) The tests involve checking the model residuals for autocorrelation, heteroscedasticity, and non-normality\n\n(iii) If the model suggested at the identification stage is appropriate, the acf and pacf for the residuals should show no additional structure\n\n(iv) If the model suggested at the identification stage is appropriate, the coefficients on the additional variables under the overfitting approach will be statistically insignificant", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": ""}
{"question": "Which one of the following would be a plausible response to a finding of residual non-normality?", "choices": [{"label": "A", "text": "Use a logarithmic functional form instead of a linear one"}, {"label": "B", "text": "Add lags of the variables on the right hand side of the regression model"}, {"label": "C", "text": "Estimate the model in first differenced form"}, {"label": "D", "text": "Remove any large outliers from the data."}], "answerKey": "D", "model_answer": ""}
{"question": "The fixed effects panel model is also sometimes known as", "choices": [{"label": "A", "text": "A seemingly unrelated regression model"}, {"label": "B", "text": "The least squares dummy variables approach"}, {"label": "C", "text": "The random effects model"}, {"label": "D", "text": "Heteroscedasticity and autocorrelation consistent"}], "answerKey": "B", "model_answer": "LECTURE: Panels of data are made up of observations on multiple units, such as multiple firms or multiple countries. Panel data have the advantage of allowing you to observe changes over time.\nOne way to analyze panel data is to use a fixed effects model. In a fixed effects model, the individual fixed effects are estimated along with the other model parameters. The fixed effects represent the differences between the units, and are assumed to be time-invariant.\nA fixed effects panel model is also sometimes known as a seemingly unrelated regression model. This is because the model estimates the individual fixed effects simultaneously with the other model parameters.\nAnother way to analyze panel data is to use a random effects model. In a random effects model, the individual fixed effects are not estimated. Instead, the model allows the variances of the errors to be different among the units.\nThe random effects model is also sometimes known as Heteroscedasticity and autocorrelation consistent. This is because the model does not assume constant variance, and is consistent with the assumption that the errors in the model are autocorrelated.\nSOLUTION: A fixed effects panel model is also sometimes known as a seemingly unrelated regression model. In a seemingly unrelated regression model, the model estimates the individual fixed effects simultaneously with the other model parameters."}
{"question": "Which of the following statements is TRUE concerning OLS estimation?", "choices": [{"label": "A", "text": "OLS minimises the sum of the vertical distances from the points to the line"}, {"label": "B", "text": "OLS minimises the sum of the squares of the vertical distances from the points to the line"}, {"label": "C", "text": "OLS minimises the sum of the horizontal distances from the points to the line"}, {"label": "D", "text": "OLS minimises the sum of the squares of the horizontal distances from the points to the line."}], "answerKey": "B", "model_answer": ""}
{"question": "If the standard tools for time-series analysis, such as estimation of the acf, pacf and spectral analysis, find no evidence of structure in the data, this implies that the data are which of the following?", "choices": [{"label": "A", "text": "Normally distributed"}, {"label": "B", "text": "Uncorrelated"}, {"label": "C", "text": "Independent"}, {"label": "D", "text": "Fat-tailed"}], "answerKey": "B", "model_answer": "LECTURE: If the sample data are uncorrelated, then the data are not dependent. That is, past values are not useful for predicting future values.\nIf the sample data are independent, then the data are not dependent. That is, the past and future values are not useful for predicting the present value.\nA time series is said to be normally distributed if its data follow a normal curve. A normal distribution is a symmetric distribution with a peak around the average value.\nA time series is said to be fat-tailed if its data have a tail that extends farther from the mean than a normal distribution. Many time series with extreme values have fat tails.\nSOLUTION: If the sample data are uncorrelated, then the data are not dependent. This means that the past values are not useful for predicting future values.\nIf the sample data are independent, then the data are not dependent. This means that the past and future values are not useful for predicting the present value.\nSo, if the standard tools for time-series analysis find no evidence of structure in the data, this implies that the data are uncorrelated."}
{"question": "If two variables, $x_t$ and $y_t$ are said to be cointegrated, which of the following statements are true?\n\ni) $x_t$ and $y_t$ must both be stationary\n\n\nii) Only one linear combination of $x_t$ and $y_t$ will be stationary\n\n\niii) The cointegrating equation for $x_t$ and $y_t$ describes the short-run relationship\n\nbetween the two series\n\n\niv) The residuals of a regression of $y_t$ on $x_t$ must be stationary", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "A", "model_answer": ""}
{"question": "A dependent variable whose values are not observable outside a certain range but where the corresponding values of the independent variables are still available would be most accurately described as what kind of variable?", "choices": [{"label": "A", "text": "Censored"}, {"label": "B", "text": "Truncated"}, {"label": "C", "text": "Multinomial variable"}, {"label": "D", "text": "Discrete choice"}], "answerKey": "A", "model_answer": ""}
{"question": "A Hausman test would be used for", "choices": [{"label": "A", "text": "Determining whether an equation that is part of a simultaneous system is identified"}, {"label": "B", "text": "Determining whether a simultaneous framework is needed for a particular variable"}, {"label": "C", "text": "Determining whether 2SLS or ILS is optimal"}, {"label": "D", "text": "Determining whether the structural form equations can be obtained via substitution from the reduced forms"}], "answerKey": "B", "model_answer": ""}
{"question": "Under the matrix notation for the classical linear regression model, $y = X \\beta + u$, what are the dimensions of $u$?", "choices": [{"label": "A", "text": "T x k"}, {"label": "B", "text": "T x 1"}, {"label": "C", "text": "k x 1"}, {"label": "D", "text": "1 x 1"}], "answerKey": "B", "model_answer": ""}
{"question": "How many parameters will be required to be estimated in total for all equations of a standard form, unrestricted, tri-variate VAR(4), ignoring the intercepts?", "choices": [{"label": "A", "text": "12"}, {"label": "B", "text": "4"}, {"label": "C", "text": "3"}, {"label": "D", "text": "36"}], "answerKey": "D", "model_answer": "LECTURE: A vector autoregression (VAR) is a model that shows how multiple variables change over time.\nThe standard form of a VAR is:\nYt=c+A11Yt\u22121+A21Yt\u22122+\u2026+ApxYt\u2212p+eYt\nwhere Yt is a vector of n variables, Ai1, Ai2, \u2026, Aip are matrices of parameters, and eYt is a vector of residuals.\nThe order of the VAR is p, which is the number of past values of the variables included in the model.\nFor example, a VAR(2) model includes two past values of the variables.\nThe VAR is unrestricted if all of the parameters are estimated.\nThe VAR is restricted if some of the parameters are not estimated.\nFor example, a VAR(2) with A11=0 and A21=0 is a restricted VAR(2).\nThe VAR is tri-variate if the vectors of coefficients A11, A21, \u2026, Apx are sparse.\nA sparse vector is one with many zero elements.\nA VAR with tri-variate coefficients is only restricted if all of the coefficients are zero.\nFor example, a VAR(2) with A11=0 and A21=0 is a restricted VAR(2) with tri-variate coefficients.\nSOLUTION: An unrestricted, tri-variate VAR(4) ignoring the intercepts has 10 parameters that are estimated.\nThe parameter estimates are shown in the VAR(4) table.\nThere are 10 parameters to be estimated in total for all equations of this VAR."}
{"question": "A researcher tests for structural stability in the following regression model:\n\n$y_t = \\beta_1 + \\beta_2 x_{2t} + \\beta_3 x_{3t} + u_t$\n\nThe total sample of 200 observations is split exactly in half for the sub-sample regressions. Which would be the unrestricted residual sum of squares?", "choices": [{"label": "A", "text": "The RSS for the whole sample"}, {"label": "B", "text": "The RSS for the first sub-sample"}, {"label": "C", "text": "The RSS for the second sub-sample"}, {"label": "D", "text": "The sum of the RSS for the first and second sub-samples"}], "answerKey": "D", "model_answer": ""}
{"question": "Suppose that we are interested in testing the null hypothesis that a GARCH(2,2) model can be restricted to a process with a constant conditional variance using the likelihood ratio test approach. Which of the following statements are true?", "choices": [{"label": "A", "text": "The test statistic will follow a chi-squared distribution with 2 degrees of freedom under the null hypothesis"}, {"label": "B", "text": "The value of the log-likelihood function will almost always be bigger for the restricted model than for the unrestricted model"}, {"label": "C", "text": "If the relevant values of the log-likelihood functions are -112.3 and -118.4, the value of the test statistic is 12.2"}, {"label": "D", "text": "The likelihood ratio test compares the slopes of the log-likelihood function at the maximum and at the restricted parameter value."}], "answerKey": "C", "model_answer": ""}
{"question": "Which one of the following is NOT a plausible remedy for near multicollinearity?", "choices": [{"label": "A", "text": "Use principal components analysis"}, {"label": "B", "text": "Drop one of the collinear variables"}, {"label": "C", "text": "Use a longer run of data"}, {"label": "D", "text": "Take logarithms of each of the variables"}], "answerKey": "D", "model_answer": ""}
{"question": "Consider the following AR(2) process:\n\nyt = 1.5 yt-1 - 0.5 yt-2 + ut\n\nThis is a", "choices": [{"label": "A", "text": "Stationary process"}, {"label": "B", "text": "Unit root process"}, {"label": "C", "text": "Explosive process"}, {"label": "D", "text": "Stationary and unit root process"}], "answerKey": "B", "model_answer": "LECTURE: A stationary process is a process where the statistical properties do not change over time. A unit root process is a process where the statistical properties change over time. An explosive process is a process that grows very quickly, but only in the short term.\nIf a process is both stationary and has a unit root, then the process is explosive.\nIf a process is neither stationary nor explosive, it may be a trend stationary process. A trend stationary process is a process where the statistical properties change over time, but the change is not explosive.\nThe AR(2) process is a generalization of the AR(1) process. An AR(1) process has only one lag. An AR(2) process has two lags.\nAn AR(2) process is stationary if and only if the two lags do not have the same sign. If the two lags have the same sign, the process is explosive. If the two lags have different signs, the process is stationary and unit root.\nSOLUTION: The AR(2) process has two lags. So, the process is stationary and unit root."}
{"question": "Which of the following could be used as a test for autocorrelation up to third order?", "choices": [{"label": "A", "text": "The Durbin Watson test"}, {"label": "B", "text": "White's test"}, {"label": "C", "text": "The RESET test"}, {"label": "D", "text": "The Breusch-Godfrey test"}], "answerKey": "D", "model_answer": ""}
{"question": "The residual from a standard regression model is defined as", "choices": [{"label": "A", "text": "The difference between the actual value, y, and the mean, y-bar"}, {"label": "B", "text": "The difference between the fitted value, y-hat, and the mean, y-bar"}, {"label": "C", "text": "The difference between the actual value, y, and the fitted value, y-hat"}, {"label": "D", "text": "The square of the difference between the fitted value, y-hat, and the mean, y-bar"}], "answerKey": "C", "model_answer": ""}
{"question": "If OLS is applied separately to each equation that is part of a simultaneous system, the resulting estimates will be", "choices": [{"label": "A", "text": "Unbiased and consistent"}, {"label": "B", "text": "Biased but consistent"}, {"label": "C", "text": "Biased and inconsistent"}, {"label": "D", "text": "It is impossible to apply OLS to equations that are part of a simultaneous system"}], "answerKey": "C", "model_answer": ""}
{"question": "Which one of the following is NOT an example of mis-specification of functional form?", "choices": [{"label": "A", "text": "Using a linear specification when y scales as a function of the squares of x"}, {"label": "B", "text": "Using a linear specification when a double-logarithmic model would be more appropriate"}, {"label": "C", "text": "Modelling y as a function of x when in fact it scales as a function of 1/x"}, {"label": "D", "text": "Excluding a relevant variable from a linear regression model"}], "answerKey": "D", "model_answer": ""}
{"question": "Suppose that we wished to evaluate the factors that affected the probability that an investor would choose an equity fund rather than a bond fund or a cash investment. Which class of model would be most appropriate?", "choices": [{"label": "A", "text": "A logit model"}, {"label": "B", "text": "A multinomial logit"}, {"label": "C", "text": "A tobit model"}, {"label": "D", "text": "An ordered logit model"}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following statements will be true if the number of replications used in a Monte Carlo study is small?\n\ni) The statistic of interest may be estimated imprecisely\n\n\nii) The results may be affected by unrepresentative combinations of random draws\n\n\niii) The standard errors on the estimated quantities may be unacceptably large\n\n\niv) Variance reduction techniques can be used to reduce the standard errors", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following is a disadvantage of the random effects approach to estimating a panel model?", "choices": [{"label": "A", "text": "The approach may not be valid if the composite error term is correlated with one or more of the explanatory variables"}, {"label": "B", "text": "The number of parameters to estimate may be large, resulting in a loss of degrees of freedom"}, {"label": "C", "text": "The random effects approach can only capture cross-sectional heterogeneity and not temporal variation in the dependent variable."}, {"label": "D", "text": "All of (a) to (c) are potential disadvantages of the random effects approach."}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following could result in autocorrelated residuals?\n\ni) Slowness of response of the dependent variable to changes in the values of the independent variables\n\nii) Over-reactions of the dependent variable to changes in the independent variables\n\niii) Omission of relevant explanatory variables that are autocorrelated\n\niv) Outliers in the data", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": "LECTURE: Autocorrelation is a type of correlation that occurs within a time series. It is the correlation of a variable with itself at different time periods.\nWhen a time series is autocorrelated, the values of the variable are not independent over time. Instead, the value of the variable at one time period is related to the value at previous time periods.\nDepending on the type of autocorrelation, the variable may be slow to respond to changes in the independent variables, may over-react to changes in the independent variables, or may have omissible relevant explanatory variables that are autocorrelated.\nAll of these things can result in autocorrelated residuals.\nSOLUTION: Slowness of response of the dependent variable to changes in the values of the independent variables could result in autocorrelated residuals.\nOver-reactions of the dependent variable to changes in the independent variables could result in autocorrelated residuals.\nOmission of relevant explanatory variables that are autocorrelated could result in autocorrelated residuals.\nOutliers in the data could also result in autocorrelated residuals."}
{"question": "Which of the following statements are true concerning the acf and pacf?\n\n(i) The acf and pacf are often hard to interpret in practice\n\n(ii) The acf and pacf can be difficult to calculate for some data sets\n\n(iii) Information criteria represent an alternative approach to model order determination\n\n(iv) If applied correctly, the acf and pacf will always deliver unique model selections", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following conditions are necessary for a series to be classifiable as a weakly stationary process?\n\n(i) It must have a constant mean\n\n(ii) It must have a constant variance\n\n(iii) It must have constant autocovariances for given lags\n\n(iv) It must have a constant probability distribution", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
{"question": "Consider the following equation and determine the class of model that it best represents\n\n$y_{it} = \\alpha + \\beta_{it} + \\mu_i + \\nu_{it}$", "choices": [{"label": "A", "text": "An entity fixed effects model"}, {"label": "B", "text": "A time fixed effects model"}, {"label": "C", "text": "A random effects model"}, {"label": "D", "text": "A pure time series model"}], "answerKey": "A", "model_answer": "LECTURE: In an entity fixed effects model, the dependent variable is a function of the entity's characteristics and the independent variables. The entity is defined by an entity fixed effect, which is assumed to be constant over time.\nAn entity fixed effects model with a random effects structure is similar to an entity fixed effects model, but allows the entity fixed effects to be different between observations. This can be useful in models where the entity is a person or other individual.\nA time fixed effects model is a model with a time fixed effect, which is assumed to be constant over all entities. The dependent variable is a function of the time fixed effect and the independent variables.\nA random effects model allows the coefficients to be different between observations. This can be useful when the patterns of relationships between the variables are assumed to be different between observations.\nA pure time series model uses only the time series part of the data. It estimates the coefficients based on the patterns in the data, without referencing the independent variables.\nA linear time series model is a pure time series model that assumes that the series is generated by a linear process. It estimates the coefficients based on the patterns in the data, without referencing the independent variables.\nA unit root time series model is a pure time series model that assumes that the series has a unit root. A unit root is a root that suggests that the series is not a stationary time series. Such a series is called a nonstationary time series.\nA stationary time series model is a pure time series model that assumes that the series is a stationary time series. A stationary time series has a constant mean and a constant variance.\nSOLUTION: The equation includes entity fixed effects, so the best model is an entity fixed effects model."}
{"question": "Note that statistical tables are not necessary to answer this question. For a sample of 1000 observations, the Dickey-Fuller test statistic values are", "choices": [{"label": "A", "text": "More negative than (i.e. bigger in absolute value than) those in the left hand tail of a normal distribution"}, {"label": "B", "text": "Less negative than (i.e. smaller in absolute value than) those in the left hand tail of a normal distribution"}, {"label": "C", "text": "Obtained from an analytical formula for the density of the Dickey-Fuller distribution"}, {"label": "D", "text": "More negative (i.e. bigger in absolute value) for a 10% size of test than a 5% test."}], "answerKey": "A", "model_answer": ""}
{"question": "Suppose that a hypothesis test is conducted using a 5% significance level. Which of the following statements are correct?\n\n(i) The significance level is equal to the size of the test\n\n(ii) The significance level is equal to the power of the test\n\n(iii) 2.5% of the total distribution will be in each tail rejection region for a 2-sided test\n\n(iv) 5% of the total distribution will be in each tail rejection region for a 2-sided test.", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": "LECTURE: A hypothesis test is conducted on a population parameter. The test has a 5% significance level.\nThe significance level is the probability of rejecting the null hypothesis when it is actually true. A 5% significance level means that the null hypothesis will be rejected if the p-value is less than 5%.\nThe power of a test is the probability of rejecting the null hypothesis when the null hypothesis is actually false. For a 5% significance level, a test can have a power of up to 5%.\nSOLUTION: The significance level is not equal to the size of the test.\nThe size of a test is the proportion of the population that is tested. A large test has a larger size than a small test.\nFor a 5% significance level, a test can have a size of up to 5%.\nThe power of a test is not equal to the size of the test.\nThe size of a test is related to the power of the test, but they are not equal.\nFor a 5% significance level, a test can have a power of up to 5%.\n2.5% of the total distribution will be in each tail rejection region for a 2-sided test.\nThis is a correct statement.\nFor a 2-sided test, 2.5% of the total distribution will be in each tail rejection region.\n5% of the total distribution will be in each tail rejection region for a 2-sided test.\nThis is a correct statement.\nFor a 2-sided test, 5% of the total distribution will be in each tail rejection region."}
{"question": "Which one of the following criticisms of the Dickey-Fuller/Engle-Granger approach to dealing with cointegrated variables is overcome by the Engle-Yoo (EY) procedure?", "choices": [{"label": "A", "text": "In the context of small samples, Dickey Fuller tests are prone to conclude that there is a unit root in a series when there is not"}, {"label": "B", "text": "The Engle-Granger (EG) approach can only detect up to one cointegrating relationship even though there could be more than one"}, {"label": "C", "text": "The variables are treated asymmetrically in the cointegrating tests"}, {"label": "D", "text": "It is not possible to perform tests about the cointegrating relationship"}], "answerKey": "D", "model_answer": ""}
{"question": "Consider a series that follows an MA(1) with zero mean and a moving average coefficient of 0.4. What is the value of the autocovariance at lag 1?", "choices": [{"label": "A", "text": "0.4"}, {"label": "B", "text": "1"}, {"label": "C", "text": "0.34"}, {"label": "D", "text": "It is not possible to determine the value of the autocovariances without knowing the disturbance variance."}], "answerKey": "D", "model_answer": "LECTURE: A stationary series is one in which the autocovariance is constant.\nIf a series is related to an MA(1) with zero mean and a moving average coefficient of 0.4, then its autocovariance at lag 1 will be 0.4.\nHowever, if the series is related to an MA(1) with a nonzero mean, then its autocovariance at lag 1 will be 0.34.\nA series with autocovariance 0.34 is not an MA(1) with zero mean. But, it is possible that this series is related to an MA(1) with a nonzero mean.\nIt is not possible to determine the value of the autocovariance without knowing the disturbance variance.\nThe disturbance variance is the variance of the disturbance to the MA(1) process. It is not possible to determine the disturbance variance from the series."}
{"question": "Which of the following estimation techniques are available for the estimation of over-identified systems of simultaneous equations?\n\ni) OLS\n\nii) ILS\n\niii) 2SLS\n\niv) IV", "choices": [{"label": "A", "text": "(iii) only"}, {"label": "B", "text": "(iii) and (iv) only"}, {"label": "C", "text": "(ii), (iii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii) and (iv)"}], "answerKey": "B", "model_answer": ""}
{"question": "Which one of the following statements best describes a Type II error?", "choices": [{"label": "A", "text": "It is the probability of incorrectly rejecting the null hypothesis"}, {"label": "B", "text": "It is equivalent to the power of the test"}, {"label": "C", "text": "It is equivalent to the size of the test"}, {"label": "D", "text": "It is the probability of failing to reject a null hypothesis that was wrong"}], "answerKey": "D", "model_answer": ""}
{"question": "Which one of the following would be the most appropriate as a 95% (two-sided) confidence interval for the intercept term of the model given in question 21?", "choices": [{"label": "A", "text": "(-4.79,2.19)"}, {"label": "B", "text": "(-4.16,4.16)"}, {"label": "C", "text": "(-1.98,1.98)"}, {"label": "D", "text": "(-5.46,2.86)"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following are characteristics of a stationary process?\n\ni) It crosses its mean value frequently\n\n\nii) It has constant mean and variance\n\n\niii) It contains no trend component\n\n\niv) It will be stationary in first difference form", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "D", "model_answer": "LECTURE: A statistical process is called stationary if it is identical for all observers at different points in time.\nThe mean, variance, and correlation of a stationary process do not depend on time.\nA stationary process contains no trend component. It has a constant mean and variance.\nThe sample mean of a stationary process is a consistent estimator of the long-run average.\nA stationary process with a finite mean and variance is a Gaussian, or normal, process.\nSOLUTION: A stationary process will be stationary in first difference form.\nThis means that the process is equally stationary when differenced by one, two, or any number of time units.\nA stationary process contains no trend component. It has a constant mean and variance.\nSo, it has constant mean and variance.\nIt crosses its mean value frequently.\nThis means that the process has a large standard deviation.\nA process with a large standard deviation frequently crosses its mean value.\nA stationary process with a finite mean and variance is a Gaussian, or normal, process."}
{"question": "Consider again the VAR model of equation 16. Which of the following conditions must hold for it to be said that there is bi-directional feedback?", "choices": [{"label": "A", "text": "The b and d coefficients significant and the a and c coefficients insignificant"}, {"label": "B", "text": "The a and c coefficients significant and the b and d coefficients insignificant"}, {"label": "C", "text": "The a and c coefficients significant"}, {"label": "D", "text": "The b and d coefficients significant"}], "answerKey": "D", "model_answer": ""}
{"question": "Consider the following sample autocorrelation estimates obtained using 250 data points:\n\n1) Lag 1 2 3\n\n2) Coefficient 0.2 -0.15 -0.1\n\n3) Assuming that the coefficients are approximately normally distributed, which of the coefficients are statistically significant at the 5% level?", "choices": [{"label": "A", "text": "1 only"}, {"label": "B", "text": "1 and 2 only"}, {"label": "C", "text": "1, 2 and 3 only"}, {"label": "D", "text": "It is not possible to determine the statistical significance since no standard errors have been given"}], "answerKey": "B", "model_answer": "LECTURE: In a correlation study, we often use autocorrelation as a measure of the correlation within a time series. Autocorrelation measures the strength of a linear relationship between a time series and a delayed version of itself.\nA correlation coefficient (r) measures the strength of a linear relationship between two time series. It has a value between -1 and 1.\nThe sample autocorrelation measures are estimated from the data using a specified lag. A lag is a time delay. For example, the sample autocorrelation at lag 1 measures the strength of the linear relationship between the time series and a delayed version of itself by 1 unit.\nSOLUTION: The coefficients are normally distributed if the autocorrelation estimates have a standard error that is smaller than the estimate. The standard error can be used to calculate a confidence interval for the coefficient. A coefficient is statistically significant at the 5% level if it is within 1 standard error of zero.\nThe standard error of the autocorrelation at lag 1 is given by:\nSE = |0.2| = 0.2\nSo, the coefficient at lag 1 is statistically significant at the 5% level.\nThe standard error of the autocorrelation at lag 2 is given by:\nSE = |-0.15| = 0.15\nSo, the coefficient at lag 2 is not statistically significant at the 5% level.\nThe standard error of the autocorrelation at lag 3 is given by:\nSE = |-0.1| = 0.1\nSo, the coefficient at lag 3 is not statistically significant at the 5% level."}
{"question": "Which one of the following is examined by looking at a goodness of fit statistic?", "choices": [{"label": "A", "text": "How well the population regression function fits the data"}, {"label": "B", "text": "How well the sample regression function fits the population regression function"}, {"label": "C", "text": "How well the sample regression function fits the data"}, {"label": "D", "text": "How well the population regression function fits the sample regression function."}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following statements are correct concerning the use of antithetic variates as part of a Monte Carlo experiment?\n\ni) Antithetic variates work by reducing the number of replications required to cover the whole probability space\n\nii) Antithetic variates involve employing a similar variable to that used in the simulation, but whose properties are known analytically\n\niii) Antithetic variates involve using the negative of each of the random draws and repeating the experiment using those values as the draws\n\niv) Antithetic variates involve taking one over each of the random draws and repeating the experiment using those values as the draws", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iv) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "B", "model_answer": ""}
{"question": "Which one of the following statements is true concerning alternative forecast accuracy measures?", "choices": [{"label": "A", "text": "Mean squared error is usually highly correlated with trading rule profitability"}, {"label": "B", "text": "Mean absolute error provides a quadratic loss function"}, {"label": "C", "text": "Mean absolute percentage error is a useful measure for evaluating asset return forecasts"}, {"label": "D", "text": "Mean squared error penalises large forecast errors disproportionately more than small forecast errors"}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following criticisms of standard (\"plain vanilla\") GARCH models can be overcome by EGARCH models?\n\ni) Estimated coefficient values from GARCH models may be negative\n\nii) GARCH models cannot account for leverage effects\n\niii) The responsiveness of future volatility to positive and negative shocks is symmetric under a GARCH formulation\n\niv) GARCH models cannot allow for a feedback from the volatility to the returns", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
{"question": "Suppose that 100 separate firms were tested to determine how many of them \"beat the market\" using a Jensen-type regression, and it is found that 3 fund managers significantly do so. Does this suggest prima facie evidence for stock market inefficiency?", "choices": [{"label": "A", "text": "Yes"}, {"label": "B", "text": "No"}, {"label": "C", "text": "In order to answer this question, you would need to test every fund manager trading in that market"}, {"label": "D", "text": "There is insufficient information given in the question to draw a conclusion about market efficiency."}], "answerKey": "B", "model_answer": "LECTURE: In an efficient market, prices fully reflect all available information. If prices do not reflect all available information, it is an indication that the market is not efficient.\nOne way to test for market efficiency is to look for fund managers who consistently \"beat the market.\" If a fund manager consistently makes better-than-average investments, it is an indication that the market is inefficient, because it means that the fund manager has information that the market does not.\nJensen's regression is a statistical technique that can be used to determine whether a fund manager significantly outperforms the market. If a fund manager does so, it is an indication that the market is inefficient.\nHowever, even if a fund manager outperforms the market, it does not necessarily mean that the market is inefficient. The fund manager may have information that the market does not, or the fund manager may have a better method of interpreting available information.\nOn the other hand, if a large number of fund managers consistently outperform the market, it would provide strong evidence that the market is inefficient.\nSOLUTION: There are 3 fund managers out of 100 who significantly outperform the market. This suggests that there are some inefficiencies in the market. However, in order to determine whether there is prima facie evidence for market inefficiency, you would need to test every fund manager trading in the market."}
{"question": "Which of the following are advantages of the use of panel data over pure cross-sectional or pure time-series modelling?\n\n(i) The use of panel data can increase the number of degrees of freedom and therefore the power of tests\n\n(ii) The use of panel data allows the average value of the dependent variable to vary either cross-sectionally or over time or both\n\n(iii) The use of panel data enables the researcher allows the estimated relationship between the independent and dependent variables to vary either cross-sectionally or over time or both", "choices": [{"label": "A", "text": "(i) only"}, {"label": "B", "text": "(i) and (ii) only"}, {"label": "C", "text": "(ii) only"}, {"label": "D", "text": "(i), (ii), and (iii)"}], "answerKey": "B", "model_answer": ""}
{"question": "If the Engle-Granger test is applied to the residuals of a potentially cointegrating regression, what would be the interpretation of the null hypothesis?", "choices": [{"label": "A", "text": "The variables are cointegrated"}, {"label": "B", "text": "The variables are not cointegrated"}, {"label": "C", "text": "Both variables are stationary"}, {"label": "D", "text": "Both variables are non-stationary"}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following statements are true concerning the autocorrelation function (acf) and partial autocorrelation function (pacf)?\n\ni) The acf and pacf will always be identical at lag one whatever the model\n\nii) The pacf for an MA(q) model will in general be non-zero beyond lag q\n\niii) The pacf for an AR(p) model will be zero beyond lag p\n\niv) The acf and pacf will be the same at lag two for an MA(1) model", "choices": [{"label": "A", "text": "(ii) and (iv) only"}, {"label": "B", "text": "(i) and (iii) only"}, {"label": "C", "text": "(i), (ii), and (iii) only"}, {"label": "D", "text": "(i), (ii), (iii), and (iv)"}], "answerKey": "C", "model_answer": ""}
