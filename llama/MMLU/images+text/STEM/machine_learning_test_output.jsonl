{"question": "Statement 1| Linear regression estimator has the smallest variance among all unbiased estimators. Statement 2| The coefficients \u03b1 assigned to the classifiers assembled by AdaBoost are always non-negative.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "LECTURE: A variable is a value that can be assigned to a variable. A function is a variable whose value is a function.\nA function is a variable whose value is a function.\nA function is a variable whose value is a function.\nA function is a variable whose value is a function.\nThe value of a function provides a rule for calculating the value of the variable.\nFor example, if X is a variable, then 2X is a variable whose value is twice the value of X.\nIf X is a function, then X^2 is a function whose value is the square of the value of X.\nSOLUTION: A linear regression estimator is an estimator for a linear regression problem. A linear regression problem is a problem where the relationship between the variables can be modeled with a linear equation.\nA linear regression estimator is an unbiased estimator for a linear regression problem. This means that, on average, a linear regression estimator does not systematically underestimate or overestimate the true value.\nA linear regression estimator has the smallest variance among all unbiased estimators. This means that, on average, a linear regression estimator is the most accurate estimator.\nSo, Statement 1 is true.\nThe coefficients \u03b1 assigned to the classifiers assembled by AdaBoost are always non-negative.\nAdaBoost is a machine learning algorithm that uses decision trees to classify data.\nEach decision tree in an AdaBoost classifier predicts one of two classes. For example, a decision tree might predict either a cat or a dog.\nThe coefficients \u03b1 are used to weight the predictions of the decision trees in an AdaBoost classifier. Higher-weighted predictions have more influence on the final prediction.\nSo, the coefficients \u03b1 assigned to the classifiers assembled by AdaBoost are always non-negative. This means that the predictions of the decision trees in an AdaBoost classifier are never negative.\nSo, Statement 2 is false."}
{"question": "Statement 1| RoBERTa pretrains on a corpus that is approximate 10x larger than the corpus BERT pretrained on. Statement 2| ResNeXts in 2018 usually used tanh activation functions.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| Support vector machines, like logistic regression models, give a probability distribution over the possible labels given an input example. Statement 2| We would expect the support vectors to remain the same in general as we move from a linear kernel to higher order polynomial kernels.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: Statement 1 is false.\nA support vector machine (SVM) uses a linear kernel. A linear kernel gives each feature equal weight. So, the SVM does not favor more complex solutions.\nStatement 2 is false.\nThe position of a support vector does not depend on the type of kernel. So, the support vectors are likely to change when you change the type of kernel."}
{"question": "A machine learning problem involves four attributes plus a class. The attributes have 3, 2, 2, and 2 possible values each. The class has 3 possible values. How many maximum possible different examples are there?", "choices": [{"label": "A", "text": "12"}, {"label": "B", "text": "24"}, {"label": "C", "text": "48"}, {"label": "D", "text": "72"}], "answerKey": "D", "model_answer": ""}
{"question": "As of 2020, which architecture is best for classifying high-resolution images?", "choices": [{"label": "A", "text": "convolutional networks"}, {"label": "B", "text": "graph networks"}, {"label": "C", "text": "fully connected networks"}, {"label": "D", "text": "RBF networks"}], "answerKey": "A", "model_answer": "LECTURE: Network architecture is an important design choice for a neural network. It involves deciding the pattern of connections between nodes in a network. Different network architectures are more suitable for different types of problems.\nConvolutional networks are well suited to image classification. They use convolution operations to analyze the features of an image. Convolution operations apply a set of filters to an image. Each filter looks for a specific feature, such as edges or corners.\nGraph networks are a type of neural network that can be used to predict structured data. A graph network uses a graph as its input. A graph is a set of nodes (also called vertices) connected by edges. A graph can represent a social network, a biological network, or any other type of network.\nFully connected networks are a type of neural network in which each node is connected to every other node. They are well suited to working with large datasets.\nRBF networks use radial basis functions to model the relationships between nodes. RBF networks are well suited to working with highly irregular data.\nSOLUTION: Convolutional networks are the most effective architecture for classifying high-resolution images. They are well suited to image classification, and they have already proven to be highly effective in this application."}
{"question": "Statement 1| The log-likelihood of the data will always increase through successive iterations of the expectation maximation algorithm. Statement 2| One disadvantage of Q-learning is that it can only be used when the learner has prior knowledge of how its actions affect its environment.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: Statements 1 and 2 are false.\nThe log-likelihood of the data will not always increase. It will increase in the first iteration, and then decrease in the second iteration.\nOne advantage of Q-learning is that it can learn from purely observational data. It can tell you how to act in situations you've never seen before."}
{"question": "Let us say that we have computed the gradient of our cost function and stored it in a vector g. What is the cost of one gradient descent update given the gradient?", "choices": [{"label": "A", "text": "O(D)"}, {"label": "B", "text": "O(N)"}, {"label": "C", "text": "O(ND)"}, {"label": "D", "text": "O(ND^2)"}], "answerKey": "A", "model_answer": "LECTURE: In the gradient descent algorithm, you adjust the parameters of your model by moving in the direction of the negative gradient of your cost function.\nThe gradient of the cost function is a vector that contains the gradient of the cost function with respect to each parameter. So, the gradient of the cost function is a vector of size D.\nThe negative gradient of the cost function is a vector with the same size as the gradient of the cost function. It is constructed by taking the negative of each element of the gradient of the cost function.\nThe negative gradient points in the opposite direction of the gradient. So, the negative gradient tells you how to move in the opposite direction of the direction specified by the gradient.\nThe cost of one gradient descent update is the value of the negative gradient of the cost function."}
{"question": "Statement 1| For a continuous random variable x and its probability distribution function p(x), it holds that 0 \u2264 p(x) \u2264 1 for all x. Statement 2| Decision tree is learned by minimizing information gain.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": ""}
{"question": "Consider the Bayesian network given below. How many independent parameters are needed for this Bayesian Network H -> U <- P <- W?", "choices": [{"label": "A", "text": "2"}, {"label": "B", "text": "4"}, {"label": "C", "text": "8"}, {"label": "D", "text": "16"}], "answerKey": "C", "model_answer": "LECTURE: For a Bayesian network, the number of independent parameters is always less than or equal to the number of nodes.\nFor a Bayesian network, the number of independent parameters is given by the formula:\nnumber of independent parameters = number of nodes - 1\nIn this Bayesian network:\nH -> U <- P <- W\nThere are four nodes.\nSo, the number of independent parameters is 4 - 1 = 3."}
{"question": "As the number of training examples goes to infinity, your model trained on that data will have:", "choices": [{"label": "A", "text": "Lower variance"}, {"label": "B", "text": "Higher variance"}, {"label": "C", "text": "Same variance"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": "LECTURE: The variance of a model is a measure of how much the model's predictions differ from each other. In other words, variance measures the spread of the model's predictions.\nLower variance means that the model's predictions are more consistent. A model with lower variance has fewer outliers and is less sensitive to outliers.\nHigher variance means that the model's predictions are more spread out. A model with higher variance has more outliers and is more sensitive to outliers.\nThe variance of a model is a critical measure for many supervised learning tasks. In general, it is better to have a model with lower variance. This means that the model is more consistent and is less sensitive to outliers.\nSOLUTION: As the number of training examples goes to infinity, the model trained on that data will have lower variance. This is true because the model will have more data to learn from, which will help the model to be more consistent."}
{"question": "Statement 1| The set of all rectangles in the 2D plane (which includes non axisaligned rectangles) can shatter a set of 5 points. Statement 2| The VC-dimension of k-Nearest Neighbour classifier when k = 1 is infinite.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "_ refers to a model that can neither model the training data nor generalize to new data.", "choices": [{"label": "A", "text": "good fitting"}, {"label": "B", "text": "overfitting"}, {"label": "C", "text": "underfitting"}, {"label": "D", "text": "all of the above"}], "answerKey": "C", "model_answer": "LECTURE: During the modeling process, a machine learning algorithm will typically iterate over a training dataset to find relationships between the input data and the target data. As a result of this iteration, the algorithm will generate a set of model parameters that are specific to the training data.\nOnce the model parameters have been determined, the algorithm can use the trained model to make predictions about new, unseen data. For example, if the algorithm is designed to predict a target variable Y for a given target variable X, it can use the trained model to make predictions about the value of Y for a new value of X.\nThere are several ways in which a model may fail to perform well on new data:\n1. Overfitting: The model may be a good fit to the training data, but it may not generalize well to new data. This may happen if the model is too complex for the amount of training data.\n2. Underfitting: The model may not be a good fit to the training data, and it may not generalize well to new data. This may happen if the model is too simple for the amount of training data.\n3. Stability: The model may not be stable. This means that small changes to the training data may produce significant changes in the model.\n4. Bias: The model may be biased. This means that the model may make incorrect predictions for certain values of the input data.\n5. Variance: The model may have high variance. This means that the model may make wide predictions for certain values of the input data.\nA model that is neither a good fit to the training data nor generalizes well to new data is an underfitting model."}
{"question": "Statement 1| The F1 score can be especially useful for datasets with class high imbalance. Statement 2| The area under the ROC curve is one of the main metrics used to assess anomaly detectors.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: Statement 1 is false.\nThe F1 score is not just for class imbalance. It evaluates a classifier's accuracy by weighing precision and recall.\nFor a binary classifier, the F1 score is the weighted average of precision and recall, with equal weight.\nFor a multiclass classifier, the F1 score is the average of the per-class F1 scores.\nSo, the F1 score can be used to assess a classifier's performance regardless of class imbalance.\nStatement 2 is false.\nThe area under the ROC curve is one of the main metrics used to assess anomaly detectors.\nAn ROC curve is a graphical plot of the true positive rate (TPR) against the false positive rate (FPR) for an anomaly detector.\nThe area under the ROC curve (AUC) is a single value that summarizes the curves.\nAUC = TPR \u00d7 FPR.\nAUC > 0.5 indicates that an anomaly detector is better than random chance.\nAUC = 0.5 indicates that an anomaly detector is no better than random chance.\nAUC < 0.5 indicates that an anomaly detector is worse than random chance.\nSo, the area under the ROC curve is one of the main metrics used to assess anomaly detectors."}
{"question": "Statement 1| The back-propagation algorithm learns a globally optimal neural network with hidden layers. Statement 2| The VC dimension of a line should be at most 2, since I can find at least one case of 3 points that cannot be shattered by any line.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: A graph is a collection of points called vertices, or nodes, which are connected by lines called edges.\nThe degree of a vertex is the number of edges that are connected to it.\nThe minimum degree of a graph is the minimum degree of any of its vertices.\nThe vertex degree sequence of a graph is the sequence of degrees of its vertices.\nA graph's vertex degree sequence does not include zero.\nA graph is a tree if it is made up of a single branch with no circles.\nA graph is a collection of disjoint trees if it is made up of a set of trees that are not connected.\nA graph is a series-parallel graph if it is made up of a set of branches, where each branch is a path or a cycle.\nThe series connection of graphs is a graph made up of a set of graphs in series.\nThe parallel connection of graphs is a graph made up of a set of graphs in parallel.\nSOLUTION: Step 1: Use the text to determine if each statement is true or false.\nThe VC dimension of a line should be at most 2, since I can find at least one case of 3 points that cannot be shattered by any line.\nThe VC dimension of a line is 2. So, each point of the line can be shattered by at most two lines.\nThe back-propagation algorithm learns a globally optimal neural network with hidden layers.\nThis statement is false. A global optimum is a function whose value is the best possible outcomes. A line cannot have a best possible outcome, since the line is not a function.\nStep 2: Look at the true statements.\nThe VC dimension of a line should be at most 2, since I can find at least one case of 3 points that cannot be shattered by any line.\nThe back-propagation algorithm learns a locally optimal neural network with hidden layers.\nA locally optimum function is a function whose value is the best possible outcome for each of its arguments. So, the back-propagation algorithm learns a globally optimal neural network with hidden layers."}
{"question": "High entropy means that the partitions in classification are", "choices": [{"label": "A", "text": "pure"}, {"label": "B", "text": "not pure"}, {"label": "C", "text": "useful"}, {"label": "D", "text": "useless"}], "answerKey": "B", "model_answer": "LECTURE: In an information system, data is stored in partitions, which are also called fields or attributes. Partitions have a data type, or classification, that determines what type of data can be stored in them. High entropy means that the partitions in classification are useful.\nEntropy is a measure of the amount of randomness in a system. In classification, entropy measures how evenly the possible partitions are distributed in the classification.\nIf the entropy is high, it means that the partitions in classification are well-utilized. There are a lot of different values that could be stored in them.\nA classification with high entropy is useful. It is more flexible and can store a wider range of values.\nIf the entropy is low, it means that the partitions in classification are not well-utilized. There are only a few different values that could be stored in them.\nA classification with low entropy is not useful. It is less flexible and can store a smaller range of values.\nSOLUTION: High entropy means that the partitions in classification are useful.\nSince the classification has high entropy, it is flexible and can store a wider range of values."}
{"question": "Statement 1| Layer Normalization is used in the original ResNet paper, not Batch Normalization. Statement 2| DCGANs use self-attention to stabilize training.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": ""}
{"question": "In building a linear regression model for a particular data set, you observe the coefficient of one of the features having a relatively high negative value. This suggests that", "choices": [{"label": "A", "text": "This feature has a strong effect on the model (should be retained)"}, {"label": "B", "text": "This feature does not have a strong effect on the model (should be ignored)"}, {"label": "C", "text": "It is not possible to comment on the importance of this feature without additional information"}, {"label": "D", "text": "Nothing can be determined."}], "answerKey": "C", "model_answer": ""}
{"question": "For a neural network, which one of these structural assumptions is the one that most affects the trade-off between underfitting (i.e. a high bias model) and overfitting (i.e. a high variance model):", "choices": [{"label": "A", "text": "The number of hidden nodes"}, {"label": "B", "text": "The learning rate"}, {"label": "C", "text": "The initial choice of weights"}, {"label": "D", "text": "The use of a constant-term unit input"}], "answerKey": "A", "model_answer": "LECTURE: Neural networks are powerful machines that can learn to recognize patterns in data. They do this by adjusting the weights of the edges between nodes.\nFor a neural network, there is a trade-off between underfitting and overfitting. Underfitting occurs when a model is too simple and cannot capture the patterns in the data. Overseeing occurs when a model is too complex and has high variance, but it has not learned to generalize.\nSOLUTION: The number of hidden nodes determines the capacity of the model. More hidden nodes allow the model to represent more complex relationships in the data.\nHowever, if the number of hidden nodes is too few, the model will underfit. The model will not be able to capture the relationships in the data.\nIf the number of hidden nodes is too many, the model will overfit. The model will have high variance, but it has not learned to generalize.\nThe learning rate determines the rate at which the model learns from the data. A higher learning rate means that the model embraces new data faster.\nHowever, a higher learning rate can lead to a model that overfits. The model will have high variance, but it has not learned to generalize.\nThe initial choice of weights determines the strength of the connections between nodes. The wrong initial weights can lead to a model that underfits or overfits.\nA model with too many weak connections will underfit. A model with too many strong connections will overfit.\nThe use of a constant-term unit input affects the type of data that the model can learn to recognize. Using a constant-term unit input allows the model to learn to recognize constants.\nHowever, using a constant-term unit input does not affect the trade-off between underfitting and overfitting."}
{"question": "For polynomial regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "The polynomial degree"}, {"label": "B", "text": "Whether we learn the weights by matrix inversion or gradient descent"}, {"label": "C", "text": "The assumed variance of the Gaussian noise"}, {"label": "D", "text": "The use of a constant-term unit input"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| As of 2020, some models attain greater than 98% accuracy on CIFAR-10. Statement 2| The original ResNets were not optimized with the Adam optimizer.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "The K-means algorithm:", "choices": [{"label": "A", "text": "Requires the dimension of the feature space to be no bigger than the number of samples"}, {"label": "B", "text": "Has the smallest value of the objective function when K = 1"}, {"label": "C", "text": "Minimizes the within class variance for a given number of clusters"}, {"label": "D", "text": "Converges to the global optimum if and only if the initial means are chosen as some of the samples themselves"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| VGGNets have convolutional kernels of smaller width and height than AlexNet's first-layer kernels. Statement 2| Data-dependent weight initialization procedures were introduced before Batch Normalization.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "What is the rank of the following matrix? A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]", "choices": [{"label": "A", "text": "0"}, {"label": "B", "text": "1"}, {"label": "C", "text": "2"}, {"label": "D", "text": "3"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| Density estimation (using say, the kernel density estimator) can be used to perform classification. Statement 2| The correspondence between logistic regression and Gaussian Naive Bayes (with identity class covariances) means that there is a one-to-one correspondence between the parameters of the two classifiers.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: Statement 1 is false. Density estimation is a technique for building models of probability distributions. Density estimation does not perform classification.\nStatement 2 is true. The correspondence between logistic regression and Gaussian Naive Bayes (with identity class covariances) shows that there is a one-to-one correspondence between the parameters of the two classifiers. This correspondence allows you to use the rich literature on logistic regression to understand the properties and performance of Gaussian Naive Bayes."}
{"question": "Suppose we would like to perform clustering on spatial data such as the geometrical locations of houses. We wish to produce clusters of many different sizes and shapes. Which of the following methods is the most appropriate?", "choices": [{"label": "A", "text": "Decision Trees"}, {"label": "B", "text": "Density-based clustering"}, {"label": "C", "text": "Model-based clustering"}, {"label": "D", "text": "K-means clustering"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| In AdaBoost weights of the misclassified examples go up by the same multiplicative factor. Statement 2| In AdaBoost, weighted training error e_t of the tth weak classifier on training data with weights D_t tends to increase as a function of t.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: Statement 1 is a restatement of Statement 2.\nIn AdaBoost, weak learners are trained one at a time. For each weak learner, the algorithm considers a different subset of the training data. The subset is determined by the outcomes of the previous weak learners. For example, for the second weak learner, the algorithm considers only the examples that the first weak learner misclassified.\nThe weighted training error of a weak learner on a subset of the training data is a measure of how often the weak learner makes errors on that subset. This measure is used to adjust the weights of the examples in the subset.\nIn particular, the weight of each example is increased by the inverse of its weighted training error. So, the weights of the examples that the weak learner misclassified will go up by the same multiplicative factor.\nStatement 2 says that the weighted training error of a weak classifier tends to increase as a function of the weak learner being considered. So, Statement 1 is a restatement of Statement 2."}
{"question": "MLE estimates are often undesirable because", "choices": [{"label": "A", "text": "they are biased"}, {"label": "B", "text": "they have high variance"}, {"label": "C", "text": "they are not consistent estimators"}, {"label": "D", "text": "None of the above"}], "answerKey": "B", "model_answer": ""}
{"question": "Computational complexity of Gradient descent is,", "choices": [{"label": "A", "text": "linear in D"}, {"label": "B", "text": "linear in N"}, {"label": "C", "text": "polynomial in D"}, {"label": "D", "text": "dependent on the number of iterations"}], "answerKey": "C", "model_answer": "LECTURE: Computational complexity is a measure of the amount of resources, such as time and memory, required by an algorithm. These resources are measured relative to the input size. For example, if an algorithm has linear computational complexity, it means that the amount of resources required grows by a factor of n, where n is the input size.\nImagine an algorithm with computational complexity quadratic in n. This means that the amount of resources required grows by a factor of n^2. For example, using a dictionary with n entries takes constant time, but looking up a word takes constant + O(1), so the overall time takes O(1), which is linear in n.\nSOLUTION: The computational complexity of Gradient descent is dependent on the number of iterations. This is because each iteration requires only linear complexity in D, but there are a number of iterations that depend on the problem."}
{"question": "Averaging the output of multiple decision trees helps _.", "choices": [{"label": "A", "text": "Increase bias"}, {"label": "B", "text": "Decrease bias"}, {"label": "C", "text": "Increase variance"}, {"label": "D", "text": "Decrease variance"}], "answerKey": "D", "model_answer": "LECTURE: The average of multiple decision trees is a single decision tree. Averaging the output of multiple decision trees helps decrease bias. This is because decision trees are individual models. When you take the average of their outputs, the averages are less extreme and less likely to be wrong in either direction.\nIn general, averaging individual models helps decrease bias and increase variance."}
{"question": "The model obtained by applying linear regression on the identified subset of features may differ from the model obtained at the end of the process of identifying the subset during", "choices": [{"label": "A", "text": "Best-subset selection"}, {"label": "B", "text": "Forward stepwise selection"}, {"label": "C", "text": "Forward stage wise selection"}, {"label": "D", "text": "All of the above"}], "answerKey": "C", "model_answer": "LECTURE: In the forward stepwise selection procedure, the analyst begins with no variables in the model. In each step of the procedure, the analyst adds one variable to the model. This variable is chosen so as to optimize the balance between the strength of the relationship with the dependent variable and the effect of the variable on the predictive accuracy of the model.\nIn the forward stage-wise selection procedure, the analyst also begins with no variables in the model. In each step of the procedure, the analyst adds a subset of variables to the model. These subsets are chosen based on the stage of the analysis. For example, in the first stage, the analyst might add variables that have a strong relationship with the dependent variable. In a subsequent stage, the analyst might add variables that have a strong relationship with each other.\nThe best-subset selection procedure is similar to forward stepwise selection, but it evaluates all possible subsets of variables. For each subset, the analyst evaluates the strength of the relationship with the dependent variable and the predictive accuracy of the model. The analyst then selects the subset with the best predictive accuracy."}
{"question": "Neural networks:", "choices": [{"label": "A", "text": "Optimize a convex objective function"}, {"label": "B", "text": "Can only be trained with stochastic gradient descent"}, {"label": "C", "text": "Can use a mix of different activation functions"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": "LECTURE: Neural networks are a family of machine learning algorithms. They are designed to recognize patterns in data.\nA neural network has the following components:\nInput layer: This layer takes in data.\nHidden layers: These layers process the data.\nOutput layer: This layer produces the results.\nActivation functions: These functions are used on each input in a hidden layer. They tell you how to combine the inputs.\nA neural network can have multiple hidden layers.\nSOLUTION: All of the following can be true of a neural network:\nIt can use a mix of different activation functions.\nActivation functions are used on each input in a hidden layer.\nA neural network can have multiple hidden layers.\nSo, a neural network can optimize a convex objective function.\nA convex objective function is a function where the path from the start to the end cannot be on average as low as the path along any single attribute.\nThere are several different types of activation functions.\nThere are many ways to construct a neural network."}
{"question": "Say the incidence of a disease D is about 5 cases per 100 people (i.e., P(D) = 0.05). Let Boolean random variable D mean a patient \u201chas disease D\u201d and let Boolean random variable TP stand for \"tests positive.\" Tests for disease D are known to be very accurate in the sense that the probability of testing positive when you have the disease is 0.99, and the probability of testing negative when you do not have the disease is 0.97. What is P(TP), the prior probability of testing positive.", "choices": [{"label": "A", "text": "0.0368"}, {"label": "B", "text": "0.473"}, {"label": "C", "text": "0.078"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| After mapped into feature space Q through a radial basis kernel function, 1-NN using unweighted Euclidean distance may be able to achieve better classification performance than in original space (though we can\u2019t guarantee this). Statement 2| The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SVM.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": ""}
{"question": "The disadvantage of Grid search is", "choices": [{"label": "A", "text": "It can not be applied to non-differentiable functions."}, {"label": "B", "text": "It can not be applied to non-continuous functions."}, {"label": "C", "text": "It is hard to implement."}, {"label": "D", "text": "It runs reasonably slow for multiple linear regression."}], "answerKey": "D", "model_answer": "LECTURE: Some machine learning algorithms can be used with any type of function, while others can be used only with specific types of functions.\nA non-differentiable function is a function that is not differentiable at any point. Differentiation is a method for finding the derivative of a function. A derivative is a measure of how a function changes.\nA non-continuous function is a function that is not continuous at any point. A function is continuous at a point if it is defined at that point.\nSOLUTION: Grid search is a method for finding the best values for a set of hyperparameters. It searches through all possible combinations of hyperparameters and evaluates each combination by training a model.\nGrid search can be applied to any type of function."}
{"question": "Predicting the amount of rainfall in a region based on various cues is a ______ problem.", "choices": [{"label": "A", "text": "Supervised learning"}, {"label": "B", "text": "Unsupervised learning"}, {"label": "C", "text": "Clustering"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": "LECTURE: Machine learning is a way of using algorithms to help computers make predictions or decisions.\nSupervised learning is a type of machine learning where the algorithm is trained on data with known outcomes. The algorithm uses this data to learn how to make predictions on new, unseen data.\nUnsupervised learning is a type of machine learning where the algorithm is trained on data without known outcomes. The algorithm uses this data to discover patterns or structures in the data.\nSOLUTION: Predicting the amount of rainfall in a region based on various cues is a supervised learning problem. In supervised learning, the algorithm is trained on data with known outcomes."}
{"question": "Which of the following sentence is FALSE regarding regression?", "choices": [{"label": "A", "text": "It relates inputs to outputs."}, {"label": "B", "text": "It is used for prediction."}, {"label": "C", "text": "It may be used for interpretation."}, {"label": "D", "text": "It discovers causal relationships"}], "answerKey": "D", "model_answer": "LECTURE: A graph shows the relationship between two quantities. The graph has a slope of 1 and a slope of 2.\nWhat do the slopes of the graph show?\nThe slopes show the relationship between the two quantities. A slope of 1 means that the two quantities increase or decrease at the same rate. A slope of 2 means that the two quantities increase or decrease twice as fast.\nA graph shows the relationship between a dependent variable and one or more independent variables.\nWhat is a dependent variable?\nA dependent variable is a variable that is measured or observed as a result of the independent variables.\nWhat is an independent variable?\nAn independent variable is a variable that is measured or observed before the dependent variable.\nWhat is a regression?\nA regression is a statistical method that uses a line to show the relationship between two or more variables.\nWhat does a regression line show?\nA regression line shows the average relationship between two variables. The regression line is made up of a set of points. Each point is the sum of the product of the independent variable and its coefficient and the constant term.\nThe coefficient is the slope of the regression line. The constant term is the y-interception of the regression line.\nSOLUTION: It may be used for interpretation.\nThe other answers are correct. Regression relates inputs to outputs, is used for prediction, and discovers causal relationships. But interpretation makes several incorrect claims.\nInterpretation says that the regression line shows how a change in the independent variable affects the dependent variable. But the independent variable does not have to change for the dependent variable to change. And the dependent variable does not have to change when the independent variable does."}
{"question": "Which one of the following is the main reason for pruning a Decision Tree?", "choices": [{"label": "A", "text": "To save computing time during testing"}, {"label": "B", "text": "To save space for storing the Decision Tree"}, {"label": "C", "text": "To make the training set error smaller"}, {"label": "D", "text": "To avoid overfitting the training set"}], "answerKey": "D", "model_answer": "LECTURE: In decision tree modeling, pruning is a technique for reducing overfitting and improving the generalization of the model.\nSOLUTION: The main reason for pruning a Decision Tree is to avoid overfitting the training set. Overfitting occurs when a model is too complex and starts to fit the noise in the training data."}
{"question": "Statement 1| The kernel density estimator is equivalent to performing kernel regression with the value Yi = 1/n at each point Xi in the original data set. Statement 2| The depth of a learned decision tree can be larger than the number of training examples used to create the tree.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: A kernel density estimator is a nonparametric way of estimating the probability density function of a random variable. The estimator is based on the idea of placing a basket of balls around the point of interest. The ball that is closest to the point of interest is considered to be the value of the random variable at that point.\nTo do this successfully, it is necessary to choose a basket of balls that is thick enough to contain the values of the random variable but not so thick that it contains too many values. One way to do this is by using a kernel density estimator.\nA kernel density estimator works by replacing the basket of balls with a smooth function, called a kernel, that is multiplied by a positive weight. The weight is inversely proportional to the distance between the point of interest and the center of the ball. The resulting multiplied kernel is the value of the random variable at that point.\nSOLUTION: Statement 1 is true. For each point in the data set, the kernel density estimator performs a kernel regression with the value Yi = 1/n at that point.\nStatement 2 is false. The depth of a decision tree is determined by the number of criteria that are used to choose the best split. These criteria may include the value of the random variable at the current point, as well as the values of the random variables at other points that are considered in the tree. The depth of the tree is not restricted by the number of training examples."}
{"question": "Suppose your model is overfitting. Which of the following is NOT a valid way to try and reduce the overfitting?", "choices": [{"label": "A", "text": "Increase the amount of training data."}, {"label": "B", "text": "Improve the optimisation algorithm being used for error minimisation."}, {"label": "C", "text": "Decrease the model complexity."}, {"label": "D", "text": "Reduce the noise in the training data."}], "answerKey": "B", "model_answer": "LECTURE: In general, there are four main ways to reduce overfitting:\n1. Decrease model complexity: Reducing the number of nodes in a neural network, or the number of parameters in a linear model, will usually decrease overfitting.\n2. Increase the amount of training data: Adding more data to the training set is useful for many types of models. For example, for a linear model, more training data can help to reduce the residual sum of squares, which contributes to overfitting.\n3. Use better optimization techniques: Using a better optimization algorithm can sometimes help to reduce overfitting. For example, using a more efficient algorithm for minimizing the error function can help to prevent the error from becoming too small.\n4. Regularize the model: Regularization is a technique for modifying the error function to reduce overfitting. The terms regularization and anti-pattern are often used interchangeably.\nRegularization can be accomplished in a number of ways. For example, you can add a penalty term to the error function, such as the L1 or L2 norm. This adds a new term to the error function that depends on the absolute value or the square root of the absolute value of the model parameters.\nAnother way to regularize is to reduce the size of the model. This can be done by using a smaller number of nodes in a neural network, or by using a smaller number of features in a model.\nSOLUTION: Noise in the training data is not a direct source of overfitting. So, decreasing the noise in the training data is not a way to reduce overfitting."}
{"question": "Statement 1| The softmax function is commonly used in mutliclass logistic regression. Statement 2| The temperature of a nonuniform softmax distribution affects its entropy.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following is/are true regarding an SVM?", "choices": [{"label": "A", "text": "For two dimensional data points, the separating hyperplane learnt by a linear SVM will be a straight line."}, {"label": "B", "text": "In theory, a Gaussian kernel SVM cannot model any complex separating hyperplane."}, {"label": "C", "text": "For every kernel function used in a SVM, one can obtain an equivalent closed form basis expansion."}, {"label": "D", "text": "Overfitting in an SVM is not a function of number of support vectors."}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following is the joint probability of H, U, P, and W described by the given Bayesian Network H -> U <- P <- W? [note: as the product of the conditional probabilities]", "choices": [{"label": "A", "text": "P(H, U, P, W) = P(H) * P(W) * P(P) * P(U)"}, {"label": "B", "text": "P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(W | H, P)"}, {"label": "C", "text": "P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(U | H, P)"}, {"label": "D", "text": "None of the above"}], "answerKey": "C", "model_answer": "LECTURE: A Bayesian network is a model that represents a set of variables and their conditional dependencies via a directed acyclic graph.\nThe probabilities of the variables in the network are defined via their probabilities given the variables in their precedence graph.\nThe precedence graph of a variable is the directed acyclic subgraph of the Bayesian network that contains that variable.\nThe conditional probability of a variable given its parents is defined as the probability that the variable takes a certain value, conditioned on its parents taking values of a certain type.\nFor example, for a variable X that is conditional on Y and Z, the probability of X given Y and Z is defined as P(X | Y, Z) = P(X | Y, Z = z).\nThe joint probability of a group of variables is the probability that all of the variables in the group take a certain set of values.\nFor example, the joint probability P(X, Y) is the probability that variables X and Y take values x and y, respectively.\nThe joint probability of a group of variables in a Bayesian network is the product of the conditional probabilities in the network.\nFor example, for a network with variables X, Y, and Z, and the joint probability P(X, Y, Z) is given by:\nP(X, Y, Z) = P(X | Y, Z) * P(Y | X, Z) * P(Z).\nSOLUTION: The given Bayesian Network is H -> U <- P <- W.\nThe joint probability P(H, U, P, W) is the product of the conditional probabilities P(H) * P(W) * P(P) * P(U)."}
{"question": "Statement 1| Since the VC dimension for an SVM with a Radial Base Kernel is infinite, such an SVM must be worse than an SVM with polynomial kernel which has a finite VC dimension. Statement 2| A two layer neural network with linear activation functions is essentially a weighted combination of linear separators, trained on a given dataset; the boosting algorithm built on linear separators also finds a combination of linear separators, therefore these two algorithms will give the same result.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| The ID3 algorithm is guaranteed to find the optimal decision tree. Statement 2| Consider a continuous probability distribution with density f() that is nonzero everywhere. The probability of a value x is equal to f(x).", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: A decision tree is a flowchart-like structure in which each internal decision node represents a test on a quantitative attribute, and each leaf node represents a class. The goal in constructing a decision tree is to find the test that most effectively separates the classes.\nThe ID3 algorithm is a popular algorithm for constructing a decision tree. The ID3 algorithm uses a heuristic called the information ratio to evaluate the effectiveness of a potential test.\nThe information ratio is the ratio of the information gained by the test to the information lost by the test. The information gained by a test is the difference between the entropy of the class before the test and the entropy of the class after the test. The entropy of a class is the average information gained by a random sample of an element from the class. The information lost by a test is the difference between the entropy of the class before the test and the entropy of the test.\nThe ID3 algorithm guarantees that the optimal decision tree is the one that has the highest information gain.\nSOLUTION: Statement 1 is false. The ID3 algorithm does not necessarily find the optimal decision tree. It is possible to find a decision tree with a higher information gain by using a different algorithm or by human intervention.\nStatement 2 is false. There are probability distributions with density f() that are nonzero everywhere, and the probability of a value x is equal to f(x). But these conditions do not guarantee that a decision tree can be constructed with the ID3 algorithm."}
{"question": "Given a Neural Net with N input nodes, no hidden layers, one output node, with Entropy Loss and Sigmoid Activation Functions, which of the following algorithms (with the proper hyper-parameters and initialization) can be used to find the global optimum?", "choices": [{"label": "A", "text": "Stochastic Gradient Descent"}, {"label": "B", "text": "Mini-Batch Gradient Descent"}, {"label": "C", "text": "Batch Gradient Descent"}, {"label": "D", "text": "All of the above"}], "answerKey": "D", "model_answer": "LECTURE: Algorithms are used to find a global optimum of a function. There are several algorithms that are used to optimize machine learning models. Some of these algorithms are:\nBatch Gradient Descent is an algorithm that is used to optimize a machine learning model. It involves the following steps:\nFor each training example, the batch gradient descent algorithm updates the model parameters as follows:\nThe main advantage of the batch gradient descent algorithm is that it is simple to implement.\nThe mini-batch gradient descent algorithm is a variation of the batch gradient descent algorithm. The mini-batch gradient descent algorithm involves the following steps:\nFor each training example, the mini-batch gradient descent algorithm updates the model parameters as follows:\nThe mini-batch gradient descent algorithm is similar to the batch gradient descent algorithm, but it uses smaller batches of data. Using smaller batches of data can make the optimization process go faster.\nThe stochastic gradient descent algorithm is an algorithm that is used to optimize a machine learning model. It involves the following steps:\nFor each training example, the stochastic gradient descent algorithm updates the model parameters as follows:\nThe stochastic gradient descent algorithm is simple to implement, and it can be used to optimize large models.\nFor a machine learning model with N input nodes, no hidden layers, one output node, with entropy loss and sigmoid activation function, the algorithms that can be used to find the global optimum are Batch Gradient Descent and Mini-Batch Gradient Descent.\nEntropy Loss is a measure of the uncertainty of the model. The entropy loss is calculated as follows:\nThe sigmoid activation function is a mathematical function that is used to introduce non-linearity into a machine learning model. The sigmoid activation function is defined as follows:\nThe global optimum of a function is the lowest point on the function. The global optimum of a machine learning model is the set of model parameters that produce the lowest loss.\nSOLUTION: Batch Gradient Descent and Mini-Batch Gradient Descent are the only algorithms that can be used to find the global optimum for a machine learning model with N input nodes, no hidden layers, one output node, with entropy loss and sigmoid activation function."}
{"question": "Adding more basis functions in a linear model, pick the most probably option:", "choices": [{"label": "A", "text": "Decreases model bias"}, {"label": "B", "text": "Decreases estimation bias"}, {"label": "C", "text": "Decreases variance"}, {"label": "D", "text": "Doesn\u2019t affect bias and variance"}], "answerKey": "A", "model_answer": ""}
{"question": "Consider the Bayesian network given below. How many independent parameters would we need if we made no assumptions about independence or conditional independence H -> U <- P <- W?", "choices": [{"label": "A", "text": "3"}, {"label": "B", "text": "4"}, {"label": "C", "text": "7"}, {"label": "D", "text": "15"}], "answerKey": "D", "model_answer": "LECTURE: A Bayesian network is a directed acyclic graph (DAG) in which each node represents a variable and each edge represents a causal dependence relationship.\nThe nodes in a Bayesian network are arranged to form a directed acyclic graph. This arrangement shows how some variables can affect the value of other variables. In a Bayesian network, each node represents a variable, and each edge represents a causal dependence relationship between variables.\nThe variables in a Bayesian network can be labeled with alphabetical characters. As a result, each variable can be uniquely identified by its label.\nThe directed edges in a Bayesian network point from parents to children. Each edge represents a causal dependence relationship between the parents and children.\nThe Bayesian network shown below has six nodes and three edges.\nThe nodes are labeled with the symbols P, H, L, S, U, and W.\nThe edges are labeled with the probabilities between 0 and 1. The edge from H to U has a probability of 0.6, and the edge from P to S has a probability of 0.3. The edge from P to U has a probability of 0.4, and the edge from S to U has a probability of 0.6.\nSOLUTION: To determine the number of independent parameters in this Bayesian network, consider the number of connections between nodes.\nEach edge in a Bayesian network connects two nodes. So, the number of independent parameters in a Bayesian network is the number of nodes minus the number of edges.\nIn this Bayesian network, there are six nodes and three edges. So, the number of independent parameters is 6 3 = 3."}
{"question": "Another term for out-of-distribution detection is?", "choices": [{"label": "A", "text": "anomaly detection"}, {"label": "B", "text": "one-class detection"}, {"label": "C", "text": "train-test mismatch robustness"}, {"label": "D", "text": "background detection"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| We learn a classifier f by boosting weak learners h. The functional form of f\u2019s decision boundary is the same as h\u2019s, but with different parameters. (e.g., if h was a linear classifier, then f is also a linear classifier). Statement 2| Cross validation can be used to select the number of iterations in boosting; this procedure may help reduce overfitting.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": ""}
{"question": "Statement 1| Highway networks were introduced after ResNets and eschew max pooling in favor of convolutions. Statement 2| DenseNets usually cost more memory than ResNets.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": ""}
{"question": "If N is the number of instances in the training dataset, nearest neighbors has a classification run time of", "choices": [{"label": "A", "text": "O(1)"}, {"label": "B", "text": "O( N )"}, {"label": "C", "text": "O(log N )"}, {"label": "D", "text": "O( N^2 )"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| The original ResNets and Transformers are feedforward neural networks. Statement 2| The original Transformers use self-attention, but the original ResNet does not.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Statement 1| RELUs are not monotonic, but sigmoids are monotonic. Statement 2| Neural networks trained with gradient descent with high probability converge to the global optimum.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": "LECTURE: A function is a monotonic if and only if the output is non-decreasing or non-increasing as the input increases.\nA function f is monotonic if and only if either f(x) \u2264 f(y) or f(x) \u2265 f(y) for all x, y.\nA function f is strictly monotonic if and only if f(x) \u2260 f(y) for all x, y.\nA function is not monotonic if and only if it is neither strictly increasing nor strictly decreasing.\nA function f is not monotonic if and only if there is some x and y such that f(x) \u2265 f(y) and f(y) \u2265 f(x).\nSOLUTION: Statement 1 is false. A sigmoid is monotonic, but a RELU is not.\nA RELU is not monotonic. For large values of x, the function is equal to x. For small values of x, the function is less than x.\nA sigmoid is monotonic. A sigmoid f(x) is either less than or equal to a sigmoid y, or greater than or equal to a sigmoid y.\nStatement 2 is false. Neural networks trained with gradient descent with high probability do not converge to the global optimum.\nThe global optimum is the point at which the fit of the function to the data is best. Local optima are points at which the function has a local minimum or a local maximum. Local optima are not necessarily the global optimum.\nEven if a neural network is trained with gradient descent, it may not converge to the global optimum. When the cost function has many local optima, the neural network may converge to a local optimum instead of the global optimum."}
{"question": "The numerical output of a sigmoid node in a neural network:", "choices": [{"label": "A", "text": "Is unbounded, encompassing all real numbers."}, {"label": "B", "text": "Is unbounded, encompassing all integers."}, {"label": "C", "text": "Is bounded between 0 and 1."}, {"label": "D", "text": "Is bounded between -1 and 1."}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following can only be used when training data are linearly separable?", "choices": [{"label": "A", "text": "Linear hard-margin SVM."}, {"label": "B", "text": "Linear Logistic Regression."}, {"label": "C", "text": "Linear Soft margin SVM."}, {"label": "D", "text": "The centroid method."}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following are the spatial clustering algorithms?", "choices": [{"label": "A", "text": "Partitioning based clustering"}, {"label": "B", "text": "K-means clustering"}, {"label": "C", "text": "Grid based clustering"}, {"label": "D", "text": "All of the above"}], "answerKey": "D", "model_answer": "LECTURE: Spatial clustering is a type of clustering that is commonly used in geographic information systems. It is used to group objects that are located near one another. There are several algorithms that can be used for spatial clustering, including partitioning-based clustering, k-means clustering, and grid-based clustering.\nPartitioning-based clustering divides the area into multiple parts based on the locations of the objects. This type of clustering creates clusters that are contiguous areas.\nK-means clustering is a type of clustering that is not specific to spatial data. It is simple to perform and understand. It involves defining the number of clusters (k) beforehand and assigning each object to the cluster that is closest to it.\nGrid-based clustering is a type of clustering that is not specific to spatial data. It involves dividing the area into a grid of cells and assigning each object to the cell that it is located in.\nSOLUTION: K-means clustering is a type of clustering that is not specific to spatial data. It involves defining the number of clusters (k) beforehand and assigning each object to the cluster that is closest to it.\nPartitioning-based clustering divides the area into multiple parts based on the locations of the objects. This type of clustering creates clusters that are contiguous areas.\nGrid-based clustering is a type of clustering that is not specific to spatial data. It involves dividing the area into a grid of cells and assigning each object to the cell that it is located in."}
{"question": "Statement 1| The maximum margin decision boundaries that support vector machines construct have the lowest generalization error among all linear classifiers. Statement 2| Any decision boundary that we get from a generative model with classconditional Gaussian distributions could in principle be reproduced with an SVM and a polynomial kernel of degree less than or equal to three.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": ""}
{"question": "Statement 1| L2 regularization of linear models tends to make models more sparse than L1 regularization. Statement 2| Residual connections can be found in ResNets and Transformers.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": ""}
{"question": "Suppose we like to calculate P(H|E, F) and we have no conditional independence information. Which of the following sets of numbers are sufficient for the calculation?", "choices": [{"label": "A", "text": "P(E, F), P(H), P(E|H), P(F|H)"}, {"label": "B", "text": "P(E, F), P(H), P(E, F|H)"}, {"label": "C", "text": "P(H), P(E|H), P(F|H)"}, {"label": "D", "text": "P(E, F), P(E|H), P(F|H)"}], "answerKey": "B", "model_answer": ""}
{"question": "Which among the following prevents overfitting when we perform bagging?", "choices": [{"label": "A", "text": "The use of sampling with replacement as the sampling technique"}, {"label": "B", "text": "The use of weak classifiers"}, {"label": "C", "text": "The use of classification algorithms which are not prone to overfitting"}, {"label": "D", "text": "The practice of validation performed on every classifier trained"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| PCA and Spectral Clustering (such as Andrew Ng\u2019s) perform eigendecomposition on two different matrices. However, the size of these two matrices are the same. Statement 2| Since classification is a special case of regression, logistic regression is a special case of linear regression.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": "LECTURE: Similarity is a relation that holds between two objects. Two objects are similar if they have the same properties.\nStatements 1 and 2 are similar because they both discuss the relationship between two matrices. Matrix analysis is used to decompose a matrix into its component parts.\nPCA and spectral clustering are types of matrix analysis. They both perform eigendecomposition on two different matrices. However, the size of these two matrices is the same.\nLogistic regression is a type of regression. Regression is a special case of logging regression."}
{"question": "Statement 1| The Stanford Sentiment Treebank contained movie reviews, not book reviews. Statement 2| The Penn Treebank has been used for language modeling.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "What is the dimensionality of the null space of the following matrix? A = [[3, 2, \u22129], [\u22126, \u22124, 18], [12, 8, \u221236]]", "choices": [{"label": "A", "text": "0"}, {"label": "B", "text": "1"}, {"label": "C", "text": "2"}, {"label": "D", "text": "3"}], "answerKey": "C", "model_answer": ""}
{"question": "What are support vectors?", "choices": [{"label": "A", "text": "The examples farthest from the decision boundary."}, {"label": "B", "text": "The only examples necessary to compute f(x) in an SVM."}, {"label": "C", "text": "The data centroid."}, {"label": "D", "text": "All the examples that have a non-zero weight \u03b1k in a SVM."}], "answerKey": "B", "model_answer": "LECTURE: In a linear SVM, the decision boundary is a hyperplane that maximizes the margin, which is the distance between the hyperplane and the closest data points.\nThe margin is defined as the distance between the hyperplane and the closest support vector. A support vector is a data point that is closest to the hyperplane.\nIf a data point is not a support vector, it is not closest to the hyperplane. So, the only examples necessary to compute f(x) in an SVM are the support vectors.\nThe weight of a support vector is denoted by \u03b1k. The weight is a positive value that represents the importance of a support vector in determining the hyperplane.\nThe data centroid is not the same as the support vectors. The centroid is a value that represents the average of the data points. The support vectors are the data points that are closest to the hyperplane, not the data points that are closest to the centroid."}
{"question": "Statement 1| Word2Vec parameters were not initialized using a Restricted Boltzman Machine. Statement 2| The tanh function is a nonlinear activation function.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "If your training loss increases with number of epochs, which of the following could be a possible issue with the learning process?", "choices": [{"label": "A", "text": "Regularization is too low and model is overfitting"}, {"label": "B", "text": "Regularization is too high and model is underfitting"}, {"label": "C", "text": "Step size is too large"}, {"label": "D", "text": "Step size is too small"}], "answerKey": "C", "model_answer": "LECTURE: During training, you may observe that the training loss increases with the number of epochs. This means that the model is not able to minimize the training loss over time. There are several possible issues that may be causing this:\n1. Regularization is too low and model is overfitting: Regularization helps prevent overfitting by adding a penalty to the loss function. If regularization is too low, the model may be overfitting to the training data.\n2. Regularization is too high and model is underfitting: Regularization adds a penalty to the loss function, which can cause the model to underfit the data. If regularization is too high, the model may not be able to capture the relationships in the data.\n3. Step size is too large: The step size is the amount the model parameters are updated after each batch of training data. If the step size is too large, the model may overshoot the optimal parameters.\n4. Step size is too small: Conversely, if the step size is too small, the model may take a long time to converge.\nSOLUTION: Increasing training loss with number of epochs is called training error. If the training error increases with the number of epochs, it is a possible issue with the learning process. However, there may be other issues as well."}
{"question": "Say the incidence of a disease D is about 5 cases per 100 people (i.e., P(D) = 0.05). Let Boolean random variable D mean a patient \u201chas disease D\u201d and let Boolean random variable TP stand for \"tests positive.\" Tests for disease D are known to be very accurate in the sense that the probability of testing positive when you have the disease is 0.99, and the probability of testing negative when you do not have the disease is 0.97. What is P(D | TP), the posterior probability that you have disease D when the test is positive?", "choices": [{"label": "A", "text": "0.0495"}, {"label": "B", "text": "0.078"}, {"label": "C", "text": "0.635"}, {"label": "D", "text": "0.97"}], "answerKey": "C", "model_answer": "LECTURE: Conditional probability is the probability that an event occurs given that another event has happened.\nThe conditional probability of event A given that event B has occurred is written as P(A | B).\nThe conditional probability is calculated as the probability that both events occur, divided by the probability that event B occurs.\nConditional probability is always between 0 and 1.\nIf P(B) = 0, then P(A | B) is undefined.\nThe posterior probability that you have disease D when the test is positive is the conditional probability that you have disease D, given that the test is positive. This probability is written as P(D | TP)."}
{"question": "Statement 1| Traditional machine learning results assume that the train and test sets are independent and identically distributed. Statement 2| In 2017, COCO models were usually pretrained on ImageNet.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: Statement 1 is true. In traditional machine learning, it is assumed that the train and test sets are independent and identically distributed. This means that the test set is a random sample of the same population as the train set.\nStatement 2 is true. In 2017, the common practice for COCO models was to be pretrained on ImageNet. Pretraining is done on a large dataset, such as ImageNet, before fine-tuning on a smaller dataset, such as COCO."}
{"question": "Statement 1| The values of the margins obtained by two different kernels K1(x, x0) and K2(x, x0) on the same training set do not tell us which classifier will perform better on the test set. Statement 2| The activation function of BERT is the GELU.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following is a clustering algorithm in machine learning?", "choices": [{"label": "A", "text": "Expectation Maximization"}, {"label": "B", "text": "CART"}, {"label": "C", "text": "Gaussian Na\u00efve Bayes"}, {"label": "D", "text": "Apriori"}], "answerKey": "A", "model_answer": "LECTURE: In machine learning, clustering is the process of organizing data into groups.\nA clustering algorithm is a way of automating this process.\nThe goal of a clustering algorithm is to group similar data points into clusters.\nClustering can be used to identify subgroups within a data set.\nFor example, a clustering algorithm might be used to identify groups of customers with similar purchasing patterns.\nThere are many different clustering algorithms.\nSome clustering algorithms work by partitioning the data into clusters. Other clustering algorithms work by minimizing the distance between clusters.\nThe choice of which clustering algorithm to use will depend on the type of data and the goals of the analysis.\nExpectation Maximization is a clustering algorithm that uses a combination of probability and statistics to find the optimal clustering.\nThe k-means algorithm is a clustering algorithm that uses the distance between data points to group them into clusters.\nThe k-medoids algorithm is a clustering algorithm that uses the medoids of data points to group them into clusters.\nGaussian Naive Bayes is a probabilistic algorithm that uses Bayes' theorem to predict the probability of a data point belonging to a cluster.\nThe Apriori algorithm is a clustering algorithm that uses a form of the greedy strategy to find the optimal clusturing.\nThe choice of which clustering algorithm to use will depend on the type of data and the goals of the analysis."}
{"question": "You've just finished training a decision tree for spam classification, and it is getting abnormally bad performance on both your training and test sets. You know that your implementation has no bugs, so what could be causing the problem?", "choices": [{"label": "A", "text": "Your decision trees are too shallow."}, {"label": "B", "text": "You need to increase the learning rate."}, {"label": "C", "text": "You are overfitting."}, {"label": "D", "text": "None of the above."}], "answerKey": "A", "model_answer": "LECTURE: In decision tree models, the trees are grown one split at a time. Starting at the root, the model selects the best feature to split the data based on the information gain. This process is called a split.\nWhen a split is performed, the model creates a new node with the selected feature. The model then selects the best split for the new node based on the information gain. This process of selecting the best split is called a partition.\nAfter the partition, the model repeats the process of growing another split from the new node. This process of growing another split is called a branch.\nThe decision tree is complete when all questions have been answered by the nodes.\nSOLUTION: The clue to this problem is that the decision tree is getting abnormally bad performance. This can be caused by overfitting.\nOverfitting occurs when a model is too complex and starts to fit the noise in the training data. For example, consider a simple decision tree that can fit the training data. The tree may have many branches and be highly complex. However, the performance of this decision tree on the test data will be poor. This overfitting occurs because the model is fitting the noise in the training data.\nThe solution to overfitting is to reduce the complexity of the model. This can be done by adding more trees to the model or by reducing the number of features."}
{"question": "K-fold cross-validation is", "choices": [{"label": "A", "text": "linear in K"}, {"label": "B", "text": "quadratic in K"}, {"label": "C", "text": "cubic in K"}, {"label": "D", "text": "exponential in K"}], "answerKey": "A", "model_answer": "LECTURE: In machine learning, cross-validation is a technique used to evaluate a model's performance. There are many ways to perform cross-validation, but one common approach is K-fold cross-validation.\nIn K-fold cross-validation, the data is split into K parts. The model is trained on K-1 parts of the data and validated on the remaining part. This process is repeated K times, each time using a different part of the data as the validation set. The validation scores from each fold are averaged to give a overall estimate of the model's performance.\nK-fold cross-validation is linear in K. As K grows, the number of times the data needs to be split increases. However, the work involved in splitting the data is linear in K, and so is the computation of the validation scores. Thus, K-fold cross-validation is linear in K."}
{"question": "Statement 1| Industrial-scale neural networks are normally trained on CPUs, not GPUs. Statement 2| The ResNet-50 model has over 1 billion parameters.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": ""}
{"question": "Given two Boolean random variables, A and B, where P(A) = 1/2, P(B) = 1/3, and P(A | \u00acB) = 1/4, what is P(A | B)?", "choices": [{"label": "A", "text": "1/6"}, {"label": "B", "text": "1/4"}, {"label": "C", "text": "3/4"}, {"label": "D", "text": "1"}], "answerKey": "D", "model_answer": "LECTURE: Conditional probability is the probability that two events will happen together.\nIf A and B are two events, then the conditional probability of A given B is written as P(A | B). P(A | B) gives you the probability that A will happen given that B has happened.\nThe formula for conditional probability is:\nP(A | B) = P(A and B) / P(B)\nIf you are given the probability that both A and B happened, P(A and B), then you can use this formula to calculate the probability that A happened given that B happened.\nIf you are given the probability that B happened, P(B), then you can use this formula to calculate the probability that A happened given that B happened.\nSOLUTION: You are given that P(A) = 1/2, P(B) = 1/3, and P(A | \u00acB) = 1/4.\nYou are asked to find P(A | B).\nFirst, calculate P(A and B):\nP(A and B) = P(A) + P(B) = 1/2 + 1/3 = 5/6.\nThen, calculate P(B | A):\nP(B | A) = P(B | A and B) / P(A and B) = 1/4 / 5/6 = 1/5.\nFinally, calculate P(A | B) using the conditional probability formula:\nP(A | B) = P(A and B) / P(B) = 5/6 / 1/3 = 5/2."}
{"question": "Existential risks posed by AI are most commonly associated with which of the following professors?", "choices": [{"label": "A", "text": "Nando de Frietas"}, {"label": "B", "text": "Yann LeCun"}, {"label": "C", "text": "Stuart Russell"}, {"label": "D", "text": "Jitendra Malik"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| Maximizing the likelihood of logistic regression model yields multiple local optimums. Statement 2| No classifier can do better than a naive Bayes classifier if the distribution of the data is known.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": ""}
{"question": "For Kernel Regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether kernel function is Gaussian versus triangular versus box-shaped"}, {"label": "B", "text": "Whether we use Euclidian versus L1 versus L\u221e metrics"}, {"label": "C", "text": "The kernel width"}, {"label": "D", "text": "The maximum height of the kernel function"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| The SVM learning algorithm is guaranteed to find the globally optimal hypothesis with respect to its object function. Statement 2| After being mapped into feature space Q through a radial basis kernel function, a Perceptron may be able to achieve better classification performance than in its original space (though we can\u2019t guarantee this).", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: When comparing two statements, look for the following terms:\nguaranteed | possible | worse | better\nThese terms make claims about the relationship between two things. A guarantee says that one thing will always hold true. Possible and worse say that something is true under certain conditions. Better says that something is true, but not necessarily all the time.\nStatements 1 and 2 use these terms.\nThe SVM learning algorithm is guaranteed to find the globally optimal hypothesis with respect to its object function.\nThis statement uses the term guaranteed. It says that SVM is always guaranteed to find the best solution.\nAfter being mapped into feature space Q through a radial basis kernel function, a Perceptron may be able to achieve better classification performance than in its original space (though we can\u2019t guarantee this).\nThis statement uses the terms possible and better. It says that a Perceptron might be able to achieve better performance, but it is not guaranteed."}
{"question": "For a Gaussian Bayes classifier, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether we learn the class centers by Maximum Likelihood or Gradient Descent"}, {"label": "B", "text": "Whether we assume full class covariance matrices or diagonal class covariance matrices"}, {"label": "C", "text": "Whether we have equal class priors or priors estimated from the data."}, {"label": "D", "text": "Whether we allow classes to have different mean vectors or we force them to share the same mean vector"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| Overfitting is more likely when the set of training data is small. Statement 2| Overfitting is more likely when the hypothesis space is small.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "D", "model_answer": ""}
{"question": "Statement 1| Besides EM, gradient descent can be used to perform inference or learning on Gaussian mixture model. Statement 2 | Assuming a fixed number of attributes, a Gaussian-based Bayes optimal classifier can be learned in time linear in the number of records in the dataset.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: When a graph is not given, you can often find the shortest path between two vertices by using a breadth-first search (BFS). The BFS visits all vertices at a given distance from the starting vertex.\nFor example, consider the following undirected graph with distance labels.\nThe BFS starts at the target vertex (5). It then visits the vertex at a distance of 1 (3). After that, it visits the vertex at a distance of 2 (4). Finally, it visits the vertex at a distance of 3 (2).\nThe shortest path from vertex 1 to vertex 5 is 3, 2, 4, 5.\nThere are two main algorithms for performing a BFS. One uses a queue. The other uses a stack.\nThe queue algorithm uses a queue data structure to hold the vertices that it has discovered but not yet visited. The queue is initially filled with the starting vertex. The BFS algorithm then removes one vertex from the queue for each step of the BFS.\nThe stack algorithm uses a stack data structure to hold the vertices that it has discovered but not yet visited. The stack is initially filled with the starting vertex. The BFS algorithm then removes one vertex from the stack for each step of the BFS.\nBoth algorithms use recursion to find the shortest path. The recursion begins with the starting vertex.\nThe vertex is added to the queue or stack. If the vertex is the target vertex, the shortest path has been found. Otherwise, the algorithm continues with the following step.\nThere are two possible steps. The algorithm can visit the vertex by removing it from the queue or stack. Or, the algorithm can visit a neighbor of the vertex by adding the neighbor to the queue or stack."}
{"question": "Statement 1| In a Bayesian network, the inference results of the junction tree algorithm are the same as the inference results of variable elimination. Statement 2| If two random variable X and Y are conditionally independent given another random variable Z, then in the corresponding Bayesian network, the nodes for X and Y are d-separated given Z.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": ""}
{"question": "Given a large dataset of medical records from patients suffering from heart disease, try to learn whether there might be different clusters of such patients for which we might tailor separate treatments. What kind of learning problem is this?", "choices": [{"label": "A", "text": "Supervised learning"}, {"label": "B", "text": "Unsupervised learning"}, {"label": "C", "text": "Both (a) and (b)"}, {"label": "D", "text": "Neither (a) nor (b)"}], "answerKey": "B", "model_answer": "LECTURE: Machine learning is the study of algorithms and models that can learn from data, without being explicitly programmed.\nA dataset is a collection of data. A dataset may be used to train a machine learning model, which can be used to make predictions on new data.\nA supervised learning model is trained on a dataset with labeled examples. A labeled example is an example with both input data and the desired output. The model learns to map input data to output data.\nA predictive model is a type of supervised learning model. A predictive model is trained on a dataset with labeled examples and is then used to make predictions on new, unlabeled data.\nAn unsupervised learning model is trained on a dataset with only input data. The model learns to identify patterns in the input data.\nAn analytical model is a type of unsupervised learning model. An analytical model is trained on a dataset with only input data and is then used to make predictions on new, unlabeled data.\nSOLUTION: The problem is an unsupervised learning problem. An unsupervised learning model is trained on a dataset with only input data.\nThe model does not have assigned outputs. It learns to identify patterns in the input data."}
{"question": "What would you do in PCA to get the same projection as SVD?", "choices": [{"label": "A", "text": "Transform data to zero mean"}, {"label": "B", "text": "Transform data to zero median"}, {"label": "C", "text": "Not possible"}, {"label": "D", "text": "None of these"}], "answerKey": "A", "model_answer": "LECTURE: Principal component analysis (PCA) and singular value decomposition (SVD) are similar in that they both use linear transformations to find patterns in data. They are also similar in that they both use the Singular Value Decomposition to perform the transformation.\nHowever, there are some important differences between PCA and SVD. One of the main differences is that PCA uses the covariance matrix of the data, while SVD uses the Singular Value Decomposition of the data. These two matrices are similar, but not identical.\nAnother difference is that PCA uses all of the principal components, while SVD uses only the most important singular values. This means that PCA transforms the data more completely than SVD.\nThe difference between the two transformations shows up when you project the data. The most important singular values are those that explain the most variance in the data. These singular values are equal to the largest eigenvalues of the covariance matrix. These eigenvalues can be computed from the covariance matrix, but they are not equal to the singular values.\nSo, to get the same projection as SVD, you should use the covariance matrix to perform PCA. This will ensure that you use all of the important singular values, and that you project the data in the same way as SVD."}
{"question": "Statement 1| The training error of 1-nearest neighbor classifier is 0. Statement 2| As the number of data points grows to infinity, the MAP estimate approaches the MLE estimate for all possible priors. In other words, given enough data, the choice of prior is irrelevant.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": "LECTURE: Statement 1 is true. The training error is the sum of the squared errors for all training points. Since the 1-nearest neighbor classifier always makes the same prediction, the training error is zero.\nStatement 2 is false. The MAP estimate is the maximum a posteriori estimate, and the MLE estimate is the maximum likelihood estimate. These two estimates are not the same, but they are equal when the prior is the same as the bayes estimate. So, as the number of data points grows to infinity, the MAP estimate approaches the MLE estimate for all possible priors. But this does not mean that the choice of prior is irrelevant."}
{"question": "When doing least-squares regression with regularisation (assuming that the optimisation can be done exactly), increasing the value of the regularisation parameter \u03bb the testing error.", "choices": [{"label": "A", "text": "will never decrease the training error."}, {"label": "B", "text": "will never increase the training error."}, {"label": "C", "text": "will never decrease the testing error."}, {"label": "D", "text": "will never increase"}], "answerKey": "A", "model_answer": ""}
{"question": "Which of the following best describes what discriminative approaches try to model? (w are the parameters in the model)", "choices": [{"label": "A", "text": "p(y|x, w)"}, {"label": "B", "text": "p(y, x)"}, {"label": "C", "text": "p(w|x, w)"}, {"label": "D", "text": "None of the above"}], "answerKey": "A", "model_answer": "LECTURE: People use discriminative approaches when they want to predict a target value for a given input. Dis discriminative approaches model the difference between pairs of input/target values.\nFor example, consider a classification problem where x is an input vector and y is a target vector. A discriminative approach tries to model the following:\np(y | x, w) = the probability that y when x.\nThis formula says that a discriminative approach tries to predict the probability that a certain target value y will occur, given a certain input value x and some parameters w.\nSOLUTION: The correct answer is A."}
{"question": "Statement 1| CIFAR-10 classification performance for convolution neural networks can exceed 95%. Statement 2| Ensembles of neural networks do not improve classification accuracy since the representations they learn are highly correlated.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following points would Bayesians and frequentists disagree on?", "choices": [{"label": "A", "text": "The use of a non-Gaussian noise model in probabilistic regression."}, {"label": "B", "text": "The use of probabilistic modelling for regression."}, {"label": "C", "text": "The use of prior distributions on the parameters in a probabilistic model."}, {"label": "D", "text": "The use of class priors in Gaussian Discriminant Analysis."}], "answerKey": "C", "model_answer": "LECTURE: Bayesian and frequentist approaches to statistics differ in their respective approaches to probability.\nA frequentist statistician views a probability as a measure of the long-run frequency of an event. A Bayesian statistician views a probability as a measure of the believer's subjective degree of belief in an event.\nBayesian and frequentist approaches to regression also differ. A frequentist approach uses maximum likelihood estimation. A Bayesian approach uses Bayesian estimation.\nIn Bayesian estimation, the probability of each value of the regression function is updated with the observation of each new data point. The prior probability is the initial probability assigned to each value of the function. The prior is updated with the observation of each data point to obtain a posterior probability. The posterior probability is the probability of each value of the function given all the observations.\nIn maximum likelihood estimation, the parameter value that maximizes the likelihood of the data is estimated. The likelihood of the data is the probability of the data given the parameter value.\nClass priors are priors that are assigned to a set of parameters. A class prior is a prior that is assigned to a class of parameters. A class prior is often used when there are a limited number of possible values for the parameter.\nGaussian Discriminant Analysis is a method of doing classification with multiple regression. It is based on probabilistic modelling.\nA Gaussian distribution is a distribution with a symmetrical curve. The curve is symmetrical about the average value of the distribution.\nA Gaussian distribution is a bell-shaped curve. The curve is shaped like a bell. The average value is the peak of the bell.\nA plot of a Gaussian distribution with a class prior is a Gaussian Mixture Model. A plot of a Gaussian Mixture Model with a class prior is a cloud of bell-shaped curves.\nThe proportion of the plots that is in the tails of the curves is the class prior. A larger proportion in the tails of the curves means that there is a larger prior probability that the observation is from that class."}
{"question": "Statement 1| The BLEU metric uses precision, while the ROGUE metric uses recall. Statement 2| Hidden markov models were frequently used to model English sentences.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: Metrics are measurements. Metrics can be used to evaluate the performance of a machine learning model.\nPrecision is a measurement of how accurate a model is. Precision considers the number of true positive predictions the model makes.\nA true positive prediction is a prediction that the model gets right.\nRecall is a measurement of how complete a model is. Recall considers the number of true positive predictions the model makes out of the total number of actual positive cases.\nA true positive prediction is a prediction that the model gets right.\nAn actual positive case is a case where the model is actually right.\nSOLUTION: Statement 1 is false. The BLEU metric uses recall, not precision.\nThe ROGUE metric uses precision, not recall.\nStatement 2 is false. Hidden markov models are used to model handwriting, not English sentences."}
{"question": "Statement 1| ImageNet has images of various resolutions. Statement 2| Caltech-101 has more images than ImageNet.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following is more appropriate to do feature selection?", "choices": [{"label": "A", "text": "Ridge"}, {"label": "B", "text": "Lasso"}, {"label": "C", "text": "both (a) and (b)"}, {"label": "D", "text": "neither (a) nor (b)"}], "answerKey": "B", "model_answer": ""}
{"question": "Suppose you are given an EM algorithm that finds maximum likelihood estimates for a model with latent variables. You are asked to modify the algorithm so that it finds MAP estimates instead. Which step or steps do you need to modify?", "choices": [{"label": "A", "text": "Expectation"}, {"label": "B", "text": "Maximization"}, {"label": "C", "text": "No modification necessary"}, {"label": "D", "text": "Both"}], "answerKey": "B", "model_answer": "LECTURE: The Expectation-Maximization (EM) algorithm is a powerful tool for estimating the maximum likelihood estimates of the parameters of a model. The EM algorithm is based on iteratively performing two steps: the expectation step (E-step) and the maximization step (M-step).\nIn the E-step, the algorithm uses the current estimate of the parameter to calculate the expected value of the latent variables.\nIn the M-step, the algorithm uses the expected value of the latent variables to calculate the new estimate of the parameter.\nBoth steps are necessary for the EM algorithm to converge to the maximum likelihood estimates.\nSOLUTION: To modify the EM algorithm to find the maximum a posteriori (MAP) estimates, you need to modify the M-step. The M-step uses the expected value of the latent variables to calculate the new estimate of the parameter. To find the MAP estimates, you need to use the maximum value of the latent variables instead."}
{"question": "For a Gaussian Bayes classifier, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:", "choices": [{"label": "A", "text": "Whether we learn the class centers by Maximum Likelihood or Gradient Descent"}, {"label": "B", "text": "Whether we assume full class covariance matrices or diagonal class covariance matrices"}, {"label": "C", "text": "Whether we have equal class priors or priors estimated from the data"}, {"label": "D", "text": "Whether we allow classes to have different mean vectors or we force them to share the same mean vector"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| For any two variables x and y having joint distribution p(x, y), we always have H[x, y] \u2265 H[x] + H[y] where H is entropy function. Statement 2| For some directed graphs, moralization decreases the number of edges present in the graph.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following is NOT supervised learning?", "choices": [{"label": "A", "text": "PCA"}, {"label": "B", "text": "Decision Tree"}, {"label": "C", "text": "Linear Regression"}, {"label": "D", "text": "Naive Bayesian"}], "answerKey": "A", "model_answer": "LECTURE: Supervised learning is a type of machine learning. It involves training an algorithm on a labeled dataset.\nThe algorithm uses the data to learn the relationship between the features and the target. It can then use this relationship to make predictions on new, unseen data.\nSOLUTION: PCA is not supervised learning.\nPrincipal component analysis is a technique used to reduce the dimensionality of a dataset. It is a type of unsupervised learning.\nDecision Tree, Linear Regression, and Naive Bayesian are all supervised learning."}
{"question": "Statement 1| A neural network's convergence depends on the learning rate. Statement 2| Dropout multiplies randomly chosen activation values by zero.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": ""}
{"question": "Which one of the following is equal to P(A, B, C) given Boolean random variables A, B and C, and no independence or conditional independence assumptions between any of them?", "choices": [{"label": "A", "text": "P(A | B) * P(B | C) * P(C | A)"}, {"label": "B", "text": "P(C | A, B) * P(A) * P(B)"}, {"label": "C", "text": "P(A, B | C) * P(C)"}, {"label": "D", "text": "P(A | B, C) * P(B | A, C) * P(C | A, B)"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following tasks can be best solved using Clustering.", "choices": [{"label": "A", "text": "Predicting the amount of rainfall based on various cues"}, {"label": "B", "text": "Detecting fraudulent credit card transactions"}, {"label": "C", "text": "Training a robot to solve a maze"}, {"label": "D", "text": "All of the above"}], "answerKey": "B", "model_answer": ""}
{"question": "After applying a regularization penalty in linear regression, you find that some of the coefficients of w are zeroed out. Which of the following penalties might have been used?", "choices": [{"label": "A", "text": "L0 norm"}, {"label": "B", "text": "L1 norm"}, {"label": "C", "text": "L2 norm"}, {"label": "D", "text": "either (a) or (b)"}], "answerKey": "D", "model_answer": ""}
{"question": "A and B are two events. If P(A, B) decreases while P(A) increases, which of the following is true?", "choices": [{"label": "A", "text": "P(A|B) decreases"}, {"label": "B", "text": "P(B|A) decreases"}, {"label": "C", "text": "P(B) decreases"}, {"label": "D", "text": "All of above"}], "answerKey": "B", "model_answer": ""}
{"question": "Statement 1| When learning an HMM for a fixed set of observations, assume we do not know the true number of hidden states (which is often the case), we can always increase the training data likelihood by permitting more hidden states. Statement 2| Collaborative filtering is often a useful model for modeling users' movie preference.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: A hidden Markov model is a probabilistic model that is used to analyze sequences of observable events. In a hidden Markov model, there are assumed to be underlying unobservable events that are connected by observable events. The underlying events are called hidden states. The observable events are called observable symbols.\nFor example, consider a hidden Markov model for handwriting recognition. In this model, there are assumed to be underlying unobservable strokes that are connected by observable symbols. The observable symbols could be the positions of the pen on a piece of paper.\nThe hidden states are not directly observable. Instead, the observable symbols are used to infer the current hidden state.\nA variable-length sequence of observable symbols is used to infer the current hidden state. The first observable symbol in the sequence is the most informative. The second observable symbol is the most informative of the remaining observable symbols, and so on.\nCollaborative filtering is a method of making predictions about what a user will like or not like. For example, a recommendation system could use collaborative filtering to suggest movies that a user is likely to rate highly.\nThere are two types of collaborative filtering:\nUser-user collaborative filtering: This involves predicting a user's preference for an item by analyzing the preferences of other users.\nItem-item collaborative filtering: This involves predicting a user's preference for an item by analyzing the preferences of other users who have liked similar items."}
{"question": "You are training a linear regression model for a simple estimation task, and notice that the model is overfitting to the data. You decide to add in $\\ell_2$ regularization to penalize the weights. As you increase the $\\ell_2$ regularization coefficient, what will happen to the bias and variance of the model?", "choices": [{"label": "A", "text": "Bias increase ; Variance increase"}, {"label": "B", "text": "Bias increase ; Variance decrease"}, {"label": "C", "text": "Bias decrease ; Variance increase"}, {"label": "D", "text": "Bias decrease ; Variance decrease"}], "answerKey": "B", "model_answer": ""}
{"question": "Which PyTorch 1.8 command(s) produce $10\\times 5$ Gaussian matrix with each entry i.i.d. sampled from $\\mathcal{N}(\\mu=5,\\sigma^2=16)$ and a $10\\times 10$ uniform matrix with each entry i.i.d. sampled from $U[-1,1)$?", "choices": [{"label": "A", "text": "\\texttt{5 + torch.randn(10,5) * 16} ; \\texttt{torch.rand(10,10,low=-1,high=1)}"}, {"label": "B", "text": "\\texttt{5 + torch.randn(10,5) * 16} ; \\texttt{(torch.rand(10,10) - 0.5) / 0.5}"}, {"label": "C", "text": "\\texttt{5 + torch.randn(10,5) * 4} ; \\texttt{2 * torch.rand(10,10) - 1}"}, {"label": "D", "text": "\\texttt{torch.normal(torch.ones(10,5)*5,torch.ones(5,5)*16)} ; \\texttt{2 * torch.rand(10,10) - 1}"}], "answerKey": "C", "model_answer": ""}
{"question": "Statement 1| The ReLU's gradient is zero for $x<0$, and the sigmoid gradient $\\sigma(x)(1-\\sigma(x))\\le \\frac{1}{4}$ for all $x$. Statement 2| The sigmoid has a continuous gradient and the ReLU has a discontinuous gradient.", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "A", "model_answer": "LECTURE: A graph is a set of vertices and a set of edges that connect pairs of vertices.\nAn edge may connect any two vertices. An edge may not connect two vertices.\nA simple graph is a graph with no edges.\nA complete graph is a graph with edges between all pairs of vertices.\nA regular graph is a graph in which each vertex has the same degree.\nThe degree of a vertex is the number of edges that connect to it.\nA graph with an even number of vertices is always simple.\nA graph with an even number of vertices is always regular.\nSOLUTION: The ReLU has a discontinuous gradient. The sigmoid has a continuous gradient.\nThe ReLU's gradient is zero for x<0, and the sigmoid gradient \u03c3(x)(1\u2212\u03c3(x))\u226414 for all x.\nSo, the statement 1 is true, and the statement 2 is true."}
{"question": "Which is true about Batch Normalization?", "choices": [{"label": "A", "text": "After applying batch normalization, the layer\u2019s activations will follow a standard Gaussian distribution."}, {"label": "B", "text": "The bias parameter of affine layers becomes redundant if a batch normalization layer follows immediately afterward."}, {"label": "C", "text": "The standard weight initialization must be changed when using Batch Normalization."}, {"label": "D", "text": "Batch Normalization is equivalent to Layer Normalization for convolutional neural networks."}], "answerKey": "B", "model_answer": "LECTURE: During training, the parameters of a neural network adjust to minimize the difference between the network's predictions and the true outputs. This process is called learning.\nOne way to make learning more stable is by normalizing the inputs to a layer. This is called batch normalization.\nBatch normalization applies a transformation to the inputs of a layer so that the inputs are more normally distributed. This makes the computation of the layer more stable.\nWhen a layer has a batch normalization layer in its predecessor layers, the batch normalization layer will normalize the inputs by transforming them to have a mean of 0 and a standard deviation of 1.\nThe batch normalization layer does not change the distribution of the inputs. It only changes their scale.\nThere are several ways to define the batch normalization layer. One way is to scale the inputs by the square root of the average of the squared inputs, plus a Constant. This is called batch normalization.\nAnother way to define batch normalization is to add a bias parameter to the layer. The bias parameter is learned during training. This is called batch normalization with a bias parameter.\nSOLUTION: After applying batch normalization, the layer\u2019s activations will follow a standard Gaussian distribution.\nThe batch normalization layer transforms the inputs to have a mean of 0 and a standard deviation of 1. For a Gaussian distribution, the standard deviation is the square root of the variance. So, the activations of a layer will follow a standard Gaussian distribution.\nThe bias parameter of affine layers becomes redundant if a batch normalization layer follows immediately afterward.\nIf a batch normalization layer follows an affine layer, the batch normalization layer will be used to normalize the inputs to the affine layer. In this case, the bias parameter of the affine layer is not used.\nThe standard weight initialization must be changed when using Batch Normalization.\nThe standard weight initialization is used when a layer has no predecessor layers. When a layer has one or more predecessor layers that are batch normalization layers, the standard weight initialization is not used. Instead, the initialization is:\nbias = 0\nfor j in range(num_successors):\nx = random values with mean 0 and variance 1\nw = standard deviation of x\nbias = 0\nfor j in range(num_successors):\nx = random values with mean 0 and variance 1\nw = standard deviation of x"}
{"question": "Suppose we have the following objective function: $\\argmin_{w} \\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\gamma \\norm{w}^2_2$ What is the gradient of $\\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\lambda \\norm{w}^2_2$ with respect to $w$?", "choices": [{"label": "A", "text": "$\\nabla_w f(w) = (X^\\top X + \\lambda I)w - X^\\top y + \\lambda w$"}, {"label": "B", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + \\lambda$"}, {"label": "C", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + \\lambda w$"}, {"label": "D", "text": "$\\nabla_w f(w) = X^\\top X w - X^\\top y + (\\lambda+1) w$"}], "answerKey": "C", "model_answer": ""}
{"question": "Which of the following is true of a convolution kernel?", "choices": [{"label": "A", "text": "Convolving an image with $\\begin{bmatrix}1 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$ would not change the image"}, {"label": "B", "text": "Convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ would not change the image"}, {"label": "C", "text": "Convolving an image with $\\begin{bmatrix}1 & 1 & 1\\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}$ would not change the image"}, {"label": "D", "text": "Convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ would not change the image"}], "answerKey": "B", "model_answer": ""}
{"question": "Which of the following is false?", "choices": [{"label": "A", "text": "Semantic segmentation models predict the class of each pixel, while multiclass image classifiers predict the class of entire image."}, {"label": "B", "text": "A bounding box with an IoU (intersection over union) equal to $96\\%$ would likely be considered at true positive."}, {"label": "C", "text": "When a predicted bounding box does not correspond to any object in the scene, it is considered a false positive."}, {"label": "D", "text": "A bounding box with an IoU (intersection over union) equal to $3\\%$ would likely be considered at false negative."}], "answerKey": "D", "model_answer": ""}
{"question": "Which of the following is false?", "choices": [{"label": "A", "text": "The following fully connected network without activation functions is linear: $g_3(g_2(g_1(x)))$, where $g_i(x) = W_i x$ and $W_i$ are matrices."}, {"label": "B", "text": "Leaky ReLU $\\max\\{0.01x,x\\}$ is convex."}, {"label": "C", "text": "A combination of ReLUs such as $ReLU(x) - ReLU(x-1)$ is convex."}, {"label": "D", "text": "The loss $\\log \\sigma(x)= -\\log(1+e^{-x})$ is concave"}], "answerKey": "C", "model_answer": ""}
{"question": "We are training fully connected network with two hidden layers to predict housing prices. Inputs are $100$-dimensional, and have several features such as the number of square feet, the median family income, etc. The first hidden layer has $1000$ activations. The second hidden layer has $10$ activations. The output is a scalar representing the house price. Assuming a vanilla network with affine transformations and with no batch normalization and no learnable parameters in the activation function, how many parameters does this network have?", "choices": [{"label": "A", "text": "111021"}, {"label": "B", "text": "110010"}, {"label": "C", "text": "111110"}, {"label": "D", "text": "110011"}], "answerKey": "A", "model_answer": "LECTURE: A fully connected network with two hidden layers has two sets of weights: one set for the input layer to the first hidden layer, and one set for the first hidden layer to the second hidden layer. Each weight is a scalar, and each has a matching bias.\nSo, the network has two sets of learnable parameters: the input layer to the first hidden layer weights and the first hidden layer to the second hidden layer weights.\nThere are 100 input features, and each has a corresponding weight and bias. So, the input layer to the first hidden layer has 100 learnable parameters.\nThe first hidden layer has 1000 activations, and each activation has a corresponding weight and bias. So, the first hidden layer to the second hidden layer has 1000 learnable parameters.\nThere are a total of 10 activations in the second hidden layer. So, the second hidden layer has 10 learnable parameters.\nThe output layer has 1 learnable parameter.\nSo, the network has a total of 110021 learnable parameters."}
{"question": "Statement 1| The derivative of the sigmoid $\\sigma(x)=(1+e^{-x})^{-1}$ with respect to $x$ is equal to $\\text{Var}(B)$ where $B\\sim \\text{Bern}(\\sigma(x))$ is a Bernoulli random variable. Statement 2| Setting the bias parameters in each layer of neural network to 0 changes the bias-variance trade-off such that the model's variance increases and the model's bias decreases", "choices": [{"label": "A", "text": "True, True"}, {"label": "B", "text": "False, False"}, {"label": "C", "text": "True, False"}, {"label": "D", "text": "False, True"}], "answerKey": "C", "model_answer": ""}
